{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Equation Focused Primary Method.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "283cbe6ab06b412db76afa28befc7108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_880c799500cf4c87a5ef2f280063319c",
              "IPY_MODEL_b395ea1f579343fe91ce25a0500bd176",
              "IPY_MODEL_d8f428480d954bd08f52002ec0581e9b"
            ],
            "layout": "IPY_MODEL_4973d3725d924cf490fee39420e6c7cd"
          }
        },
        "880c799500cf4c87a5ef2f280063319c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47ee91b8da254d7098b1c055b8e2a565",
            "placeholder": "​",
            "style": "IPY_MODEL_c32c8cc7b43440918bd0c89aed11a3e8",
            "value": "Downloading: 100%"
          }
        },
        "b395ea1f579343fe91ce25a0500bd176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8a375b66e7e4436994e09444bdb003f",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09621c0c703b4414bb29da92c63688e4",
            "value": 213450
          }
        },
        "d8f428480d954bd08f52002ec0581e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10647349a4394c08a89e6b5a9155ea81",
            "placeholder": "​",
            "style": "IPY_MODEL_b84ba112dc574252be365fdfc5c1fc11",
            "value": " 208k/208k [00:00&lt;00:00, 806kB/s]"
          }
        },
        "4973d3725d924cf490fee39420e6c7cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47ee91b8da254d7098b1c055b8e2a565": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c32c8cc7b43440918bd0c89aed11a3e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8a375b66e7e4436994e09444bdb003f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09621c0c703b4414bb29da92c63688e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10647349a4394c08a89e6b5a9155ea81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b84ba112dc574252be365fdfc5c1fc11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ad56382b3e64f9480ea737cbd162871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24f6c3d92c6347cf991276f727b82dee",
              "IPY_MODEL_1a4f65424b8b44019b20bb6937f46494",
              "IPY_MODEL_ec0d973546134e5a9cb30012587b9ccd"
            ],
            "layout": "IPY_MODEL_8a456990f8ae4c5d9b9e355689eef90d"
          }
        },
        "24f6c3d92c6347cf991276f727b82dee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17fab71ecb894fbc92ce1a79efbe9864",
            "placeholder": "​",
            "style": "IPY_MODEL_0db06db025b648cc80b5e807d4ac2663",
            "value": "Downloading: 100%"
          }
        },
        "1a4f65424b8b44019b20bb6937f46494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_181bced3d92f46328e0152ec34a2b388",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b04106a115154f0bad0ab8adcf3ba61a",
            "value": 29
          }
        },
        "ec0d973546134e5a9cb30012587b9ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee314572c426446ca2964e8fe92be904",
            "placeholder": "​",
            "style": "IPY_MODEL_e46f1507b3d643388ff766fc5a59c3c4",
            "value": " 29.0/29.0 [00:00&lt;00:00, 1.39kB/s]"
          }
        },
        "8a456990f8ae4c5d9b9e355689eef90d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17fab71ecb894fbc92ce1a79efbe9864": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0db06db025b648cc80b5e807d4ac2663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "181bced3d92f46328e0152ec34a2b388": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b04106a115154f0bad0ab8adcf3ba61a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee314572c426446ca2964e8fe92be904": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e46f1507b3d643388ff766fc5a59c3c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bcefe34172546c8a646f33d0f3a899e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac6094a7d6f24032a4928e689108d384",
              "IPY_MODEL_ef7774d9dd1f48cf908948e0cad11531",
              "IPY_MODEL_011abd78cf754e9c9e33fad839f05f29"
            ],
            "layout": "IPY_MODEL_2735f9cb23f5453d962c1de6ef1cde03"
          }
        },
        "ac6094a7d6f24032a4928e689108d384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b338cd5450bb43e3b207b7190e23a4db",
            "placeholder": "​",
            "style": "IPY_MODEL_94734c1131004ddd963a4f36b700266a",
            "value": "Downloading: 100%"
          }
        },
        "ef7774d9dd1f48cf908948e0cad11531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b568f327a56f44f38c9b6b949157f71d",
            "max": 411,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9383d4ccff4b4c07873407127e07c2dc",
            "value": 411
          }
        },
        "011abd78cf754e9c9e33fad839f05f29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f63d53bf0bc5411a8fe81dd40a175caa",
            "placeholder": "​",
            "style": "IPY_MODEL_57a7e20e3df243c098ebf2c2682e03c0",
            "value": " 411/411 [00:00&lt;00:00, 8.81kB/s]"
          }
        },
        "2735f9cb23f5453d962c1de6ef1cde03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b338cd5450bb43e3b207b7190e23a4db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94734c1131004ddd963a4f36b700266a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b568f327a56f44f38c9b6b949157f71d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9383d4ccff4b4c07873407127e07c2dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f63d53bf0bc5411a8fe81dd40a175caa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57a7e20e3df243c098ebf2c2682e03c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66e18dab2bb44ad1a9ea59b20f664a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35e46a037969497eb8aba4a22becc1ec",
              "IPY_MODEL_abac3779f6e74b2eab2c144dfbb92761",
              "IPY_MODEL_f1374fe3620b463881e8fa00a5c46c1b"
            ],
            "layout": "IPY_MODEL_1aae53ef80e94364b2c481dd788389d7"
          }
        },
        "35e46a037969497eb8aba4a22becc1ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_435f9f6bb1854368aa2fdb2811c481a7",
            "placeholder": "​",
            "style": "IPY_MODEL_64b344b04d0f499c9009278a4fea02e3",
            "value": "Downloading: 100%"
          }
        },
        "abac3779f6e74b2eab2c144dfbb92761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da624ba024f94418ae290e1bb100e072",
            "max": 263273408,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2eff09af05054817948b3a20c03b9c1e",
            "value": 263273408
          }
        },
        "f1374fe3620b463881e8fa00a5c46c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc506fcf6091473cb41aec0357705076",
            "placeholder": "​",
            "style": "IPY_MODEL_6a14de693f6346b58c2705efec783e3d",
            "value": " 251M/251M [00:04&lt;00:00, 65.7MB/s]"
          }
        },
        "1aae53ef80e94364b2c481dd788389d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "435f9f6bb1854368aa2fdb2811c481a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64b344b04d0f499c9009278a4fea02e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da624ba024f94418ae290e1bb100e072": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eff09af05054817948b3a20c03b9c1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc506fcf6091473cb41aec0357705076": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a14de693f6346b58c2705efec783e3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhwagle/code-match/blob/main/Equation_Focused_Primary_Method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82i_Cc08zWK3"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing codegen. Their install_env.sh won't work for colab so modifying such that all conda imports are done with pip"
      ],
      "metadata": {
        "id": "Lq8FKDVXwgxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%pip install transformers pylatexenc"
      ],
      "metadata": {
        "id": "YzjVFdEo5rwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import transformers\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "from pylatexenc.latex2text import LatexNodes2Text"
      ],
      "metadata": {
        "id": "ZXwX4tnk4xlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUL_IFxeA3L7",
        "outputId": "63e0d488-87ca-4c9a-c358-bada02bb049c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/gdrive/MyDrive/RSS/Data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-dGMK1NA3R8",
        "outputId": "5420ca50-45b8-4b44-b264-b5a77f1a17ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "algorithms.csv\tcode.csv\t  code-small.csv  func-rep-small.csv\n",
            "code-all.csv\tcode-func-rep.pt  equations.csv   func-rep-small.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eqns = pd.read_csv(\"/content/gdrive/MyDrive/RSS/Data/equations.csv\")\n",
        "algs = pd.read_csv(\"/content/gdrive/MyDrive/RSS/Data/algorithms.csv\")\n",
        "code = pd.read_csv(\"/content/gdrive/MyDrive/RSS/Data/code.csv\")"
      ],
      "metadata": {
        "id": "UQe_7U9zmPKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gkM5fw6ASbCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing methods for reading in latex"
      ],
      "metadata": {
        "id": "a6WSS85agxc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_class = transformers.DistilBertModel \n",
        "tokenizer_class = transformers.DistilBertTokenizer\n",
        "weights = 'distilbert-base-cased'\n",
        "\n",
        "tokenizer = tokenizer_class.from_pretrained(weights)\n",
        "model = model_class.from_pretrained(weights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218,
          "referenced_widgets": [
            "283cbe6ab06b412db76afa28befc7108",
            "880c799500cf4c87a5ef2f280063319c",
            "b395ea1f579343fe91ce25a0500bd176",
            "d8f428480d954bd08f52002ec0581e9b",
            "4973d3725d924cf490fee39420e6c7cd",
            "47ee91b8da254d7098b1c055b8e2a565",
            "c32c8cc7b43440918bd0c89aed11a3e8",
            "c8a375b66e7e4436994e09444bdb003f",
            "09621c0c703b4414bb29da92c63688e4",
            "10647349a4394c08a89e6b5a9155ea81",
            "b84ba112dc574252be365fdfc5c1fc11",
            "7ad56382b3e64f9480ea737cbd162871",
            "24f6c3d92c6347cf991276f727b82dee",
            "1a4f65424b8b44019b20bb6937f46494",
            "ec0d973546134e5a9cb30012587b9ccd",
            "8a456990f8ae4c5d9b9e355689eef90d",
            "17fab71ecb894fbc92ce1a79efbe9864",
            "0db06db025b648cc80b5e807d4ac2663",
            "181bced3d92f46328e0152ec34a2b388",
            "b04106a115154f0bad0ab8adcf3ba61a",
            "ee314572c426446ca2964e8fe92be904",
            "e46f1507b3d643388ff766fc5a59c3c4",
            "4bcefe34172546c8a646f33d0f3a899e",
            "ac6094a7d6f24032a4928e689108d384",
            "ef7774d9dd1f48cf908948e0cad11531",
            "011abd78cf754e9c9e33fad839f05f29",
            "2735f9cb23f5453d962c1de6ef1cde03",
            "b338cd5450bb43e3b207b7190e23a4db",
            "94734c1131004ddd963a4f36b700266a",
            "b568f327a56f44f38c9b6b949157f71d",
            "9383d4ccff4b4c07873407127e07c2dc",
            "f63d53bf0bc5411a8fe81dd40a175caa",
            "57a7e20e3df243c098ebf2c2682e03c0",
            "66e18dab2bb44ad1a9ea59b20f664a0d",
            "35e46a037969497eb8aba4a22becc1ec",
            "abac3779f6e74b2eab2c144dfbb92761",
            "f1374fe3620b463881e8fa00a5c46c1b",
            "1aae53ef80e94364b2c481dd788389d7",
            "435f9f6bb1854368aa2fdb2811c481a7",
            "64b344b04d0f499c9009278a4fea02e3",
            "da624ba024f94418ae290e1bb100e072",
            "2eff09af05054817948b3a20c03b9c1e",
            "fc506fcf6091473cb41aec0357705076",
            "6a14de693f6346b58c2705efec783e3d"
          ]
        },
        "id": "9RN3BbnwhWfK",
        "outputId": "4a694c4f-95d0-4bc6-ff8b-3e1070cbf80e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "283cbe6ab06b412db76afa28befc7108"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ad56382b3e64f9480ea737cbd162871"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/411 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bcefe34172546c8a646f33d0f3a899e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/251M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66e18dab2bb44ad1a9ea59b20f664a0d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eqn_index = random.randint(0,10000)\n",
        "#bellman:\n",
        "# eqn_index = 3210\n",
        "\n",
        "\n",
        "print(f\"Example of equation index number {eqn_index}\")\n",
        "\n",
        "latex = eqns.iloc[eqn_index].eqn\n",
        "print(\"\")\n",
        "print(\"======\")\n",
        "print(\"Multistep\")\n",
        "print(\"======\")\n",
        "print(\"Raw latex below:\")\n",
        "print(\"\")\n",
        "print(latex)\n",
        "print(\"Converted Unicode below:\")\n",
        "uni_rep = LatexNodes2Text().latex_to_text(latex)\n",
        "print(uni_rep)\n",
        "print(\"Tokenization below:\")\n",
        "print(\"\")\n",
        "print(tokenizer(uni_rep,padding=\"max_length\",truncation=True))\n",
        "print(\"\")\n",
        "print(\"Inverted Tokenization\")\n",
        "print(\"\")\n",
        "print(tokenizer.decode(tokenizer(uni_rep)['input_ids']))\n",
        "\n",
        "print(\"======\")\n",
        "print(\"Single step\")\n",
        "print(\"======\")\n",
        "print(\"Inverted Tokenization\")\n",
        "print(\"\")\n",
        "print(tokenizer.decode(tokenizer(latex)['input_ids']))"
      ],
      "metadata": {
        "id": "vGiDynIxAh9w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "193d0970-122d-482b-d045-f4d57925374a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example of equation index number 2311\n",
            "\n",
            "======\n",
            "Multistep\n",
            "======\n",
            "Raw latex below:\n",
            "\n",
            "\\label{eq:alifZ}\n",
            "            z^t_j = H\\left(v_j^t - v_\\text{th} - \\beta a^t_j\\right)\n",
            "            \n",
            "Converted Unicode below:\n",
            "\n",
            "            z^t_j = H(v_j^t - v_th - βa^t_j)\n",
            "            \n",
            "Tokenization below:\n",
            "\n",
            "{'input_ids': [101, 195, 167, 189, 168, 179, 134, 145, 113, 191, 168, 179, 167, 189, 118, 191, 168, 24438, 118, 419, 1161, 167, 189, 168, 179, 114, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "\n",
            "Inverted Tokenization\n",
            "\n",
            "[CLS] z ^ t _ j = H ( v _ j ^ t - v _ th - βa ^ t _ j ) [SEP]\n",
            "======\n",
            "Single step\n",
            "======\n",
            "Inverted Tokenization\n",
            "\n",
            "[CLS] \\ label { eq : alifZ } z ^ t _ j = H \\ left ( v _ j ^ t - v _ \\ text { th } - \\ beta a ^ t _ j \\ right ) [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Appears to be how to work with tokenized latex..."
      ],
      "metadata": {
        "id": "NRWqBHfNsUL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model(**tokenizer(latex,return_tensors='pt',padding='max_length',truncation=True))[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JQtdoWxk8JN",
        "outputId": "47fb0b2b-1ba4-427f-9a34-1d22c944cdfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = tokenizer(latex,return_tensors='pt',padding='max_length',truncation=True)\n",
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzfqXM8IoHr9",
        "outputId": "f25242bc-3f9e-4546-d3f3-178270353740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,   165,  3107,   196,   174,  4426,   131,  2393,  8914,  5301,\n",
              "           198,   195,   167,   189,   168,   179,   134,   145,   165,  1286,\n",
              "           113,   191,   168,   179,   167,   189,   118,   191,   168,   165,\n",
              "          3087,   196, 24438,   198,   118,   165, 11933,   170,   167,   189,\n",
              "           168,   179,   165,  1268,   114,   102,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls gdrive/MyDrive/RSS/Data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzLHThU1Ci3n",
        "outputId": "d95f116a-4f9c-43ef-fc31-8e57539f5f5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "algorithms.csv\tcode.csv\t  code-small.csv  func-rep-small.csv\n",
            "code-all.csv\tcode-func-rep.pt  equations.csv   func-rep-small.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "func_rep_df = pd.read_pickle('gdrive/MyDrive/RSS/Data/code-func-rep.pt')"
      ],
      "metadata": {
        "id": "GFgpn_f9C1-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "func_rep_df = func_rep_df[func_rep_df.functions.apply(len) != 0]\n",
        "func_rep_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "MmYp0Fo8Jgh6",
        "outputId": "633f023d-6d3b-453e-eefc-1f5b1eddc094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               id                                          functions  \\\n",
              "0      1811.02182  [def main ( config ) : NEW_LINE INDENT from da...   \n",
              "1      1811.02182  [def check_config_used ( config , target_sourc...   \n",
              "2      1811.02182  [def __init__ ( self , batch_size , paired = F...   \n",
              "3      1811.02182  [def weights_init ( m ) : NEW_LINE INDENT clas...   \n",
              "4      1811.02182  [def weights_init ( m ) : NEW_LINE INDENT clas...   \n",
              "...           ...                                                ...   \n",
              "29193  2112.01073  [def my_lcs ( string , sub ) : NEW_LINE INDENT...   \n",
              "29194  2112.01073  [def __init__ ( self , n = 4 ) : NEW_LINE INDE...   \n",
              "29195  2112.01073  [def precook ( s , n = 4 , out = False ) : NEW...   \n",
              "29197  2112.01073  [def __init__ ( self ) : NEW_LINE INDENT self ...   \n",
              "29199  2112.01073  [def tokenize ( self , captions_for_image ) : ...   \n",
              "\n",
              "                                         representations  \n",
              "0      [[[tensor(0.6232), tensor(-0.2805), tensor(0.3...  \n",
              "1      [[[tensor(0.6108), tensor(-0.2560), tensor(0.1...  \n",
              "2      [[[tensor(0.8430), tensor(0.1034), tensor(0.30...  \n",
              "3      [[[tensor(0.6790), tensor(-0.0221), tensor(0.1...  \n",
              "4      [[[tensor(0.6790), tensor(-0.0221), tensor(0.1...  \n",
              "...                                                  ...  \n",
              "29193  [[[tensor(0.6292), tensor(0.0059), tensor(0.09...  \n",
              "29194  [[[tensor(0.4932), tensor(-0.1197), tensor(-0....  \n",
              "29195  [[[tensor(0.7558), tensor(-0.0280), tensor(0.0...  \n",
              "29197  [[[tensor(0.7251), tensor(-0.0360), tensor(0.0...  \n",
              "29199  [[[tensor(0.8905), tensor(-0.4485), tensor(0.2...  \n",
              "\n",
              "[23814 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b07cdf32-8108-4c2f-9291-d40f5623bebf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>functions</th>\n",
              "      <th>representations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1811.02182</td>\n",
              "      <td>[def main ( config ) : NEW_LINE INDENT from da...</td>\n",
              "      <td>[[[tensor(0.6232), tensor(-0.2805), tensor(0.3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1811.02182</td>\n",
              "      <td>[def check_config_used ( config , target_sourc...</td>\n",
              "      <td>[[[tensor(0.6108), tensor(-0.2560), tensor(0.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1811.02182</td>\n",
              "      <td>[def __init__ ( self , batch_size , paired = F...</td>\n",
              "      <td>[[[tensor(0.8430), tensor(0.1034), tensor(0.30...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1811.02182</td>\n",
              "      <td>[def weights_init ( m ) : NEW_LINE INDENT clas...</td>\n",
              "      <td>[[[tensor(0.6790), tensor(-0.0221), tensor(0.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1811.02182</td>\n",
              "      <td>[def weights_init ( m ) : NEW_LINE INDENT clas...</td>\n",
              "      <td>[[[tensor(0.6790), tensor(-0.0221), tensor(0.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29193</th>\n",
              "      <td>2112.01073</td>\n",
              "      <td>[def my_lcs ( string , sub ) : NEW_LINE INDENT...</td>\n",
              "      <td>[[[tensor(0.6292), tensor(0.0059), tensor(0.09...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29194</th>\n",
              "      <td>2112.01073</td>\n",
              "      <td>[def __init__ ( self , n = 4 ) : NEW_LINE INDE...</td>\n",
              "      <td>[[[tensor(0.4932), tensor(-0.1197), tensor(-0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29195</th>\n",
              "      <td>2112.01073</td>\n",
              "      <td>[def precook ( s , n = 4 , out = False ) : NEW...</td>\n",
              "      <td>[[[tensor(0.7558), tensor(-0.0280), tensor(0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29197</th>\n",
              "      <td>2112.01073</td>\n",
              "      <td>[def __init__ ( self ) : NEW_LINE INDENT self ...</td>\n",
              "      <td>[[[tensor(0.7251), tensor(-0.0360), tensor(0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29199</th>\n",
              "      <td>2112.01073</td>\n",
              "      <td>[def tokenize ( self , captions_for_image ) : ...</td>\n",
              "      <td>[[[tensor(0.8905), tensor(-0.4485), tensor(0.2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>23814 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b07cdf32-8108-4c2f-9291-d40f5623bebf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b07cdf32-8108-4c2f-9291-d40f5623bebf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b07cdf32-8108-4c2f-9291-d40f5623bebf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eqns['id'] = eqns.id.astype(str)\n",
        "func_rep_df['id'] = func_rep_df['id'].astype(str)\n",
        "collected_func_reps = func_rep_df.groupby(by='id').sum()"
      ],
      "metadata": {
        "id": "ujFld01NTNx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gbWd5VBeT74V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demofuncs = collected_func_reps[collected_func_reps.index=='1811.02182']\n",
        "demofuncs.functions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1P73AE7lXZpK",
        "outputId": "5e54d55d-ea9d-4644-bc88-e90844bbe0c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "1811.02182    [def main ( config ) : NEW_LINE INDENT from da...\n",
              "Name: functions, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demofuncs.functions[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woNBKrDPYgGl",
        "outputId": "2ab4ec53-39ed-4d81-d6ee-b4e9e4bce0a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"def main ( config ) : NEW_LINE INDENT from data_loader import DataLoader NEW_LINE if ( config . trainer == ' minimize _ DCE ' ) : NEW_LINE INDENT from trainer_DCE import Trainer NEW_LINE paired = True NEW_LINE DEDENT elif ( config . trainer == ' acoustic _ supervision ' ) : NEW_LINE INDENT from trainer_acoustic import Trainer NEW_LINE paired = False NEW_LINE DEDENT elif ( config . trainer == ' AAS ' ) : NEW_LINE INDENT from trainer_AAS import Trainer NEW_LINE paired = False NEW_LINE DEDENT elif ( config . trainer == ' FSEGAN ' ) : NEW_LINE INDENT from trainer_FSEGAN import Trainer NEW_LINE paired = True NEW_LINE DEDENT if config . gpu >= 0 : NEW_LINE INDENT torch . cuda . manual_seed ( config . random_seed ) NEW_LINE torch . cuda . set_device ( config . gpu ) NEW_LINE DEDENT if ( config . DB_name == ' librispeech ' ) : NEW_LINE INDENT if ( paired ) : NEW_LINE INDENT config . tr_ny_manifest = ' data / libri _ tr _ ny _ paired . csv ' NEW_LINE config . trsub_manifest = ' data / libri _ trsub _ ny _ paired . csv ' NEW_LINE config . val_manifest = ' data / libri _ val _ paired . csv ' NEW_LINE DEDENT else : NEW_LINE INDENT config . tr_ny_manifest = ' data / libri _ tr _ ny . csv ' NEW_LINE config . trsub_manifest = ' data / libri _ trsub _ ny . csv ' NEW_LINE config . val_manifest = ' data / libri _ val . csv ' NEW_LINE DEDENT config . tr_cl_manifest = ' data / libri _ tr _ cl . csv ' NEW_LINE DEDENT elif ( config . DB_name == ' chime ' ) : NEW_LINE INDENT if ( paired ) : NEW_LINE INDENT config . tr_ny_manifest = ' data / chime _ ' + config . simul_real + ' _ tr _ ny _ paired . csv ' NEW_LINE config . trsub_manifest = ' data / chime _ ' + config . simul_real + ' _ trsub _ ny _ paired . csv ' NEW_LINE config . val_manifest = ' data / chime _ real _ val _ paired . csv ' NEW_LINE confnig . val2_manifest = ' data / chime _ simul _ val _ paired . csv ' NEW_LINE DEDENT else : NEW_LINE INDENT config . tr_ny_manifest = ' data / chime _ ' + config . simul_real + ' _ tr _ ny . csv ' NEW_LINE config . trsub_manifest = ' data / chime _ ' + config . simul_real + ' _ trsub _ ny . csv ' NEW_LINE config . val_manifest = ' data / chime _ real _ val . csv ' NEW_LINE confnig . val2_manifest = ' data / chime _ simul _ val . csv ' NEW_LINE DEDENT config . tr_cl_manifest = ' data / chime _ tr _ org . csv ' NEW_LINE DEDENT with open ( config . labels_path ) as label_file : NEW_LINE INDENT labels = str ( ' ' . join ( json . load ( label_file ) ) ) NEW_LINE DEDENT data_loader = DataLoader ( batch_size = config . batch_size , paired = paired , tr_cl_manifest = config . tr_cl_manifest , tr_ny_manifest = config . tr_ny_manifest , trsub_manifest = config . trsub_manifest , val_manifest = config . val_manifest , val2_manifest = config . val2_manifest , labels = labels ) NEW_LINE if not os . path . exists ( ' logs / ' + str ( config . expnum ) ) : NEW_LINE INDENT os . makedirs ( ' logs / ' + str ( config . expnum ) ) NEW_LINE DEDENT trainer = Trainer ( config , data_loader ) NEW_LINE torch . manual_seed ( config . random_seed ) NEW_LINE if ( config . mode == ' train ' ) : NEW_LINE INDENT trainer . train ( ) NEW_LINE DEDENT elif ( config . mode == ' test ' ) : NEW_LINE INDENT trainer . test ( ) NEW_LINE DEDENT elif ( config . mode == ' visualize ' ) : NEW_LINE INDENT trainer . visualize ( ) NEW_LINE DEDENT DEDENT\",\n",
              " \"def check_config_used ( config , target_source ) : NEW_LINE INDENT config_count = dict ( vars ( config ) ) NEW_LINE for k in config_count . keys ( ) : NEW_LINE INDENT config_count [ k ] = 0 NEW_LINE DEDENT for source in target_source : NEW_LINE INDENT fp = open ( source , ' r ' ) NEW_LINE text = fp . read ( ) NEW_LINE for k in config_count . keys ( ) : NEW_LINE INDENT if ( text . find ( k ) >= 0 ) : NEW_LINE INDENT config_count [ k ] = 1 NEW_LINE DEDENT DEDENT fp . close ( ) NEW_LINE DEDENT config_unused = [ ] NEW_LINE for k in config_count . keys ( ) : NEW_LINE INDENT if ( config_count [ k ] == 0 ) : NEW_LINE INDENT config_unused . append ( k ) NEW_LINE DEDENT DEDENT print ( ' unused ▁ config ▁ = ▁ ' ) NEW_LINE print ( config_unused ) NEW_LINE assert ( len ( config_unused ) == 0 ) , ' unused ▁ config ▁ exists , ▁ please ▁ properly ▁ use ▁ it ▁ or ▁ comment ▁ it ' NEW_LINE DEDENT\",\n",
              " 'def to_np ( x ) : NEW_LINE INDENT return x . data . cpu ( ) . numpy ( ) NEW_LINE DEDENT',\n",
              " \"def get_weight_statistic ( M ) : NEW_LINE INDENT print ( ' Model ▁ parameter ▁ statistic ' ) NEW_LINE modules = list ( M . modules ( ) ) [ 0 ] . _modules NEW_LINE for k , v in modules . items ( ) : NEW_LINE INDENT if ( len ( v . state_dict ( ) ) > 2 ) : NEW_LINE INDENT for l in range ( len ( v ) ) : NEW_LINE INDENT layer = v [ l ] NEW_LINE if ( hasattr ( layer , ' module ' ) ) : NEW_LINE INDENT layer_m = layer . module NEW_LINE for j in range ( len ( layer_m ) ) : NEW_LINE INDENT sublayer = layer_m [ j ] NEW_LINE if ( hasattr ( sublayer , ' bias ' ) ) : NEW_LINE INDENT if ( sublayer . bias is not None ) : NEW_LINE INDENT print ( str ( sublayer ) + ' ▁ : ▁ weight ▁ = ▁ ' + str ( sublayer . weight . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( sublayer . weight . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( sublayer . weight . data . mean ( ) ) ) [ : 7 ] + ' ) ' ' , ▁ bias ▁ = ▁ ' + str ( sublayer . bias . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( sublayer . bias . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( sublayer . bias . data . mean ( ) ) ) [ : 7 ] + ' ) ' ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( str ( sublayer ) + ' ▁ : ▁ weight ▁ = ▁ ' + str ( sublayer . weight . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( sublayer . weight . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( sublayer . weight . data . mean ( ) ) ) [ : 7 ] + ' ) ' ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT print ( str ( sublayer ) + ' ▁ : ▁ weight ▁ = ▁ ' + str ( sublayer . weight . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( sublayer . weight . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( sublayer . weight . data . mean ( ) ) ) [ : 7 ] + ' ) ' ) NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT if ( hasattr ( layer , ' weight ' ) ) : NEW_LINE INDENT if ( hasattr ( layer , ' bias ' ) ) : NEW_LINE INDENT if ( hasattr ( layer . bias , ' data ' ) ) : NEW_LINE INDENT print ( str ( layer ) + ' ▁ : ▁ weight ▁ = ▁ ' + str ( layer . weight . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( layer . weight . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( layer . weight . data . mean ( ) ) ) [ : 7 ] + ' ) ' ' , ▁ bias ▁ = ▁ ' + str ( layer . bias . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( layer . bias . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( layer . bias . data . mean ( ) ) ) [ : 7 ] + ' ) ' ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT print ( str ( layer ) + ' ▁ : ▁ weight ▁ = ▁ ' + str ( layer . weight . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( layer . weight . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( layer . weight . data . mean ( ) ) ) [ : 7 ] + ' ) ' ) NEW_LINE DEDENT DEDENT if ( hasattr ( layer , ' rnn ' ) ) : NEW_LINE INDENT rnn_layer = layer . rnn NEW_LINE print ( str ( rnn_layer ) ) NEW_LINE print ( ' \\\\tweight _ hh _ l0 ▁ = ▁ ' + str ( rnn_layer . weight_hh_l0 . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( rnn_layer . weight_hh_l0 . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( rnn_layer . weight_hh_l0 . data . mean ( ) ) ) [ : 7 ] + ' ) ' ) NEW_LINE print ( ' \\\\tweight _ hh _ l0 _ reverse ▁ = ▁ ' + str ( rnn_layer . weight_hh_l0_reverse . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( rnn_layer . weight_hh_l0_reverse . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( rnn_layer . weight_hh_l0_reverse . data . mean ( ) ) ) [ : 7 ] + ' ) ' ) NEW_LINE print ( ' \\\\tweight _ ih _ l0 ▁ = ▁ ' + str ( rnn_layer . weight_ih_l0 . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( rnn_layer . weight_ih_l0 . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( rnn_layer . weight_ih_l0 . data . mean ( ) ) ) [ : 7 ] + ' ) ' ) NEW_LINE print ( ' \\\\tweight _ hh _ l0 _ reverse ▁ = ▁ ' + str ( rnn_layer . weight_hh_l0_reverse . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( rnn_layer . weight_hh_l0_reverse . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( rnn_layer . weight_hh_l0_reverse . data . mean ( ) ) ) [ : 7 ] + ' ) ' ) NEW_LINE DEDENT if ( hasattr ( layer , ' batch _ norm ' ) ) : NEW_LINE INDENT if ( layer . batch_norm ) : NEW_LINE INDENT bn_layer = layer . batch_norm . module NEW_LINE print ( str ( bn_layer ) + ' ▁ : ▁ weight ▁ = ▁ ' + str ( bn_layer . weight . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( bn_layer . weight . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( bn_layer . weight . data . mean ( ) ) ) [ : 7 ] + ' ) , ▁ bias ▁ = ▁ ' + str ( bn_layer . bias . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( bn_layer . bias . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( bn_layer . bias . data . mean ( ) ) ) [ : 7 ] + ' ) ' ) NEW_LINE DEDENT DEDENT DEDENT DEDENT DEDENT else : NEW_LINE INDENT if ( hasattr ( v , ' weight ' ) ) : NEW_LINE INDENT if ( hasattr ( v , ' bias ' ) ) : NEW_LINE INDENT print ( k + ' ▁ : ▁ weight ▁ = ▁ ' + str ( v . weight . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( v . weight . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( v . weight . data . mean ( ) ) ) [ : 7 ] + ' ) ' ' , ▁ bias ▁ = ▁ ' + str ( v . bias . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( v . bias . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( v . bias . data . mean ( ) ) ) [ : 7 ] + ' ) ' ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( k + ' ▁ : ▁ weight ▁ = ▁ ' + str ( v . weight . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( v . weight . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( v . weight . data . mean ( ) ) ) [ : 7 ] + ' ) ' ) NEW_LINE DEDENT DEDENT DEDENT print ( ' ▁ ' ) NEW_LINE print ( ' ▁ ' ) NEW_LINE DEDENT DEDENT\",\n",
              " \"def weights_init ( m ) : NEW_LINE INDENT classname = m . __class__ . __name__ NEW_LINE if classname . find ( ' Conv ' ) != - 1 and classname . find ( ' ConvResidualBlock ' ) == - 1 : NEW_LINE INDENT m . weight . data . normal_ ( 0.0 , 0.1 ) NEW_LINE if hasattr ( m , ' bias ' ) : NEW_LINE INDENT if ( hasattr ( m . bias , ' data ' ) ) : NEW_LINE INDENT m . bias . data . fill_ ( 0 ) NEW_LINE DEDENT DEDENT DEDENT elif classname . find ( ' BatchNorm ' ) != - 1 : NEW_LINE INDENT m . weight . data . normal_ ( 1.0 , 0.01 ) NEW_LINE m . bias . data . fill_ ( 0 ) NEW_LINE DEDENT elif classname . find ( ' Embedding ' ) != - 1 : NEW_LINE INDENT m . weight . data . normal_ ( 0.0 , 0.01 ) NEW_LINE DEDENT DEDENT\",\n",
              " 'def _get_variable ( inputs , cuda = True ) : NEW_LINE INDENT if ( cuda ) : NEW_LINE INDENT out = Variable ( inputs . cuda ( ) ) NEW_LINE DEDENT else : NEW_LINE INDENT out = Variable ( inputs ) NEW_LINE DEDENT return out NEW_LINE DEDENT',\n",
              " 'def _get_variable_volatile ( inputs , cuda = True ) : NEW_LINE INDENT if ( cuda ) : NEW_LINE INDENT out = Variable ( inputs . cuda ( ) , volatile = True ) NEW_LINE DEDENT else : NEW_LINE INDENT out = Variable ( inputs , volatile = True ) NEW_LINE DEDENT return out NEW_LINE DEDENT',\n",
              " 'def _get_variable_nograd ( inputs , cuda = True ) : NEW_LINE INDENT if ( cuda ) : NEW_LINE INDENT out = Variable ( inputs . cuda ( ) , requires_grad = False ) NEW_LINE DEDENT else : NEW_LINE INDENT out = Variable ( inputs , requires_grad = False ) NEW_LINE DEDENT return out NEW_LINE DEDENT',\n",
              " 'def __init__ ( self ) : NEW_LINE INDENT self . reset ( ) NEW_LINE DEDENT',\n",
              " 'def reset ( self ) : NEW_LINE INDENT self . val = 0 NEW_LINE self . avg = 0 NEW_LINE self . sum = 0 NEW_LINE self . count = 0 NEW_LINE DEDENT',\n",
              " 'def update ( self , val , n = 1 ) : NEW_LINE INDENT self . val = val NEW_LINE self . sum += val * n NEW_LINE self . count += n NEW_LINE self . avg = self . sum / self . count NEW_LINE DEDENT',\n",
              " 'def __init__ ( self , batch_size , paired = False , tr_cl_manifest = \" \" , tr_ny_manifest = \" \" , trsub_manifest = \" \" , val_manifest = \" \" , val2_manifest = \" \" , labels = None ) : NEW_LINE INDENT self . batch_size = batch_size NEW_LINE self . labels = labels NEW_LINE if ( paired ) : NEW_LINE INDENT self . Loader = FeatLoader_paired NEW_LINE DEDENT else : NEW_LINE INDENT self . Loader = FeatLoader NEW_LINE DEDENT if ( len ( tr_cl_manifest ) > 0 ) : NEW_LINE INDENT self . tr_cl_ds = FeatDataset ( manifest = tr_cl_manifest , labels = labels ) NEW_LINE self . tr_cl_sp = FeatSampler ( self . tr_cl_ds , batch_size = batch_size ) NEW_LINE self . tr_cl_dl = iter ( self . Loader ( self . tr_cl_ds , num_workers = 1 , batch_sampler = self . tr_cl_sp ) ) NEW_LINE DEDENT if ( len ( tr_ny_manifest ) > 0 ) : NEW_LINE INDENT self . tr_ny_ds = FeatDataset ( manifest = tr_ny_manifest , labels = labels ) NEW_LINE self . tr_ny_sp = FeatSampler ( self . tr_ny_ds , batch_size = batch_size ) NEW_LINE self . tr_ny_dl = iter ( self . Loader ( self . tr_ny_ds , num_workers = 1 , batch_sampler = self . tr_ny_sp ) ) NEW_LINE DEDENT if ( len ( trsub_manifest ) > 0 ) : NEW_LINE INDENT self . trsub_ds = FeatDataset ( manifest = trsub_manifest , labels = labels ) NEW_LINE self . trsub_dl = iter ( self . Loader ( self . trsub_ds , batch_size = batch_size ) ) NEW_LINE DEDENT if ( len ( val_manifest ) > 0 ) : NEW_LINE INDENT self . val_ds = FeatDataset ( manifest = val_manifest , labels = labels ) NEW_LINE self . val_dl = iter ( self . Loader ( self . val_ds , batch_size = batch_size ) ) NEW_LINE DEDENT if ( len ( val2_manifest ) > 0 ) : NEW_LINE INDENT self . val2_ds = FeatDataset ( manifest = val2_manifest , labels = labels ) NEW_LINE self . val2_dl = iter ( self . Loader ( self . val2_ds , batch_size = batch_size ) ) NEW_LINE DEDENT DEDENT',\n",
              " \"def next ( self , cl_ny = ' ' , type = ' ' ) : NEW_LINE INDENT if ( cl_ny == ' ny ' ) : NEW_LINE INDENT if ( type == ' train ' ) : NEW_LINE INDENT loader = self . tr_ny_dl NEW_LINE DEDENT elif ( type == ' trsub ' ) : NEW_LINE INDENT loader = self . trsub_dl NEW_LINE DEDENT elif ( type == ' val ' ) : NEW_LINE INDENT loader = self . val_dl NEW_LINE DEDENT elif ( type == ' val2' ) : NEW_LINE INDENT loader = self . val2_dl NEW_LINE DEDENT DEDENT elif ( cl_ny == ' cl ' ) : NEW_LINE INDENT if ( type == ' train ' ) : NEW_LINE INDENT loader = self . tr_cl_dl NEW_LINE DEDENT DEDENT try : NEW_LINE INDENT data_list = loader . next ( ) NEW_LINE DEDENT except StopIteration : NEW_LINE INDENT if ( cl_ny == ' ny ' ) : NEW_LINE INDENT if ( type == ' train ' ) : NEW_LINE INDENT self . tr_ny_sp . shuffle ( ) NEW_LINE self . tr_ny_dl = iter ( self . Loader ( self . tr_ny_ds , num_workers = 1 , batch_sampler = self . tr_ny_sp ) ) NEW_LINE loader = self . tr_ny_dl NEW_LINE DEDENT elif ( type == ' trsub ' ) : NEW_LINE INDENT self . trsub_dl = iter ( self . Loader ( self . trsub_ds , batch_size = self . batch_size , num_workers = 1 ) ) NEW_LINE loader = self . trsub_dl NEW_LINE DEDENT elif ( type == ' val ' ) : NEW_LINE INDENT self . val_dl = iter ( self . Loader ( self . val_ds , batch_size = self . batch_size , num_workers = 1 ) ) NEW_LINE loader = self . val_dl NEW_LINE DEDENT elif ( type == ' val2' ) : NEW_LINE INDENT self . val2_dl = iter ( self . Loader ( self . val2_ds , batch_size = self . batch_size , num_workers = 1 ) ) NEW_LINE loader = self . val2_dl NEW_LINE loader = self . te_dl NEW_LINE DEDENT DEDENT elif ( cl_ny == ' cl ' ) : NEW_LINE INDENT if ( type == ' train ' ) : NEW_LINE INDENT self . tr_cl_sp . shuffle ( ) NEW_LINE self . tr_cl_dl = iter ( self . Loader ( self . tr_cl_ds , num_workers = 1 , batch_sampler = self . tr_cl_sp ) ) NEW_LINE loader = self . tr_cl_dl NEW_LINE DEDENT DEDENT data_list = loader . next ( ) NEW_LINE DEDENT return data_list NEW_LINE DEDENT\",\n",
              " \"def weights_init ( m ) : NEW_LINE INDENT classname = m . __class__ . __name__ NEW_LINE if classname . find ( ' Conv ' ) != - 1 : NEW_LINE INDENT m . weight . data . normal_ ( 0.0 , 0.01 ) NEW_LINE DEDENT elif classname . find ( ' BatchNorm ' ) != - 1 : NEW_LINE INDENT m . weight . data . normal_ ( 1.0 , 0.01 ) NEW_LINE m . bias . data . fill_ ( 0 ) NEW_LINE DEDENT elif classname . find ( ' Embedding ' ) != - 1 : NEW_LINE INDENT m . weight . data . normal_ ( 0.0 , 0.01 ) NEW_LINE DEDENT DEDENT\",\n",
              " \"def __init__ ( self , config , data_loader = None ) : NEW_LINE INDENT self . config = config NEW_LINE self . data_loader = data_loader NEW_LINE self . lr = config . lr NEW_LINE self . beta1 = config . beta1 NEW_LINE self . beta2 = config . beta2 NEW_LINE self . optimizer = config . optimizer NEW_LINE self . batch_size = config . batch_size NEW_LINE self . diffLoss = L1Loss_mask ( ) NEW_LINE self . valmin_iter = 0 NEW_LINE self . model_dir = ' logs / ' + str ( config . expnum ) NEW_LINE self . savename_G = ' ' NEW_LINE self . decoder = GreedyDecoder ( data_loader . labels ) NEW_LINE self . kt = 0 NEW_LINE self . lb = 0.001 NEW_LINE self . conv_measure = 0 NEW_LINE self . dce_tr = AverageMeter ( ) NEW_LINE self . dce_val = AverageMeter ( ) NEW_LINE self . wer_tr = AverageMeter ( ) NEW_LINE self . cer_tr = AverageMeter ( ) NEW_LINE self . wer_val = AverageMeter ( ) NEW_LINE self . cer_val = AverageMeter ( ) NEW_LINE self . build_model ( ) NEW_LINE self . G . loss_stop = 100000 NEW_LINE if self . config . gpu >= 0 : NEW_LINE INDENT self . G . cuda ( ) NEW_LINE self . ASR . cuda ( ) NEW_LINE DEDENT if len ( self . config . load_path ) > 0 : NEW_LINE INDENT self . load_model ( ) NEW_LINE DEDENT if config . mode == ' train ' : NEW_LINE INDENT self . logFile = open ( self . model_dir + ' / log . txt ' , ' w ' ) NEW_LINE DEDENT DEDENT\",\n",
              " 'def zero_grad_all ( self ) : NEW_LINE INDENT self . G . zero_grad ( ) NEW_LINE DEDENT',\n",
              " \"def build_model ( self ) : NEW_LINE INDENT print ( ' initialize ▁ enhancement ▁ model ' ) NEW_LINE self . G = stackedBRNN ( I = self . config . nFeat , H = self . config . rnn_size , L = self . config . rnn_layers , rnn_type = supported_rnns [ self . config . rnn_type ] ) NEW_LINE print ( ' load ▁ pre - trained ▁ ASR ▁ model ' ) NEW_LINE package_ASR = torch . load ( self . config . ASR_path , map_location = lambda storage , loc : storage ) NEW_LINE self . ASR = DeepSpeech . load_model_package ( package_ASR ) NEW_LINE DEDENT\",\n",
              " 'def load_model ( self ) : NEW_LINE INDENT print ( \" [ * ] ▁ Load ▁ models ▁ from ▁ { } . . . \" . format ( self . load_path ) ) NEW_LINE postfix = \\' _ valmin \\' NEW_LINE paths = glob ( os . path . join ( self . load_path , \\' G { } * . pth \\' . format ( postfix ) ) ) NEW_LINE paths . sort ( ) NEW_LINE if len ( paths ) == 0 : NEW_LINE INDENT print ( \" [ ! ] ▁ No ▁ checkpoint ▁ found ▁ in ▁ { } . . . \" . format ( self . load_path ) ) NEW_LINE assert ( 0 ) , \\' checkpoint ▁ not ▁ avilable \\' NEW_LINE DEDENT idxes = [ int ( os . path . basename ( path . split ( \\' . \\' ) [ 0 ] . split ( \\' _ \\' ) [ - 1 ] ) ) for path in paths ] NEW_LINE if self . config . start_iter < 0 : NEW_LINE INDENT self . config . start_iter = max ( idxes ) NEW_LINE if ( self . config . start_iter < 0 ) : NEW_LINE INDENT raise Exception ( \" start ▁ iter ▁ is ▁ still ▁ less ▁ than ▁ 0 ▁ - - > ▁ probably ▁ try ▁ to ▁ load ▁ initial ▁ random ▁ model \" ) NEW_LINE DEDENT DEDENT if self . config . gpu < 0 : NEW_LINE INDENT map_location = lambda storage , loc : storage NEW_LINE DEDENT else : NEW_LINE INDENT map_location = None NEW_LINE DEDENT print ( \\' Load ▁ models ▁ from ▁ \\' + self . load_path + \\' , ▁ ITERATION ▁ = ▁ \\' + str ( self . config . start_iter ) ) NEW_LINE self . G . load_state_dict ( torch . load ( \\' { } / G { } _ { } . pth \\' . format ( self . load_path [ : - 1 ] , postfix , self . config . start_iter ) , map_location = map_location ) ) NEW_LINE print ( \" [ * ] ▁ Model ▁ loaded \" ) NEW_LINE DEDENT',\n",
              " 'def train ( self ) : NEW_LINE INDENT optimizer_g = torch . optim . Adam ( self . G . parameters ( ) , lr = self . config . lr , betas = ( self . beta1 , self . beta2 ) , amsgrad = True ) NEW_LINE for iter in trange ( self . config . start_iter , self . config . max_iter ) : NEW_LINE INDENT data_list = self . data_loader . next ( cl_ny = \\' ny \\' , type = \\' train \\' ) NEW_LINE inputs , cleans , mask = _get_variable_nograd ( data_list [ 0 ] ) , _get_variable_nograd ( data_list [ 1 ] ) , _get_variable_nograd ( data_list [ 2 ] ) NEW_LINE outputs = self . G ( inputs ) NEW_LINE dce , nElement = self . diffLoss ( outputs , cleans , mask ) NEW_LINE self . zero_grad_all ( ) NEW_LINE dce . backward ( ) NEW_LINE optimizer_g . step ( ) NEW_LINE if ( iter + 1 ) % self . config . log_iter == 0 : NEW_LINE INDENT str_loss = \" [ { } / { } ] ▁ ( train ) ▁ DCE : ▁ { : . 7f } \" . format ( iter , self . config . max_iter , dce . data [ 0 ] ) NEW_LINE print ( str_loss ) NEW_LINE self . logFile . write ( str_loss + \\' \\\\n \\' ) NEW_LINE self . logFile . flush ( ) NEW_LINE DEDENT if ( iter + 1 ) % self . config . save_iter == 0 : NEW_LINE INDENT self . G . eval ( ) NEW_LINE self . dce_tr . reset ( ) NEW_LINE self . wer_tr . reset ( ) NEW_LINE self . cer_tr . reset ( ) NEW_LINE for _ in trange ( 0 , len ( self . data_loader . trsub_dl ) ) : NEW_LINE INDENT data_list = self . data_loader . next ( cl_ny = \\' ny \\' , type = \\' trsub \\' ) NEW_LINE inputs , cleans , mask , targets , input_percentages , target_sizes = _get_variable_volatile ( data_list [ 0 ] ) , _get_variable_volatile ( data_list [ 1 ] ) , _get_variable_volatile ( data_list [ 2 ] ) , data_list [ 3 ] , data_list [ 4 ] , data_list [ 5 ] NEW_LINE outputs = self . G ( inputs ) NEW_LINE dce , nElement = self . diffLoss ( outputs , cleans , mask ) NEW_LINE self . dce_tr . update ( dce . data [ 0 ] , nElement ) NEW_LINE wer , cer , nWord , nChar = self . greedy_decoding ( inputs , targets , input_percentages , target_sizes ) NEW_LINE self . wer_tr . update ( wer , nWord ) NEW_LINE self . cer_tr . update ( cer , nChar ) NEW_LINE DEDENT str_loss = \" [ { } / { } ] ▁ ( training ▁ subset ) ▁ DCE : ▁ { : . 7f } \" . format ( iter , self . config . max_iter , self . dce_tr . avg ) NEW_LINE print ( str_loss ) NEW_LINE self . logFile . write ( str_loss + \\' \\\\n \\' ) NEW_LINE str_loss = \" [ { } / { } ] ▁ ( training ▁ subset ) ▁ WER : ▁ { : . 7f } , ▁ CER : ▁ { : . 7f } \" . format ( iter , self . config . max_iter , self . wer_tr . avg * 100 , self . cer_tr . avg * 100 ) NEW_LINE print ( str_loss ) NEW_LINE self . logFile . write ( str_loss + \\' \\\\n \\' ) NEW_LINE self . dce_val . reset ( ) NEW_LINE self . wer_val . reset ( ) NEW_LINE self . cer_val . reset ( ) NEW_LINE for _ in trange ( 0 , len ( self . data_loader . val_dl ) ) : NEW_LINE INDENT data_list = self . data_loader . next ( cl_ny = \\' ny \\' , type = \\' val \\' ) NEW_LINE inputs , cleans , mask , targets , input_percentages , target_sizes = _get_variable_volatile ( data_list [ 0 ] ) , _get_variable_volatile ( data_list [ 1 ] ) , _get_variable_volatile ( data_list [ 2 ] ) , data_list [ 3 ] , data_list [ 4 ] , data_list [ 5 ] NEW_LINE outputs = self . G ( inputs ) NEW_LINE dce , nElement = self . diffLoss ( outputs , cleans , mask ) NEW_LINE self . dce_val . update ( dce . data [ 0 ] , nElement ) NEW_LINE wer , cer , nWord , nChar = self . greedy_decoding ( inputs , targets , input_percentages , target_sizes ) NEW_LINE self . wer_val . update ( wer , nWord ) NEW_LINE self . cer_val . update ( cer , nChar ) NEW_LINE DEDENT str_loss = \" [ { } / { } ] ▁ ( validation ) ▁ DCE : ▁ { : . 7f } \" . format ( iter , self . config . max_iter , self . dce_val . avg ) NEW_LINE print ( str_loss ) NEW_LINE self . logFile . write ( str_loss + \\' \\\\n \\' ) NEW_LINE str_loss = \" [ { } / { } ] ▁ ( validation ) ▁ WER : ▁ { : . 7f } , ▁ CER : ▁ { : . 7f } \" . format ( iter , self . config . max_iter , self . wer_val . avg * 100 , self . cer_val . avg * 100 ) NEW_LINE print ( str_loss ) NEW_LINE self . logFile . write ( str_loss + \\' \\\\n \\' ) NEW_LINE self . G . train ( ) NEW_LINE self . logFile . flush ( ) NEW_LINE if ( len ( self . savename_G ) > 0 ) : NEW_LINE INDENT if os . path . exists ( self . savename_G ) : NEW_LINE INDENT os . remove ( self . savename_G ) NEW_LINE DEDENT DEDENT self . savename_G = \\' { } / G _ { } . pth \\' . format ( self . model_dir , iter ) NEW_LINE torch . save ( self . G . state_dict ( ) , self . savename_G ) NEW_LINE if ( self . G . loss_stop > self . wer_val . avg ) : NEW_LINE INDENT self . G . loss_stop = self . wer_val . avg NEW_LINE savename_G_valmin_prev = \\' { } / G _ valmin _ { } . pth \\' . format ( self . model_dir , self . valmin_iter ) NEW_LINE if os . path . exists ( savename_G_valmin_prev ) : NEW_LINE INDENT os . remove ( savename_G_valmin_prev ) NEW_LINE DEDENT print ( \\' save ▁ model ▁ for ▁ this ▁ checkpoint \\' ) NEW_LINE savename_G_valmin = \\' { } / G _ valmin _ { } . pth \\' . format ( self . model_dir , iter ) NEW_LINE copyfile ( self . savename_G , savename_G_valmin ) NEW_LINE self . valmin_iter = iter NEW_LINE DEDENT DEDENT DEDENT DEDENT',\n",
              " \"def greedy_decoding ( self , inputs , targets , input_percentages , target_sizes , transcript_prob = 0.001 ) : NEW_LINE INDENT split_targets = [ ] NEW_LINE offset = 0 NEW_LINE for size in target_sizes : NEW_LINE INDENT split_targets . append ( targets [ offset : offset + size ] ) NEW_LINE offset += size NEW_LINE DEDENT enhanced = self . G ( inputs ) NEW_LINE prob = self . ASR ( enhanced ) NEW_LINE prob = prob . transpose ( 0 , 1 ) NEW_LINE T = prob . size ( 0 ) NEW_LINE sizes = input_percentages . mul_ ( int ( T ) ) . int ( ) NEW_LINE decoded_output , _ = self . decoder . decode ( prob . data , sizes ) NEW_LINE target_strings = self . decoder . convert_to_strings ( split_targets ) NEW_LINE we , ce , total_word , total_char = 0 , 0 , 0 , 0 NEW_LINE for x in range ( len ( target_strings ) ) : NEW_LINE INDENT decoding , reference = decoded_output [ x ] [ 0 ] , target_strings [ x ] [ 0 ] NEW_LINE nChar = len ( reference ) NEW_LINE nWord = len ( reference . split ( ) ) NEW_LINE we_i = self . decoder . wer ( decoding , reference ) NEW_LINE ce_i = self . decoder . cer ( decoding , reference ) NEW_LINE we += we_i NEW_LINE ce += ce_i NEW_LINE total_word += nWord NEW_LINE total_char += nChar NEW_LINE if ( random . uniform ( 0 , 1 ) < transcript_prob ) : NEW_LINE INDENT print ( ' reference ▁ = ▁ ' + reference ) NEW_LINE print ( ' decoding ▁ = ▁ ' + decoding ) NEW_LINE print ( ' wer ▁ = ▁ ' + str ( we_i / float ( nWord ) ) + ' , ▁ cer ▁ = ▁ ' + str ( ce_i / float ( nChar ) ) ) NEW_LINE DEDENT DEDENT wer = we / total_word NEW_LINE cer = ce / total_word NEW_LINE return wer , cer , total_word , total_char NEW_LINE DEDENT\",\n",
              " \"def weights_init ( m ) : NEW_LINE INDENT classname = m . __class__ . __name__ NEW_LINE if classname . find ( ' Conv ' ) != - 1 : NEW_LINE INDENT m . weight . data . normal_ ( 0.0 , 0.01 ) NEW_LINE DEDENT elif classname . find ( ' BatchNorm ' ) != - 1 : NEW_LINE INDENT m . weight . data . normal_ ( 1.0 , 0.01 ) NEW_LINE m . bias . data . fill_ ( 0 ) NEW_LINE DEDENT elif classname . find ( ' Embedding ' ) != - 1 : NEW_LINE INDENT m . weight . data . normal_ ( 0.0 , 0.01 ) NEW_LINE DEDENT DEDENT\",\n",
              " \"def __init__ ( self , config , data_loader = None ) : NEW_LINE INDENT self . config = config NEW_LINE self . data_loader = data_loader NEW_LINE self . lr = config . lr NEW_LINE self . beta1 = config . beta1 NEW_LINE self . beta2 = config . beta2 NEW_LINE self . optimizer = config . optimizer NEW_LINE self . batch_size = config . batch_size NEW_LINE self . diffLoss = L1Loss_mask ( ) NEW_LINE self . valmin_iter = 0 NEW_LINE self . model_dir = ' logs / ' + str ( config . expnum ) NEW_LINE self . savename_G = ' ' NEW_LINE self . savename_D = ' ' NEW_LINE self . savename_ASR = ' ' NEW_LINE self . kt = 0 NEW_LINE self . lb = self . config . lambda_k NEW_LINE self . gamma = self . config . gamma NEW_LINE self . conv_measure = 0 NEW_LINE self . ctc_tr = AverageMeter ( ) NEW_LINE self . ctc_tr_local = AverageMeter ( ) NEW_LINE self . ctc_val = AverageMeter ( ) NEW_LINE self . adv_ny_tr = AverageMeter ( ) NEW_LINE self . adv_ny_val = AverageMeter ( ) NEW_LINE self . wer_tr = AverageMeter ( ) NEW_LINE self . wer_val = AverageMeter ( ) NEW_LINE self . cer_tr = AverageMeter ( ) NEW_LINE self . cer_val = AverageMeter ( ) NEW_LINE self . CTCLoss = CTCLoss ( ) NEW_LINE self . decoder = GreedyDecoder ( data_loader . labels ) NEW_LINE self . build_model ( ) NEW_LINE self . G . loss_stop = 100000 NEW_LINE if self . config . gpu >= 0 : NEW_LINE INDENT self . G . cuda ( ) NEW_LINE self . D . cuda ( ) NEW_LINE self . diffLoss . cuda ( ) NEW_LINE self . ASR . cuda ( ) NEW_LINE DEDENT if len ( self . config . load_path ) > 0 : NEW_LINE INDENT self . load_model ( ) NEW_LINE DEDENT if config . mode == ' train ' : NEW_LINE INDENT self . logFile = open ( self . model_dir + ' / log . txt ' , ' w ' ) NEW_LINE DEDENT DEDENT\",\n",
              " 'def zero_grad_all ( self ) : NEW_LINE INDENT self . G . zero_grad ( ) NEW_LINE self . D . zero_grad ( ) NEW_LINE self . ASR . zero_grad ( ) NEW_LINE DEDENT',\n",
              " \"def build_model ( self ) : NEW_LINE INDENT print ( ' initialize ▁ enhancement ▁ & ▁ discriminator ▁ model ' ) NEW_LINE self . G = stackedBRNN ( I = self . config . nFeat , H = self . config . rnn_size , L = self . config . rnn_layers , rnn_type = supported_rnns [ self . config . rnn_type ] ) NEW_LINE self . D = stackedBRNN ( I = self . config . nFeat , H = self . config . rnn_size , L = self . config . rnn_layers , rnn_type = supported_rnns [ self . config . rnn_type ] ) NEW_LINE print ( ' load ▁ pre - trained ▁ ASR ▁ model ' ) NEW_LINE package_ASR = torch . load ( self . config . ASR_path , map_location = lambda storage , loc : storage ) NEW_LINE self . ASR = DeepSpeech . load_model_package ( package_ASR ) NEW_LINE DEDENT\",\n",
              " 'def load_model ( self ) : NEW_LINE INDENT print ( \" [ * ] ▁ Load ▁ models ▁ from ▁ { } . . . \" . format ( self . config . load_path ) ) NEW_LINE postfix = \\' _ valmin \\' NEW_LINE paths = glob ( os . path . join ( self . config . load_path , \\' G { } * . pth \\' . format ( postfix ) ) ) NEW_LINE paths . sort ( ) NEW_LINE if len ( paths ) == 0 : NEW_LINE INDENT print ( \" [ ! ] ▁ No ▁ checkpoint ▁ found ▁ in ▁ { } . . . \" . format ( self . config . load_path ) ) NEW_LINE assert ( 0 ) , \\' checkpoint ▁ not ▁ avilable \\' NEW_LINE DEDENT idxes = [ int ( os . path . basename ( path . split ( \\' . \\' ) [ 0 ] . split ( \\' _ \\' ) [ - 1 ] ) ) for path in paths ] NEW_LINE if self . config . start_iter <= 0 : NEW_LINE INDENT self . config . start_iter = max ( idxes ) NEW_LINE if ( self . config . start_iter < 0 ) : NEW_LINE INDENT raise Exception ( \" start ▁ iter ▁ is ▁ still ▁ less ▁ than ▁ 0 ▁ - - > ▁ probably ▁ try ▁ to ▁ load ▁ initial ▁ random ▁ model \" ) NEW_LINE DEDENT DEDENT if self . config . gpu < 0 : NEW_LINE INDENT map_location = lambda storage , loc : storage NEW_LINE DEDENT else : NEW_LINE INDENT map_location = None NEW_LINE DEDENT print ( \\' Load ▁ models ▁ from ▁ \\' + self . config . load_path + \\' , ▁ ITERATION ▁ = ▁ \\' + str ( self . config . start_iter ) ) NEW_LINE self . G . load_state_dict ( torch . load ( \\' { } / G { } _ { } . pth \\' . format ( self . config . load_path , postfix , self . config . start_iter ) , map_location = map_location ) ) NEW_LINE print ( \" [ * ] ▁ Model ▁ loaded \" ) NEW_LINE DEDENT',\n",
              " 'def train ( self ) : NEW_LINE INDENT optimizer_g = torch . optim . Adam ( self . G . parameters ( ) , lr = self . config . lr , betas = ( self . beta1 , self . beta2 ) , amsgrad = True ) NEW_LINE optimizer_asr = torch . optim . Adam ( self . ASR . parameters ( ) , lr = self . config . lr , betas = ( self . beta1 , self . beta2 ) , amsgrad = True ) NEW_LINE optimizer_d = torch . optim . Adam ( self . D . parameters ( ) , lr = self . config . lr , betas = ( self . beta1 , self . beta2 ) , amsgrad = True ) NEW_LINE for iter in trange ( self . config . start_iter , self . config . max_iter ) : NEW_LINE INDENT self . zero_grad_all ( ) NEW_LINE data_list = self . data_loader . next ( cl_ny = \\' ny \\' , type = \\' train \\' ) NEW_LINE inputs , targets , input_percentages , target_sizes , mask = _get_variable_nograd ( data_list [ 0 ] ) , _get_variable_nograd ( data_list [ 1 ] , cuda = False ) , data_list [ 2 ] , _get_variable_nograd ( data_list [ 3 ] , cuda = False ) , _get_variable_nograd ( data_list [ 4 ] ) NEW_LINE N = inputs . size ( 0 ) NEW_LINE enhanced = self . G ( inputs ) NEW_LINE enhanced_D = enhanced . detach ( ) NEW_LINE ae_ny_G = self . D ( enhanced ) NEW_LINE l_adv_ny_G , _ = self . diffLoss ( ae_ny_G , enhanced , mask ) NEW_LINE l_adv_ny_G = l_adv_ny_G * self . config . w_adversarial NEW_LINE l_adv_ny_G_data = l_adv_ny_G . data [ 0 ] NEW_LINE l_adv_ny_G . backward ( retain_graph = True ) NEW_LINE g_adv = self . get_gradient_norm ( self . G ) NEW_LINE self . D . zero_grad ( ) NEW_LINE del l_adv_ny_G NEW_LINE ae_ny_D = self . D ( enhanced_D ) NEW_LINE l_adv_ny_D , _ = self . diffLoss ( ae_ny_D , enhanced_D , mask ) NEW_LINE l_adv_ny_D = l_adv_ny_D * ( - self . kt ) * self . config . w_adversarial NEW_LINE l_adv_ny_D . backward ( ) NEW_LINE del l_adv_ny_D NEW_LINE prob = self . ASR ( enhanced ) NEW_LINE prob = prob . transpose ( 0 , 1 ) NEW_LINE T = prob . size ( 0 ) NEW_LINE sizes = _get_variable_nograd ( input_percentages . mul_ ( int ( T ) ) . int ( ) , cuda = False ) NEW_LINE l_CTC = self . config . w_acoustic * self . CTCLoss ( prob , targets , sizes , target_sizes ) / N NEW_LINE self . ctc_tr_local . update ( l_CTC . data [ 0 ] , N ) NEW_LINE l_CTC . backward ( ) NEW_LINE g_ctc_adv = self . get_gradient_norm ( self . G ) NEW_LINE del l_CTC NEW_LINE data_list_cl = self . data_loader . next ( cl_ny = \\' cl \\' , type = \\' train \\' ) NEW_LINE inputs , mask = _get_variable_nograd ( data_list_cl [ 0 ] ) , _get_variable_nograd ( data_list_cl [ 4 ] ) NEW_LINE ae_cl = self . D ( inputs ) NEW_LINE l_adv_cl , _ = self . diffLoss ( ae_cl , inputs , mask ) NEW_LINE l_adv_cl = self . config . w_adversarial * l_adv_cl NEW_LINE l_adv_cl . backward ( ) NEW_LINE l_adv_cl_data = l_adv_cl . data [ 0 ] NEW_LINE del l_adv_cl NEW_LINE optimizer_g . step ( ) NEW_LINE optimizer_d . step ( ) NEW_LINE if ( iter > self . config . allow_ASR_update_iter ) : NEW_LINE INDENT optimizer_asr . step ( ) NEW_LINE DEDENT g_d_balance = self . gamma * l_adv_cl_data - l_adv_ny_G_data NEW_LINE self . kt += self . lb * g_d_balance NEW_LINE self . kt = max ( min ( 1 , self . kt ) , 0 ) NEW_LINE conv_measure = l_adv_cl_data + abs ( g_d_balance ) NEW_LINE if ( iter + 1 ) % self . config . log_iter == 0 : NEW_LINE INDENT str_loss = \" [ { } / { } ] ▁ ( train ) ▁ CTC : ▁ { : . 7f } , ▁ ADV _ cl : ▁ { : . 7f } , ▁ ADV _ ny : ▁ { : . 7f } \" . format ( iter , self . config . max_iter , self . ctc_tr_local . avg , l_adv_cl_data , l_adv_ny_G_data ) NEW_LINE print ( str_loss ) NEW_LINE self . logFile . write ( str_loss + \\' \\\\n \\' ) NEW_LINE str_loss = \" [ { } / { } ] ▁ ( train ) ▁ conv _ measure : ▁ { : . 4f } , ▁ kt : ▁ { : . 4f } ▁ \" . format ( iter , self . config . max_iter , conv_measure , self . kt ) NEW_LINE print ( str_loss ) NEW_LINE self . logFile . write ( str_loss + \\' \\\\n \\' ) NEW_LINE str_loss = \" [ { } / { } ] ▁ ( train ) ▁ gradient ▁ norm , ▁ adv : ▁ { : . 4f } , ▁ adv ▁ + ▁ ctc ▁ : ▁ { : . 4f } \" . format ( iter , self . config . max_iter , g_adv . data [ 0 ] , g_ctc_adv . data [ 0 ] ) NEW_LINE print ( str_loss ) NEW_LINE self . logFile . write ( str_loss + \\' \\\\n \\' ) NEW_LINE self . logFile . flush ( ) NEW_LINE self . ctc_tr_local . reset ( ) NEW_LINE DEDENT if ( iter + 1 ) % self . config . save_iter == 0 : NEW_LINE INDENT self . G . eval ( ) NEW_LINE self . ctc_tr . reset ( ) NEW_LINE self . adv_ny_tr . reset ( ) NEW_LINE self . wer_tr . reset ( ) NEW_LINE self . cer_tr . reset ( ) NEW_LINE for _ in trange ( 0 , len ( self . data_loader . trsub_dl ) ) : NEW_LINE INDENT data_list = self . data_loader . next ( cl_ny = \\' ny \\' , type = \\' trsub \\' ) NEW_LINE inputs , targets , input_percentages , target_sizes , mask = data_list [ 0 ] , data_list [ 1 ] , data_list [ 2 ] , data_list [ 3 ] , _get_variable_volatile ( data_list [ 4 ] ) NEW_LINE ctc , adv_ny , nElement , wer , cer , nWord , nChar = self . greedy_decoding_and_AAS ( inputs , targets , input_percentages , target_sizes , mask ) NEW_LINE N = inputs . size ( 0 ) NEW_LINE self . ctc_tr . update ( ctc . data [ 0 ] , N ) NEW_LINE self . adv_ny_tr . update ( adv_ny . data [ 0 ] , nElement ) NEW_LINE self . wer_tr . update ( wer , nWord ) NEW_LINE self . cer_tr . update ( cer , nChar ) NEW_LINE del ctc , adv_ny NEW_LINE DEDENT str_loss = \" [ { } / { } ] ▁ ( training ▁ subset ) ▁ CTC : ▁ { : . 7f } , ▁ WER : ▁ { : . 7f } , ▁ CER : ▁ { : . 7f } \" . format ( iter , self . config . max_iter , self . ctc_tr . avg , self . wer_tr . avg * 100 , self . cer_tr . avg * 100 ) NEW_LINE print ( str_loss ) NEW_LINE self . logFile . write ( str_loss + \\' \\\\n \\' ) NEW_LINE self . ctc_val . reset ( ) NEW_LINE self . adv_ny_val . reset ( ) NEW_LINE self . wer_val . reset ( ) NEW_LINE self . cer_val . reset ( ) NEW_LINE for _ in trange ( 0 , len ( self . data_loader . val_dl ) ) : NEW_LINE INDENT data_list = self . data_loader . next ( cl_ny = \\' ny \\' , type = \\' val \\' ) NEW_LINE inputs , targets , input_percentages , target_sizes , mask = data_list [ 0 ] , data_list [ 1 ] , data_list [ 2 ] , data_list [ 3 ] , _get_variable_volatile ( data_list [ 4 ] ) NEW_LINE ctc , adv_ny , nElement , wer , cer , nWord , nChar = self . greedy_decoding_and_AAS ( inputs , targets , input_percentages , target_sizes , mask ) NEW_LINE N = inputs . size ( 0 ) NEW_LINE self . ctc_val . update ( ctc . data [ 0 ] , N ) NEW_LINE self . adv_ny_val . update ( adv_ny . data [ 0 ] , nElement ) NEW_LINE self . wer_val . update ( wer , nWord ) NEW_LINE self . cer_val . update ( cer , nChar ) NEW_LINE del ctc , adv_ny NEW_LINE DEDENT str_loss = \" [ { } / { } ] ▁ ( validation ) ▁ CTC : ▁ { : . 7f } , ▁ WER : ▁ { : . 7f } , ▁ CER : ▁ { : . 7f } \" . format ( iter , self . config . max_iter , self . ctc_val . avg , self . wer_val . avg * 100 , self . cer_val . avg * 100 ) NEW_LINE print ( str_loss ) NEW_LINE self . logFile . write ( str_loss + \\' \\\\n \\' ) NEW_LINE self . logFile . flush ( ) NEW_LINE self . G . train ( ) NEW_LINE if ( len ( self . savename_G ) > 0 ) : NEW_LINE INDENT if os . path . exists ( self . savename_G ) : NEW_LINE INDENT os . remove ( self . savename_G ) NEW_LINE DEDENT DEDENT self . savename_G = \\' { } / G _ { } . pth \\' . format ( self . model_dir , iter ) NEW_LINE torch . save ( self . G . state_dict ( ) , self . savename_G ) NEW_LINE if ( len ( self . savename_ASR ) > 0 ) : NEW_LINE INDENT if os . path . exists ( self . savename_ASR ) : NEW_LINE INDENT os . remove ( self . savename_ASR ) NEW_LINE DEDENT DEDENT self . savename_ASR = \\' { } / ASR _ { } . pth \\' . format ( self . model_dir , iter ) NEW_LINE torch . save ( self . ASR . state_dict ( ) , self . savename_ASR ) NEW_LINE if ( self . G . loss_stop > self . wer_val . avg ) : NEW_LINE INDENT self . G . loss_stop = self . wer_val . avg NEW_LINE savename_G_valmin_prev = \\' { } / G _ valmin _ { } . pth \\' . format ( self . model_dir , self . valmin_iter ) NEW_LINE if os . path . exists ( savename_G_valmin_prev ) : NEW_LINE INDENT os . remove ( savename_G_valmin_prev ) NEW_LINE DEDENT print ( \\' save ▁ model ▁ for ▁ this ▁ checkpoint \\' ) NEW_LINE savename_G_valmin = \\' { } / G _ valmin _ { } . pth \\' . format ( self . model_dir , iter ) NEW_LINE copyfile ( self . savename_G , savename_G_valmin ) NEW_LINE savename_ASR_valmin_prev = \\' { } / ASR _ valmin _ { } . pth \\' . format ( self . model_dir , self . valmin_iter ) NEW_LINE if os . path . exists ( savename_ASR_valmin_prev ) : NEW_LINE INDENT os . remove ( savename_ASR_valmin_prev ) NEW_LINE DEDENT print ( \\' save ▁ model ▁ for ▁ this ▁ checkpoint \\' ) NEW_LINE savename_ASR_valmin = \\' { } / ASR _ valmin _ { } . pth \\' . format ( self . model_dir , iter ) NEW_LINE copyfile ( self . savename_ASR , savename_ASR_valmin ) NEW_LINE self . valmin_iter = iter NEW_LINE DEDENT DEDENT DEDENT DEDENT',\n",
              " \"def greedy_decoding_and_AAS ( self , inputs , targets , input_percentages , target_sizes , mask , transcript_prob = 0.001 ) : NEW_LINE INDENT inputs = _get_variable_volatile ( inputs ) NEW_LINE N = inputs . size ( 0 ) NEW_LINE split_targets = [ ] NEW_LINE offset = 0 NEW_LINE for size in target_sizes : NEW_LINE INDENT split_targets . append ( targets [ offset : offset + size ] ) NEW_LINE offset += size NEW_LINE DEDENT enhanced = self . G ( inputs ) NEW_LINE prob = self . ASR ( enhanced ) NEW_LINE prob = prob . transpose ( 0 , 1 ) NEW_LINE T = prob . size ( 0 ) NEW_LINE sizes = input_percentages . mul_ ( int ( T ) ) . int ( ) NEW_LINE decoded_output , _ = self . decoder . decode ( prob . data , sizes ) NEW_LINE target_strings = self . decoder . convert_to_strings ( split_targets ) NEW_LINE we , ce , total_word , total_char = 0 , 0 , 0 , 0 NEW_LINE for x in range ( len ( target_strings ) ) : NEW_LINE INDENT decoding , reference = decoded_output [ x ] [ 0 ] , target_strings [ x ] [ 0 ] NEW_LINE nChar = len ( reference ) NEW_LINE nWord = len ( reference . split ( ) ) NEW_LINE we_i = self . decoder . wer ( decoding , reference ) NEW_LINE ce_i = self . decoder . cer ( decoding , reference ) NEW_LINE we += we_i NEW_LINE ce += ce_i NEW_LINE total_word += nWord NEW_LINE total_char += nChar NEW_LINE if ( random . uniform ( 0 , 1 ) < transcript_prob ) : NEW_LINE INDENT print ( ' reference ▁ = ▁ ' + reference ) NEW_LINE print ( ' decoding ▁ = ▁ ' + decoding ) NEW_LINE print ( ' wer ▁ = ▁ ' + str ( we_i / float ( nWord ) ) + ' , ▁ cer ▁ = ▁ ' + str ( ce_i / float ( nChar ) ) ) NEW_LINE DEDENT DEDENT wer = we / total_word NEW_LINE cer = ce / total_word NEW_LINE ae_ny = self . D ( enhanced ) NEW_LINE l_adv_ny , nElement = self . diffLoss ( ae_ny , enhanced , mask ) NEW_LINE l_adv_ny = l_adv_ny * self . config . w_adversarial NEW_LINE targets = _get_variable_volatile ( targets , cuda = False ) NEW_LINE sizes = _get_variable_volatile ( sizes , cuda = False ) NEW_LINE target_sizes = _get_variable_volatile ( target_sizes , cuda = False ) NEW_LINE l_CTC = self . config . w_acoustic * self . CTCLoss ( prob , targets , sizes , target_sizes ) / N NEW_LINE return l_CTC , l_adv_ny , nElement , wer , cer , total_word , total_char NEW_LINE DEDENT\",\n",
              " 'def get_gradient_norm ( self , model ) : NEW_LINE INDENT params = list ( model . parameters ( ) ) NEW_LINE grad_norm = 0 NEW_LINE for param in params : NEW_LINE INDENT grad_norm += torch . pow ( param . grad , 2 ) . sum ( ) NEW_LINE DEDENT grad_norm = torch . pow ( grad_norm , 0.5 ) NEW_LINE return grad_norm NEW_LINE DEDENT',\n",
              " \"def weights_init ( m ) : NEW_LINE INDENT classname = m . __class__ . __name__ NEW_LINE if classname . find ( ' Conv ' ) != - 1 : NEW_LINE INDENT m . weight . data . normal_ ( 0.0 , 0.01 ) NEW_LINE DEDENT elif classname . find ( ' BatchNorm ' ) != - 1 : NEW_LINE INDENT m . weight . data . normal_ ( 1.0 , 0.01 ) NEW_LINE m . bias . data . fill_ ( 0 ) NEW_LINE DEDENT elif classname . find ( ' Embedding ' ) != - 1 : NEW_LINE INDENT m . weight . data . normal_ ( 0.0 , 0.01 ) NEW_LINE DEDENT DEDENT\",\n",
              " \"def __init__ ( self , config , data_loader = None ) : NEW_LINE INDENT self . config = config NEW_LINE self . data_loader = data_loader NEW_LINE self . lr = config . lr NEW_LINE self . beta1 = config . beta1 NEW_LINE self . beta2 = config . beta2 NEW_LINE self . optimizer = config . optimizer NEW_LINE self . batch_size = config . batch_size NEW_LINE self . valmin_iter = 0 NEW_LINE self . model_dir = ' logs / ' + str ( config . expnum ) NEW_LINE self . savename_G = ' ' NEW_LINE self . savename_ASR = ' ' NEW_LINE self . kt = 0 NEW_LINE self . lb = 0.001 NEW_LINE self . conv_measure = 0 NEW_LINE self . ctc_tr = AverageMeter ( ) NEW_LINE self . ctc_tr_local = AverageMeter ( ) NEW_LINE self . ctc_val = AverageMeter ( ) NEW_LINE self . wer_tr = AverageMeter ( ) NEW_LINE self . wer_val = AverageMeter ( ) NEW_LINE self . cer_tr = AverageMeter ( ) NEW_LINE self . cer_val = AverageMeter ( ) NEW_LINE self . CTCLoss = CTCLoss ( ) NEW_LINE self . decoder = GreedyDecoder ( data_loader . labels ) NEW_LINE self . build_model ( ) NEW_LINE self . G . loss_stop = 100000 NEW_LINE if self . config . gpu >= 0 : NEW_LINE INDENT self . G . cuda ( ) NEW_LINE self . ASR . cuda ( ) NEW_LINE DEDENT if len ( self . config . load_path ) > 0 : NEW_LINE INDENT self . load_model ( ) NEW_LINE DEDENT if config . mode == ' train ' : NEW_LINE INDENT self . logFile = open ( self . model_dir + ' / log . txt ' , ' w ' ) NEW_LINE DEDENT DEDENT\",\n",
              " 'def zero_grad_all ( self ) : NEW_LINE INDENT self . G . zero_grad ( ) NEW_LINE self . ASR . zero_grad ( ) NEW_LINE DEDENT',\n",
              " \"def build_model ( self ) : NEW_LINE INDENT print ( ' initialize ▁ enhancement ▁ model ' ) NEW_LINE self . G = stackedBRNN ( I = self . config . nFeat , H = self . config . rnn_size , L = self . config . rnn_layers , rnn_type = supported_rnns [ self . config . rnn_type ] ) NEW_LINE print ( ' load ▁ pre - trained ▁ ASR ▁ model ' ) NEW_LINE package_ASR = torch . load ( self . config . ASR_path , map_location = lambda storage , loc : storage ) NEW_LINE self . ASR = DeepSpeech . load_model_package ( package_ASR ) NEW_LINE DEDENT\",\n",
              " 'def load_model ( self ) : NEW_LINE INDENT print ( \" [ * ] ▁ Load ▁ models ▁ from ▁ { } . . . \" . format ( self . config . load_path ) ) NEW_LINE postfix = \\' _ valmin \\' NEW_LINE paths = glob ( os . path . join ( self . config . load_path , \\' G { } * . pth \\' . format ( postfix ) ) ) NEW_LINE paths . sort ( ) NEW_LINE if len ( paths ) == 0 : NEW_LINE INDENT print ( \" [ ! ] ▁ No ▁ checkpoint ▁ found ▁ in ▁ { } . . . \" . format ( self . config . load_path ) ) NEW_LINE assert ( 0 ) , \\' checkpoint ▁ not ▁ avilable \\' NEW_LINE DEDENT idxes = [ int ( os . path . basename ( path . split ( \\' . \\' ) [ 0 ] . split ( \\' _ \\' ) [ - 1 ] ) ) for path in paths ] NEW_LINE if self . config . start_iter <= 0 : NEW_LINE INDENT self . config . start_iter = max ( idxes ) NEW_LINE if ( self . config . start_iter < 0 ) : NEW_LINE INDENT raise Exception ( \" start ▁ iter ▁ is ▁ still ▁ less ▁ than ▁ 0 ▁ - - > ▁ probably ▁ try ▁ to ▁ load ▁ initial ▁ random ▁ model \" ) NEW_LINE DEDENT DEDENT if self . config . gpu < 0 : NEW_LINE INDENT map_location = lambda storage , loc : storage NEW_LINE DEDENT else : NEW_LINE INDENT map_location = None NEW_LINE DEDENT print ( \\' Load ▁ models ▁ from ▁ \\' + self . config . load_path + \\' , ▁ ITERATION ▁ = ▁ \\' + str ( self . config . start_iter ) ) NEW_LINE self . G . load_state_dict ( torch . load ( \\' { } / G { } _ { } . pth \\' . format ( self . config . load_path , postfix , self . config . start_iter ) , map_location = map_location ) ) NEW_LINE print ( \" [ * ] ▁ Model ▁ loaded \" ) NEW_LINE DEDENT',\n",
              " 'def train ( self ) : NEW_LINE INDENT optimizer_g = torch . optim . Adam ( self . G . parameters ( ) , lr = self . config . lr , betas = ( self . beta1 , self . beta2 ) , amsgrad = True ) NEW_LINE optimizer_asr = torch . optim . Adam ( self . ASR . parameters ( ) , lr = self . config . lr , betas = ( self . beta1 , self . beta2 ) , amsgrad = True ) NEW_LINE for iter in trange ( self . config . start_iter , self . config . max_iter ) : NEW_LINE INDENT data_list = self . data_loader . next ( cl_ny = \\' ny \\' , type = \\' train \\' ) NEW_LINE inputs , targets , input_percentages , target_sizes = _get_variable_nograd ( data_list [ 0 ] ) , _get_variable_nograd ( data_list [ 1 ] , cuda = False ) , data_list [ 2 ] , _get_variable_nograd ( data_list [ 3 ] , cuda = False ) NEW_LINE N = inputs . size ( 0 ) NEW_LINE enhanced = self . G ( inputs ) NEW_LINE prob = self . ASR ( enhanced ) NEW_LINE prob = prob . transpose ( 0 , 1 ) NEW_LINE T = prob . size ( 0 ) NEW_LINE sizes = _get_variable_nograd ( input_percentages . mul_ ( int ( T ) ) . int ( ) , cuda = False ) NEW_LINE loss = self . CTCLoss ( prob , targets , sizes , target_sizes ) NEW_LINE loss = loss / N NEW_LINE self . zero_grad_all ( ) NEW_LINE loss . backward ( ) NEW_LINE optimizer_g . step ( ) NEW_LINE if ( iter > self . config . allow_ASR_update_iter ) : NEW_LINE INDENT optimizer_asr . step ( ) NEW_LINE DEDENT self . ctc_tr_local . update ( loss . data [ 0 ] , N ) NEW_LINE del loss NEW_LINE if ( iter + 1 ) % self . config . log_iter == 0 : NEW_LINE INDENT str_loss = \" [ { } / { } ] ▁ ( train ) ▁ CTC : ▁ { : . 7f } \" . format ( iter , self . config . max_iter , self . ctc_tr_local . avg ) NEW_LINE print ( str_loss ) NEW_LINE self . logFile . write ( str_loss + \\' \\\\n \\' ) NEW_LINE self . logFile . flush ( ) NEW_LINE self . ctc_tr_local . reset ( ) NEW_LINE DEDENT if ( iter + 1 ) % self . config . save_iter == 0 : NEW_LINE INDENT self . G . eval ( ) NEW_LINE self . ctc_tr . reset ( ) NEW_LINE self . wer_tr . reset ( ) NEW_LINE self . cer_tr . reset ( ) NEW_LINE for _ in trange ( 0 , len ( self . data_loader . trsub_dl ) ) : NEW_LINE INDENT data_list = self . data_loader . next ( cl_ny = \\' ny \\' , type = \\' trsub \\' ) NEW_LINE inputs , targets , input_percentages , target_sizes = data_list [ 0 ] , data_list [ 1 ] , data_list [ 2 ] , data_list [ 3 ] NEW_LINE ctc , wer , cer , nWord , nChar = self . greedy_decoding_and_CTCLoss ( inputs , targets , input_percentages , target_sizes ) NEW_LINE N = inputs . size ( 0 ) NEW_LINE self . ctc_tr . update ( ctc . data [ 0 ] , N ) NEW_LINE self . wer_tr . update ( wer , nWord ) NEW_LINE self . cer_tr . update ( cer , nChar ) NEW_LINE del ctc NEW_LINE DEDENT str_loss = \" [ { } / { } ] ▁ ( training ▁ subset ) ▁ CTC : ▁ { : . 7f } , ▁ WER : ▁ { : . 7f } , ▁ CER : ▁ { : . 7f } \" . format ( iter , self . config . max_iter , self . ctc_tr . avg , self . wer_tr . avg * 100 , self . cer_tr . avg * 100 ) NEW_LINE print ( str_loss ) NEW_LINE self . logFile . write ( str_loss + \\' \\\\n \\' ) NEW_LINE self . ctc_val . reset ( ) NEW_LINE self . wer_val . reset ( ) NEW_LINE self . cer_val . reset ( ) NEW_LINE for _ in trange ( 0 , len ( self . data_loader . val_dl ) ) : NEW_LINE INDENT data_list = self . data_loader . next ( cl_ny = \\' ny \\' , type = \\' val \\' ) NEW_LINE inputs , targets , input_percentages , target_sizes = data_list [ 0 ] , data_list [ 1 ] , data_list [ 2 ] , data_list [ 3 ] NEW_LINE ctc , wer , cer , nWord , nChar = self . greedy_decoding_and_CTCLoss ( inputs , targets , input_percentages , target_sizes ) NEW_LINE N = inputs . size ( 0 ) NEW_LINE self . ctc_val . update ( ctc . data [ 0 ] , N ) NEW_LINE self . wer_val . update ( wer , nWord ) NEW_LINE self . cer_val . update ( cer , nChar ) NEW_LINE del ctc NEW_LINE DEDENT str_loss = \" [ { } / { } ] ▁ ( validation ) ▁ CTC : ▁ { : . 7f } , ▁ WER : ▁ { : . 7f } , ▁ CER : ▁ { : . 7f } \" . format ( iter , self . config . max_iter , self . ctc_val . avg , self . wer_val . avg * 100 , self . cer_val . avg * 100 ) NEW_LINE print ( str_loss ) NEW_LINE self . logFile . write ( str_loss + \\' \\\\n \\' ) NEW_LINE self . logFile . flush ( ) NEW_LINE self . G . train ( ) NEW_LINE if ( len ( self . savename_G ) > 0 ) : NEW_LINE INDENT if os . path . exists ( self . savename_G ) : NEW_LINE INDENT os . remove ( self . savename_G ) NEW_LINE DEDENT DEDENT self . savename_G = \\' { } / G _ { } . pth \\' . format ( self . model_dir , iter ) NEW_LINE torch . save ( self . G . state_dict ( ) , self . savename_G ) NEW_LINE if ( len ( self . savename_ASR ) > 0 ) : NEW_LINE INDENT if os . path . exists ( self . savename_ASR ) : NEW_LINE INDENT os . remove ( self . savename_ASR ) NEW_LINE DEDENT DEDENT self . savename_ASR = \\' { } / ASR _ { } . pth \\' . format ( self . model_dir , iter ) NEW_LINE torch . save ( self . ASR . state_dict ( ) , self . savename_ASR ) NEW_LINE if ( self . G . loss_stop > self . wer_val . avg ) : NEW_LINE INDENT self . G . loss_stop = self . wer_val . avg NEW_LINE savename_G_valmin_prev = \\' { } / G _ valmin _ { } . pth \\' . format ( self . model_dir , self . valmin_iter ) NEW_LINE if os . path . exists ( savename_G_valmin_prev ) : NEW_LINE INDENT os . remove ( savename_G_valmin_prev ) NEW_LINE DEDENT print ( \\' save ▁ model ▁ for ▁ this ▁ checkpoint \\' ) NEW_LINE savename_G_valmin = \\' { } / G _ valmin _ { } . pth \\' . format ( self . model_dir , iter ) NEW_LINE copyfile ( self . savename_G , savename_G_valmin ) NEW_LINE savename_ASR_valmin_prev = \\' { } / ASR _ valmin _ { } . pth \\' . format ( self . model_dir , self . valmin_iter ) NEW_LINE if os . path . exists ( savename_ASR_valmin_prev ) : NEW_LINE INDENT os . remove ( savename_ASR_valmin_prev ) NEW_LINE DEDENT print ( \\' save ▁ model ▁ for ▁ this ▁ checkpoint \\' ) NEW_LINE savename_ASR_valmin = \\' { } / ASR _ valmin _ { } . pth \\' . format ( self . model_dir , iter ) NEW_LINE copyfile ( self . savename_ASR , savename_ASR_valmin ) NEW_LINE self . valmin_iter = iter NEW_LINE DEDENT DEDENT DEDENT DEDENT',\n",
              " \"def greedy_decoding_and_CTCLoss ( self , inputs , targets , input_percentages , target_sizes , transcript_prob = 0.001 ) : NEW_LINE INDENT inputs = _get_variable_volatile ( inputs ) NEW_LINE N = inputs . size ( 0 ) NEW_LINE split_targets = [ ] NEW_LINE offset = 0 NEW_LINE for size in target_sizes : NEW_LINE INDENT split_targets . append ( targets [ offset : offset + size ] ) NEW_LINE offset += size NEW_LINE DEDENT enhanced = self . G ( inputs ) NEW_LINE prob = self . ASR ( enhanced ) NEW_LINE prob = prob . transpose ( 0 , 1 ) NEW_LINE T = prob . size ( 0 ) NEW_LINE sizes = input_percentages . mul_ ( int ( T ) ) . int ( ) NEW_LINE decoded_output , _ = self . decoder . decode ( prob . data , sizes ) NEW_LINE target_strings = self . decoder . convert_to_strings ( split_targets ) NEW_LINE we , ce , total_word , total_char = 0 , 0 , 0 , 0 NEW_LINE for x in range ( len ( target_strings ) ) : NEW_LINE INDENT decoding , reference = decoded_output [ x ] [ 0 ] , target_strings [ x ] [ 0 ] NEW_LINE nChar = len ( reference ) NEW_LINE nWord = len ( reference . split ( ) ) NEW_LINE we_i = self . decoder . wer ( decoding , reference ) NEW_LINE ce_i = self . decoder . cer ( decoding , reference ) NEW_LINE we += we_i NEW_LINE ce += ce_i NEW_LINE total_word += nWord NEW_LINE total_char += nChar NEW_LINE if ( random . uniform ( 0 , 1 ) < transcript_prob ) : NEW_LINE INDENT print ( ' reference ▁ = ▁ ' + reference ) NEW_LINE print ( ' decoding ▁ = ▁ ' + decoding ) NEW_LINE print ( ' wer ▁ = ▁ ' + str ( we_i / float ( nWord ) ) + ' , ▁ cer ▁ = ▁ ' + str ( ce_i / float ( nChar ) ) ) NEW_LINE DEDENT DEDENT wer = we / total_word NEW_LINE cer = ce / total_word NEW_LINE targets = _get_variable_volatile ( targets , cuda = False ) NEW_LINE sizes = _get_variable_volatile ( sizes , cuda = False ) NEW_LINE target_sizes = _get_variable_volatile ( target_sizes , cuda = False ) NEW_LINE loss = self . CTCLoss ( prob , targets , sizes , target_sizes ) NEW_LINE loss = loss / N NEW_LINE return loss , wer , cer , total_word , total_char NEW_LINE DEDENT\",\n",
              " 'def _collate_fn ( batch ) : NEW_LINE INDENT def func ( p ) : NEW_LINE INDENT return p [ 0 ] . size ( 1 ) NEW_LINE DEDENT batch = sorted ( batch , key = lambda sample : sample [ 0 ] . size ( 1 ) , reverse = True ) NEW_LINE longest_sample = max ( batch , key = func ) [ 0 ] NEW_LINE freq_size = longest_sample . size ( 0 ) NEW_LINE minibatch_size = len ( batch ) NEW_LINE max_seqlength = longest_sample . size ( 1 ) NEW_LINE inputs = torch . zeros ( minibatch_size , freq_size , max_seqlength ) NEW_LINE input_percentages = torch . FloatTensor ( minibatch_size ) NEW_LINE target_sizes = torch . IntTensor ( minibatch_size ) NEW_LINE targets = [ ] NEW_LINE mask = torch . ByteTensor ( minibatch_size , 1 , max_seqlength ) . zero_ ( ) NEW_LINE for x in range ( minibatch_size ) : NEW_LINE INDENT sample = batch [ x ] NEW_LINE tensor = sample [ 0 ] NEW_LINE target = sample [ 1 ] NEW_LINE seq_length = tensor . size ( 1 ) NEW_LINE inputs [ x ] . narrow ( 1 , 0 , seq_length ) . copy_ ( tensor ) NEW_LINE input_percentages [ x ] = seq_length / float ( max_seqlength ) NEW_LINE target_sizes [ x ] = len ( target ) NEW_LINE targets . extend ( target ) NEW_LINE if ( seq_length < max_seqlength ) : NEW_LINE INDENT mask [ x ] [ : , seq_length : ] . fill_ ( 1 ) NEW_LINE DEDENT DEDENT targets = torch . IntTensor ( targets ) NEW_LINE return inputs , targets , input_percentages , target_sizes , mask NEW_LINE DEDENT',\n",
              " 'def _collate_fn_paired ( batch ) : NEW_LINE INDENT def func ( p ) : NEW_LINE INDENT return p [ 0 ] . size ( 1 ) NEW_LINE DEDENT batch = sorted ( batch , key = lambda sample : sample [ 0 ] . size ( 1 ) , reverse = True ) NEW_LINE longest_sample = max ( batch , key = func ) [ 0 ] NEW_LINE freq_size = longest_sample . size ( 0 ) NEW_LINE minibatch_size = len ( batch ) NEW_LINE max_seqlength = longest_sample . size ( 1 ) NEW_LINE inputs = torch . zeros ( minibatch_size , freq_size , max_seqlength ) NEW_LINE outputs = torch . zeros ( minibatch_size , freq_size , max_seqlength ) NEW_LINE mask = torch . ByteTensor ( minibatch_size , 1 , max_seqlength ) . zero_ ( ) NEW_LINE input_percentages = torch . FloatTensor ( minibatch_size ) NEW_LINE target_sizes = torch . IntTensor ( minibatch_size ) NEW_LINE targets = [ ] NEW_LINE for x in range ( minibatch_size ) : NEW_LINE INDENT sample = batch [ x ] NEW_LINE tensor = sample [ 0 ] NEW_LINE txt = sample [ 1 ] NEW_LINE target = sample [ 2 ] NEW_LINE seq_length = tensor . size ( 1 ) NEW_LINE inputs [ x ] . narrow ( 1 , 0 , seq_length ) . copy_ ( tensor ) NEW_LINE outputs [ x ] . narrow ( 1 , 0 , seq_length ) . copy_ ( target ) NEW_LINE if ( seq_length < max_seqlength ) : NEW_LINE INDENT mask [ x ] [ : , seq_length : ] . fill_ ( 1 ) NEW_LINE DEDENT input_percentages [ x ] = seq_length / float ( max_seqlength ) NEW_LINE target_sizes [ x ] = len ( txt ) NEW_LINE targets . extend ( txt ) NEW_LINE DEDENT targets = torch . IntTensor ( targets ) NEW_LINE return inputs , outputs , mask , targets , input_percentages , target_sizes NEW_LINE DEDENT',\n",
              " \"def __init__ ( self , manifest , labels ) : NEW_LINE INDENT with open ( manifest ) as f : NEW_LINE INDENT ids = f . readlines ( ) NEW_LINE DEDENT ids = [ x . strip ( ) . split ( ' , ' ) for x in ids ] NEW_LINE self . ids = ids NEW_LINE self . size = len ( ids ) NEW_LINE self . labels_map = dict ( [ ( labels [ i ] , i ) for i in range ( len ( labels ) ) ] ) NEW_LINE super ( FeatDataset , self ) . __init__ ( ) NEW_LINE DEDENT\",\n",
              " 'def __getitem__ ( self , index ) : NEW_LINE INDENT sample = self . ids [ index ] NEW_LINE if ( len ( sample ) == 2 ) : NEW_LINE INDENT feat_path , transcript_path = sample [ 0 ] , sample [ 1 ] NEW_LINE DEDENT else : NEW_LINE INDENT feat_path , transcript_path , feat_paired_path = sample [ 0 ] , sample [ 1 ] , sample [ 2 ] NEW_LINE DEDENT feat = torch . load ( feat_path ) NEW_LINE transcript = self . parse_transcript ( transcript_path ) NEW_LINE if ( len ( sample ) == 2 ) : NEW_LINE INDENT return feat , transcript NEW_LINE DEDENT else : NEW_LINE INDENT feat_paired = torch . load ( feat_paired_path ) NEW_LINE return feat , transcript , feat_paired NEW_LINE DEDENT DEDENT',\n",
              " \"def parse_transcript ( self , transcript_path ) : NEW_LINE INDENT with open ( transcript_path , ' r ' , encoding = ' utf8' ) as transcript_file : NEW_LINE INDENT transcript = transcript_file . read ( ) . replace ( ' \\\\n ' , ' ' ) NEW_LINE DEDENT transcript = list ( filter ( None , [ self . labels_map . get ( x ) for x in list ( transcript ) ] ) ) NEW_LINE return transcript NEW_LINE DEDENT\",\n",
              " 'def __len__ ( self ) : NEW_LINE INDENT return self . size NEW_LINE DEDENT',\n",
              " 'def __init__ ( self , * args , ** kwargs ) : NEW_LINE INDENT super ( FeatLoader , self ) . __init__ ( * args , ** kwargs ) NEW_LINE self . collate_fn = _collate_fn NEW_LINE DEDENT',\n",
              " 'def __init__ ( self , * args , ** kwargs ) : NEW_LINE INDENT super ( FeatLoader_paired , self ) . __init__ ( * args , ** kwargs ) NEW_LINE self . collate_fn = _collate_fn_paired NEW_LINE DEDENT',\n",
              " 'def __init__ ( self , data_source , batch_size = 1 ) : NEW_LINE INDENT super ( FeatSampler , self ) . __init__ ( data_source ) NEW_LINE self . data_source = data_source NEW_LINE ids = list ( range ( 0 , len ( data_source ) ) ) NEW_LINE self . bins = [ ids [ i : i + batch_size ] for i in range ( 0 , len ( ids ) , batch_size ) ] NEW_LINE DEDENT',\n",
              " 'def __iter__ ( self ) : NEW_LINE INDENT for ids in self . bins : NEW_LINE INDENT np . random . shuffle ( ids ) NEW_LINE yield ids NEW_LINE DEDENT DEDENT',\n",
              " 'def __len__ ( self ) : NEW_LINE INDENT return len ( self . bins ) NEW_LINE DEDENT',\n",
              " 'def shuffle ( self ) : NEW_LINE INDENT np . random . shuffle ( self . bins ) NEW_LINE DEDENT',\n",
              " \"def load_model ( cls , path , gpu = - 1 ) : NEW_LINE INDENT package = torch . load ( path , map_location = lambda storage , loc : storage ) NEW_LINE model = cls ( rnn_hidden_size = package [ ' rnn _ size ' ] , rnn_layers = package [ ' rnn _ layers ' ] , rnn_type = supported_rnns [ package [ ' rnn _ type ' ] ] , map = package [ ' cnn _ map ' ] , stride = package [ ' cnn _ stride ' ] , kernel_sz = package [ ' cnn _ kernel ' ] , cnn_layers = package [ ' cnn _ layers ' ] , labels = package [ ' labels ' ] ) NEW_LINE blacklist = [ ' rnns . 0 . batch _ norm . module . weight ' , ' rnns . 0 . batch _ norm . module . bias ' , ' rnns . 0 . batch _ norm . module . running _ mean ' , ' rnns . 0 . batch _ norm . module . running _ var ' ] NEW_LINE for x in blacklist : NEW_LINE INDENT if x in package [ ' state _ dict ' ] : NEW_LINE INDENT del package [ ' state _ dict ' ] [ x ] NEW_LINE DEDENT DEDENT model . load_state_dict ( package [ ' state _ dict ' ] ) NEW_LINE for x in model . rnns : NEW_LINE INDENT x . flatten_parameters ( ) NEW_LINE DEDENT if gpu >= 0 : NEW_LINE INDENT model = model . cuda ( ) NEW_LINE DEDENT return model NEW_LINE DEDENT\",\n",
              " \"def load_model_package ( cls , package , gpu = - 1 ) : NEW_LINE INDENT model = cls ( rnn_hidden_size = package [ ' rnn _ size ' ] , rnn_layers = package [ ' rnn _ layers ' ] , rnn_type = supported_rnns [ package [ ' rnn _ type ' ] ] , map = package [ ' cnn _ map ' ] , stride = package [ ' cnn _ stride ' ] , kernel_sz = package [ ' cnn _ kernel ' ] , cnn_layers = package [ ' cnn _ layers ' ] , labels = package [ ' labels ' ] , ) NEW_LINE model . load_state_dict ( package [ ' state _ dict ' ] ) NEW_LINE if ( gpu >= 0 ) : NEW_LINE INDENT model = model . cuda ( ) NEW_LINE DEDENT return model NEW_LINE DEDENT\",\n",
              " \"def serialize ( model , optimizer = None , epoch = None , iteration = None , loss_results = None , cer_results = None , wer_results = None , avg_loss = None , meta = None ) : NEW_LINE INDENT package = { ' version ' : model . _version , ' rnn _ size ' : model . rnn_size , ' rnn _ layers ' : model . rnn_layers , ' cnn _ map ' : model . cnn_map , ' cnn _ kernel ' : model . cnn_kernel , ' cnn _ stride ' : model . cnn_stride , ' cnn _ layers ' : model . cnn_layers , ' rnn _ type ' : supported_rnns_inv . get ( model . rnn_type , model . rnn_type . __name__ . lower ( ) ) , ' labels ' : model . _labels , ' state _ dict ' : model . state_dict ( ) } NEW_LINE if optimizer is not None : NEW_LINE INDENT package [ ' optim _ dict ' ] = optimizer . state_dict ( ) NEW_LINE DEDENT if avg_loss is not None : NEW_LINE INDENT package [ ' avg _ loss ' ] = avg_loss NEW_LINE DEDENT if epoch is not None : NEW_LINE INDENT package [ ' epoch ' ] = epoch + 1 NEW_LINE DEDENT if iteration is not None : NEW_LINE INDENT package [ ' iteration ' ] = iteration NEW_LINE DEDENT if loss_results is not None : NEW_LINE INDENT package [ ' loss _ results ' ] = loss_results NEW_LINE package [ ' cer _ results ' ] = cer_results NEW_LINE package [ ' wer _ results ' ] = wer_results NEW_LINE DEDENT if meta is not None : NEW_LINE INDENT package [ ' meta ' ] = meta NEW_LINE DEDENT return package NEW_LINE DEDENT\",\n",
              " 'def get_labels ( model ) : NEW_LINE INDENT return model . _labels NEW_LINE DEDENT',\n",
              " 'def get_param_size ( model ) : NEW_LINE INDENT params = 0 NEW_LINE for p in model . parameters ( ) : NEW_LINE INDENT tmp = 1 NEW_LINE for x in p . size ( ) : NEW_LINE INDENT tmp *= x NEW_LINE DEDENT params += tmp NEW_LINE DEDENT return params NEW_LINE DEDENT',\n",
              " 'def get_audio_conf ( model ) : NEW_LINE INDENT return model . _audio_conf NEW_LINE DEDENT',\n",
              " 'def get_meta ( model ) : NEW_LINE INDENT model_is_cuda = next ( model . parameters ( ) ) . is_cuda NEW_LINE m = model . module if model_is_cuda else model NEW_LINE meta = { \" version \" : m . _version , \" rnn _ size \" : m . rnn_size , \" rnn _ layers \" : m . rnn_layers , \" cnn _ map \" : m . cnn_map , \" cnn _ kernel \" : m . cnn_kernel , \" cnn _ stride \" : m . cnn_stride , \" cnn _ layers \" : m . cnn_layers , \" rnn _ type \" : supported_rnns_inv [ m . rnn_type ] } NEW_LINE return meta NEW_LINE DEDENT',\n",
              " 'def __init__ ( self ) : NEW_LINE INDENT super ( L1Loss_mask , self ) . __init__ ( ) NEW_LINE DEDENT',\n",
              " 'def forward ( self , input , target , mask ) : NEW_LINE INDENT mask_sum = mask . data . sum ( ) NEW_LINE if ( mask . data [ 0 ] [ 0 ] [ 0 ] == 0 ) : NEW_LINE INDENT nElement = mask . data . nelement ( ) - mask_sum NEW_LINE DEDENT err = torch . abs ( input - target ) NEW_LINE err . masked_fill ( mask , 0 ) NEW_LINE loss = err . sum ( ) / nElement NEW_LINE return loss , nElement NEW_LINE DEDENT',\n",
              " 'def __init__ ( self , module ) : NEW_LINE INDENT super ( SequenceWise , self ) . __init__ ( ) NEW_LINE self . module = module NEW_LINE DEDENT',\n",
              " 'def forward ( self , x ) : NEW_LINE INDENT t , n = x . size ( 0 ) , x . size ( 1 ) NEW_LINE x = x . view ( t * n , - 1 ) NEW_LINE x = self . module ( x ) NEW_LINE x = x . view ( t , n , - 1 ) NEW_LINE return x NEW_LINE DEDENT',\n",
              " \"def __repr__ ( self ) : NEW_LINE INDENT tmpstr = self . __class__ . __name__ + ' ▁ ( \\\\n ' NEW_LINE tmpstr += self . module . __repr__ ( ) NEW_LINE tmpstr += ' ) ' NEW_LINE return tmpstr NEW_LINE DEDENT\",\n",
              " 'def forward ( self , input_ ) : NEW_LINE INDENT if not self . training : NEW_LINE INDENT batch_size = input_ . size ( ) [ 0 ] NEW_LINE return torch . stack ( [ F . softmax ( input_ [ i ] , dim = 1 ) for i in range ( batch_size ) ] , 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT return input_ NEW_LINE DEDENT DEDENT',\n",
              " 'def __init__ ( self , input_size , hidden_size , rnn_type = nn . LSTM , bidirectional = False , batch_norm = True ) : NEW_LINE INDENT super ( BatchRNN , self ) . __init__ ( ) NEW_LINE self . input_size = input_size NEW_LINE self . hidden_size = hidden_size NEW_LINE self . bidirectional = bidirectional NEW_LINE self . batch_norm = SequenceWise ( nn . BatchNorm1d ( input_size ) ) if batch_norm else None NEW_LINE self . rnn = rnn_type ( input_size = input_size , hidden_size = hidden_size , bidirectional = bidirectional , bias = False ) NEW_LINE self . num_directions = 2 if bidirectional else 1 NEW_LINE DEDENT',\n",
              " 'def flatten_parameters ( self ) : NEW_LINE INDENT self . rnn . flatten_parameters ( ) NEW_LINE DEDENT',\n",
              " 'def forward ( self , x ) : NEW_LINE INDENT if self . batch_norm is not None : NEW_LINE INDENT x = self . batch_norm ( x ) NEW_LINE DEDENT x , _ = self . rnn ( x ) NEW_LINE if self . bidirectional : NEW_LINE INDENT x = x . view ( x . size ( 0 ) , x . size ( 1 ) , 2 , - 1 ) . sum ( 2 ) . view ( x . size ( 0 ) , x . size ( 1 ) , - 1 ) NEW_LINE DEDENT return x NEW_LINE DEDENT',\n",
              " 'def __init__ ( self , input_size , hidden_size , rnn_type = nn . LSTM , bidirectional = False ) : NEW_LINE INDENT super ( BRNN , self ) . __init__ ( ) NEW_LINE self . input_size = input_size NEW_LINE self . hidden_size = hidden_size NEW_LINE self . bidirectional = bidirectional NEW_LINE self . rnn = rnn_type ( input_size = input_size , hidden_size = hidden_size , bidirectional = bidirectional , bias = False ) NEW_LINE self . num_directions = 2 if bidirectional else 1 NEW_LINE DEDENT',\n",
              " 'def flatten_parameters ( self ) : NEW_LINE INDENT self . rnn . flatten_parameters ( ) NEW_LINE DEDENT',\n",
              " 'def forward ( self , x ) : NEW_LINE INDENT x , _ = self . rnn ( x ) NEW_LINE if self . bidirectional : NEW_LINE INDENT x = x . view ( x . size ( 0 ) , x . size ( 1 ) , 2 , - 1 ) . sum ( 2 ) . view ( x . size ( 0 ) , x . size ( 1 ) , - 1 ) NEW_LINE DEDENT return x NEW_LINE DEDENT',\n",
              " 'def __init__ ( self , I , O , H , L = 3 , rnn_type = nn . LSTM ) : NEW_LINE INDENT super ( SpeechClassifierRNN , self ) . __init__ ( ) NEW_LINE self . I = I NEW_LINE self . H = H NEW_LINE self . L = L NEW_LINE self . rnn1 = BRNN ( input_size = H , hidden_size = H , rnn_type = rnn_type , bidirectional = True ) NEW_LINE self . rnn2 = BRNN ( input_size = H , hidden_size = H , rnn_type = rnn_type , bidirectional = True ) NEW_LINE self . rnn3 = BRNN ( input_size = H , hidden_size = H , rnn_type = rnn_type , bidirectional = True ) NEW_LINE if ( I != H ) : NEW_LINE INDENT self . first_linear = nn . Conv1d ( I , H , kernel_size = 1 , stride = 1 , padding = 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT self . first_linear = None NEW_LINE DEDENT self . final_linear = nn . Linear ( H , O ) NEW_LINE self . criterion = nn . CrossEntropyLoss ( size_average = False ) NEW_LINE DEDENT',\n",
              " 'def forward ( self , input , target ) : NEW_LINE INDENT if ( self . first_linear ) : NEW_LINE INDENT input = self . first_linear ( input ) NEW_LINE DEDENT input = input . transpose ( 1 , 2 ) . transpose ( 0 , 1 ) NEW_LINE h1 = self . rnn1 ( input ) + input NEW_LINE h2 = self . rnn2 ( h1 ) + h1 NEW_LINE h3 = self . rnn3 ( h2 ) + h2 NEW_LINE h3 = h3 . sum ( 0 ) NEW_LINE output = self . final_linear ( h3 ) NEW_LINE loss = self . criterion ( output , target ) NEW_LINE return loss NEW_LINE DEDENT',\n",
              " 'def __init__ ( self , I , H , L , nCH , mel_basis , rnn_type = nn . GRU ) : NEW_LINE INDENT super ( BRNNmultiCH , self ) . __init__ ( ) NEW_LINE self . I = I NEW_LINE self . H = H NEW_LINE self . nCH = nCH NEW_LINE self . rnn_type = rnn_type NEW_LINE self . L = L NEW_LINE self . rnn1 = BRNN ( input_size = H , hidden_size = H , rnn_type = rnn_type , bidirectional = True ) NEW_LINE self . rnn2 = BRNN ( input_size = H , hidden_size = H , rnn_type = rnn_type , bidirectional = True ) NEW_LINE if ( self . L == 3 ) : NEW_LINE INDENT self . rnn3 = BRNN ( input_size = H , hidden_size = H , rnn_type = rnn_type , bidirectional = True ) NEW_LINE DEDENT self . first_linear = nn . Conv1d ( I , H , kernel_size = 1 , stride = 1 , padding = 0 ) NEW_LINE self . final_linear_real = nn . Conv1d ( H , int ( I / 2 ) , kernel_size = 1 , stride = 1 , padding = 0 ) NEW_LINE self . final_linear_imag = nn . Conv1d ( H , int ( I / 2 ) , kernel_size = 1 , stride = 1 , padding = 0 ) NEW_LINE self . mel_basis = Variable ( torch . unsqueeze ( torch . FloatTensor ( mel_basis ) . repeat ( 1 , self . nCH ) , - 1 ) . cuda ( ) ) NEW_LINE DEDENT',\n",
              " 'def forward ( self , input ) : NEW_LINE INDENT input_linear = self . first_linear ( input ) NEW_LINE input_linear = input_linear . transpose ( 1 , 2 ) . transpose ( 0 , 1 ) NEW_LINE h1 = self . rnn1 ( input_linear ) + input_linear NEW_LINE h2 = self . rnn2 ( h1 ) + h1 NEW_LINE if ( self . L == 3 ) : NEW_LINE INDENT h3 = self . rnn3 ( h2 ) + h2 NEW_LINE h = h3 . transpose ( 0 , 1 ) . transpose ( 1 , 2 ) NEW_LINE DEDENT else : NEW_LINE INDENT h = h2 . transpose ( 0 , 1 ) . transpose ( 1 , 2 ) NEW_LINE DEDENT mask_real = self . final_linear_real ( h ) NEW_LINE mask_imag = self . final_linear_imag ( h ) NEW_LINE stft = input . view ( input . size ( 0 ) , 2 , - 1 , input . size ( - 1 ) ) NEW_LINE stft_real = stft [ : , 0 ] NEW_LINE stft_imag = stft [ : , 1 ] NEW_LINE enh_real = torch . mul ( stft_real , mask_real ) NEW_LINE enh_imag = torch . mul ( stft_imag , mask_imag ) NEW_LINE enh_power = torch . pow ( enh_real , 2 ) + torch . pow ( enh_imag , 2 ) NEW_LINE enh_mel = F . conv1d ( enh_power , self . mel_basis ) NEW_LINE output = torch . log1p ( enh_mel ) NEW_LINE return output NEW_LINE DEDENT',\n",
              " 'def __init__ ( self , I , O , H , L , rnn_type = nn . LSTM ) : NEW_LINE INDENT super ( stackedBRNN , self ) . __init__ ( ) NEW_LINE self . I = I NEW_LINE self . H = H NEW_LINE self . L = L NEW_LINE self . rnn_type = rnn_type NEW_LINE self . rnn1 = BRNN ( input_size = H , hidden_size = H , rnn_type = rnn_type , bidirectional = True ) NEW_LINE self . rnn2 = BRNN ( input_size = H , hidden_size = H , rnn_type = rnn_type , bidirectional = True ) NEW_LINE self . rnn3 = BRNN ( input_size = H , hidden_size = H , rnn_type = rnn_type , bidirectional = True ) NEW_LINE self . rnn4 = BRNN ( input_size = H , hidden_size = H , rnn_type = rnn_type , bidirectional = True ) NEW_LINE self . first_linear = nn . Conv1d ( I , H , kernel_size = 1 , stride = 1 , padding = 0 ) NEW_LINE self . final_linear = nn . Conv1d ( H , O , kernel_size = 1 , stride = 1 , padding = 0 ) NEW_LINE DEDENT',\n",
              " 'def forward ( self , input ) : NEW_LINE INDENT input_linear = self . first_linear ( input ) NEW_LINE input_linear = input_linear . transpose ( 1 , 2 ) . transpose ( 0 , 1 ) NEW_LINE h1 = self . rnn1 ( input_linear ) + input_linear NEW_LINE h2 = self . rnn2 ( h1 ) + h1 NEW_LINE h3 = self . rnn3 ( h2 ) + h2 NEW_LINE h4 = self . rnn4 ( h3 ) + h3 NEW_LINE h4 = h4 . transpose ( 0 , 1 ) . transpose ( 1 , 2 ) NEW_LINE output = self . final_linear ( h4 ) NEW_LINE return output NEW_LINE DEDENT',\n",
              " 'def forward_paired ( self , input , paired ) : NEW_LINE INDENT input = torch . cat ( ( input , paired ) , dim = 1 ) NEW_LINE output = self . forward ( input ) NEW_LINE return output NEW_LINE DEDENT',\n",
              " 'def forward_with_intermediate_output ( self , input ) : NEW_LINE INDENT input_linear = self . first_linear ( input ) NEW_LINE input_linear = input_linear . transpose ( 1 , 2 ) . transpose ( 0 , 1 ) NEW_LINE h1 = self . rnn1 ( input_linear ) + input_linear NEW_LINE h2 = self . rnn2 ( h1 ) + h1 NEW_LINE h3 = self . rnn3 ( h2 ) + h2 NEW_LINE h4 = self . rnn4 ( h3 ) + h3 NEW_LINE h4 = h4 . transpose ( 0 , 1 ) . transpose ( 1 , 2 ) NEW_LINE output = self . final_linear ( h4 ) NEW_LINE return [ output , h4 ] NEW_LINE DEDENT',\n",
              " 'def __init__ ( self , rnn_type = nn . LSTM , labels = \" abc \" , rnn_hidden_size = 512 , rnn_layers = 2 , bidirectional = True , kernel_sz = 11 , stride = 2 , map = 256 , cnn_layers = 2 , nFreq = 40 , nDownsample = 1 , audio_conf = None ) : NEW_LINE INDENT super ( DeepSpeech , self ) . __init__ ( ) NEW_LINE self . nFreq = nFreq NEW_LINE self . _version = \\'0.0.1\\' NEW_LINE self . _audio_conf = audio_conf NEW_LINE self . rnn_size = rnn_hidden_size NEW_LINE self . rnn_layers = rnn_layers NEW_LINE self . rnn_type = rnn_type NEW_LINE self . bidirectional = bidirectional NEW_LINE self . cnn_stride = stride NEW_LINE self . cnn_map = map NEW_LINE self . cnn_kernel = kernel_sz NEW_LINE self . nDownsample = nDownsample NEW_LINE self . cnn_layers = cnn_layers NEW_LINE self . _labels = labels NEW_LINE num_classes = len ( self . _labels ) NEW_LINE conv_list = [ ] NEW_LINE conv_list . append ( nn . Conv1d ( nFreq , map , kernel_size = kernel_sz , stride = stride ) ) NEW_LINE conv_list . append ( nn . BatchNorm1d ( map ) ) NEW_LINE conv_list . append ( nn . LeakyReLU ( map , inplace = True ) ) NEW_LINE if ( self . nDownsample == 1 ) : NEW_LINE INDENT stride = 1 NEW_LINE DEDENT for x in range ( self . cnn_layers - 1 ) : NEW_LINE INDENT conv_list . append ( nn . Conv1d ( map , map , kernel_size = kernel_sz , stride = stride ) ) NEW_LINE conv_list . append ( nn . BatchNorm1d ( map ) ) NEW_LINE conv_list . append ( nn . LeakyReLU ( map , inplace = True ) ) NEW_LINE DEDENT self . conv = nn . Sequential ( * conv_list ) NEW_LINE rnn_input_size = map NEW_LINE rnns = [ ] NEW_LINE rnn = BatchRNN ( input_size = rnn_input_size , hidden_size = rnn_hidden_size , rnn_type = rnn_type , bidirectional = bidirectional , batch_norm = False ) NEW_LINE rnns . append ( ( \\'0\\' , rnn ) ) NEW_LINE for x in range ( self . rnn_layers - 1 ) : NEW_LINE INDENT rnn = BatchRNN ( input_size = rnn_hidden_size , hidden_size = rnn_hidden_size , rnn_type = rnn_type , bidirectional = bidirectional ) NEW_LINE rnns . append ( ( \\' % d \\' % ( x + 1 ) , rnn ) ) NEW_LINE DEDENT self . rnns = nn . Sequential ( OrderedDict ( rnns ) ) NEW_LINE fully_connected = nn . Sequential ( nn . BatchNorm1d ( rnn_hidden_size ) , nn . Linear ( rnn_hidden_size , num_classes , bias = False ) ) NEW_LINE self . fc = nn . Sequential ( SequenceWise ( fully_connected ) , ) NEW_LINE self . inference_softmax = InferenceBatchSoftmax ( ) NEW_LINE DEDENT',\n",
              " 'def forward ( self , x ) : NEW_LINE INDENT x = self . conv ( x ) NEW_LINE x = x . transpose ( 1 , 2 ) . transpose ( 0 , 1 ) NEW_LINE x = self . rnns ( x ) NEW_LINE x = self . fc ( x ) NEW_LINE x = x . transpose ( 0 , 1 ) NEW_LINE x = self . inference_softmax ( x ) NEW_LINE return x NEW_LINE DEDENT',\n",
              " \"def weights_init ( m ) : NEW_LINE INDENT classname = m . __class__ . __name__ NEW_LINE if classname . find ( ' Conv ' ) != - 1 : NEW_LINE INDENT m . weight . data . normal_ ( 0.0 , 0.01 ) NEW_LINE DEDENT elif classname . find ( ' BatchNorm ' ) != - 1 : NEW_LINE INDENT m . weight . data . normal_ ( 1.0 , 0.01 ) NEW_LINE m . bias . data . fill_ ( 0 ) NEW_LINE DEDENT elif classname . find ( ' Embedding ' ) != - 1 : NEW_LINE INDENT m . weight . data . normal_ ( 0.0 , 0.01 ) NEW_LINE DEDENT DEDENT\",\n",
              " \"def __init__ ( self , config , data_loader = None ) : NEW_LINE INDENT self . config = config NEW_LINE self . data_loader = data_loader NEW_LINE self . lr = config . lr NEW_LINE self . beta1 = config . beta1 NEW_LINE self . beta2 = config . beta2 NEW_LINE self . optimizer = config . optimizer NEW_LINE self . batch_size = config . batch_size NEW_LINE self . diffLoss = L1Loss_mask ( ) NEW_LINE self . valmin_iter = 0 NEW_LINE self . model_dir = ' logs / ' + str ( config . expnum ) NEW_LINE self . savename_G = ' ' NEW_LINE self . savename_D = ' ' NEW_LINE self . savename_ASR = ' ' NEW_LINE self . kt = 0 NEW_LINE self . lb = self . config . lambda_k NEW_LINE self . gamma = self . config . gamma NEW_LINE self . conv_measure = 0 NEW_LINE self . dce_tr = AverageMeter ( ) NEW_LINE self . dce_tr_local = AverageMeter ( ) NEW_LINE self . dce_val = AverageMeter ( ) NEW_LINE self . adv_ny_tr = AverageMeter ( ) NEW_LINE self . adv_ny_val = AverageMeter ( ) NEW_LINE self . wer_tr = AverageMeter ( ) NEW_LINE self . wer_val = AverageMeter ( ) NEW_LINE self . cer_tr = AverageMeter ( ) NEW_LINE self . cer_val = AverageMeter ( ) NEW_LINE self . decoder = GreedyDecoder ( data_loader . labels ) NEW_LINE self . build_model ( ) NEW_LINE self . G . loss_stop = 100000 NEW_LINE if self . config . gpu >= 0 : NEW_LINE INDENT self . G . cuda ( ) NEW_LINE self . D . cuda ( ) NEW_LINE self . diffLoss . cuda ( ) NEW_LINE self . ASR . cuda ( ) NEW_LINE DEDENT if len ( self . config . load_path ) > 0 : NEW_LINE INDENT self . load_model ( ) NEW_LINE DEDENT if config . mode == ' train ' : NEW_LINE INDENT self . logFile = open ( self . model_dir + ' / log . txt ' , ' w ' ) NEW_LINE DEDENT DEDENT\",\n",
              " 'def zero_grad_all ( self ) : NEW_LINE INDENT self . G . zero_grad ( ) NEW_LINE self . D . zero_grad ( ) NEW_LINE self . ASR . zero_grad ( ) NEW_LINE DEDENT',\n",
              " \"def build_model ( self ) : NEW_LINE INDENT print ( ' initialize ▁ enhancement ▁ & ▁ discriminator ▁ model ' ) NEW_LINE self . G = stackedBRNN ( I = self . config . nFeat_in , O = self . config . nFeat_out , H = self . config . rnn_size , L = self . config . rnn_layers , rnn_type = supported_rnns [ self . config . rnn_type ] ) NEW_LINE self . D = stackedBRNN ( I = self . config . nFeat_D , O = self . config . nFeat_out , H = self . config . rnn_size , L = self . config . rnn_layers , rnn_type = supported_rnns [ self . config . rnn_type ] ) NEW_LINE print ( ' load ▁ pre - trained ▁ ASR ▁ model ' ) NEW_LINE package_ASR = torch . load ( self . config . ASR_path , map_location = lambda storage , loc : storage ) NEW_LINE self . ASR = DeepSpeech . load_model_package ( package_ASR ) NEW_LINE DEDENT\",\n",
              " 'def load_model ( self ) : NEW_LINE INDENT print ( \" [ * ] ▁ Load ▁ models ▁ from ▁ { } . . . \" . format ( self . config . load_path ) ) NEW_LINE postfix = \\' _ valmin \\' NEW_LINE paths = glob ( os . path . join ( self . config . load_path , \\' G { } * . pth \\' . format ( postfix ) ) ) NEW_LINE paths . sort ( ) NEW_LINE if len ( paths ) == 0 : NEW_LINE INDENT print ( \" [ ! ] ▁ No ▁ checkpoint ▁ found ▁ in ▁ { } . . . \" . format ( self . config . load_path ) ) NEW_LINE assert ( 0 ) , \\' checkpoint ▁ not ▁ avilable \\' NEW_LINE DEDENT idxes = [ int ( os . path . basename ( path . split ( \\' . \\' ) [ 0 ] . split ( \\' _ \\' ) [ - 1 ] ) ) for path in paths ] NEW_LINE if self . config . start_iter <= 0 : NEW_LINE INDENT self . config . start_iter = max ( idxes ) NEW_LINE if ( self . config . start_iter < 0 ) : NEW_LINE INDENT raise Exception ( \" start ▁ iter ▁ is ▁ still ▁ less ▁ than ▁ 0 ▁ - - > ▁ probably ▁ try ▁ to ▁ load ▁ initial ▁ random ▁ model \" ) NEW_LINE DEDENT DEDENT if self . config . gpu < 0 : NEW_LINE INDENT map_location = lambda storage , loc : storage NEW_LINE DEDENT else : NEW_LINE INDENT map_location = None NEW_LINE DEDENT print ( \\' Load ▁ models ▁ from ▁ \\' + self . config . load_path + \\' , ▁ ITERATION ▁ = ▁ \\' + str ( self . config . start_iter ) ) NEW_LINE self . G . load_state_dict ( torch . load ( \\' { } / G { } _ { } . pth \\' . format ( self . config . load_path , postfix , self . config . start_iter ) , map_location = map_location ) ) NEW_LINE print ( \" [ * ] ▁ Model ▁ loaded \" ) NEW_LINE DEDENT',\n",
              " 'def train ( self ) : NEW_LINE INDENT optimizer_g = torch . optim . Adam ( self . G . parameters ( ) , lr = self . config . lr , betas = ( self . beta1 , self . beta2 ) , amsgrad = True ) NEW_LINE optimizer_d = torch . optim . Adam ( self . D . parameters ( ) , lr = self . config . lr , betas = ( self . beta1 , self . beta2 ) , amsgrad = True ) NEW_LINE for iter in trange ( self . config . start_iter , self . config . max_iter ) : NEW_LINE INDENT self . zero_grad_all ( ) NEW_LINE data_list = self . data_loader . next ( cl_ny = \\' ny \\' , type = \\' train \\' ) NEW_LINE mixture , cleans , mask = _get_variable_nograd ( data_list [ 0 ] ) , _get_variable_nograd ( data_list [ 1 ] ) , _get_variable_nograd ( data_list [ 2 ] ) NEW_LINE enhanced = self . G ( mixture ) NEW_LINE enhanced_D = enhanced . detach ( ) NEW_LINE ae_ny_G = self . D . forward_paired ( enhanced , mixture ) NEW_LINE l_adv_ny_G , _ = self . diffLoss ( ae_ny_G , enhanced , mask ) NEW_LINE l_adv_ny_G = l_adv_ny_G * self . config . w_adversarial NEW_LINE l_adv_ny_G_data = l_adv_ny_G . data [ 0 ] NEW_LINE l_adv_ny_G . backward ( retain_graph = True ) NEW_LINE g_adv = self . get_gradient_norm ( self . G ) NEW_LINE self . D . zero_grad ( ) NEW_LINE del l_adv_ny_G NEW_LINE ae_ny_D = self . D . forward_paired ( enhanced_D , mixture ) NEW_LINE l_adv_ny_D , _ = self . diffLoss ( ae_ny_D , enhanced_D , mask ) NEW_LINE l_adv_ny_D = l_adv_ny_D * ( - self . kt ) * self . config . w_adversarial NEW_LINE l_adv_ny_D . backward ( ) NEW_LINE del l_adv_ny_D NEW_LINE dce , nElement = self . diffLoss ( enhanced , cleans , mask ) NEW_LINE dce_loss = dce . data [ 0 ] NEW_LINE dce_tr_local . update ( dce_loss , nElement ) NEW_LINE ae_cl = self . D ( cleans , mixture ) NEW_LINE l_adv_cl , _ = self . diffLoss ( ae_cl , cleans , mask ) NEW_LINE l_adv_cl = self . config . w_adversarial * l_adv_cl NEW_LINE l_adv_cl . backward ( ) NEW_LINE l_adv_cl_data = l_adv_cl . data [ 0 ] NEW_LINE del l_adv_cl NEW_LINE optimizer_g . step ( ) NEW_LINE optimizer_d . step ( ) NEW_LINE g_d_balance = self . gamma * l_adv_cl_data - l_adv_ny_G_data NEW_LINE self . kt += self . lb * g_d_balance NEW_LINE self . kt = max ( min ( 1 , self . kt ) , 0 ) NEW_LINE conv_measure = l_adv_cl_data + abs ( g_d_balance ) NEW_LINE if ( iter + 1 ) % self . config . log_iter == 0 : NEW_LINE INDENT str_loss = \" [ { } / { } ] ▁ ( train ) ▁ DCE : ▁ { : . 7f } , ▁ ADV _ cl : ▁ { : . 7f } , ▁ ADV _ ny : ▁ { : . 7f } \" . format ( iter , self . config . max_iter , self . dce_tr_local . avg , l_adv_cl_data , l_adv_ny_G_data ) NEW_LINE print ( str_loss ) NEW_LINE self . logFile . write ( str_loss + \\' \\\\n \\' ) NEW_LINE str_loss = \" [ { } / { } ] ▁ ( train ) ▁ conv _ measure : ▁ { : . 4f } , ▁ kt : ▁ { : . 4f } ▁ \" . format ( iter , self . config . max_iter , conv_measure , self . kt ) NEW_LINE print ( str_loss ) NEW_LINE self . logFile . write ( str_loss + \\' \\\\n \\' ) NEW_LINE self . logFile . flush ( ) NEW_LINE self . dce_tr_local . reset ( ) NEW_LINE DEDENT if ( iter + 1 ) % self . config . save_iter == 0 : NEW_LINE INDENT self . G . eval ( ) NEW_LINE self . dce_tr . reset ( ) NEW_LINE self . adv_ny_tr . reset ( ) NEW_LINE self . wer_tr . reset ( ) NEW_LINE self . cer_tr . reset ( ) NEW_LINE for _ in trange ( 0 , len ( self . data_loader . trsub_dl ) ) : NEW_LINE INDENT data_list = self . data_loader . next ( cl_ny = \\' ny \\' , type = \\' trsub \\' ) NEW_LINE mixture , cleans , mask , targets , input_percentages , target_sizes = data_list [ 0 ] , data_list [ 1 ] , _get_variable_volatile ( data_list [ 2 ] ) , data_list [ 3 ] , data_list [ 4 ] , data_list [ 5 ] NEW_LINE dce , adv_ny , nElement , wer , cer , nWord , nChar = self . greedy_decoding_and_FSEGAN ( mixture , cleans , targets , input_percentages , target_sizes , mask ) NEW_LINE self . dce_tr . update ( dce . data [ 0 ] , nElement ) NEW_LINE self . adv_ny_tr . update ( adv_ny . data [ 0 ] , nElement ) NEW_LINE self . wer_tr . update ( wer , nWord ) NEW_LINE self . cer_tr . update ( cer , nChar ) NEW_LINE del dce , adv_ny NEW_LINE DEDENT str_loss = \" [ { } / { } ] ▁ ( training ▁ subset ) ▁ CTC : ▁ { : . 7f } , ▁ WER : ▁ { : . 7f } , ▁ CER : ▁ { : . 7f } \" . format ( iter , self . config . max_iter , self . dce_tr . avg , self . wer_tr . avg * 100 , self . cer_tr . avg * 100 ) NEW_LINE print ( str_loss ) NEW_LINE self . logFile . write ( str_loss + \\' \\\\n \\' ) NEW_LINE self . dce_val . reset ( ) NEW_LINE self . adv_ny_val . reset ( ) NEW_LINE self . wer_val . reset ( ) NEW_LINE self . cer_val . reset ( ) NEW_LINE for _ in trange ( 0 , len ( self . data_loader . val_dl ) ) : NEW_LINE INDENT data_list = self . data_loader . next ( cl_ny = \\' ny \\' , type = \\' val \\' ) NEW_LINE mixture , cleans , mask , targets , input_percentages , target_sizes = data_list [ 0 ] , data_list [ 1 ] , _get_variable_volatile ( data_list [ 2 ] ) , data_list [ 3 ] , data_list [ 4 ] , data_list [ 5 ] NEW_LINE dce , adv_ny , nElement , wer , cer , nWord , nChar = self . greedy_decoding_and_FSEGAN ( mixture , cleans , targets , input_percentages , target_sizes , mask ) NEW_LINE self . dce_val . update ( dce . data [ 0 ] , nElement ) NEW_LINE self . adv_ny_val . update ( adv_ny . data [ 0 ] , nElement ) NEW_LINE self . wer_val . update ( wer , nWord ) NEW_LINE self . cer_val . update ( cer , nChar ) NEW_LINE del ctc , adv_ny NEW_LINE DEDENT str_loss = \" [ { } / { } ] ▁ ( validation ) ▁ CTC : ▁ { : . 7f } , ▁ WER : ▁ { : . 7f } , ▁ CER : ▁ { : . 7f } \" . format ( iter , self . config . max_iter , self . dce_val . avg , self . wer_val . avg * 100 , self . cer_val . avg * 100 ) NEW_LINE print ( str_loss ) NEW_LINE self . logFile . write ( str_loss + \\' \\\\n \\' ) NEW_LINE self . logFile . flush ( ) NEW_LINE self . G . train ( ) NEW_LINE if ( len ( self . savename_G ) > 0 ) : NEW_LINE INDENT if os . path . exists ( self . savename_G ) : NEW_LINE INDENT os . remove ( self . savename_G ) NEW_LINE DEDENT DEDENT self . savename_G = \\' { } / G _ { } . pth \\' . format ( self . model_dir , iter ) NEW_LINE torch . save ( self . G . state_dict ( ) , self . savename_G ) NEW_LINE if ( self . G . loss_stop > self . wer_val . avg ) : NEW_LINE INDENT self . G . loss_stop = self . wer_val . avg NEW_LINE savename_G_valmin_prev = \\' { } / G _ valmin _ { } . pth \\' . format ( self . model_dir , self . valmin_iter ) NEW_LINE if os . path . exists ( savename_G_valmin_prev ) : NEW_LINE INDENT os . remove ( savename_G_valmin_prev ) NEW_LINE DEDENT print ( \\' save ▁ model ▁ for ▁ this ▁ checkpoint \\' ) NEW_LINE savename_G_valmin = \\' { } / G _ valmin _ { } . pth \\' . format ( self . model_dir , iter ) NEW_LINE copyfile ( self . savename_G , savename_G_valmin ) NEW_LINE self . valmin_iter = iter NEW_LINE DEDENT DEDENT DEDENT DEDENT',\n",
              " \"def greedy_decoding_and_FSEGAN ( self , mixture , cleans , targets , input_percentages , target_sizes , mask , transcript_prob = 0.001 ) : NEW_LINE INDENT mixture = _get_variable_volatile ( mixture ) NEW_LINE N = inputs . size ( 0 ) NEW_LINE split_targets = [ ] NEW_LINE offset = 0 NEW_LINE for size in target_sizes : NEW_LINE INDENT split_targets . append ( targets [ offset : offset + size ] ) NEW_LINE offset += size NEW_LINE DEDENT enhanced = self . G ( mixture ) NEW_LINE prob = self . ASR ( enhanced ) NEW_LINE prob = prob . transpose ( 0 , 1 ) NEW_LINE T = prob . size ( 0 ) NEW_LINE sizes = input_percentages . mul_ ( int ( T ) ) . int ( ) NEW_LINE decoded_output , _ = self . decoder . decode ( prob . data , sizes ) NEW_LINE target_strings = self . decoder . convert_to_strings ( split_targets ) NEW_LINE we , ce , total_word , total_char = 0 , 0 , 0 , 0 NEW_LINE for x in range ( len ( target_strings ) ) : NEW_LINE INDENT decoding , reference = decoded_output [ x ] [ 0 ] , target_strings [ x ] [ 0 ] NEW_LINE nChar = len ( reference ) NEW_LINE nWord = len ( reference . split ( ) ) NEW_LINE we_i = self . decoder . wer ( decoding , reference ) NEW_LINE ce_i = self . decoder . cer ( decoding , reference ) NEW_LINE we += we_i NEW_LINE ce += ce_i NEW_LINE total_word += nWord NEW_LINE total_char += nChar NEW_LINE if ( random . uniform ( 0 , 1 ) < transcript_prob ) : NEW_LINE INDENT print ( ' reference ▁ = ▁ ' + reference ) NEW_LINE print ( ' decoding ▁ = ▁ ' + decoding ) NEW_LINE print ( ' wer ▁ = ▁ ' + str ( we_i / float ( nWord ) ) + ' , ▁ cer ▁ = ▁ ' + str ( ce_i / float ( nChar ) ) ) NEW_LINE DEDENT DEDENT wer = we / total_word NEW_LINE cer = ce / total_word NEW_LINE ae_ny = self . D . forward_paired ( enhanced , mixture ) NEW_LINE l_adv_ny , nElement = self . diffLoss ( ae_ny , enhanced , mask ) NEW_LINE l_adv_ny = l_adv_ny * self . config . w_adversarial NEW_LINE dce , nElement_ = self . diffLoss ( enhanced , cleans , mask ) NEW_LINE assert ( nElement == nElement_ ) NEW_LINE return dce , l_adv_ny , nElement , wer , cer , total_word , total_char NEW_LINE DEDENT\",\n",
              " \"def str2bool ( v ) : NEW_LINE INDENT return v . lower ( ) in ( ' true ' , '1' ) NEW_LINE DEDENT\",\n",
              " 'def add_argument_group ( name ) : NEW_LINE INDENT arg = parser . add_argument_group ( name ) NEW_LINE arg_lists . append ( arg ) NEW_LINE return arg NEW_LINE DEDENT',\n",
              " \"def get_config ( ) : NEW_LINE INDENT config , unparsed = parser . parse_known_args ( ) NEW_LINE if ( len ( unparsed ) > 0 ) : NEW_LINE INDENT print ( unparsed ) NEW_LINE assert ( len ( unparsed ) == 0 ) , ' length ▁ of ▁ unparsed ▁ option ▁ should ▁ be ▁ 0' NEW_LINE DEDENT return config , unparsed NEW_LINE DEDENT\",\n",
              " 'def random_combination ( iterable , r ) : NEW_LINE INDENT pool = tuple ( iterable ) NEW_LINE n = len ( pool ) NEW_LINE indices = sorted ( random . sample ( range ( n ) , r ) ) NEW_LINE return tuple ( pool [ i ] for i in indices ) NEW_LINE DEDENT',\n",
              " \"def check_config_used ( config , target_source ) : NEW_LINE INDENT config_count = dict ( vars ( config ) ) NEW_LINE for k in config_count . keys ( ) : NEW_LINE INDENT config_count [ k ] = 0 NEW_LINE DEDENT for source in target_source : NEW_LINE INDENT fp = open ( source , ' r ' ) NEW_LINE text = fp . read ( ) NEW_LINE for k in config_count . keys ( ) : NEW_LINE INDENT if ( text . find ( k ) >= 0 ) : NEW_LINE INDENT config_count [ k ] = 1 NEW_LINE DEDENT DEDENT fp . close ( ) NEW_LINE DEDENT config_unused = [ ] NEW_LINE for k in config_count . keys ( ) : NEW_LINE INDENT if ( config_count [ k ] == 0 ) : NEW_LINE INDENT config_unused . append ( k ) NEW_LINE DEDENT DEDENT print ( ' unused ▁ config ▁ = ▁ ' ) NEW_LINE print ( config_unused ) NEW_LINE assert ( len ( config_unused ) == 0 ) , ' unused ▁ config ▁ exists , ▁ please ▁ properly ▁ use ▁ it ▁ or ▁ comment ▁ it ' NEW_LINE DEDENT\",\n",
              " 'def to_np ( x ) : NEW_LINE INDENT return x . data . cpu ( ) . numpy ( ) NEW_LINE DEDENT',\n",
              " \"def get_weight_statistic ( M ) : NEW_LINE INDENT print ( ' Model ▁ parameter ▁ statistic ' ) NEW_LINE modules = list ( M . modules ( ) ) [ 0 ] . _modules NEW_LINE for k , v in modules . items ( ) : NEW_LINE INDENT if ( len ( v . state_dict ( ) ) > 2 ) : NEW_LINE INDENT for l in range ( len ( v ) ) : NEW_LINE INDENT layer = v [ l ] NEW_LINE if ( hasattr ( layer , ' module ' ) ) : NEW_LINE INDENT layer_m = layer . module NEW_LINE for j in range ( len ( layer_m ) ) : NEW_LINE INDENT sublayer = layer_m [ j ] NEW_LINE if ( hasattr ( sublayer , ' bias ' ) ) : NEW_LINE INDENT if ( sublayer . bias is not None ) : NEW_LINE INDENT print ( str ( sublayer ) + ' ▁ : ▁ weight ▁ = ▁ ' + str ( sublayer . weight . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( sublayer . weight . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( sublayer . weight . data . mean ( ) ) ) [ : 7 ] + ' ) ' ' , ▁ bias ▁ = ▁ ' + str ( sublayer . bias . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( sublayer . bias . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( sublayer . bias . data . mean ( ) ) ) [ : 7 ] + ' ) ' ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( str ( sublayer ) + ' ▁ : ▁ weight ▁ = ▁ ' + str ( sublayer . weight . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( sublayer . weight . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( sublayer . weight . data . mean ( ) ) ) [ : 7 ] + ' ) ' ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT print ( str ( sublayer ) + ' ▁ : ▁ weight ▁ = ▁ ' + str ( sublayer . weight . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( sublayer . weight . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( sublayer . weight . data . mean ( ) ) ) [ : 7 ] + ' ) ' ) NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT if ( hasattr ( layer , ' weight ' ) ) : NEW_LINE INDENT if ( hasattr ( layer , ' bias ' ) ) : NEW_LINE INDENT if ( hasattr ( layer . bias , ' data ' ) ) : NEW_LINE INDENT print ( str ( layer ) + ' ▁ : ▁ weight ▁ = ▁ ' + str ( layer . weight . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( layer . weight . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( layer . weight . data . mean ( ) ) ) [ : 7 ] + ' ) ' ' , ▁ bias ▁ = ▁ ' + str ( layer . bias . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( layer . bias . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( layer . bias . data . mean ( ) ) ) [ : 7 ] + ' ) ' ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT print ( str ( layer ) + ' ▁ : ▁ weight ▁ = ▁ ' + str ( layer . weight . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( layer . weight . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( layer . weight . data . mean ( ) ) ) [ : 7 ] + ' ) ' ) NEW_LINE DEDENT DEDENT if ( hasattr ( layer , ' rnn ' ) ) : NEW_LINE INDENT rnn_layer = layer . rnn NEW_LINE print ( str ( rnn_layer ) ) NEW_LINE print ( ' \\\\tweight _ hh _ l0 ▁ = ▁ ' + str ( rnn_layer . weight_hh_l0 . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( rnn_layer . weight_hh_l0 . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( rnn_layer . weight_hh_l0 . data . mean ( ) ) ) [ : 7 ] + ' ) ' ) NEW_LINE print ( ' \\\\tweight _ hh _ l0 _ reverse ▁ = ▁ ' + str ( rnn_layer . weight_hh_l0_reverse . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( rnn_layer . weight_hh_l0_reverse . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( rnn_layer . weight_hh_l0_reverse . data . mean ( ) ) ) [ : 7 ] + ' ) ' ) NEW_LINE print ( ' \\\\tweight _ ih _ l0 ▁ = ▁ ' + str ( rnn_layer . weight_ih_l0 . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( rnn_layer . weight_ih_l0 . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( rnn_layer . weight_ih_l0 . data . mean ( ) ) ) [ : 7 ] + ' ) ' ) NEW_LINE print ( ' \\\\tweight _ hh _ l0 _ reverse ▁ = ▁ ' + str ( rnn_layer . weight_hh_l0_reverse . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( rnn_layer . weight_hh_l0_reverse . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( rnn_layer . weight_hh_l0_reverse . data . mean ( ) ) ) [ : 7 ] + ' ) ' ) NEW_LINE DEDENT if ( hasattr ( layer , ' batch _ norm ' ) ) : NEW_LINE INDENT if ( layer . batch_norm ) : NEW_LINE INDENT bn_layer = layer . batch_norm . module NEW_LINE print ( str ( bn_layer ) + ' ▁ : ▁ weight ▁ = ▁ ' + str ( bn_layer . weight . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( bn_layer . weight . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( bn_layer . weight . data . mean ( ) ) ) [ : 7 ] + ' ) , ▁ bias ▁ = ▁ ' + str ( bn_layer . bias . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( bn_layer . bias . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( bn_layer . bias . data . mean ( ) ) ) [ : 7 ] + ' ) ' ) NEW_LINE DEDENT DEDENT DEDENT DEDENT DEDENT else : NEW_LINE INDENT if ( hasattr ( v , ' weight ' ) ) : NEW_LINE INDENT if ( hasattr ( v , ' bias ' ) ) : NEW_LINE INDENT print ( k + ' ▁ : ▁ weight ▁ = ▁ ' + str ( v . weight . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( v . weight . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( v . weight . data . mean ( ) ) ) [ : 7 ] + ' ) ' ' , ▁ bias ▁ = ▁ ' + str ( v . bias . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( v . bias . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( v . bias . data . mean ( ) ) ) [ : 7 ] + ' ) ' ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( k + ' ▁ : ▁ weight ▁ = ▁ ' + str ( v . weight . data . min ( ) ) [ : 5 ] + ' ▁ ~ ▁ ' + str ( v . weight . data . max ( ) ) [ : 5 ] + ' ▁ ( ' + str ( decimal . Decimal ( v . weight . data . mean ( ) ) ) [ : 7 ] + ' ) ' ) NEW_LINE DEDENT DEDENT DEDENT print ( ' ▁ ' ) NEW_LINE print ( ' ▁ ' ) NEW_LINE DEDENT DEDENT\",\n",
              " \"def weights_init ( m ) : NEW_LINE INDENT classname = m . __class__ . __name__ NEW_LINE if classname . find ( ' Conv ' ) != - 1 and classname . find ( ' ConvResidualBlock ' ) == - 1 : NEW_LINE INDENT m . weight . data . normal_ ( 0.0 , 0.1 ) NEW_LINE if hasattr ( m , ' bias ' ) : NEW_LINE INDENT if ( hasattr ( m . bias , ' data ' ) ) : NEW_LINE INDENT m . bias . data . fill_ ( 0 ) NEW_LINE DEDENT DEDENT DEDENT elif classname . find ( ' BatchNorm ' ) != - 1 : NEW_LINE INDENT m . weight . data . normal_ ( 1.0 , 0.01 ) NEW_LINE m . bias . data . fill_ ( 0 ) NEW_LINE DEDENT elif classname . find ( ' Embedding ' ) != - 1 : NEW_LINE INDENT m . weight . data . normal_ ( 0.0 , 0.01 ) NEW_LINE DEDENT DEDENT\",\n",
              " 'def _get_variable ( inputs , cuda = True ) : NEW_LINE INDENT if ( cuda ) : NEW_LINE INDENT out = Variable ( inputs . cuda ( ) ) NEW_LINE DEDENT else : NEW_LINE INDENT out = Variable ( inputs ) NEW_LINE DEDENT return out NEW_LINE DEDENT',\n",
              " 'def _get_variable_volatile ( inputs , cuda = True ) : NEW_LINE INDENT if ( cuda ) : NEW_LINE INDENT out = Variable ( inputs . cuda ( ) , volatile = True ) NEW_LINE DEDENT else : NEW_LINE INDENT out = Variable ( inputs , volatile = True ) NEW_LINE DEDENT return out NEW_LINE DEDENT',\n",
              " 'def _get_variable_nograd ( inputs , cuda = True ) : NEW_LINE INDENT if ( cuda ) : NEW_LINE INDENT out = Variable ( inputs . cuda ( ) , requires_grad = False ) NEW_LINE DEDENT else : NEW_LINE INDENT out = Variable ( inputs , requires_grad = False ) NEW_LINE DEDENT return out NEW_LINE DEDENT',\n",
              " 'def __init__ ( self ) : NEW_LINE INDENT self . reset ( ) NEW_LINE DEDENT',\n",
              " 'def reset ( self ) : NEW_LINE INDENT self . val = 0 NEW_LINE self . avg = 0 NEW_LINE self . sum = 0 NEW_LINE self . count = 0 NEW_LINE DEDENT',\n",
              " 'def update ( self , val , n = 1 ) : NEW_LINE INDENT self . val = val NEW_LINE self . sum += val * n NEW_LINE self . count += n NEW_LINE self . avg = self . sum / self . count NEW_LINE DEDENT',\n",
              " 'def decode_dataset ( logits , test_dataset , batch_size , lm_alpha , lm_beta , mesh_x , mesh_y , labels ) : NEW_LINE INDENT print ( \" Beginning ▁ decode ▁ for ▁ { } , ▁ { } \" . format ( lm_alpha , lm_beta ) ) NEW_LINE test_loader = FeatLoader ( test_dataset , batch_size = batch_size , num_workers = 0 ) NEW_LINE target_decoder = GreedyDecoder ( labels , blank_index = labels . index ( \\' _ \\' ) ) NEW_LINE decoder = BeamCTCDecoder ( labels , beam_width = args . beam_width , cutoff_top_n = args . cutoff_top_n , blank_index = labels . index ( \\' _ \\' ) , lm_path = args . lm_path , alpha = lm_alpha , beta = lm_beta , num_processes = 1 ) NEW_LINE total_cer , total_wer = 0 , 0 NEW_LINE for i , ( data ) in enumerate ( test_loader ) : NEW_LINE INDENT inputs , targets , input_percentages , target_sizes = data NEW_LINE split_targets = [ ] NEW_LINE offset = 0 NEW_LINE for size in target_sizes : NEW_LINE INDENT split_targets . append ( targets [ offset : offset + size ] ) NEW_LINE offset += size NEW_LINE DEDENT out = torch . from_numpy ( logits [ i ] [ 0 ] ) NEW_LINE sizes = torch . from_numpy ( logits [ i ] [ 1 ] ) NEW_LINE decoded_output , _ = decoder . decode ( out , sizes ) NEW_LINE target_strings = target_decoder . convert_to_strings ( split_targets ) NEW_LINE wer , cer = 0 , 0 NEW_LINE for x in range ( len ( target_strings ) ) : NEW_LINE INDENT transcript , reference = decoded_output [ x ] [ 0 ] , target_strings [ x ] [ 0 ] NEW_LINE wer_inst = decoder . wer ( transcript , reference ) / float ( len ( reference . split ( ) ) ) NEW_LINE cer_inst = decoder . cer ( transcript , reference ) / float ( len ( reference ) ) NEW_LINE wer += wer_inst NEW_LINE cer += cer_inst NEW_LINE if ( random . uniform ( 0 , 1 ) < float ( args . detail_log_print_prob ) ) : NEW_LINE INDENT print ( \\' decoding ▁ : ▁ \\' + transcript ) NEW_LINE print ( \\' reference ▁ : ▁ \\' + reference ) NEW_LINE print ( \\' WER ▁ = ▁ \\' + str ( wer_inst ) + \\' , ▁ CER ▁ = ▁ \\' + str ( cer_inst ) ) NEW_LINE print ( \\' ▁ \\' ) NEW_LINE logger . error ( \\' decoding ▁ : ▁ \\' + transcript ) NEW_LINE logger . error ( \\' reference ▁ : ▁ \\' + reference ) NEW_LINE logger . error ( \\' WER ▁ = ▁ \\' + str ( wer_inst ) + \\' , ▁ CER ▁ = ▁ \\' + str ( cer_inst ) ) NEW_LINE logger . error ( \\' ▁ \\' ) NEW_LINE DEDENT DEDENT total_cer += cer NEW_LINE total_wer += wer NEW_LINE DEDENT wer = total_wer / len ( test_loader . dataset ) NEW_LINE cer = total_cer / len ( test_loader . dataset ) NEW_LINE return [ mesh_x , mesh_y , lm_alpha , lm_beta , wer , cer ] NEW_LINE DEDENT',\n",
              " 'def getWER ( item ) : NEW_LINE INDENT return item [ 5 ] NEW_LINE DEDENT',\n",
              " 'def result_callback ( result ) : NEW_LINE INDENT results . append ( result ) NEW_LINE DEDENT',\n",
              " \"def __init__ ( self , labels , blank_index = 0 ) : NEW_LINE INDENT self . labels = labels NEW_LINE self . int_to_char = dict ( [ ( i , c ) for ( i , c ) in enumerate ( labels ) ] ) NEW_LINE self . blank_index = blank_index NEW_LINE space_index = len ( labels ) NEW_LINE if ' ▁ ' in labels : NEW_LINE INDENT space_index = labels . index ( ' ▁ ' ) NEW_LINE DEDENT self . space_index = space_index NEW_LINE DEDENT\",\n",
              " \"def wer ( self , s1 , s2 ) : NEW_LINE INDENT b = set ( s1 . split ( ) + s2 . split ( ) ) NEW_LINE word2char = dict ( zip ( b , range ( len ( b ) ) ) ) NEW_LINE w1 = [ chr ( word2char [ w ] ) for w in s1 . split ( ) ] NEW_LINE w2 = [ chr ( word2char [ w ] ) for w in s2 . split ( ) ] NEW_LINE return Lev . distance ( ' ' . join ( w1 ) , ' ' . join ( w2 ) ) NEW_LINE DEDENT\",\n",
              " \"def cer ( self , s1 , s2 ) : NEW_LINE INDENT s1 , s2 , = s1 . replace ( ' ▁ ' , ' ' ) , s2 . replace ( ' ▁ ' , ' ' ) NEW_LINE return Lev . distance ( s1 , s2 ) NEW_LINE DEDENT\",\n",
              " 'def decode ( self , probs , sizes = None ) : NEW_LINE INDENT raise NotImplementedError NEW_LINE DEDENT',\n",
              " 'def __init__ ( self , labels , lm_path = None , alpha = 0 , beta = 0 , cutoff_top_n = 40 , cutoff_prob = 1.0 , beam_width = 100 , num_processes = 4 , blank_index = 0 ) : NEW_LINE INDENT super ( BeamCTCDecoder , self ) . __init__ ( labels ) NEW_LINE try : NEW_LINE INDENT from ctcdecode import CTCBeamDecoder NEW_LINE DEDENT except ImportError : NEW_LINE INDENT raise ImportError ( \" BeamCTCDecoder ▁ requires ▁ paddledecoder ▁ package . \" ) NEW_LINE DEDENT self . _decoder = CTCBeamDecoder ( labels , lm_path , alpha , beta , cutoff_top_n , cutoff_prob , beam_width , num_processes , blank_index ) NEW_LINE DEDENT',\n",
              " \"def convert_to_strings ( self , out , seq_len ) : NEW_LINE INDENT results = [ ] NEW_LINE for b , batch in enumerate ( out ) : NEW_LINE INDENT utterances = [ ] NEW_LINE for p , utt in enumerate ( batch ) : NEW_LINE INDENT size = seq_len [ b ] [ p ] NEW_LINE if size > 0 : NEW_LINE INDENT transcript = ' ' . join ( map ( lambda x : self . int_to_char [ x ] , utt [ 0 : size ] ) ) NEW_LINE DEDENT else : NEW_LINE INDENT transcript = ' ' NEW_LINE DEDENT utterances . append ( transcript ) NEW_LINE DEDENT results . append ( utterances ) NEW_LINE DEDENT return results NEW_LINE DEDENT\",\n",
              " 'def convert_tensor ( self , offsets , sizes ) : NEW_LINE INDENT results = [ ] NEW_LINE for b , batch in enumerate ( offsets ) : NEW_LINE INDENT utterances = [ ] NEW_LINE for p , utt in enumerate ( batch ) : NEW_LINE INDENT size = sizes [ b ] [ p ] NEW_LINE if sizes [ b ] [ p ] > 0 : NEW_LINE INDENT utterances . append ( utt [ 0 : size ] ) NEW_LINE DEDENT else : NEW_LINE INDENT utterances . append ( torch . IntTensor ( ) ) NEW_LINE DEDENT DEDENT results . append ( utterances ) NEW_LINE DEDENT return results NEW_LINE DEDENT',\n",
              " 'def decode ( self , probs , sizes = None ) : NEW_LINE INDENT probs = probs . cpu ( ) . transpose ( 0 , 1 ) . contiguous ( ) NEW_LINE out , scores , offsets , seq_lens = self . _decoder . decode ( probs ) NEW_LINE strings = self . convert_to_strings ( out , seq_lens ) NEW_LINE offsets = self . convert_tensor ( offsets , seq_lens ) NEW_LINE return strings , offsets NEW_LINE DEDENT',\n",
              " 'def __init__ ( self , labels , blank_index = 0 ) : NEW_LINE INDENT super ( GreedyDecoder , self ) . __init__ ( labels , blank_index ) NEW_LINE DEDENT',\n",
              " \"def process_string ( self , sequence , size , remove_repetitions = False ) : NEW_LINE INDENT string = ' ' NEW_LINE offsets = [ ] NEW_LINE for i in range ( size ) : NEW_LINE INDENT if ( sequence [ i ] != self . blank_index ) : NEW_LINE INDENT char = self . int_to_char [ sequence [ i ] ] NEW_LINE if remove_repetitions and i != 0 and char == self . int_to_char [ sequence [ i - 1 ] ] : NEW_LINE INDENT pass NEW_LINE DEDENT elif char == self . labels [ self . space_index ] : NEW_LINE INDENT string += ' ▁ ' NEW_LINE offsets . append ( i ) NEW_LINE DEDENT else : NEW_LINE INDENT string = string + char NEW_LINE offsets . append ( i ) NEW_LINE DEDENT DEDENT DEDENT return string , torch . IntTensor ( offsets ) NEW_LINE DEDENT\",\n",
              " 'def decode ( self , probs , sizes = None ) : NEW_LINE INDENT _ , max_probs = torch . max ( probs . transpose ( 0 , 1 ) , 2 ) NEW_LINE strings , offsets = self . convert_to_strings ( max_probs . view ( max_probs . size ( 0 ) , max_probs . size ( 1 ) ) , sizes , remove_repetitions = True , return_offsets = True ) NEW_LINE return strings , offsets NEW_LINE DEDENT',\n",
              " \"def str2bool ( v ) : NEW_LINE INDENT return v . lower ( ) in ( ' true ' , '1' ) NEW_LINE DEDENT\",\n",
              " \"def str2bool ( v ) : NEW_LINE INDENT return v . lower ( ) in ( ' true ' , '1' ) NEW_LINE DEDENT\",\n",
              " \"def load_model ( cls , path , gpu = - 1 ) : NEW_LINE INDENT package = torch . load ( path , map_location = lambda storage , loc : storage ) NEW_LINE model = cls ( rnn_hidden_size = package [ ' rnn _ size ' ] , rnn_layers = package [ ' rnn _ layers ' ] , rnn_type = supported_rnns [ package [ ' rnn _ type ' ] ] , map = package [ ' cnn _ map ' ] , stride = package [ ' cnn _ stride ' ] , kernel_sz = package [ ' cnn _ kernel ' ] , cnn_layers = package [ ' cnn _ layers ' ] , labels = package [ ' labels ' ] ) NEW_LINE blacklist = [ ' rnns . 0 . batch _ norm . module . weight ' , ' rnns . 0 . batch _ norm . module . bias ' , ' rnns . 0 . batch _ norm . module . running _ mean ' , ' rnns . 0 . batch _ norm . module . running _ var ' ] NEW_LINE for x in blacklist : NEW_LINE INDENT if x in package [ ' state _ dict ' ] : NEW_LINE INDENT del package [ ' state _ dict ' ] [ x ] NEW_LINE DEDENT DEDENT model . load_state_dict ( package [ ' state _ dict ' ] ) NEW_LINE for x in model . rnns : NEW_LINE INDENT x . flatten_parameters ( ) NEW_LINE DEDENT if gpu >= 0 : NEW_LINE INDENT model = model . cuda ( ) NEW_LINE DEDENT return model NEW_LINE DEDENT\",\n",
              " \"def load_model_package ( cls , package , gpu = - 1 ) : NEW_LINE INDENT model = cls ( rnn_hidden_size = package [ ' rnn _ size ' ] , rnn_layers = package [ ' rnn _ layers ' ] , rnn_type = supported_rnns [ package [ ' rnn _ type ' ] ] , map = package [ ' cnn _ map ' ] , stride = package [ ' cnn _ stride ' ] , kernel_sz = package [ ' cnn _ kernel ' ] , cnn_layers = package [ ' cnn _ layers ' ] , labels = package [ ' labels ' ] , ) NEW_LINE model . load_state_dict ( package [ ' state _ dict ' ] ) NEW_LINE if ( gpu >= 0 ) : NEW_LINE INDENT model = model . cuda ( ) NEW_LINE DEDENT return model NEW_LINE DEDENT\",\n",
              " \"def serialize ( model , optimizer = None , epoch = None , iteration = None , loss_results = None , cer_results = None , wer_results = None , avg_loss = None , meta = None ) : NEW_LINE INDENT package = { ' version ' : model . _version , ' rnn _ size ' : model . rnn_size , ' rnn _ layers ' : model . rnn_layers , ' cnn _ map ' : model . cnn_map , ' cnn _ kernel ' : model . cnn_kernel , ' cnn _ stride ' : model . cnn_stride , ' cnn _ layers ' : model . cnn_layers , ' rnn _ type ' : supported_rnns_inv . get ( model . rnn_type , model . rnn_type . __name__ . lower ( ) ) , ' labels ' : model . _labels , ' state _ dict ' : model . state_dict ( ) } NEW_LINE if optimizer is not None : NEW_LINE INDENT package [ ' optim _ dict ' ] = optimizer . state_dict ( ) NEW_LINE DEDENT if avg_loss is not None : NEW_LINE INDENT package [ ' avg _ loss ' ] = avg_loss NEW_LINE DEDENT if epoch is not None : NEW_LINE INDENT package [ ' epoch ' ] = epoch + 1 NEW_LINE DEDENT if iteration is not None : NEW_LINE INDENT package [ ' iteration ' ] = iteration NEW_LINE DEDENT if loss_results is not None : NEW_LINE INDENT package [ ' loss _ results ' ] = loss_results NEW_LINE package [ ' cer _ results ' ] = cer_results NEW_LINE package [ ' wer _ results ' ] = wer_results NEW_LINE DEDENT if meta is not None : NEW_LINE INDENT package [ ' meta ' ] = meta NEW_LINE DEDENT return package NEW_LINE DEDENT\",\n",
              " 'def get_labels ( model ) : NEW_LINE INDENT return model . _labels NEW_LINE DEDENT',\n",
              " 'def get_param_size ( model ) : NEW_LINE INDENT params = 0 NEW_LINE for p in model . parameters ( ) : NEW_LINE INDENT tmp = 1 NEW_LINE for x in p . size ( ) : NEW_LINE INDENT tmp *= x NEW_LINE DEDENT params += tmp NEW_LINE DEDENT return params NEW_LINE DEDENT',\n",
              " 'def get_audio_conf ( model ) : NEW_LINE INDENT return model . _audio_conf NEW_LINE DEDENT',\n",
              " 'def get_meta ( model ) : NEW_LINE INDENT model_is_cuda = next ( model . parameters ( ) ) . is_cuda NEW_LINE m = model . module if model_is_cuda else model NEW_LINE meta = { \" version \" : m . _version , \" rnn _ size \" : m . rnn_size , \" rnn _ layers \" : m . rnn_layers , \" cnn _ map \" : m . cnn_map , \" cnn _ kernel \" : m . cnn_kernel , \" cnn _ stride \" : m . cnn_stride , \" cnn _ layers \" : m . cnn_layers , \" rnn _ type \" : supported_rnns_inv [ m . rnn_type ] } NEW_LINE return meta NEW_LINE DEDENT',\n",
              " \"def load_model ( cls , path , gpu = - 1 ) : NEW_LINE INDENT package = torch . load ( path , map_location = lambda storage , loc : storage ) NEW_LINE model = cls ( rnn_hidden_size = package [ ' rnn _ size ' ] , rnn_layers = package [ ' rnn _ layers ' ] , rnn_type = supported_rnns [ package [ ' rnn _ type ' ] ] , map = package [ ' cnn _ map ' ] , stride = package [ ' cnn _ stride ' ] , kernel_sz = package [ ' cnn _ kernel ' ] , cnn_layers = package [ ' cnn _ layers ' ] , labels = package [ ' labels ' ] ) NEW_LINE blacklist = [ ' rnns . 0 . batch _ norm . module . weight ' , ' rnns . 0 . batch _ norm . module . bias ' , ' rnns . 0 . batch _ norm . module . running _ mean ' , ' rnns . 0 . batch _ norm . module . running _ var ' ] NEW_LINE for x in blacklist : NEW_LINE INDENT if x in package [ ' state _ dict ' ] : NEW_LINE INDENT del package [ ' state _ dict ' ] [ x ] NEW_LINE DEDENT DEDENT model . load_state_dict ( package [ ' state _ dict ' ] ) NEW_LINE for x in model . rnns : NEW_LINE INDENT x . flatten_parameters ( ) NEW_LINE DEDENT if gpu >= 0 : NEW_LINE INDENT model = model . cuda ( ) NEW_LINE DEDENT return model NEW_LINE DEDENT\",\n",
              " \"def load_model_package ( cls , package , gpu = - 1 ) : NEW_LINE INDENT model = cls ( rnn_hidden_size = package [ ' rnn _ size ' ] , rnn_layers = package [ ' rnn _ layers ' ] , rnn_type = supported_rnns [ package [ ' rnn _ type ' ] ] , map = package [ ' cnn _ map ' ] , stride = package [ ' cnn _ stride ' ] , kernel_sz = package [ ' cnn _ kernel ' ] , cnn_layers = package [ ' cnn _ layers ' ] , labels = package [ ' labels ' ] , ) NEW_LINE model . load_state_dict ( package [ ' state _ dict ' ] ) NEW_LINE if ( gpu >= 0 ) : NEW_LINE INDENT model = model . cuda ( ) NEW_LINE DEDENT return model NEW_LINE DEDENT\",\n",
              " \"def serialize ( model , optimizer = None , epoch = None , iteration = None , loss_results = None , cer_results = None , wer_results = None , avg_loss = None , param_norm = None , param_max = None , grad_norm = None , grad_max = None , meta = None ) : NEW_LINE INDENT package = { ' version ' : model . _version , ' rnn _ size ' : model . rnn_size , ' rnn _ layers ' : model . rnn_layers , ' cnn _ map ' : model . cnn_map , ' cnn _ kernel ' : model . cnn_kernel , ' cnn _ stride ' : model . cnn_stride , ' cnn _ layers ' : model . cnn_layers , ' rnn _ type ' : supported_rnns_inv . get ( model . rnn_type , model . rnn_type . __name__ . lower ( ) ) , ' labels ' : model . _labels , ' state _ dict ' : model . state_dict ( ) } NEW_LINE if optimizer is not None : NEW_LINE INDENT package [ ' optim _ dict ' ] = optimizer . state_dict ( ) NEW_LINE DEDENT if avg_loss is not None : NEW_LINE INDENT package [ ' avg _ loss ' ] = avg_loss NEW_LINE DEDENT if epoch is not None : NEW_LINE INDENT package [ ' epoch ' ] = epoch + 1 NEW_LINE DEDENT if iteration is not None : NEW_LINE INDENT package [ ' iteration ' ] = iteration NEW_LINE DEDENT if loss_results is not None : NEW_LINE INDENT package [ ' loss _ results ' ] = loss_results NEW_LINE package [ ' cer _ results ' ] = cer_results NEW_LINE package [ ' wer _ results ' ] = wer_results NEW_LINE package [ ' param _ norm ' ] = param_norm NEW_LINE package [ ' param _ max ' ] = param_max NEW_LINE package [ ' grad _ norm ' ] = grad_norm NEW_LINE package [ ' grad _ max ' ] = grad_max NEW_LINE DEDENT if meta is not None : NEW_LINE INDENT package [ ' meta ' ] = meta NEW_LINE DEDENT return package NEW_LINE DEDENT\",\n",
              " 'def get_labels ( model ) : NEW_LINE INDENT return model . _labels NEW_LINE DEDENT',\n",
              " 'def get_param_size ( model ) : NEW_LINE INDENT params = 0 NEW_LINE for p in model . parameters ( ) : NEW_LINE INDENT tmp = 1 NEW_LINE for x in p . size ( ) : NEW_LINE INDENT tmp *= x NEW_LINE DEDENT params += tmp NEW_LINE DEDENT return params NEW_LINE DEDENT',\n",
              " 'def get_audio_conf ( model ) : NEW_LINE INDENT return model . _audio_conf NEW_LINE DEDENT',\n",
              " 'def get_meta ( model ) : NEW_LINE INDENT model_is_cuda = next ( model . parameters ( ) ) . is_cuda NEW_LINE m = model . module if model_is_cuda else model NEW_LINE meta = { \" version \" : m . _version , \" rnn _ size \" : m . rnn_size , \" rnn _ layers \" : m . rnn_layers , \" cnn _ map \" : m . cnn_map , \" cnn _ kernel \" : m . cnn_kernel , \" cnn _ stride \" : m . cnn_stride , \" cnn _ layers \" : m . cnn_layers , \" rnn _ type \" : supported_rnns_inv [ m . rnn_type ] } NEW_LINE return meta NEW_LINE DEDENT',\n",
              " \"def load_model ( cls , path , gpu = - 1 ) : NEW_LINE INDENT package = torch . load ( path , map_location = lambda storage , loc : storage ) NEW_LINE model = cls ( rnn_hidden_size = package [ ' rnn _ size ' ] , rnn_layers = package [ ' rnn _ layers ' ] , rnn_type = supported_rnns [ package [ ' rnn _ type ' ] ] , map = package [ ' cnn _ map ' ] , stride = package [ ' cnn _ stride ' ] , kernel_sz = package [ ' cnn _ kernel ' ] , cnn_residual_blocks = package [ ' cnn _ residual _ blocks ' ] , labels = package [ ' labels ' ] ) NEW_LINE blacklist = [ ' rnns . 0 . batch _ norm . module . weight ' , ' rnns . 0 . batch _ norm . module . bias ' , ' rnns . 0 . batch _ norm . module . running _ mean ' , ' rnns . 0 . batch _ norm . module . running _ var ' ] NEW_LINE for x in blacklist : NEW_LINE INDENT if x in package [ ' state _ dict ' ] : NEW_LINE INDENT del package [ ' state _ dict ' ] [ x ] NEW_LINE DEDENT DEDENT model . load_state_dict ( package [ ' state _ dict ' ] ) NEW_LINE for x in model . rnns : NEW_LINE INDENT x . flatten_parameters ( ) NEW_LINE DEDENT if gpu >= 0 : NEW_LINE INDENT model = model . cuda ( ) NEW_LINE DEDENT return model NEW_LINE DEDENT\",\n",
              " \"def load_model_package ( cls , package , gpu = - 1 ) : NEW_LINE INDENT model = cls ( rnn_hidden_size = package [ ' rnn _ size ' ] , rnn_layers = package [ ' rnn _ layers ' ] , rnn_type = supported_rnns [ package [ ' rnn _ type ' ] ] , map = package [ ' cnn _ map ' ] , stride = package [ ' cnn _ stride ' ] , kernel_sz = package [ ' cnn _ kernel ' ] , cnn_residual_blocks = package [ ' cnn _ residual _ blocks ' ] , labels = package [ ' labels ' ] , ) NEW_LINE model . load_state_dict ( package [ ' state _ dict ' ] ) NEW_LINE if ( gpu >= 0 ) : NEW_LINE INDENT model = model . cuda ( ) NEW_LINE DEDENT return model NEW_LINE DEDENT\",\n",
              " \"def serialize ( model , optimizer = None , epoch = None , iteration = None , loss_results = None , cer_results = None , wer_results = None , avg_loss = None , meta = None ) : NEW_LINE INDENT package = { ' version ' : model . _version , ' rnn _ size ' : model . rnn_size , ' rnn _ layers ' : model . rnn_layers , ' cnn _ map ' : model . cnn_map , ' cnn _ kernel ' : model . cnn_kernel , ' cnn _ stride ' : model . cnn_stride , ' cnn _ residual _ blocks ' : model . cnn_residual_blocks , ' rnn _ type ' : supported_rnns_inv . get ( model . rnn_type , model . rnn_type . __name__ . lower ( ) ) , ' labels ' : model . _labels , ' state _ dict ' : model . state_dict ( ) } NEW_LINE if optimizer is not None : NEW_LINE INDENT package [ ' optim _ dict ' ] = optimizer . state_dict ( ) NEW_LINE DEDENT if avg_loss is not None : NEW_LINE INDENT package [ ' avg _ loss ' ] = avg_loss NEW_LINE DEDENT if epoch is not None : NEW_LINE INDENT package [ ' epoch ' ] = epoch + 1 NEW_LINE DEDENT if iteration is not None : NEW_LINE INDENT package [ ' iteration ' ] = iteration NEW_LINE DEDENT if loss_results is not None : NEW_LINE INDENT package [ ' loss _ results ' ] = loss_results NEW_LINE package [ ' cer _ results ' ] = cer_results NEW_LINE package [ ' wer _ results ' ] = wer_results NEW_LINE DEDENT if meta is not None : NEW_LINE INDENT package [ ' meta ' ] = meta NEW_LINE DEDENT return package NEW_LINE DEDENT\",\n",
              " 'def get_labels ( model ) : NEW_LINE INDENT return model . _labels NEW_LINE DEDENT',\n",
              " 'def get_param_size ( model ) : NEW_LINE INDENT params = 0 NEW_LINE for p in model . parameters ( ) : NEW_LINE INDENT tmp = 1 NEW_LINE for x in p . size ( ) : NEW_LINE INDENT tmp *= x NEW_LINE DEDENT params += tmp NEW_LINE DEDENT return params NEW_LINE DEDENT',\n",
              " 'def get_audio_conf ( model ) : NEW_LINE INDENT return model . _audio_conf NEW_LINE DEDENT',\n",
              " 'def get_meta ( model ) : NEW_LINE INDENT model_is_cuda = next ( model . parameters ( ) ) . is_cuda NEW_LINE m = model . module if model_is_cuda else model NEW_LINE meta = { \" version \" : m . _version , \" rnn _ size \" : m . rnn_size , \" rnn _ layers \" : m . rnn_layers , \" cnn _ map \" : m . cnn_map , \" cnn _ kernel \" : m . cnn_kernel , \" cnn _ stride \" : m . cnn_stride , \" cnn _ layers \" : m . cnn_layers , \" rnn _ type \" : supported_rnns_inv [ m . rnn_type ] } NEW_LINE return meta NEW_LINE DEDENT',\n",
              " \"def load_model ( cls , path , gpu = - 1 ) : NEW_LINE INDENT package = torch . load ( path , map_location = lambda storage , loc : storage ) NEW_LINE model = cls ( map = package [ ' cnn _ map ' ] , stride = package [ ' cnn _ stride ' ] , kernel_sz = package [ ' cnn _ kernel ' ] , labels = package [ ' labels ' ] ) NEW_LINE model . load_state_dict ( package [ ' state _ dict ' ] ) NEW_LINE for x in model . rnns : NEW_LINE INDENT x . flatten_parameters ( ) NEW_LINE DEDENT if gpu >= 0 : NEW_LINE INDENT model = model . cuda ( ) NEW_LINE DEDENT return model NEW_LINE DEDENT\",\n",
              " \"def load_model_package ( cls , package , gpu = - 1 ) : NEW_LINE INDENT model = cls ( map = package [ ' cnn _ map ' ] , stride = package [ ' cnn _ stride ' ] , kernel_sz = package [ ' cnn _ kernel ' ] , labels = package [ ' labels ' ] , ) NEW_LINE model . load_state_dict ( package [ ' state _ dict ' ] ) NEW_LINE if ( gpu >= 0 ) : NEW_LINE INDENT model = model . cuda ( ) NEW_LINE DEDENT return model NEW_LINE DEDENT\",\n",
              " \"def serialize ( model , optimizer = None , epoch = None , iteration = None , loss_results = None , cer_results = None , wer_results = None , avg_loss = None , meta = None ) : NEW_LINE INDENT package = { ' version ' : model . _version , ' cnn _ map ' : model . cnn_map , ' cnn _ kernel ' : model . cnn_kernel , ' cnn _ stride ' : model . cnn_stride , ' labels ' : model . _labels , ' state _ dict ' : model . state_dict ( ) } NEW_LINE if optimizer is not None : NEW_LINE INDENT package [ ' optim _ dict ' ] = optimizer . state_dict ( ) NEW_LINE DEDENT if avg_loss is not None : NEW_LINE INDENT package [ ' avg _ loss ' ] = avg_loss NEW_LINE DEDENT if epoch is not None : NEW_LINE INDENT package [ ' epoch ' ] = epoch + 1 NEW_LINE DEDENT if iteration is not None : NEW_LINE INDENT package [ ' iteration ' ] = iteration NEW_LINE DEDENT if loss_results is not None : NEW_LINE INDENT package [ ' loss _ results ' ] = loss_results NEW_LINE package [ ' cer _ results ' ] = cer_results NEW_LINE package [ ' wer _ results ' ] = wer_results NEW_LINE DEDENT if meta is not None : NEW_LINE INDENT package [ ' meta ' ] = meta NEW_LINE DEDENT return package NEW_LINE DEDENT\",\n",
              " 'def get_labels ( model ) : NEW_LINE INDENT return model . _labels NEW_LINE DEDENT',\n",
              " 'def get_param_size ( model ) : NEW_LINE INDENT params = 0 NEW_LINE for p in model . parameters ( ) : NEW_LINE INDENT tmp = 1 NEW_LINE for x in p . size ( ) : NEW_LINE INDENT tmp *= x NEW_LINE DEDENT params += tmp NEW_LINE DEDENT return params NEW_LINE DEDENT',\n",
              " 'def get_audio_conf ( model ) : NEW_LINE INDENT return model . _audio_conf NEW_LINE DEDENT',\n",
              " 'def get_meta ( model ) : NEW_LINE INDENT model_is_cuda = next ( model . parameters ( ) ) . is_cuda NEW_LINE m = model . module if model_is_cuda else model NEW_LINE meta = { \" version \" : m . _version , \" cnn _ map \" : m . cnn_map , \" cnn _ kernel \" : m . cnn_kernel , \" cnn _ stride \" : m . cnn_stride , \" cnn _ layers \" : m . cnn_layers , } NEW_LINE return meta NEW_LINE DEDENT',\n",
              " 'def __init__ ( self , module ) : NEW_LINE INDENT super ( SequenceWise , self ) . __init__ ( ) NEW_LINE self . module = module NEW_LINE DEDENT',\n",
              " 'def forward ( self , x ) : NEW_LINE INDENT t , n = x . size ( 0 ) , x . size ( 1 ) NEW_LINE x = x . view ( t * n , - 1 ) NEW_LINE x = self . module ( x ) NEW_LINE x = x . view ( t , n , - 1 ) NEW_LINE return x NEW_LINE DEDENT',\n",
              " \"def __repr__ ( self ) : NEW_LINE INDENT tmpstr = self . __class__ . __name__ + ' ▁ ( \\\\n ' NEW_LINE tmpstr += self . module . __repr__ ( ) NEW_LINE tmpstr += ' ) ' NEW_LINE return tmpstr NEW_LINE DEDENT\",\n",
              " 'def forward ( self , input_ ) : NEW_LINE INDENT if not self . training : NEW_LINE INDENT return F . softmax ( input_ , dim = - 1 ) NEW_LINE DEDENT else : NEW_LINE INDENT return input_ NEW_LINE DEDENT DEDENT',\n",
              " 'def __init__ ( self , input_size , hidden_size , rnn_type = nn . LSTM , bidirectional = False , batch_norm = True ) : NEW_LINE INDENT super ( BatchRNN , self ) . __init__ ( ) NEW_LINE self . input_size = input_size NEW_LINE self . hidden_size = hidden_size NEW_LINE self . bidirectional = bidirectional NEW_LINE self . batch_norm = SequenceWise ( nn . BatchNorm1d ( input_size ) ) if batch_norm else None NEW_LINE self . rnn = rnn_type ( input_size = input_size , hidden_size = hidden_size , bidirectional = bidirectional , bias = False ) NEW_LINE self . num_directions = 2 if bidirectional else 1 NEW_LINE DEDENT',\n",
              " 'def flatten_parameters ( self ) : NEW_LINE INDENT self . rnn . flatten_parameters ( ) NEW_LINE DEDENT',\n",
              " 'def forward ( self , x ) : NEW_LINE INDENT if self . batch_norm is not None : NEW_LINE INDENT x = self . batch_norm ( x ) NEW_LINE DEDENT x , _ = self . rnn ( x ) NEW_LINE if self . bidirectional : NEW_LINE INDENT x = x . view ( x . size ( 0 ) , x . size ( 1 ) , 2 , - 1 ) . sum ( 2 ) . view ( x . size ( 0 ) , x . size ( 1 ) , - 1 ) NEW_LINE DEDENT return x NEW_LINE DEDENT',\n",
              " \"def __init__ ( self , n_features , context ) : NEW_LINE INDENT super ( Lookahead , self ) . __init__ ( ) NEW_LINE self . n_features = n_features NEW_LINE self . weight = Parameter ( torch . Tensor ( n_features , context + 1 ) ) NEW_LINE assert context > 0 NEW_LINE self . context = context NEW_LINE self . register_parameter ( ' bias ' , None ) NEW_LINE self . init_parameters ( ) NEW_LINE DEDENT\",\n",
              " 'def init_parameters ( self ) : NEW_LINE INDENT stdv = 1. / math . sqrt ( self . weight . size ( 1 ) ) NEW_LINE self . weight . data . uniform_ ( - stdv , stdv ) NEW_LINE DEDENT',\n",
              " 'def forward ( self , input ) : NEW_LINE INDENT seq_len = input . size ( 0 ) NEW_LINE padding = torch . zeros ( self . context , * ( input . size ( ) [ 1 : ] ) ) . type_as ( input . data ) NEW_LINE x = torch . cat ( ( input , Variable ( padding ) ) , 0 ) NEW_LINE x = [ x [ i : i + self . context + 1 ] for i in range ( seq_len ) ] NEW_LINE x = torch . stack ( x ) NEW_LINE x = x . permute ( 0 , 2 , 3 , 1 ) NEW_LINE x = torch . mul ( x , self . weight ) . sum ( dim = 3 ) NEW_LINE return x NEW_LINE DEDENT',\n",
              " \"def __repr__ ( self ) : NEW_LINE INDENT return self . __class__ . __name__ + ' ( ' + ' n _ features = ' + str ( self . n_features ) + ' , ▁ context = ' + str ( self . context ) + ' ) ' NEW_LINE DEDENT\",\n",
              " 'def __init__ ( self , rnn_type = nn . LSTM , labels = \" abc \" , rnn_hidden_size = 512 , rnn_layers = 2 , bidirectional = True , kernel_sz = 11 , stride = 2 , map = 256 , cnn_layers = 2 , nFreq = 40 , nDownsample = 1 , audio_conf = None ) : NEW_LINE INDENT super ( DeepSpeech_ken , self ) . __init__ ( ) NEW_LINE self . nFreq = nFreq NEW_LINE self . _version = \\'0.0.1\\' NEW_LINE self . _audio_conf = audio_conf NEW_LINE self . rnn_size = rnn_hidden_size NEW_LINE self . rnn_layers = rnn_layers NEW_LINE self . rnn_type = rnn_type NEW_LINE self . bidirectional = bidirectional NEW_LINE self . cnn_stride = stride NEW_LINE self . cnn_map = map NEW_LINE self . cnn_kernel = kernel_sz NEW_LINE self . nDownsample = nDownsample NEW_LINE self . cnn_layers = cnn_layers NEW_LINE self . _labels = labels NEW_LINE num_classes = len ( self . _labels ) NEW_LINE conv_list = [ ] NEW_LINE conv_list . append ( nn . Conv1d ( nFreq , map , kernel_size = kernel_sz , stride = stride ) ) NEW_LINE conv_list . append ( nn . BatchNorm1d ( map ) ) NEW_LINE conv_list . append ( nn . LeakyReLU ( map , inplace = True ) ) NEW_LINE if ( self . nDownsample == 1 ) : NEW_LINE INDENT stride = 1 NEW_LINE DEDENT for x in range ( self . cnn_layers - 1 ) : NEW_LINE INDENT conv_list . append ( nn . Conv1d ( map , map , kernel_size = kernel_sz , stride = stride ) ) NEW_LINE conv_list . append ( nn . BatchNorm1d ( map ) ) NEW_LINE conv_list . append ( nn . LeakyReLU ( map , inplace = True ) ) NEW_LINE DEDENT self . conv = nn . Sequential ( * conv_list ) NEW_LINE rnn_input_size = map NEW_LINE print ( \\' rnn ▁ input ▁ size ▁ = ▁ \\' + str ( rnn_input_size ) ) NEW_LINE rnns = [ ] NEW_LINE rnn = BatchRNN ( input_size = rnn_input_size , hidden_size = rnn_hidden_size , rnn_type = rnn_type , bidirectional = bidirectional , batch_norm = False ) NEW_LINE rnns . append ( ( \\'0\\' , rnn ) ) NEW_LINE for x in range ( self . rnn_layers - 1 ) : NEW_LINE INDENT rnn = BatchRNN ( input_size = rnn_hidden_size , hidden_size = rnn_hidden_size , rnn_type = rnn_type , bidirectional = bidirectional ) NEW_LINE rnns . append ( ( \\' % d \\' % ( x + 1 ) , rnn ) ) NEW_LINE DEDENT self . rnns = nn . Sequential ( OrderedDict ( rnns ) ) NEW_LINE fully_connected = nn . Sequential ( nn . BatchNorm1d ( rnn_hidden_size ) , nn . Linear ( rnn_hidden_size , num_classes , bias = False ) ) NEW_LINE self . fc = nn . Sequential ( SequenceWise ( fully_connected ) , ) NEW_LINE self . inference_softmax = InferenceBatchSoftmax ( ) NEW_LINE DEDENT',\n",
              " 'def forward ( self , x ) : NEW_LINE INDENT if ( x . dim ( ) == 4 ) : NEW_LINE INDENT x = x . squeeze ( ) NEW_LINE DEDENT x = self . conv ( x ) NEW_LINE x = x . transpose ( 1 , 2 ) . transpose ( 0 , 1 ) . contiguous ( ) NEW_LINE x = self . rnns ( x ) NEW_LINE x = self . fc ( x ) NEW_LINE x = x . transpose ( 0 , 1 ) NEW_LINE x = self . inference_softmax ( x ) NEW_LINE return x NEW_LINE DEDENT',\n",
              " 'def __init__ ( self , rnn_type = nn . LSTM , labels = \" abc \" , rnn_hidden_size = 512 , rnn_layers = 2 , bidirectional = True , kernel_sz = 11 , stride = 2 , map = 256 , cnn_layers = 2 , nFreq = 40 , nDownsample = 1 , audio_conf = None , include_first_BN = True ) : NEW_LINE INDENT super ( DeepSpeech_ken , self ) . __init__ ( ) NEW_LINE self . nFreq = nFreq NEW_LINE self . _version = \\'0.0.1\\' NEW_LINE self . _audio_conf = audio_conf NEW_LINE self . rnn_size = rnn_hidden_size NEW_LINE self . rnn_layers = rnn_layers NEW_LINE self . rnn_type = rnn_type NEW_LINE self . bidirectional = bidirectional NEW_LINE self . cnn_stride = stride NEW_LINE self . cnn_map = map NEW_LINE self . cnn_kernel = kernel_sz NEW_LINE self . nDownsample = nDownsample NEW_LINE self . cnn_layers = cnn_layers NEW_LINE self . _labels = labels NEW_LINE num_classes = len ( self . _labels ) NEW_LINE conv_list = [ ] NEW_LINE conv_list . append ( nn . Conv1d ( nFreq , map , kernel_size = kernel_sz , stride = stride ) ) NEW_LINE if ( include_first_BN ) : NEW_LINE INDENT conv_list . append ( nn . BatchNorm1d ( map ) ) NEW_LINE DEDENT conv_list . append ( nn . LeakyReLU ( map , inplace = True ) ) NEW_LINE if ( self . nDownsample == 1 ) : NEW_LINE INDENT stride = 1 NEW_LINE DEDENT for x in range ( self . cnn_layers - 1 ) : NEW_LINE INDENT conv_list . append ( nn . Conv1d ( map , map , kernel_size = kernel_sz , stride = stride ) ) NEW_LINE conv_list . append ( nn . BatchNorm1d ( map ) ) NEW_LINE conv_list . append ( nn . LeakyReLU ( map , inplace = True ) ) NEW_LINE DEDENT self . conv = nn . Sequential ( * conv_list ) NEW_LINE rnn_input_size = map NEW_LINE print ( \\' rnn ▁ input ▁ size ▁ = ▁ \\' + str ( rnn_input_size ) ) NEW_LINE rnns = [ ] NEW_LINE rnn = BatchRNN ( input_size = rnn_input_size , hidden_size = rnn_hidden_size , rnn_type = rnn_type , bidirectional = bidirectional , batch_norm = False ) NEW_LINE rnns . append ( ( \\'0\\' , rnn ) ) NEW_LINE for x in range ( self . rnn_layers - 1 ) : NEW_LINE INDENT rnn = BatchRNN ( input_size = rnn_hidden_size , hidden_size = rnn_hidden_size , rnn_type = rnn_type , bidirectional = bidirectional ) NEW_LINE rnns . append ( ( \\' % d \\' % ( x + 1 ) , rnn ) ) NEW_LINE DEDENT self . rnns = nn . Sequential ( OrderedDict ( rnns ) ) NEW_LINE fully_connected = nn . Sequential ( nn . BatchNorm1d ( rnn_hidden_size ) , nn . Linear ( rnn_hidden_size , num_classes , bias = False ) ) NEW_LINE self . fc = nn . Sequential ( SequenceWise ( fully_connected ) , ) NEW_LINE self . inference_softmax = InferenceBatchSoftmax ( ) NEW_LINE DEDENT',\n",
              " 'def forward ( self , x ) : NEW_LINE INDENT if ( x . dim ( ) == 4 ) : NEW_LINE INDENT x = x . squeeze ( ) NEW_LINE DEDENT x = self . conv ( x ) NEW_LINE x = x . transpose ( 1 , 2 ) . transpose ( 0 , 1 ) . contiguous ( ) NEW_LINE x = self . rnns ( x ) NEW_LINE x = self . fc ( x ) NEW_LINE x = x . transpose ( 0 , 1 ) NEW_LINE x = self . inference_softmax ( x ) NEW_LINE return x NEW_LINE DEDENT',\n",
              " 'def __init__ ( self , rnn_type = nn . GRU , labels = \" abc \" , rnn_hidden_size = 512 , rnn_layers = 2 , bidirectional = True , kernel_sz = 11 , stride = 2 , map = 256 , cnn_residual_blocks = 1 , nFreq = 40 , nDownsample = 1 , audio_conf = None ) : NEW_LINE INDENT super ( ResidualDeepSpeech , self ) . __init__ ( ) NEW_LINE self . nFreq = nFreq NEW_LINE self . _version = \\'0.0.1\\' NEW_LINE self . _audio_conf = audio_conf NEW_LINE self . rnn_size = rnn_hidden_size NEW_LINE self . rnn_layers = rnn_layers NEW_LINE self . rnn_type = rnn_type NEW_LINE self . bidirectional = bidirectional NEW_LINE self . cnn_stride = stride NEW_LINE self . cnn_map = map NEW_LINE self . cnn_kernel = kernel_sz NEW_LINE self . nDownsample = nDownsample NEW_LINE self . cnn_residual_blocks = cnn_residual_blocks NEW_LINE self . _labels = labels NEW_LINE num_classes = len ( self . _labels ) NEW_LINE conv1 = [ ] NEW_LINE conv1 . append ( nn . Conv1d ( nFreq , map , kernel_size = kernel_sz , stride = stride ) ) NEW_LINE conv1 . append ( nn . LeakyReLU ( map , inplace = True ) ) NEW_LINE self . conv1 = nn . Sequential ( * conv1 ) NEW_LINE if ( self . nDownsample == 1 ) : NEW_LINE INDENT stride = 1 NEW_LINE DEDENT padding = int ( ( kernel_sz - 1 ) / 2 ) NEW_LINE assert ( stride == 1 ) , \\' padding ▁ is ▁ only ▁ valid ▁ when ▁ stride = 1\\' NEW_LINE residual2 = [ ] NEW_LINE residual2 . append ( nn . Conv1d ( map , map , kernel_size = kernel_sz , stride = stride , padding = padding ) ) NEW_LINE residual2 . append ( nn . BatchNorm1d ( map ) ) NEW_LINE residual2 . append ( nn . LeakyReLU ( map , inplace = True ) ) NEW_LINE residual2 . append ( nn . Conv1d ( map , map , kernel_size = kernel_sz , stride = stride , padding = padding ) ) NEW_LINE residual2 . append ( nn . BatchNorm1d ( map ) ) NEW_LINE self . residual2 = nn . Sequential ( * residual2 ) NEW_LINE self . dim_match_layer = nn . Conv1d ( map , rnn_hidden_size , kernel_size = 1 , stride = 1 , padding = 0 ) NEW_LINE rnn_input_size = rnn_hidden_size NEW_LINE print ( \\' rnn ▁ input ▁ size ▁ = ▁ \\' + str ( rnn_input_size ) ) NEW_LINE rnns = [ ] NEW_LINE rnn = BatchRNN ( input_size = rnn_input_size , hidden_size = rnn_hidden_size , rnn_type = rnn_type , bidirectional = bidirectional , batch_norm = False ) NEW_LINE rnns . append ( ( \\'0\\' , rnn ) ) NEW_LINE for x in range ( self . rnn_layers - 1 ) : NEW_LINE INDENT rnn = BatchRNN ( input_size = rnn_hidden_size , hidden_size = rnn_hidden_size , rnn_type = rnn_type , bidirectional = bidirectional ) NEW_LINE rnns . append ( ( \\' % d \\' % ( x + 1 ) , rnn ) ) NEW_LINE DEDENT self . rnns = nn . Sequential ( OrderedDict ( rnns ) ) NEW_LINE fully_connected = nn . Sequential ( nn . BatchNorm1d ( rnn_hidden_size ) , nn . Linear ( rnn_hidden_size , num_classes , bias = False ) ) NEW_LINE self . fc = nn . Sequential ( SequenceWise ( fully_connected ) , ) NEW_LINE self . inference_softmax = InferenceBatchSoftmax ( ) NEW_LINE DEDENT',\n",
              " 'def forward ( self , x ) : NEW_LINE INDENT if ( x . dim ( ) == 4 ) : NEW_LINE INDENT x = x . squeeze ( ) NEW_LINE DEDENT x = self . conv1 ( x ) NEW_LINE x = self . residual2 ( x ) + x NEW_LINE x = self . dim_match_layer ( x ) NEW_LINE x = x . transpose ( 1 , 2 ) . transpose ( 0 , 1 ) . contiguous ( ) NEW_LINE for l in range ( self . rnn_layers ) : NEW_LINE INDENT x = self . rnns [ l ] ( x ) + x NEW_LINE DEDENT x = self . fc ( x ) NEW_LINE x = x . transpose ( 0 , 1 ) NEW_LINE x = self . inference_softmax ( x ) NEW_LINE return x NEW_LINE DEDENT',\n",
              " 'def __init__ ( self , labels = \" abc \" , kernel_sz = 11 , stride = 2 , map = 512 , nFreq = 40 , nDownsample = 1 , audio_conf = None ) : NEW_LINE INDENT super ( ResidualCNN4block , self ) . __init__ ( ) NEW_LINE self . nFreq = nFreq NEW_LINE self . _version = \\'0.0.1\\' NEW_LINE self . _audio_conf = audio_conf NEW_LINE self . cnn_stride = stride NEW_LINE self . cnn_map = map NEW_LINE self . cnn_kernel = kernel_sz NEW_LINE self . nDownsample = nDownsample NEW_LINE self . _labels = labels NEW_LINE num_classes = len ( self . _labels ) NEW_LINE conv1 = [ ] NEW_LINE conv1 . append ( nn . Conv1d ( nFreq , map , kernel_size = kernel_sz , stride = stride , bias = False ) ) NEW_LINE conv1 . append ( nn . LeakyReLU ( map , inplace = True ) ) NEW_LINE self . conv1 = nn . Sequential ( * conv1 ) NEW_LINE if ( self . nDownsample == 1 ) : NEW_LINE INDENT stride = 1 NEW_LINE DEDENT padding = int ( ( kernel_sz - 1 ) / 2 ) NEW_LINE assert ( stride == 1 ) , \\' padding ▁ is ▁ only ▁ valid ▁ when ▁ stride = 1\\' NEW_LINE residual2 = [ ] NEW_LINE residual2 . append ( nn . Conv1d ( map , map , kernel_size = kernel_sz , stride = stride , padding = padding , bias = False ) ) NEW_LINE residual2 . append ( nn . BatchNorm1d ( map ) ) NEW_LINE residual2 . append ( nn . LeakyReLU ( map , inplace = True ) ) NEW_LINE residual2 . append ( nn . Conv1d ( map , map , kernel_size = kernel_sz , stride = stride , padding = padding , bias = False ) ) NEW_LINE residual2 . append ( nn . BatchNorm1d ( map ) ) NEW_LINE self . residual2 = nn . Sequential ( * residual2 ) NEW_LINE residual3 = [ ] NEW_LINE residual3 . append ( nn . Conv1d ( map , map , kernel_size = kernel_sz , stride = stride , padding = padding , bias = False ) ) NEW_LINE residual3 . append ( nn . BatchNorm1d ( map ) ) NEW_LINE residual3 . append ( nn . LeakyReLU ( map , inplace = True ) ) NEW_LINE residual3 . append ( nn . Conv1d ( map , map , kernel_size = kernel_sz , stride = stride , padding = padding , bias = False ) ) NEW_LINE residual3 . append ( nn . BatchNorm1d ( map ) ) NEW_LINE self . residual3 = nn . Sequential ( * residual3 ) NEW_LINE residual4 = [ ] NEW_LINE residual4 . append ( nn . Conv1d ( map , map , kernel_size = kernel_sz , stride = stride , padding = padding , bias = False ) ) NEW_LINE residual4 . append ( nn . BatchNorm1d ( map ) ) NEW_LINE residual4 . append ( nn . LeakyReLU ( map , inplace = True ) ) NEW_LINE residual4 . append ( nn . Conv1d ( map , map , kernel_size = kernel_sz , stride = stride , padding = padding , bias = False ) ) NEW_LINE residual4 . append ( nn . BatchNorm1d ( map ) ) NEW_LINE self . residual4 = nn . Sequential ( * residual4 ) NEW_LINE residual5 = [ ] NEW_LINE residual5 . append ( nn . Conv1d ( map , map , kernel_size = kernel_sz , stride = stride , padding = padding , bias = False ) ) NEW_LINE residual5 . append ( nn . BatchNorm1d ( map ) ) NEW_LINE residual5 . append ( nn . LeakyReLU ( map , inplace = True ) ) NEW_LINE residual5 . append ( nn . Conv1d ( map , map , kernel_size = kernel_sz , stride = stride , padding = padding , bias = False ) ) NEW_LINE residual5 . append ( nn . BatchNorm1d ( map ) ) NEW_LINE self . residual5 = nn . Sequential ( * residual5 ) NEW_LINE fully_connected = nn . Sequential ( nn . Linear ( map , num_classes ) ) NEW_LINE self . fc = nn . Sequential ( SequenceWise ( fully_connected ) , ) NEW_LINE self . inference_softmax = InferenceBatchSoftmax ( ) NEW_LINE DEDENT',\n",
              " 'def forward ( self , x ) : NEW_LINE INDENT if ( x . dim ( ) == 4 ) : NEW_LINE INDENT x = x . squeeze ( ) NEW_LINE DEDENT x = self . conv1 ( x ) NEW_LINE x = self . residual2 ( x ) + x NEW_LINE x = self . residual3 ( x ) + x NEW_LINE x = self . residual4 ( x ) + x NEW_LINE x = self . residual5 ( x ) + x NEW_LINE x = x . transpose ( 1 , 2 ) . transpose ( 0 , 1 ) . contiguous ( ) NEW_LINE x = self . fc ( x ) NEW_LINE x = x . transpose ( 0 , 1 ) NEW_LINE x = self . inference_softmax ( x ) NEW_LINE return x NEW_LINE DEDENT']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_df = eqns.merge(collected_func_reps , on='id')"
      ],
      "metadata": {
        "id": "SJkjhyPyY6Mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for row in full_df.iterrows():\n",
        "  print(tokenizer(row[1].eqn,return_tensors='pt',truncation=True))\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rghVH0GYooer",
        "outputId": "366251d5-214e-48a1-9d27-82837ae836f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101,   165,  3295,   196,  3325,   198,   165, 11241,   168,   196,\n",
            "           144,   198,   165, 12477,  1775,   168,   196,   141,   198,   159,\n",
            "           168,   196,   172, 10583,  2249,   198,   113,   144,   117,   141,\n",
            "           114,   134,   165,   142,   168,   196,   113,   165,  3087,  1830,\n",
            "          2087,   196,   193,   198,   168,   196,   188,   198,   117,   165,\n",
            "          3087,  1830,  2087,   196,   193,   198,   168,   196,   189,   198,\n",
            "           114,   165, 27466,  1306,   185,   113,   165,  3087,  1830,  2087,\n",
            "           196,   193,   198,   168,   196,   188,   198,   117,   165,  3087,\n",
            "          1830,  2087,   196,   193,   198,   168,   196,   189,   198,   114,\n",
            "           198,   164,   165,  9366,   141,   113,   165,  3087,  1830,  2087,\n",
            "           196,   193,   198,   168,   188,   117,   165,  3087,  1830,  2087,\n",
            "           196,   193,   198,   168,   196,   189,   198,   114,   166,   165,\n",
            "           165,   116,   165,   142,   168,   196,   165,  3087,  1830,  2087,\n",
            "           196,   193,   198,   168,   196,   188,   198,   165, 27466,  1306,\n",
            "           185,   113,   165,  3087,  1830,  2087,   196,   193,   198,   168,\n",
            "           196,   188,   198,   114,   117,   165,  3087,  1830,  2087,   196,\n",
            "           195,   198,   165, 27466,  1306,   151,   113,   121,   117,   146,\n",
            "           114,   198,   164,   165,  9366,   113,   122,   118,   141,   113,\n",
            "           165,  3087,  1830,  2087,   196,   193,   198,   168,   196,   188,\n",
            "           198,   117,   144,   113,   165,  3087,  1830,  2087,   196,   193,\n",
            "           198,   168,   196,   188,   198,   117,   165,  3087,  1830,  2087,\n",
            "           196,   195,   198,   114,   114,   114,   166,   119,   165,  1322,\n",
            "           196,  3325,   198,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ContrastiveDataset(Dataset):\n",
        "\n",
        "    def __init__(self, combined_df, all_eqns):\n",
        "        \"\"\"Simple init function\"\"\"\n",
        "        self.df = combined_df\n",
        "        tok_eqns = []\n",
        "        for row in self.df.iterrows():\n",
        "          tok_eqns.append(tokenizer(row[1].eqn,return_tensors='pt',truncation=True))\n",
        "        self.tok_eqns = tok_eqns\n",
        "\n",
        "        self.neg_eqns = all_eqns\n",
        "        neg_eqns = []\n",
        "        for item in all_eqns:\n",
        "          neg_eqns.append(tokenizer(item,return_tensors='pt',truncation=True))\n",
        "\n",
        "        self.neg_toks = neg_eqns\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Get length of dataset\"\"\"\n",
        "        return len(self.df)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        entry = self.df.iloc[idx]\n",
        "\n",
        "        eqn_paper_id = entry.id\n",
        "        code_id = eqn_paper_id \n",
        "        code_rep = entry.representations\n",
        "        code_funcs = entry.functions\n",
        "\n",
        "        pos_eqn = entry.eqn\n",
        "        pos_eqn_tok = self.tok_eqns[idx]\n",
        "\n",
        "        neg_idx = random.randint(0,len(self.neg_eqns)-1)\n",
        "        neg_eqn = self.neg_eqns.iloc[neg_idx]\n",
        "        neg_eqn_tok = self.neg_toks[neg_idx]\n",
        "\n",
        "        return code_rep, pos_eqn_tok, neg_eqn_tok, pos_eqn, neg_eqn, eqn_paper_id, code_id, code_funcs\n",
        "\n",
        "        \n"
      ],
      "metadata": {
        "id": "1jXByPfkDDQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ContrastiveDataset(full_df, eqns.eqn.dropna())"
      ],
      "metadata": {
        "id": "8eGPuAX_eZHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ContrastiveModel(nn.Module):\n",
        "  def __init__(self, embedding_model):\n",
        "    super(ContrastiveModel,self).__init__()\n",
        "\n",
        "    self.latex_encoder = embedding_model\n",
        "\n",
        "    self.remap_eqn_fc1 = nn.Linear(768,768)\n",
        "    # self.reduce_eqn_fc2 = nn.Linear(768,1024)\n",
        "    self.expand_eqn_fc3 = nn.Linear(768,1024)\n",
        "\n",
        "    self.remix_res_fc1 = nn.Linear(1024,1024)\n",
        "    self.remix_res_fc2  = nn.Linear(1024,768)\n",
        "\n",
        "    self.softmax = nn.Softmax(dim=0)\n",
        "    self.eqn_drop = nn.Dropout(p=0.5)\n",
        "    \n",
        "\n",
        "\n",
        "  def embed_eqn(self, eqn):\n",
        "      return self.latex_encoder(input_ids=eqn[0],attention_mask=eqn[1])[0].mean(-2)\n",
        "\n",
        "  def reduce_eqn(self,eqn_embedding):\n",
        "      eqn_embedding = self.eqn_drop(eqn_embedding)\n",
        "      h = self.remap_eqn_fc1(eqn_embedding)\n",
        "      h = F.relu(h)\n",
        "      h = self.expand_eqn_fc3(h)\n",
        "      h = F.normalize(h)\n",
        "      return h\n",
        "\n",
        "\n",
        "  def forward(self, func_reps,pos_eqn, neg_eqn):\n",
        "      # get embeddings\n",
        "      pos_eqn_embedding = self.embed_eqn(pos_eqn)\n",
        "      neg_eqn_embedding = self.embed_eqn(neg_eqn)\n",
        "\n",
        "\n",
        "      #reduce the embedding size of pos_h and then expand it to match func_reps\n",
        "      #the expansion is concerning, but the hope is we reduce the information           \n",
        "      pos_h_norm = self.reduce_eqn(pos_eqn_embedding)\n",
        "\n",
        "      #norm func reps as well because we want the next operation to correspond \n",
        "      #to cosine similarity\n",
        "      normed_reps = F.normalize(func_reps,dim=-1)\n",
        "      # print(normed_reps)\n",
        "     \n",
        "      #get an attention map\n",
        "      attn_map = torch.matmul(normed_reps.squeeze(1),pos_h_norm.squeeze())\n",
        "\n",
        "      #zero out so don't have negatives influencing results\n",
        "      pre_soft_attn_map = F.relu(attn_map)\n",
        "      #convert to probabilities\n",
        "      attn_map = self.softmax(pre_soft_attn_map)\n",
        "\n",
        "      #recombine function reps based on attention\n",
        "      z = torch.matmul(attn_map,func_reps.squeeze()) if func_reps.shape[0] > 1 else func_reps\n",
        "\n",
        "      z = F.relu(z)\n",
        "      z = self.remix_res_fc1(z)\n",
        "      z = F.relu(z)\n",
        "      z = self.remix_res_fc2(z)\n",
        "\n",
        "      return z, pos_eqn_embedding, neg_eqn_embedding, attn_map\n",
        "\n"
      ],
      "metadata": {
        "id": "e_7GNTcLk_2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset,batch_size=1,shuffle=True)"
      ],
      "metadata": {
        "id": "SNFDNx3menro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DistilBertModel.from_pretrained(\"distilbert-base-cased\")\n",
        "\n",
        "combined_model = ContrastiveModel(model)\n",
        "combined_model.train()\n",
        "combined_model.cuda()\n",
        "\n",
        "optimizer = optim.Adam(combined_model.parameters(), lr=5e-5)\n",
        "criterion = nn.TripletMarginLoss()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMBv8zzX05u3",
        "outputId": "83cac672-e470-41f7-e747-983053d8f982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKy8VDLWtVJ2",
        "outputId": "5f365827-939d-4d86-bc86-8a36c15289fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Apr 27 00:53:29 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    33W / 250W |   4735MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30"
      ],
      "metadata": {
        "id": "XXPXvWgoAh3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_model.train()\n",
        "accum_iter = 256\n",
        "for epoch in range(epochs):\n",
        "    print(\"--------\")\n",
        "    print(f\"Epoch {epoch}\")\n",
        "    print(\"--------\")\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    loss_avg = 0\n",
        "    for batch_idx,input in enumerate(train_loader):\n",
        "\n",
        "     \n",
        "\n",
        "      code_rep, pos_eqn_tok, neg_eqn_tok, pos_eqn, neg_eqn, eqn_paper_id, code_id, code_funcs = input  \n",
        "      # if len(code_funcs) < 1:\n",
        "      #     print('continuing')\n",
        "      #     continue    \n",
        "\n",
        "\n",
        "\n",
        "      # forward + backward + optimize\n",
        "      curr_rep = torch.cat(code_rep).cuda()\n",
        "      pos_eqn_prep = pos_eqn_tok['input_ids'].flatten(1).cuda(),pos_eqn_tok['attention_mask'].flatten(1).cuda()\n",
        "      neg_eqn_prep = neg_eqn_tok['input_ids'].flatten(1).cuda(),neg_eqn_tok['attention_mask'].flatten(1).cuda()\n",
        "\n",
        "      # output\n",
        "      z,pos,neg,attn = combined_model(curr_rep,pos_eqn_prep,neg_eqn_prep)\n",
        "      \n",
        "      loss = criterion(z.squeeze(),pos.squeeze(),neg.squeeze()) \n",
        "      \n",
        "      loss = loss / accum_iter\n",
        "      loss.backward()\n",
        "\n",
        "      if ((batch_idx + 1) % accum_iter == 0) or (batch_idx + 1 == len(train_loader)):\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            print(f\"{loss_avg}\")\n",
        "            \n",
        "            loss_avg = 0\n",
        "            print(f\"On batch {batch_idx}\")\n",
        "\n",
        "            print(attn)\n",
        "            print(pos_eqn)\n",
        "            print(code_funcs)\n",
        "\n",
        "\n",
        "      loss_avg += loss.item()\n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rRHGr83gjXt5",
        "outputId": "4d5b133a-45f3-48a2-f12f-c7640194a202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------\n",
            "Epoch 0\n",
            "--------\n",
            "2.7579037696123123\n",
            "On batch 255\n",
            "tensor([0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "('\\\\label{IoU}\\n% \\\\mathit{IoU} = \\\\frac{area(B_r\\\\cap B_{gt})}{area(B_r\\\\cup B_{gt})}\\n% ',)\n",
            "[(\"def get_segmentation_train_batch ( segdb , config ) : NEW_LINE INDENT assert len ( segdb ) == 1 , ' Single ▁ batch ▁ only ' NEW_LINE imgs , seg_cls_gts , segdb = get_segmentation_image ( segdb , config ) NEW_LINE im_array = imgs [ 0 ] NEW_LINE seg_cls_gt = seg_cls_gts [ 0 ] NEW_LINE im_info = np . array ( [ segdb [ 0 ] [ ' im _ info ' ] ] , dtype = np . float32 ) NEW_LINE data = { ' data ' : im_array , ' im _ info ' : im_info } NEW_LINE label = { ' label ' : seg_cls_gt } NEW_LINE return data , label NEW_LINE DEDENT\",), ('def show_boxes ( im , dets , classes , scale = 1.0 ) : NEW_LINE INDENT plt . cla ( ) NEW_LINE plt . axis ( \" off \" ) NEW_LINE plt . imshow ( im ) NEW_LINE for cls_idx , cls_name in enumerate ( classes ) : NEW_LINE INDENT cls_dets = dets [ cls_idx ] NEW_LINE for det in cls_dets : NEW_LINE INDENT bbox = det [ : 4 ] * scale NEW_LINE color = ( rand ( ) , rand ( ) , rand ( ) ) NEW_LINE rect = plt . Rectangle ( ( bbox [ 0 ] , bbox [ 1 ] ) , bbox [ 2 ] - bbox [ 0 ] , bbox [ 3 ] - bbox [ 1 ] , fill = False , edgecolor = color , linewidth = 2.5 ) NEW_LINE plt . gca ( ) . add_patch ( rect ) NEW_LINE if cls_dets . shape [ 1 ] == 5 : NEW_LINE INDENT score = det [ - 1 ] NEW_LINE plt . gca ( ) . text ( bbox [ 0 ] , bbox [ 1 ] , \\' { : s } ▁ { : . 3f } \\' . format ( cls_name , score ) , bbox = dict ( facecolor = color , alpha = 0.5 ) , fontsize = 9 , color = \\' white \\' ) NEW_LINE DEDENT DEDENT DEDENT plt . show ( ) NEW_LINE return im NEW_LINE DEDENT',), (\"def encodeMask ( M ) : NEW_LINE INDENT [ h , w ] = M . shape NEW_LINE M = M . flatten ( order = ' F ' ) NEW_LINE N = len ( M ) NEW_LINE counts_list = [ ] NEW_LINE pos = 0 NEW_LINE counts_list . append ( 1 ) NEW_LINE diffs = np . logical_xor ( M [ 0 : N - 1 ] , M [ 1 : N ] ) NEW_LINE for diff in diffs : NEW_LINE INDENT if diff : NEW_LINE INDENT pos += 1 NEW_LINE counts_list . append ( 1 ) NEW_LINE DEDENT else : NEW_LINE INDENT counts_list [ pos ] += 1 NEW_LINE DEDENT DEDENT if M [ 0 ] == 1 : NEW_LINE INDENT counts_list = [ 0 ] + counts_list NEW_LINE DEDENT return { ' size ' : [ h , w ] , ' counts ' : counts_list , } NEW_LINE DEDENT\",), ('def __init__ ( self , iters , rename_data = None , rename_label = None ) : NEW_LINE INDENT super ( PrefetchingIter , self ) . __init__ ( ) NEW_LINE if not isinstance ( iters , list ) : NEW_LINE INDENT iters = [ iters ] NEW_LINE DEDENT self . n_iter = len ( iters ) NEW_LINE assert self . n_iter == 1 , \" Our ▁ prefetching ▁ iter ▁ only ▁ support ▁ 1 ▁ DataIter \" NEW_LINE self . iters = iters NEW_LINE self . rename_data = rename_data NEW_LINE self . rename_label = rename_label NEW_LINE self . batch_size = len ( self . provide_data ) * self . provide_data [ 0 ] [ 0 ] [ 1 ] [ 0 ] NEW_LINE self . data_ready = [ threading . Event ( ) for i in range ( self . n_iter ) ] NEW_LINE self . data_taken = [ threading . Event ( ) for i in range ( self . n_iter ) ] NEW_LINE for e in self . data_taken : NEW_LINE INDENT e . set ( ) NEW_LINE DEDENT self . started = True NEW_LINE self . current_batch = [ None for _ in range ( self . n_iter ) ] NEW_LINE self . next_batch = [ None for _ in range ( self . n_iter ) ] NEW_LINE def prefetch_func ( self , i ) : NEW_LINE INDENT while True : NEW_LINE INDENT self . data_taken [ i ] . wait ( ) NEW_LINE if not self . started : NEW_LINE INDENT break NEW_LINE DEDENT try : NEW_LINE INDENT self . next_batch [ i ] = self . iters [ i ] . next ( ) NEW_LINE DEDENT except StopIteration : NEW_LINE INDENT self . next_batch [ i ] = None NEW_LINE DEDENT self . data_taken [ i ] . clear ( ) NEW_LINE self . data_ready [ i ] . set ( ) NEW_LINE DEDENT DEDENT self . prefetch_threads = [ threading . Thread ( target = prefetch_func , args = [ self , i ] ) for i in range ( self . n_iter ) ] NEW_LINE for thread in self . prefetch_threads : NEW_LINE INDENT thread . setDaemon ( True ) NEW_LINE thread . start ( ) NEW_LINE DEDENT DEDENT',), ('def __del__ ( self ) : NEW_LINE INDENT self . started = False NEW_LINE for e in self . data_taken : NEW_LINE INDENT e . set ( ) NEW_LINE DEDENT for thread in self . prefetch_threads : NEW_LINE INDENT thread . join ( ) NEW_LINE DEDENT DEDENT',), ('def provide_data ( self ) : NEW_LINE INDENT if self . rename_data is None : NEW_LINE INDENT return sum ( [ i . provide_data for i in self . iters ] , [ ] ) NEW_LINE DEDENT else : NEW_LINE INDENT return sum ( [ [ DataDesc ( r [ x . name ] , x . shape , x . dtype ) if isinstance ( x , DataDesc ) else DataDesc ( * x ) for x in i . provide_data ] for r , i in zip ( self . rename_data , self . iters ) ] , [ ] ) NEW_LINE DEDENT DEDENT',), ('def provide_label ( self ) : NEW_LINE INDENT if self . rename_label is None : NEW_LINE INDENT return sum ( [ i . provide_label for i in self . iters ] , [ ] ) NEW_LINE DEDENT else : NEW_LINE INDENT return sum ( [ [ DataDesc ( r [ x . name ] , x . shape , x . dtype ) if isinstance ( x , DataDesc ) else DataDesc ( * x ) for x in i . provide_label ] for r , i in zip ( self . rename_label , self . iters ) ] , [ ] ) NEW_LINE DEDENT DEDENT',), ('def reset ( self ) : NEW_LINE INDENT for e in self . data_ready : NEW_LINE INDENT e . wait ( ) NEW_LINE DEDENT for i in self . iters : NEW_LINE INDENT i . reset ( ) NEW_LINE DEDENT for e in self . data_ready : NEW_LINE INDENT e . clear ( ) NEW_LINE DEDENT for e in self . data_taken : NEW_LINE INDENT e . set ( ) NEW_LINE DEDENT DEDENT',), ('def iter_next ( self ) : NEW_LINE INDENT for e in self . data_ready : NEW_LINE INDENT e . wait ( ) NEW_LINE DEDENT if self . next_batch [ 0 ] is None : NEW_LINE INDENT return False NEW_LINE DEDENT else : NEW_LINE INDENT self . current_batch = self . next_batch [ 0 ] NEW_LINE for e in self . data_ready : NEW_LINE INDENT e . clear ( ) NEW_LINE DEDENT for e in self . data_taken : NEW_LINE INDENT e . set ( ) NEW_LINE DEDENT return True NEW_LINE DEDENT DEDENT',), ('def next ( self ) : NEW_LINE INDENT if self . iter_next ( ) : NEW_LINE INDENT return self . current_batch NEW_LINE DEDENT else : NEW_LINE INDENT raise StopIteration NEW_LINE DEDENT DEDENT',), ('def getdata ( self ) : NEW_LINE INDENT return self . current_batch . data NEW_LINE DEDENT',), ('def getlabel ( self ) : NEW_LINE INDENT return self . current_batch . label NEW_LINE DEDENT',), ('def getindex ( self ) : NEW_LINE INDENT return self . current_batch . index NEW_LINE DEDENT',), ('def getpad ( self ) : NEW_LINE INDENT return self . current_batch . pad NEW_LINE DEDENT',), (\"def save_checkpoint ( prefix , epoch , arg_params , aux_params ) : NEW_LINE INDENT save_dict = { ( ' arg : % s ' % k ) : v for k , v in arg_params . items ( ) } NEW_LINE save_dict . update ( { ( ' aux : % s ' % k ) : v for k , v in aux_params . items ( ) } ) NEW_LINE param_name = ' % s - %04d . params ' % ( prefix , epoch ) NEW_LINE mx . nd . save ( param_name , save_dict ) NEW_LINE DEDENT\",), ('def __init__ ( self , step , factor = 1 , warmup = False , warmup_lr = 0 , warmup_step = 0 ) : NEW_LINE INDENT super ( WarmupMultiFactorScheduler , self ) . __init__ ( ) NEW_LINE assert isinstance ( step , list ) and len ( step ) >= 1 NEW_LINE for i , _step in enumerate ( step ) : NEW_LINE INDENT if i != 0 and step [ i ] <= step [ i - 1 ] : NEW_LINE INDENT raise ValueError ( \" Schedule ▁ step ▁ must ▁ be ▁ an ▁ increasing ▁ integer ▁ list \" ) NEW_LINE DEDENT if _step < 1 : NEW_LINE INDENT raise ValueError ( \" Schedule ▁ step ▁ must ▁ be ▁ greater ▁ or ▁ equal ▁ than ▁ 1 ▁ round \" ) NEW_LINE DEDENT DEDENT if factor > 1.0 : NEW_LINE INDENT raise ValueError ( \" Factor ▁ must ▁ be ▁ no ▁ more ▁ than ▁ 1 ▁ to ▁ make ▁ lr ▁ reduce \" ) NEW_LINE DEDENT self . step = step NEW_LINE self . cur_step_ind = 0 NEW_LINE self . factor = factor NEW_LINE self . count = 0 NEW_LINE self . warmup = warmup NEW_LINE self . warmup_lr = warmup_lr NEW_LINE self . warmup_step = warmup_step NEW_LINE DEDENT',), ('def __call__ ( self , num_update ) : NEW_LINE INDENT if self . warmup and num_update < self . warmup_step : NEW_LINE INDENT return self . warmup_lr NEW_LINE DEDENT while self . cur_step_ind <= len ( self . step ) - 1 : NEW_LINE INDENT if num_update > self . step [ self . cur_step_ind ] : NEW_LINE INDENT self . count = self . step [ self . cur_step_ind ] NEW_LINE self . cur_step_ind += 1 NEW_LINE self . base_lr *= self . factor NEW_LINE logging . info ( \" Update [ % d ] : ▁ Change ▁ learning ▁ rate ▁ to ▁ % 0.5e \" , num_update , self . base_lr ) NEW_LINE DEDENT else : NEW_LINE INDENT return self . base_lr NEW_LINE DEDENT DEDENT return self . base_lr NEW_LINE DEDENT',), (\"def load_checkpoint ( prefix , epoch ) : NEW_LINE INDENT save_dict = mx . nd . load ( ' % s - %04d . params ' % ( prefix , epoch ) ) NEW_LINE arg_params = { } NEW_LINE aux_params = { } NEW_LINE for k , v in save_dict . items ( ) : NEW_LINE INDENT tp , name = k . split ( ' : ' , 1 ) NEW_LINE if tp == ' arg ' : NEW_LINE INDENT arg_params [ name ] = v NEW_LINE DEDENT if tp == ' aux ' : NEW_LINE INDENT aux_params [ name ] = v NEW_LINE DEDENT DEDENT return arg_params , aux_params NEW_LINE DEDENT\",), ('def convert_context ( params , ctx ) : NEW_LINE INDENT new_params = dict ( ) NEW_LINE for k , v in params . items ( ) : NEW_LINE INDENT new_params [ k ] = v . as_in_context ( ctx ) NEW_LINE DEDENT return new_params NEW_LINE DEDENT',), (\"def load_param ( prefix , epoch , convert = False , ctx = None , process = False ) : NEW_LINE INDENT arg_params , aux_params = load_checkpoint ( prefix , epoch ) NEW_LINE if convert : NEW_LINE INDENT if ctx is None : NEW_LINE INDENT ctx = mx . cpu ( ) NEW_LINE DEDENT arg_params = convert_context ( arg_params , ctx ) NEW_LINE aux_params = convert_context ( aux_params , ctx ) NEW_LINE DEDENT if process : NEW_LINE INDENT tests = [ k for k in arg_params . keys ( ) if ' _ test ' in k ] NEW_LINE for test in tests : NEW_LINE INDENT arg_params [ test . replace ( ' _ test ' , ' ' ) ] = arg_params . pop ( test ) NEW_LINE DEDENT DEDENT return arg_params , aux_params NEW_LINE DEDENT\",), ('def tic ( ) : NEW_LINE INDENT import time NEW_LINE global startTime_for_tictoc NEW_LINE startTime_for_tictoc = time . time ( ) NEW_LINE return startTime_for_tictoc NEW_LINE DEDENT',), (\"def toc ( ) : NEW_LINE INDENT if ' startTime _ for _ tictoc ' in globals ( ) : NEW_LINE INDENT endTime = time . time ( ) NEW_LINE return endTime - startTime_for_tictoc NEW_LINE DEDENT else : NEW_LINE INDENT return None NEW_LINE DEDENT DEDENT\",), ('def combine_model ( prefix1 , epoch1 , prefix2 , epoch2 , prefix_out , epoch_out ) : NEW_LINE INDENT args1 , auxs1 = load_checkpoint ( prefix1 , epoch1 ) NEW_LINE args2 , auxs2 = load_checkpoint ( prefix2 , epoch2 ) NEW_LINE arg_names = args1 . keys ( ) + args2 . keys ( ) NEW_LINE aux_names = auxs1 . keys ( ) + auxs2 . keys ( ) NEW_LINE args = dict ( ) NEW_LINE for arg in arg_names : NEW_LINE INDENT if arg in args1 : NEW_LINE INDENT args [ arg ] = args1 [ arg ] NEW_LINE DEDENT if arg in args2 : NEW_LINE INDENT args [ arg ] = args2 [ arg ] NEW_LINE DEDENT DEDENT auxs = dict ( ) NEW_LINE for aux in aux_names : NEW_LINE INDENT if aux in auxs1 : NEW_LINE INDENT auxs [ aux ] = auxs1 [ aux ] NEW_LINE DEDENT if aux in auxs2 : NEW_LINE INDENT auxs [ aux ] = auxs2 [ aux ] NEW_LINE DEDENT DEDENT save_checkpoint ( prefix_out , epoch_out , args , auxs ) NEW_LINE DEDENT',), ('def __init__ ( self ) : NEW_LINE INDENT self . arg_shape_dict = None NEW_LINE self . out_shape_dict = None NEW_LINE self . aux_shape_dict = None NEW_LINE self . sym = None NEW_LINE DEDENT',), ('def symbol ( self ) : NEW_LINE INDENT return self . sym NEW_LINE DEDENT',), ('def get_symbol ( self , cfg , is_train = True ) : NEW_LINE INDENT raise NotImplementedError ( ) NEW_LINE DEDENT',), ('def init_weights ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT raise NotImplementedError ( ) NEW_LINE DEDENT',), ('def get_msra_std ( self , shape ) : NEW_LINE INDENT fan_in = float ( shape [ 1 ] ) NEW_LINE if len ( shape ) > 2 : NEW_LINE INDENT fan_in *= np . prod ( shape [ 2 : ] ) NEW_LINE DEDENT print ( np . sqrt ( 2 / fan_in ) ) NEW_LINE return np . sqrt ( 2 / fan_in ) NEW_LINE DEDENT',), ('def infer_shape ( self , data_shape_dict ) : NEW_LINE INDENT arg_shape , out_shape , aux_shape = self . sym . infer_shape ( ** data_shape_dict ) NEW_LINE self . arg_shape_dict = dict ( zip ( self . sym . list_arguments ( ) , arg_shape ) ) NEW_LINE self . out_shape_dict = dict ( zip ( self . sym . list_outputs ( ) , out_shape ) ) NEW_LINE self . aux_shape_dict = dict ( zip ( self . sym . list_auxiliary_states ( ) , aux_shape ) ) NEW_LINE DEDENT',), (\"def check_parameter_shapes ( self , arg_params , aux_params , data_shape_dict , is_train = True ) : NEW_LINE INDENT for k in self . sym . list_arguments ( ) : NEW_LINE INDENT if k in data_shape_dict or ( False if is_train else ' label ' in k ) : NEW_LINE INDENT continue NEW_LINE DEDENT assert k in arg_params , k + ' ▁ not ▁ initialized ' NEW_LINE assert arg_params [ k ] . shape == self . arg_shape_dict [ k ] , ' shape ▁ inconsistent ▁ for ▁ ' + k + ' ▁ inferred ▁ ' + str ( self . arg_shape_dict [ k ] ) + ' ▁ provided ▁ ' + str ( arg_params [ k ] . shape ) NEW_LINE DEDENT for k in self . sym . list_auxiliary_states ( ) : NEW_LINE INDENT assert k in aux_params , k + ' ▁ not ▁ initialized ' NEW_LINE assert aux_params [ k ] . shape == self . aux_shape_dict [ k ] , ' shape ▁ inconsistent ▁ for ▁ ' + k + ' ▁ inferred ▁ ' + str ( self . aux_shape_dict [ k ] ) + ' ▁ provided ▁ ' + str ( aux_params [ k ] . shape ) NEW_LINE DEDENT DEDENT\",), ('def resize ( im , target_size , max_size ) : NEW_LINE INDENT im_shape = im . shape NEW_LINE im_size_min = np . min ( im_shape [ 0 : 2 ] ) NEW_LINE im_size_max = np . max ( im_shape [ 0 : 2 ] ) NEW_LINE im_scale = float ( target_size ) / float ( im_size_min ) NEW_LINE if np . round ( im_scale * im_size_max ) > max_size : NEW_LINE INDENT im_scale = float ( max_size ) / float ( im_size_max ) NEW_LINE DEDENT im = cv2 . resize ( im , None , None , fx = im_scale , fy = im_scale , interpolation = cv2 . INTER_LINEAR ) NEW_LINE return im , im_scale NEW_LINE DEDENT',), ('def transform ( im , pixel_means , need_mean = False ) : NEW_LINE INDENT assert False , \" shouldn \\' t ▁ reach ▁ here . \" NEW_LINE im = im . copy ( ) NEW_LINE im [ : , : , ( 0 , 1 , 2 ) ] = im [ : , : , ( 2 , 1 , 0 ) ] NEW_LINE im = im . astype ( float ) NEW_LINE if need_mean : NEW_LINE INDENT im -= pixel_means NEW_LINE DEDENT im_tensor = im [ np . newaxis , : ] NEW_LINE channel_swap = ( 0 , 3 , 1 , 2 ) NEW_LINE im_tensor = im_tensor . transpose ( channel_swap ) NEW_LINE return im_tensor NEW_LINE DEDENT',), ('def transform_inverse ( im_tensor , pixel_means ) : NEW_LINE INDENT assert im_tensor . shape [ 0 ] == 1 NEW_LINE im_tensor = im_tensor . copy ( ) NEW_LINE channel_swap = ( 0 , 2 , 3 , 1 ) NEW_LINE im_tensor = im_tensor . transpose ( channel_swap ) NEW_LINE im = im_tensor [ 0 ] NEW_LINE assert im . shape [ 2 ] == 3 NEW_LINE im += pixel_means NEW_LINE im = im . astype ( np . uint8 ) NEW_LINE return im NEW_LINE DEDENT',), (\"def tensor_vstack ( tensor_list , pad = 0 ) : NEW_LINE INDENT ndim = len ( tensor_list [ 0 ] . shape ) NEW_LINE if ndim == 1 : NEW_LINE INDENT return np . hstack ( tensor_list ) NEW_LINE DEDENT dimensions = [ 0 ] NEW_LINE for dim in range ( 1 , ndim ) : NEW_LINE INDENT dimensions . append ( max ( [ tensor . shape [ dim ] for tensor in tensor_list ] ) ) NEW_LINE DEDENT for ind , tensor in enumerate ( tensor_list ) : NEW_LINE INDENT pad_shape = [ ( 0 , 0 ) ] NEW_LINE for dim in range ( 1 , ndim ) : NEW_LINE INDENT pad_shape . append ( ( 0 , dimensions [ dim ] - tensor . shape [ dim ] ) ) NEW_LINE DEDENT tensor_list [ ind ] = np . lib . pad ( tensor , pad_shape , ' constant ' , constant_values = pad ) NEW_LINE DEDENT all_tensor = np . vstack ( tensor_list ) NEW_LINE return all_tensor NEW_LINE DEDENT\",), (\"def create_logger ( root_output_path , cfg , image_set ) : NEW_LINE INDENT if not os . path . exists ( root_output_path ) : NEW_LINE INDENT os . makedirs ( root_output_path ) NEW_LINE DEDENT assert os . path . exists ( root_output_path ) , ' { } ▁ does ▁ not ▁ exist ' . format ( root_output_path ) NEW_LINE cfg_name = os . path . basename ( cfg ) . split ( ' . ' ) [ 0 ] NEW_LINE config_output_path = os . path . join ( root_output_path , ' { } ' . format ( cfg_name ) ) NEW_LINE if not os . path . exists ( config_output_path ) : NEW_LINE INDENT os . makedirs ( config_output_path ) NEW_LINE DEDENT image_sets = [ iset for iset in image_set . split ( ' + ' ) ] NEW_LINE final_output_path = os . path . join ( config_output_path , ' { } ' . format ( ' _ ' . join ( image_sets ) ) ) NEW_LINE if not os . path . exists ( final_output_path ) : NEW_LINE INDENT os . makedirs ( final_output_path ) NEW_LINE DEDENT log_file = ' { } _ { } . log ' . format ( cfg_name , time . strftime ( ' % Y - % m - % d - % H - % M ' ) ) NEW_LINE head = ' % ( asctime ) -15s ▁ % ( message ) s ' NEW_LINE logging . basicConfig ( filename = os . path . join ( final_output_path , log_file ) , format = head ) NEW_LINE logger = logging . getLogger ( ) NEW_LINE logger . setLevel ( logging . INFO ) NEW_LINE return logger , final_output_path NEW_LINE DEDENT\",), ('def load_gt_roidb ( dataset_name , image_set_name , root_path , dataset_path , result_path = None , flip = False ) : NEW_LINE INDENT imdb = eval ( dataset_name ) ( image_set_name , root_path , dataset_path , result_path ) NEW_LINE roidb = imdb . gt_roidb ( ) NEW_LINE if flip : NEW_LINE INDENT roidb = imdb . append_flipped_images ( roidb ) NEW_LINE DEDENT return roidb NEW_LINE DEDENT',), ('def load_gt_roidb_poly ( dataset_name , image_set_name , root_path , dataset_path , result_path = None , flip = False ) : NEW_LINE INDENT imdb = eval ( dataset_name ) ( image_set_name , root_path , dataset_path , result_path ) NEW_LINE roidb = imdb . gt_roidb ( ) NEW_LINE if flip : NEW_LINE INDENT roidb = imdb . append_flipped_images_poly ( roidb ) NEW_LINE DEDENT return roidb NEW_LINE DEDENT',), (\"def load_proposal_roidb ( dataset_name , image_set_name , root_path , dataset_path , result_path = None , proposal = ' rpn ' , append_gt = True , flip = False ) : NEW_LINE INDENT imdb = eval ( dataset_name ) ( image_set_name , root_path , dataset_path , result_path ) NEW_LINE gt_roidb = imdb . gt_roidb ( ) NEW_LINE roidb = eval ( ' imdb . ' + proposal + ' _ roidb ' ) ( gt_roidb , append_gt ) NEW_LINE if flip : NEW_LINE INDENT roidb = imdb . append_flipped_images ( roidb ) NEW_LINE DEDENT return roidb NEW_LINE DEDENT\",), ('def merge_roidb ( roidbs ) : NEW_LINE INDENT roidb = roidbs [ 0 ] NEW_LINE for r in roidbs [ 1 : ] : NEW_LINE INDENT roidb . extend ( r ) NEW_LINE DEDENT return roidb NEW_LINE DEDENT',), ('def load_gt_segdb ( dataset_name , image_set_name , root_path , dataset_path , result_path = None , flip = False ) : NEW_LINE INDENT imdb = eval ( dataset_name ) ( image_set_name , root_path , dataset_path , result_path ) NEW_LINE segdb = imdb . gt_segdb ( ) NEW_LINE if flip : NEW_LINE INDENT segdb = imdb . append_flipped_images_for_segmentation ( segdb ) NEW_LINE DEDENT return segdb NEW_LINE DEDENT',), ('def merge_segdb ( segdbs ) : NEW_LINE INDENT segdb = segdbs [ 0 ] NEW_LINE for r in segdbs [ 1 : ] : NEW_LINE INDENT segdb . extend ( r ) NEW_LINE DEDENT return segdb NEW_LINE DEDENT',), ('def segToMask ( S , h , w ) : NEW_LINE INDENT M = np . zeros ( ( h , w ) , dtype = np . bool ) NEW_LINE for s in S : NEW_LINE INDENT N = len ( s ) NEW_LINE rr , cc = polygon ( np . array ( s [ 1 : N : 2 ] ) . clip ( max = h - 1 ) , np . array ( s [ 0 : N : 2 ] ) . clip ( max = w - 1 ) ) NEW_LINE M [ rr , cc ] = 1 NEW_LINE DEDENT return M NEW_LINE DEDENT',), (\"def decodeMask ( R ) : NEW_LINE INDENT N = len ( R [ ' counts ' ] ) NEW_LINE M = np . zeros ( ( R [ ' size ' ] [ 0 ] * R [ ' size ' ] [ 1 ] , ) ) NEW_LINE n = 0 NEW_LINE val = 1 NEW_LINE for pos in range ( N ) : NEW_LINE INDENT val = not val NEW_LINE for c in range ( R [ ' counts ' ] [ pos ] ) : NEW_LINE INDENT R [ ' counts ' ] [ pos ] NEW_LINE M [ n ] = val NEW_LINE n += 1 NEW_LINE DEDENT DEDENT return M . reshape ( ( R [ ' size ' ] ) , order = ' F ' ) NEW_LINE DEDENT\",), ('def mask_coco2voc ( coco_masks , im_height , im_width ) : NEW_LINE INDENT voc_masks = np . zeros ( ( len ( coco_masks ) , im_height , im_width ) ) NEW_LINE for i , ann in enumerate ( coco_masks ) : NEW_LINE INDENT if type ( ann ) == list : NEW_LINE INDENT m = segToMask ( ann , im_height , im_width ) NEW_LINE DEDENT else : NEW_LINE INDENT m = decodeMask ( ann ) NEW_LINE DEDENT voc_masks [ i , : , : ] = m ; NEW_LINE DEDENT return voc_masks NEW_LINE DEDENT',), (\"def show_boxes_simple ( bbox , color = ' r ' , lw = 2 ) : NEW_LINE INDENT rect = plt . Rectangle ( ( bbox [ 0 ] , bbox [ 1 ] ) , bbox [ 2 ] - bbox [ 0 ] , bbox [ 3 ] - bbox [ 1 ] , fill = False , edgecolor = color , linewidth = lw ) NEW_LINE plt . gca ( ) . add_patch ( rect ) NEW_LINE DEDENT\",), (\"def kernel_inv_map ( vis_attr , target_point , map_h , map_w ) : NEW_LINE INDENT pos_shift = [ vis_attr [ ' dilation ' ] * 0 - vis_attr [ ' pad ' ] , vis_attr [ ' dilation ' ] * 1 - vis_attr [ ' pad ' ] , vis_attr [ ' dilation ' ] * 2 - vis_attr [ ' pad ' ] ] NEW_LINE source_point = [ ] NEW_LINE for idx in range ( vis_attr [ ' filter _ size ' ] ** 2 ) : NEW_LINE INDENT cur_source_point = np . array ( [ target_point [ 0 ] + pos_shift [ idx / 3 ] , target_point [ 1 ] + pos_shift [ idx % 3 ] ] ) NEW_LINE if cur_source_point [ 0 ] < 0 or cur_source_point [ 1 ] < 0 or cur_source_point [ 0 ] > map_h - 1 or cur_source_point [ 1 ] > map_w - 1 : NEW_LINE INDENT continue NEW_LINE DEDENT source_point . append ( cur_source_point . astype ( ' f ' ) ) NEW_LINE DEDENT return source_point NEW_LINE DEDENT\",), ('def offset_inv_map ( source_points , offset ) : NEW_LINE INDENT for idx , _ in enumerate ( source_points ) : NEW_LINE INDENT source_points [ idx ] [ 0 ] += offset [ 2 * idx ] NEW_LINE source_points [ idx ] [ 1 ] += offset [ 2 * idx + 1 ] NEW_LINE DEDENT return source_points NEW_LINE DEDENT',), (\"def get_bottom_position ( vis_attr , top_points , all_offset ) : NEW_LINE INDENT map_h = all_offset [ 0 ] . shape [ 2 ] NEW_LINE map_w = all_offset [ 0 ] . shape [ 3 ] NEW_LINE for level in range ( vis_attr [ ' plot _ level ' ] ) : NEW_LINE INDENT source_points = [ ] NEW_LINE for idx , cur_top_point in enumerate ( top_points ) : NEW_LINE INDENT cur_top_point = np . round ( cur_top_point ) NEW_LINE if cur_top_point [ 0 ] < 0 or cur_top_point [ 1 ] < 0 or cur_top_point [ 0 ] > map_h - 1 or cur_top_point [ 1 ] > map_w - 1 : NEW_LINE INDENT continue NEW_LINE DEDENT cur_source_point = kernel_inv_map ( vis_attr , cur_top_point , map_h , map_w ) NEW_LINE cur_offset = np . squeeze ( all_offset [ level ] [ : , : , int ( cur_top_point [ 0 ] ) , int ( cur_top_point [ 1 ] ) ] ) NEW_LINE cur_source_point = offset_inv_map ( cur_source_point , cur_offset ) NEW_LINE source_points = source_points + cur_source_point NEW_LINE DEDENT top_points = source_points NEW_LINE DEDENT return source_points NEW_LINE DEDENT\",), (\"def plot_according_to_point ( vis_attr , im , source_points , map_h , map_w , color = [ 255 , 0 , 0 ] ) : NEW_LINE INDENT plot_area = vis_attr [ ' plot _ area ' ] NEW_LINE for idx , cur_source_point in enumerate ( source_points ) : NEW_LINE INDENT y = np . round ( ( cur_source_point [ 0 ] + 0.5 ) * im . shape [ 0 ] / map_h ) . astype ( ' i ' ) NEW_LINE x = np . round ( ( cur_source_point [ 1 ] + 0.5 ) * im . shape [ 1 ] / map_w ) . astype ( ' i ' ) NEW_LINE if x < 0 or y < 0 or x > im . shape [ 1 ] - 1 or y > im . shape [ 0 ] - 1 : NEW_LINE INDENT continue NEW_LINE DEDENT y = min ( y , im . shape [ 0 ] - vis_attr [ ' plot _ area ' ] - 1 ) NEW_LINE x = min ( x , im . shape [ 1 ] - vis_attr [ ' plot _ area ' ] - 1 ) NEW_LINE y = max ( y , vis_attr [ ' plot _ area ' ] ) NEW_LINE x = max ( x , vis_attr [ ' plot _ area ' ] ) NEW_LINE im [ y - plot_area : y + plot_area + 1 , x - plot_area : x + plot_area + 1 , : ] = np . tile ( np . reshape ( color , ( 1 , 1 , 3 ) ) , ( 2 * plot_area + 1 , 2 * plot_area + 1 , 1 ) ) NEW_LINE DEDENT return im NEW_LINE DEDENT\",), ('def show_dpsroi_offset ( im , boxes , offset , classes , trans_std = 0.1 ) : NEW_LINE INDENT plt . cla NEW_LINE for idx , bbox in enumerate ( boxes ) : NEW_LINE INDENT plt . figure ( idx + 1 ) NEW_LINE plt . axis ( \" off \" ) NEW_LINE plt . imshow ( im ) NEW_LINE offset_w = np . squeeze ( offset [ idx , classes [ idx ] * 2 , : , : ] ) * trans_std NEW_LINE offset_h = np . squeeze ( offset [ idx , classes [ idx ] * 2 + 1 , : , : ] ) * trans_std NEW_LINE x1 = int ( bbox [ 0 ] ) NEW_LINE y1 = int ( bbox [ 1 ] ) NEW_LINE x2 = int ( bbox [ 2 ] ) NEW_LINE y2 = int ( bbox [ 3 ] ) NEW_LINE roi_width = x2 - x1 + 1 NEW_LINE roi_height = y2 - y1 + 1 NEW_LINE part_size = offset_w . shape [ 0 ] NEW_LINE bin_size_w = roi_width / part_size NEW_LINE bin_size_h = roi_height / part_size NEW_LINE show_boxes_simple ( bbox , color = \\' b \\' ) NEW_LINE for ih in range ( part_size ) : NEW_LINE INDENT for iw in range ( part_size ) : NEW_LINE INDENT sub_box = np . array ( [ x1 + iw * bin_size_w , y1 + ih * bin_size_h , x1 + ( iw + 1 ) * bin_size_w , y1 + ( ih + 1 ) * bin_size_h ] ) NEW_LINE sub_offset = offset_h [ ih , iw ] * np . array ( [ 0 , 1 , 0 , 1 ] ) * roi_height + offset_w [ ih , iw ] * np . array ( [ 1 , 0 , 1 , 0 ] ) * roi_width NEW_LINE sub_box = sub_box + sub_offset NEW_LINE show_boxes_simple ( sub_box ) NEW_LINE DEDENT DEDENT plt . show ( ) NEW_LINE DEDENT DEDENT',), ('def show_dconv_offset ( im , all_offset , step = [ 2 , 2 ] , filter_size = 3 , dilation = 2 , pad = 2 , plot_area = 2 , plot_level = 3 ) : NEW_LINE INDENT vis_attr = { \\' filter _ size \\' : filter_size , \\' dilation \\' : dilation , \\' pad \\' : pad , \\' plot _ area \\' : plot_area , \\' plot _ level \\' : plot_level } NEW_LINE map_h = all_offset [ 0 ] . shape [ 2 ] NEW_LINE map_w = all_offset [ 0 ] . shape [ 3 ] NEW_LINE step_h = step [ 0 ] NEW_LINE step_w = step [ 1 ] NEW_LINE start_h = np . round ( step_h / 2 ) NEW_LINE start_w = np . round ( step_w / 2 ) NEW_LINE plt . figure ( ) NEW_LINE for im_h in range ( start_h , map_h , step_h ) : NEW_LINE INDENT for im_w in range ( start_w , map_w , step_w ) : NEW_LINE INDENT target_point = np . array ( [ im_h , im_w ] ) NEW_LINE source_y = np . round ( target_point [ 0 ] * im . shape [ 0 ] / map_h ) NEW_LINE source_x = np . round ( target_point [ 1 ] * im . shape [ 1 ] / map_w ) NEW_LINE if source_y < plot_area or source_x < plot_area or source_y >= im . shape [ 0 ] - plot_area or source_x >= im . shape [ 1 ] - plot_area : NEW_LINE INDENT continue NEW_LINE DEDENT cur_im = np . copy ( im ) NEW_LINE source_points = get_bottom_position ( vis_attr , [ target_point ] , all_offset ) NEW_LINE cur_im = plot_according_to_point ( vis_attr , cur_im , source_points , map_h , map_w ) NEW_LINE cur_im [ source_y - plot_area : source_y + plot_area + 1 , source_x - plot_area : source_x + plot_area + 1 , : ] = np . tile ( np . reshape ( [ 0 , 255 , 0 ] , ( 1 , 1 , 3 ) ) , ( 2 * plot_area + 1 , 2 * plot_area + 1 , 1 ) ) NEW_LINE plt . axis ( \" off \" ) NEW_LINE plt . imshow ( cur_im ) NEW_LINE plt . show ( block = False ) NEW_LINE plt . pause ( 0.01 ) NEW_LINE plt . clf ( ) NEW_LINE DEDENT DEDENT DEDENT',), (\"def get_test_image ( roidb , config ) : NEW_LINE INDENT num_images = len ( roidb ) NEW_LINE processed_ims = [ ] NEW_LINE processed_roidb = [ ] NEW_LINE for i in range ( num_images ) : NEW_LINE INDENT roi_rec = roidb [ i ] NEW_LINE assert os . path . exists ( roi_rec [ ' image ' ] ) , ' % s ▁ does ▁ not ▁ exist ' . format ( roi_rec [ ' image ' ] ) NEW_LINE im = cv2 . imread ( roi_rec [ ' image ' ] , cv2 . IMREAD_COLOR | cv2 . IMREAD_IGNORE_ORIENTATION ) NEW_LINE new_rec = roi_rec . copy ( ) NEW_LINE scale_ind = random . randrange ( len ( config . SCALES ) ) NEW_LINE target_size = config . SCALES [ scale_ind ] [ 0 ] NEW_LINE max_size = config . SCALES [ scale_ind ] [ 1 ] NEW_LINE im , im_scale = resize ( im , target_size , max_size , stride = config . network . IMAGE_STRIDE ) NEW_LINE im_tensor = transform ( im , config . network . PIXEL_MEANS ) NEW_LINE processed_ims . append ( im_tensor ) NEW_LINE im_info = [ im_tensor . shape [ 2 ] , im_tensor . shape [ 3 ] , im_scale ] NEW_LINE new_rec [ ' im _ info ' ] = im_info NEW_LINE processed_roidb . append ( new_rec ) NEW_LINE DEDENT return processed_ims , processed_roidb NEW_LINE DEDENT\",), (\"def get_image ( roidb , config ) : NEW_LINE INDENT num_images = len ( roidb ) NEW_LINE processed_ims = [ ] NEW_LINE processed_roidb = [ ] NEW_LINE for i in range ( num_images ) : NEW_LINE INDENT roi_rec = roidb [ i ] NEW_LINE assert os . path . exists ( roi_rec [ ' image ' ] ) , ' % s ▁ does ▁ not ▁ exist ' . format ( roi_rec [ ' image ' ] ) NEW_LINE im = cv2 . imread ( roi_rec [ ' image ' ] , cv2 . IMREAD_COLOR | cv2 . IMREAD_IGNORE_ORIENTATION ) NEW_LINE if roidb [ i ] [ ' flipped ' ] : NEW_LINE INDENT im = im [ : , : : - 1 , : ] NEW_LINE DEDENT new_rec = roi_rec . copy ( ) NEW_LINE scale_ind = random . randrange ( len ( config . SCALES ) ) NEW_LINE target_size = config . SCALES [ scale_ind ] [ 0 ] NEW_LINE max_size = config . SCALES [ scale_ind ] [ 1 ] NEW_LINE im , im_scale = resize ( im , target_size , max_size , stride = config . network . IMAGE_STRIDE ) NEW_LINE im_tensor = transform ( im , config . network . PIXEL_MEANS ) NEW_LINE processed_ims . append ( im_tensor ) NEW_LINE im_info = [ im_tensor . shape [ 2 ] , im_tensor . shape [ 3 ] , im_scale ] NEW_LINE new_rec [ ' boxes ' ] = clip_boxes ( np . round ( roi_rec [ ' boxes ' ] . copy ( ) * im_scale ) , im_info [ : 2 ] ) NEW_LINE new_rec [ ' im _ info ' ] = im_info NEW_LINE processed_roidb . append ( new_rec ) NEW_LINE DEDENT return processed_ims , processed_roidb NEW_LINE DEDENT\",), (\"def get_segmentation_image ( segdb , config ) : NEW_LINE INDENT num_images = len ( segdb ) NEW_LINE assert num_images > 0 , ' No ▁ images ' NEW_LINE processed_ims = [ ] NEW_LINE processed_segdb = [ ] NEW_LINE processed_seg_cls_gt = [ ] NEW_LINE for i in range ( num_images ) : NEW_LINE INDENT seg_rec = segdb [ i ] NEW_LINE assert os . path . exists ( seg_rec [ ' image ' ] ) , ' % s ▁ does ▁ not ▁ exist ' . format ( seg_rec [ ' image ' ] ) NEW_LINE im = np . array ( cv2 . imread ( seg_rec [ ' image ' ] ) ) NEW_LINE new_rec = seg_rec . copy ( ) NEW_LINE scale_ind = random . randrange ( len ( config . SCALES ) ) NEW_LINE target_size = config . SCALES [ scale_ind ] [ 0 ] NEW_LINE max_size = config . SCALES [ scale_ind ] [ 1 ] NEW_LINE im , im_scale = resize ( im , target_size , max_size , stride = config . network . IMAGE_STRIDE ) NEW_LINE im_tensor = transform ( im , config . network . PIXEL_MEANS ) NEW_LINE im_info = [ im_tensor . shape [ 2 ] , im_tensor . shape [ 3 ] , im_scale ] NEW_LINE new_rec [ ' im _ info ' ] = im_info NEW_LINE seg_cls_gt = np . array ( Image . open ( seg_rec [ ' seg _ cls _ path ' ] ) ) NEW_LINE seg_cls_gt , seg_cls_gt_scale = resize ( seg_cls_gt , target_size , max_size , stride = config . network . IMAGE_STRIDE , interpolation = cv2 . INTER_NEAREST ) NEW_LINE seg_cls_gt_tensor = transform_seg_gt ( seg_cls_gt ) NEW_LINE processed_ims . append ( im_tensor ) NEW_LINE processed_segdb . append ( new_rec ) NEW_LINE processed_seg_cls_gt . append ( seg_cls_gt_tensor ) NEW_LINE DEDENT return processed_ims , processed_seg_cls_gt , processed_segdb NEW_LINE DEDENT\",), ('def resize ( im , target_size , max_size , stride = 0 , interpolation = cv2 . INTER_LINEAR ) : NEW_LINE INDENT im_shape = im . shape NEW_LINE im_size_min = np . min ( im_shape [ 0 : 2 ] ) NEW_LINE im_size_max = np . max ( im_shape [ 0 : 2 ] ) NEW_LINE im_scale = float ( target_size ) / float ( im_size_min ) NEW_LINE if np . round ( im_scale * im_size_max ) > max_size : NEW_LINE INDENT im_scale = float ( max_size ) / float ( im_size_max ) NEW_LINE DEDENT im = cv2 . resize ( im , None , None , fx = im_scale , fy = im_scale , interpolation = interpolation ) NEW_LINE if stride == 0 : NEW_LINE INDENT return im , im_scale NEW_LINE DEDENT else : NEW_LINE INDENT im_height = int ( np . ceil ( im . shape [ 0 ] / float ( stride ) ) * stride ) NEW_LINE im_width = int ( np . ceil ( im . shape [ 1 ] / float ( stride ) ) * stride ) NEW_LINE im_channel = im . shape [ 2 ] NEW_LINE padded_im = np . zeros ( ( im_height , im_width , im_channel ) ) NEW_LINE padded_im [ : im . shape [ 0 ] , : im . shape [ 1 ] , : ] = im NEW_LINE return padded_im , im_scale NEW_LINE DEDENT DEDENT',), ('def transform ( im , pixel_means ) : NEW_LINE INDENT im_tensor = np . zeros ( ( 1 , 3 , im . shape [ 0 ] , im . shape [ 1 ] ) ) NEW_LINE for i in range ( 3 ) : NEW_LINE INDENT im_tensor [ 0 , i , : , : ] = im [ : , : , 2 - i ] - pixel_means [ 2 - i ] NEW_LINE DEDENT return im_tensor NEW_LINE DEDENT',), ('def transform_seg_gt ( gt ) : NEW_LINE INDENT gt_tensor = np . zeros ( ( 1 , 1 , gt . shape [ 0 ] , gt . shape [ 1 ] ) ) NEW_LINE gt_tensor [ 0 , 0 , : , : ] = gt [ : , : ] NEW_LINE return gt_tensor NEW_LINE DEDENT',), ('def transform_inverse ( im_tensor , pixel_means ) : NEW_LINE INDENT assert im_tensor . shape [ 0 ] == 1 NEW_LINE im_tensor = im_tensor . copy ( ) NEW_LINE channel_swap = ( 0 , 2 , 3 , 1 ) NEW_LINE im_tensor = im_tensor . transpose ( channel_swap ) NEW_LINE im = im_tensor [ 0 ] NEW_LINE assert im . shape [ 2 ] == 3 NEW_LINE im += pixel_means [ [ 2 , 1 , 0 ] ] NEW_LINE im = im . astype ( np . uint8 ) NEW_LINE return im NEW_LINE DEDENT',), (\"def tensor_vstack ( tensor_list , pad = 0 ) : NEW_LINE INDENT ndim = len ( tensor_list [ 0 ] . shape ) NEW_LINE dtype = tensor_list [ 0 ] . dtype NEW_LINE islice = tensor_list [ 0 ] . shape [ 0 ] NEW_LINE dimensions = [ ] NEW_LINE first_dim = sum ( [ tensor . shape [ 0 ] for tensor in tensor_list ] ) NEW_LINE dimensions . append ( first_dim ) NEW_LINE for dim in range ( 1 , ndim ) : NEW_LINE INDENT dimensions . append ( max ( [ tensor . shape [ dim ] for tensor in tensor_list ] ) ) NEW_LINE DEDENT if pad == 0 : NEW_LINE INDENT all_tensor = np . zeros ( tuple ( dimensions ) , dtype = dtype ) NEW_LINE DEDENT elif pad == 1 : NEW_LINE INDENT all_tensor = np . ones ( tuple ( dimensions ) , dtype = dtype ) NEW_LINE DEDENT else : NEW_LINE INDENT all_tensor = np . full ( tuple ( dimensions ) , pad , dtype = dtype ) NEW_LINE DEDENT if ndim == 1 : NEW_LINE INDENT for ind , tensor in enumerate ( tensor_list ) : NEW_LINE INDENT all_tensor [ ind * islice : ( ind + 1 ) * islice ] = tensor NEW_LINE DEDENT DEDENT elif ndim == 2 : NEW_LINE INDENT for ind , tensor in enumerate ( tensor_list ) : NEW_LINE INDENT all_tensor [ ind * islice : ( ind + 1 ) * islice , : tensor . shape [ 1 ] ] = tensor NEW_LINE DEDENT DEDENT elif ndim == 3 : NEW_LINE INDENT for ind , tensor in enumerate ( tensor_list ) : NEW_LINE INDENT all_tensor [ ind * islice : ( ind + 1 ) * islice , : tensor . shape [ 1 ] , : tensor . shape [ 2 ] ] = tensor NEW_LINE DEDENT DEDENT elif ndim == 4 : NEW_LINE INDENT for ind , tensor in enumerate ( tensor_list ) : NEW_LINE INDENT all_tensor [ ind * islice : ( ind + 1 ) * islice , : tensor . shape [ 1 ] , : tensor . shape [ 2 ] , : tensor . shape [ 3 ] ] = tensor NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT raise Exception ( ' Sorry , ▁ unimplemented . ' ) NEW_LINE DEDENT return all_tensor NEW_LINE DEDENT\",), ('def show_masks ( im , dets , msks , show = True , thresh = 1e-3 , scale = 1.0 ) : NEW_LINE INDENT plt . cla ( ) NEW_LINE plt . imshow ( im ) NEW_LINE for det , msk in zip ( dets , msks ) : NEW_LINE INDENT color = ( random . random ( ) , random . random ( ) , random . random ( ) ) NEW_LINE bbox = det [ : 4 ] * scale NEW_LINE cod = np . zeros ( 4 ) . astype ( int ) NEW_LINE cod [ 0 ] = int ( bbox [ 0 ] ) NEW_LINE cod [ 1 ] = int ( bbox [ 1 ] ) NEW_LINE cod [ 2 ] = int ( bbox [ 2 ] ) NEW_LINE cod [ 3 ] = int ( bbox [ 3 ] ) NEW_LINE if im [ cod [ 0 ] : cod [ 2 ] , cod [ 1 ] : cod [ 3 ] , 0 ] . size > 0 : NEW_LINE INDENT msk = cv2 . resize ( msk , im [ cod [ 1 ] : cod [ 3 ] , cod [ 0 ] : cod [ 2 ] , 0 ] . T . shape ) NEW_LINE bimsk = msk > thresh NEW_LINE bimsk = bimsk . astype ( int ) NEW_LINE bimsk = np . repeat ( bimsk [ : , : , np . newaxis ] , 3 , axis = 2 ) NEW_LINE mskd = im [ cod [ 1 ] : cod [ 3 ] , cod [ 0 ] : cod [ 2 ] , : ] * bimsk NEW_LINE clmsk = np . ones ( bimsk . shape ) * bimsk NEW_LINE clmsk [ : , : , 0 ] = clmsk [ : , : , 0 ] * color [ 0 ] * 256 ; NEW_LINE clmsk [ : , : , 1 ] = clmsk [ : , : , 1 ] * color [ 1 ] * 256 ; NEW_LINE clmsk [ : , : , 2 ] = clmsk [ : , : , 2 ] * color [ 2 ] * 256 ; NEW_LINE im [ cod [ 1 ] : cod [ 3 ] , cod [ 0 ] : cod [ 2 ] , : ] = im [ cod [ 1 ] : cod [ 3 ] , cod [ 0 ] : cod [ 2 ] , : ] + 0.8 * clmsk - 0.8 * mskd NEW_LINE DEDENT DEDENT plt . imshow ( im ) NEW_LINE if ( show ) : NEW_LINE INDENT plt . show ( ) NEW_LINE DEDENT return im NEW_LINE DEDENT',), (\"def _get_ann_file ( self ) : NEW_LINE INDENT prefix = ' instances ' if ' test ' not in self . image_set else ' image _ info ' NEW_LINE return os . path . join ( self . data_path , ' annotations ' , prefix + ' _ ' + self . image_set + ' . json ' ) NEW_LINE DEDENT\",), ('def _load_image_set_index ( self ) : NEW_LINE INDENT image_ids = self . coco . getImgIds ( ) NEW_LINE return image_ids NEW_LINE DEDENT',), (\"def image_path_from_index ( self , index ) : NEW_LINE INDENT filename = ' COCO _ % s _ %012d . jpg ' % ( self . data_name , index ) NEW_LINE image_path = os . path . join ( self . data_path , ' images ' , self . data_name , filename ) NEW_LINE assert os . path . exists ( image_path ) , ' Path ▁ does ▁ not ▁ exist : ▁ { } ' . format ( image_path ) NEW_LINE return image_path NEW_LINE DEDENT\",), (\"def _load_coco_annotation ( self , index ) : NEW_LINE INDENT im_ann = self . coco . loadImgs ( index ) [ 0 ] NEW_LINE width = im_ann [ ' width ' ] NEW_LINE height = im_ann [ ' height ' ] NEW_LINE annIds = self . coco . getAnnIds ( imgIds = index , iscrowd = False ) NEW_LINE objs = self . coco . loadAnns ( annIds ) NEW_LINE valid_objs = [ ] NEW_LINE for obj in objs : NEW_LINE INDENT x , y , w , h = obj [ ' bbox ' ] NEW_LINE x1 = np . max ( ( 0 , x ) ) NEW_LINE y1 = np . max ( ( 0 , y ) ) NEW_LINE x2 = np . min ( ( width - 1 , x1 + np . max ( ( 0 , w - 1 ) ) ) ) NEW_LINE y2 = np . min ( ( height - 1 , y1 + np . max ( ( 0 , h - 1 ) ) ) ) NEW_LINE if obj [ ' area ' ] > 0 and x2 >= x1 and y2 >= y1 : NEW_LINE INDENT obj [ ' clean _ bbox ' ] = [ x1 , y1 , x2 , y2 ] NEW_LINE valid_objs . append ( obj ) NEW_LINE DEDENT DEDENT objs = valid_objs NEW_LINE num_objs = len ( objs ) NEW_LINE boxes = np . zeros ( ( num_objs , 4 ) , dtype = np . uint16 ) NEW_LINE gt_classes = np . zeros ( ( num_objs ) , dtype = np . int32 ) NEW_LINE overlaps = np . zeros ( ( num_objs , self . num_classes ) , dtype = np . float32 ) NEW_LINE for ix , obj in enumerate ( objs ) : NEW_LINE INDENT cls = self . _coco_ind_to_class_ind [ obj [ ' category _ id ' ] ] NEW_LINE boxes [ ix , : ] = obj [ ' clean _ bbox ' ] NEW_LINE gt_classes [ ix ] = cls NEW_LINE if obj [ ' iscrowd ' ] : NEW_LINE INDENT overlaps [ ix , : ] = - 1.0 NEW_LINE DEDENT else : NEW_LINE INDENT overlaps [ ix , cls ] = 1.0 NEW_LINE DEDENT DEDENT roi_rec = { ' image ' : self . image_path_from_index ( index ) , ' height ' : height , ' width ' : width , ' boxes ' : boxes , ' gt _ classes ' : gt_classes , ' gt _ overlaps ' : overlaps , ' max _ classes ' : overlaps . argmax ( axis = 1 ) , ' max _ overlaps ' : overlaps . max ( axis = 1 ) , ' flipped ' : False } NEW_LINE return roi_rec NEW_LINE DEDENT\",), (\"def mask_path_from_index ( self , index ) : NEW_LINE INDENT if self . data_name == ' val ' : NEW_LINE INDENT return [ ] NEW_LINE DEDENT cache_file = os . path . join ( self . cache_path , ' COCOMask ' , self . data_name ) NEW_LINE if not os . path . exists ( cache_file ) : NEW_LINE INDENT os . makedirs ( cache_file ) NEW_LINE DEDENT filename = ' COCO _ % s _ %012d ' % ( self . data_name , index ) NEW_LINE gt_mask_file = os . path . join ( cache_file , filename + ' . hkl ' ) NEW_LINE return gt_mask_file NEW_LINE DEDENT\",), (\"def load_coco_sds_annotation ( self , index ) : NEW_LINE INDENT im_ann = self . coco . loadImgs ( index ) [ 0 ] NEW_LINE width = im_ann [ ' width ' ] NEW_LINE height = im_ann [ ' height ' ] NEW_LINE annIds = self . coco . getAnnIds ( imgIds = index , iscrowd = False ) NEW_LINE objs = self . coco . loadAnns ( annIds ) NEW_LINE valid_objs = [ ] NEW_LINE for obj in objs : NEW_LINE INDENT x , y , w , h = obj [ ' bbox ' ] NEW_LINE x1 = np . max ( ( 0 , x ) ) NEW_LINE y1 = np . max ( ( 0 , y ) ) NEW_LINE x2 = np . min ( ( width - 1 , x1 + np . max ( ( 0 , w - 1 ) ) ) ) NEW_LINE y2 = np . min ( ( height - 1 , y1 + np . max ( ( 0 , h - 1 ) ) ) ) NEW_LINE if obj [ ' area ' ] > 0 and x2 >= x1 and y2 >= y1 : NEW_LINE INDENT obj [ ' clean _ bbox ' ] = [ x1 , y1 , x2 , y2 ] NEW_LINE valid_objs . append ( obj ) NEW_LINE DEDENT DEDENT objs = valid_objs NEW_LINE num_objs = len ( objs ) NEW_LINE boxes = np . zeros ( ( num_objs , 4 ) , dtype = np . uint16 ) NEW_LINE gt_classes = np . zeros ( ( num_objs ) , dtype = np . int32 ) NEW_LINE overlaps = np . zeros ( ( num_objs , self . num_classes ) , dtype = np . float32 ) NEW_LINE for ix , obj in enumerate ( objs ) : NEW_LINE INDENT cls = self . _coco_ind_to_class_ind [ obj [ ' category _ id ' ] ] NEW_LINE boxes [ ix , : ] = obj [ ' clean _ bbox ' ] NEW_LINE gt_classes [ ix ] = cls NEW_LINE if obj [ ' iscrowd ' ] : NEW_LINE INDENT overlaps [ ix , : ] = - 1.0 NEW_LINE DEDENT else : NEW_LINE INDENT overlaps [ ix , cls ] = 1.0 NEW_LINE DEDENT DEDENT sds_rec = { ' image ' : self . image_path_from_index ( index ) , ' height ' : height , ' width ' : width , ' boxes ' : boxes , ' gt _ classes ' : gt_classes , ' gt _ overlaps ' : overlaps , ' max _ classes ' : overlaps . argmax ( axis = 1 ) , ' max _ overlaps ' : overlaps . max ( axis = 1 ) , ' cache _ seg _ inst ' : self . mask_path_from_index ( index ) , ' flipped ' : False } NEW_LINE return sds_rec , objs NEW_LINE DEDENT\",), (\"def evaluate_detections ( self , detections , ann_type = ' bbox ' , all_masks = None ) : NEW_LINE INDENT res_folder = os . path . join ( self . result_path , ' results ' ) NEW_LINE if not os . path . exists ( res_folder ) : NEW_LINE INDENT os . makedirs ( res_folder ) NEW_LINE DEDENT res_file = os . path . join ( res_folder , ' detections _ % s _ results . json ' % self . image_set ) NEW_LINE self . _write_coco_results ( detections , res_file , ann_type , all_masks ) NEW_LINE if ' test ' not in self . image_set : NEW_LINE INDENT info_str = self . _do_python_eval ( res_file , res_folder , ann_type ) NEW_LINE return info_str NEW_LINE DEDENT DEDENT\",), (\"def evaluate_sds ( self , all_boxes , all_masks ) : NEW_LINE INDENT info_str = self . evaluate_detections ( all_boxes , ' segm ' , all_masks ) NEW_LINE return info_str NEW_LINE DEDENT\",), ('def get_flipped_entry_outclass_wrapper ( IMDB_instance , seg_rec ) : NEW_LINE INDENT return IMDB_instance . get_flipped_entry ( seg_rec ) NEW_LINE DEDENT',), (\"def merge_roidbs ( a , b ) : NEW_LINE INDENT assert len ( a ) == len ( b ) NEW_LINE for i in range ( len ( a ) ) : NEW_LINE INDENT a [ i ] [ ' boxes ' ] = np . vstack ( ( a [ i ] [ ' boxes ' ] , b [ i ] [ ' boxes ' ] ) ) NEW_LINE a [ i ] [ ' gt _ classes ' ] = np . hstack ( ( a [ i ] [ ' gt _ classes ' ] , b [ i ] [ ' gt _ classes ' ] ) ) NEW_LINE a [ i ] [ ' gt _ overlaps ' ] = np . vstack ( ( a [ i ] [ ' gt _ overlaps ' ] , b [ i ] [ ' gt _ overlaps ' ] ) ) NEW_LINE a [ i ] [ ' max _ classes ' ] = np . hstack ( ( a [ i ] [ ' max _ classes ' ] , b [ i ] [ ' max _ classes ' ] ) ) NEW_LINE a [ i ] [ ' max _ overlaps ' ] = np . hstack ( ( a [ i ] [ ' max _ overlaps ' ] , b [ i ] [ ' max _ overlaps ' ] ) ) NEW_LINE DEDENT return a NEW_LINE DEDENT\",), (\"def __init__ ( self , name , image_set , root_path , dataset_path , result_path = None ) : NEW_LINE INDENT self . name = name + ' _ ' + image_set NEW_LINE self . image_set = image_set NEW_LINE self . root_path = root_path NEW_LINE self . data_path = dataset_path NEW_LINE self . _result_path = result_path NEW_LINE self . classes = [ ] NEW_LINE self . num_classes = 0 NEW_LINE self . image_set_index = [ ] NEW_LINE self . num_images = 0 NEW_LINE self . config = { } NEW_LINE DEDENT\",), ('def image_path_from_index ( self , index ) : NEW_LINE INDENT raise NotImplementedError NEW_LINE DEDENT',), ('def gt_roidb ( self ) : NEW_LINE INDENT raise NotImplementedError NEW_LINE DEDENT',), ('def evaluate_detections ( self , detections ) : NEW_LINE INDENT raise NotImplementedError NEW_LINE DEDENT',), ('def evaluate_segmentations ( self , segmentations ) : NEW_LINE INDENT raise NotImplementedError NEW_LINE DEDENT',), (\"def cache_path ( self ) : NEW_LINE INDENT cache_path = os . path . join ( self . root_path , ' cache ' ) NEW_LINE if not os . path . exists ( cache_path ) : NEW_LINE INDENT os . mkdir ( cache_path ) NEW_LINE DEDENT return cache_path NEW_LINE DEDENT\",), ('def result_path ( self ) : NEW_LINE INDENT if self . _result_path and os . path . exists ( self . _result_path ) : NEW_LINE INDENT return self . _result_path NEW_LINE DEDENT else : NEW_LINE INDENT return self . cache_path NEW_LINE DEDENT DEDENT',), ('def image_path_at ( self , index ) : NEW_LINE INDENT return self . image_path_from_index ( self . image_set_index [ index ] ) NEW_LINE DEDENT',), ('def load_rpn_roidb ( self , gt_roidb ) : NEW_LINE INDENT box_list = self . load_rpn_data ( ) NEW_LINE return self . create_roidb_from_box_list ( box_list , gt_roidb ) NEW_LINE DEDENT',), (\"def create_roidb_from_box_list ( self , box_list , gt_roidb ) : NEW_LINE INDENT assert len ( box_list ) == self . num_images , ' number ▁ of ▁ boxes ▁ matrix ▁ must ▁ match ▁ number ▁ of ▁ images ' NEW_LINE roidb = [ ] NEW_LINE for i in range ( self . num_images ) : NEW_LINE INDENT roi_rec = dict ( ) NEW_LINE roi_rec [ ' image ' ] = gt_roidb [ i ] [ ' image ' ] NEW_LINE roi_rec [ ' height ' ] = gt_roidb [ i ] [ ' height ' ] NEW_LINE roi_rec [ ' width ' ] = gt_roidb [ i ] [ ' width ' ] NEW_LINE boxes = box_list [ i ] NEW_LINE if boxes . shape [ 1 ] == 5 : NEW_LINE INDENT boxes = boxes [ : , : 4 ] NEW_LINE DEDENT num_boxes = boxes . shape [ 0 ] NEW_LINE overlaps = np . zeros ( ( num_boxes , self . num_classes ) , dtype = np . float32 ) NEW_LINE if gt_roidb is not None and gt_roidb [ i ] [ ' boxes ' ] . size > 0 : NEW_LINE INDENT gt_boxes = gt_roidb [ i ] [ ' boxes ' ] NEW_LINE gt_classes = gt_roidb [ i ] [ ' gt _ classes ' ] NEW_LINE gt_overlaps = bbox_overlaps ( boxes . astype ( np . float ) , gt_boxes . astype ( np . float ) ) NEW_LINE argmaxes = gt_overlaps . argmax ( axis = 1 ) NEW_LINE maxes = gt_overlaps . max ( axis = 1 ) NEW_LINE I = np . where ( maxes > 0 ) [ 0 ] NEW_LINE overlaps [ I , gt_classes [ argmaxes [ I ] ] ] = maxes [ I ] NEW_LINE DEDENT roi_rec . update ( { ' boxes ' : boxes , ' gt _ classes ' : np . zeros ( ( num_boxes , ) , dtype = np . int32 ) , ' gt _ overlaps ' : overlaps , ' max _ classes ' : overlaps . argmax ( axis = 1 ) , ' max _ overlaps ' : overlaps . max ( axis = 1 ) , ' flipped ' : False } ) NEW_LINE zero_indexes = np . where ( roi_rec [ ' max _ overlaps ' ] == 0 ) [ 0 ] NEW_LINE assert all ( roi_rec [ ' max _ classes ' ] [ zero_indexes ] == 0 ) NEW_LINE nonzero_indexes = np . where ( roi_rec [ ' max _ overlaps ' ] > 0 ) [ 0 ] NEW_LINE assert all ( roi_rec [ ' max _ classes ' ] [ nonzero_indexes ] != 0 ) NEW_LINE roidb . append ( roi_rec ) NEW_LINE DEDENT return roidb NEW_LINE DEDENT\",), (\"def get_flipped_entry ( self , seg_rec ) : NEW_LINE INDENT return { ' image ' : self . flip_and_save ( seg_rec [ ' image ' ] ) , ' seg _ cls _ path ' : self . flip_and_save ( seg_rec [ ' seg _ cls _ path ' ] ) , ' height ' : seg_rec [ ' height ' ] , ' width ' : seg_rec [ ' width ' ] , ' flipped ' : True } NEW_LINE DEDENT\",), ('def append_rotated_images ( self , roidb ) : NEW_LINE INDENT pass NEW_LINE DEDENT',), (\"def flip_and_save ( self , image_path ) : NEW_LINE INDENT [ image_name , image_ext ] = os . path . splitext ( os . path . basename ( image_path ) ) NEW_LINE image_dir = os . path . dirname ( image_path ) NEW_LINE saved_image_path = os . path . join ( image_dir , image_name + ' _ flip ' + image_ext ) NEW_LINE try : NEW_LINE INDENT flipped_image = Image . open ( saved_image_path ) NEW_LINE DEDENT except : NEW_LINE INDENT flipped_image = Image . open ( image_path ) NEW_LINE flipped_image = flipped_image . transpose ( Image . FLIP_LEFT_RIGHT ) NEW_LINE flipped_image . save ( saved_image_path , ' png ' ) NEW_LINE DEDENT return saved_image_path NEW_LINE DEDENT\",), (\"def parse_voc_rec ( filename ) : NEW_LINE INDENT import xml . etree . ElementTree as ET NEW_LINE tree = ET . parse ( filename ) NEW_LINE objects = [ ] NEW_LINE for obj in tree . findall ( ' object ' ) : NEW_LINE INDENT obj_dict = dict ( ) NEW_LINE obj_dict [ ' name ' ] = obj . find ( ' name ' ) . text NEW_LINE obj_dict [ ' difficult ' ] = int ( obj . find ( ' difficult ' ) . text ) NEW_LINE bbox = obj . find ( ' bndbox ' ) NEW_LINE obj_dict [ ' bbox ' ] = [ int ( float ( bbox . find ( ' xmin ' ) . text ) ) , int ( float ( bbox . find ( ' ymin ' ) . text ) ) , int ( float ( bbox . find ( ' xmax ' ) . text ) ) , int ( float ( bbox . find ( ' ymax ' ) . text ) ) ] NEW_LINE objects . append ( obj_dict ) NEW_LINE DEDENT return objects NEW_LINE DEDENT\",), ('def voc_ap ( rec , prec , use_07_metric = False ) : NEW_LINE INDENT if use_07_metric : NEW_LINE INDENT ap = 0. NEW_LINE for t in np . arange ( 0. , 1.1 , 0.1 ) : NEW_LINE INDENT if np . sum ( rec >= t ) == 0 : NEW_LINE INDENT p = 0 NEW_LINE DEDENT else : NEW_LINE INDENT p = np . max ( prec [ rec >= t ] ) NEW_LINE DEDENT ap += p / 11. NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT mrec = np . concatenate ( ( [ 0. ] , rec , [ 1. ] ) ) NEW_LINE mpre = np . concatenate ( ( [ 0. ] , prec , [ 0. ] ) ) NEW_LINE for i in range ( mpre . size - 1 , 0 , - 1 ) : NEW_LINE INDENT mpre [ i - 1 ] = np . maximum ( mpre [ i - 1 ] , mpre [ i ] ) NEW_LINE DEDENT i = np . where ( mrec [ 1 : ] != mrec [ : - 1 ] ) [ 0 ] NEW_LINE ap = np . sum ( ( mrec [ i + 1 ] - mrec [ i ] ) * mpre [ i + 1 ] ) NEW_LINE DEDENT return ap NEW_LINE DEDENT',), ('def load_image_set_index ( self ) : NEW_LINE INDENT image_set_main_folder_path = os . path . join ( self . data_path , self . image_set_main_folder , self . image_set_sub_folder ) NEW_LINE image_name_set = [ filename for parent , dirname , filename in os . walk ( image_set_main_folder_path ) ] NEW_LINE image_name_set = list ( itertools . chain . from_iterable ( image_name_set ) ) NEW_LINE index_set = [ \\' \\' for x in range ( len ( image_name_set ) ) ] NEW_LINE valid_index_count = 0 NEW_LINE for i , image_name in enumerate ( image_name_set ) : NEW_LINE INDENT splited_name_set = image_name . split ( \\' _ \\' ) NEW_LINE ext_split = splited_name_set [ len ( splited_name_set ) - 1 ] . split ( \\' . \\' ) NEW_LINE ext = ext_split [ len ( ext_split ) - 1 ] NEW_LINE if splited_name_set [ len ( splited_name_set ) - 1 ] != \\' flip . png \\' and ext == \\' png \\' : NEW_LINE INDENT index_set [ valid_index_count ] = \" _ \" . join ( splited_name_set [ : len ( splited_name_set ) - 1 ] ) NEW_LINE valid_index_count += 1 NEW_LINE DEDENT DEDENT return index_set [ : valid_index_count ] NEW_LINE DEDENT',), (\"def image_path_from_index ( self , index ) : NEW_LINE INDENT index_folder = index . split ( ' _ ' ) [ 0 ] NEW_LINE image_file = os . path . join ( self . data_path , self . image_set_main_folder , self . image_set_sub_folder , index_folder , index + ' _ ' + self . image_set_main_folder + ' . png ' ) NEW_LINE assert os . path . exists ( image_file ) , ' Path ▁ does ▁ not ▁ exist : ▁ { } ' . format ( image_file ) NEW_LINE return image_file NEW_LINE DEDENT\",), (\"def annotation_path_from_index ( self , index ) : NEW_LINE INDENT index_folder = index . split ( ' _ ' ) [ 0 ] NEW_LINE image_file = os . path . join ( self . data_path , ' gtFine ' , self . image_set_sub_folder , index_folder , index + ' _ gtFine _ labelTrainIds . png ' ) NEW_LINE assert os . path . exists ( image_file ) , ' Path ▁ does ▁ not ▁ exist : ▁ { } ' . format ( image_file ) NEW_LINE return image_file NEW_LINE DEDENT\",), (\"def load_segdb_from_index ( self , index ) : NEW_LINE INDENT seg_rec = dict ( ) NEW_LINE seg_rec [ ' image ' ] = self . image_path_from_index ( index ) NEW_LINE size = cv2 . imread ( seg_rec [ ' image ' ] ) . shape NEW_LINE seg_rec [ ' height ' ] = size [ 0 ] NEW_LINE seg_rec [ ' width ' ] = size [ 1 ] NEW_LINE seg_rec [ ' seg _ cls _ path ' ] = self . annotation_path_from_index ( index ) NEW_LINE seg_rec [ ' flipped ' ] = False NEW_LINE return seg_rec NEW_LINE DEDENT\",), (\"def getpallete ( self , num_cls ) : NEW_LINE INDENT n = num_cls NEW_LINE pallete_raw = np . zeros ( ( n , 3 ) ) . astype ( ' uint8' ) NEW_LINE pallete = np . zeros ( ( n , 3 ) ) . astype ( ' uint8' ) NEW_LINE pallete_raw [ 6 , : ] = [ 111 , 74 , 0 ] NEW_LINE pallete_raw [ 7 , : ] = [ 81 , 0 , 81 ] NEW_LINE pallete_raw [ 8 , : ] = [ 128 , 64 , 128 ] NEW_LINE pallete_raw [ 9 , : ] = [ 244 , 35 , 232 ] NEW_LINE pallete_raw [ 10 , : ] = [ 250 , 170 , 160 ] NEW_LINE pallete_raw [ 11 , : ] = [ 230 , 150 , 140 ] NEW_LINE pallete_raw [ 12 , : ] = [ 70 , 70 , 70 ] NEW_LINE pallete_raw [ 13 , : ] = [ 102 , 102 , 156 ] NEW_LINE pallete_raw [ 14 , : ] = [ 190 , 153 , 153 ] NEW_LINE pallete_raw [ 15 , : ] = [ 180 , 165 , 180 ] NEW_LINE pallete_raw [ 16 , : ] = [ 150 , 100 , 100 ] NEW_LINE pallete_raw [ 17 , : ] = [ 150 , 120 , 90 ] NEW_LINE pallete_raw [ 18 , : ] = [ 153 , 153 , 153 ] NEW_LINE pallete_raw [ 19 , : ] = [ 153 , 153 , 153 ] NEW_LINE pallete_raw [ 20 , : ] = [ 250 , 170 , 30 ] NEW_LINE pallete_raw [ 21 , : ] = [ 220 , 220 , 0 ] NEW_LINE pallete_raw [ 22 , : ] = [ 107 , 142 , 35 ] NEW_LINE pallete_raw [ 23 , : ] = [ 152 , 251 , 152 ] NEW_LINE pallete_raw [ 24 , : ] = [ 70 , 130 , 180 ] NEW_LINE pallete_raw [ 25 , : ] = [ 220 , 20 , 60 ] NEW_LINE pallete_raw [ 26 , : ] = [ 255 , 0 , 0 ] NEW_LINE pallete_raw [ 27 , : ] = [ 0 , 0 , 142 ] NEW_LINE pallete_raw [ 28 , : ] = [ 0 , 0 , 70 ] NEW_LINE pallete_raw [ 29 , : ] = [ 0 , 60 , 100 ] NEW_LINE pallete_raw [ 30 , : ] = [ 0 , 0 , 90 ] NEW_LINE pallete_raw [ 31 , : ] = [ 0 , 0 , 110 ] NEW_LINE pallete_raw [ 32 , : ] = [ 0 , 80 , 100 ] NEW_LINE pallete_raw [ 33 , : ] = [ 0 , 0 , 230 ] NEW_LINE pallete_raw [ 34 , : ] = [ 119 , 11 , 32 ] NEW_LINE train2regular = [ 7 , 8 , 11 , 12 , 13 , 17 , 19 , 20 , 21 , 22 , 23 , 24 , 25 , 26 , 27 , 28 , 31 , 32 , 33 ] NEW_LINE for i in range ( len ( train2regular ) ) : NEW_LINE INDENT pallete [ i , : ] = pallete_raw [ train2regular [ i ] + 1 , : ] NEW_LINE DEDENT pallete = pallete . reshape ( - 1 ) NEW_LINE return pallete NEW_LINE DEDENT\",), ('def evaluate_segmentations ( self , pred_segmentations = None ) : NEW_LINE INDENT if not ( pred_segmentations is None ) : NEW_LINE INDENT self . write_segmentation_result ( pred_segmentations ) NEW_LINE DEDENT info = self . _py_evaluate_segmentation ( ) NEW_LINE return info NEW_LINE DEDENT',), (\"def get_confusion_matrix ( self , gt_label , pred_label , class_num ) : NEW_LINE INDENT index = ( gt_label * class_num + pred_label ) . astype ( ' int32' ) NEW_LINE label_count = np . bincount ( index ) NEW_LINE confusion_matrix = np . zeros ( ( class_num , class_num ) ) NEW_LINE for i_label in range ( class_num ) : NEW_LINE INDENT for i_pred_label in range ( class_num ) : NEW_LINE INDENT cur_index = i_label * class_num + i_pred_label NEW_LINE if cur_index < len ( label_count ) : NEW_LINE INDENT confusion_matrix [ i_label , i_pred_label ] = label_count [ cur_index ] NEW_LINE DEDENT DEDENT DEDENT return confusion_matrix NEW_LINE DEDENT\",), (\"def _py_evaluate_segmentation ( self ) : NEW_LINE INDENT res_file_folder = os . path . join ( self . result_path , ' results ' ) NEW_LINE confusion_matrix = np . zeros ( ( self . num_classes , self . num_classes ) ) NEW_LINE for i , index in enumerate ( self . image_set_index ) : NEW_LINE INDENT seg_gt_info = self . load_segdb_from_index ( index ) NEW_LINE seg_gt = np . array ( Image . open ( seg_gt_info [ ' seg _ cls _ path ' ] ) ) . astype ( ' float32' ) NEW_LINE seg_pathes = os . path . split ( seg_gt_info [ ' seg _ cls _ path ' ] ) NEW_LINE res_image_name = seg_pathes [ 1 ] [ : - len ( ' _ gtFine _ labelTrainIds . png ' ) ] NEW_LINE res_subfolder_name = os . path . split ( seg_pathes [ 0 ] ) [ - 1 ] NEW_LINE res_save_folder = os . path . join ( res_file_folder , res_subfolder_name ) NEW_LINE res_save_path = os . path . join ( res_save_folder , res_image_name + ' . png ' ) NEW_LINE seg_pred = np . array ( Image . open ( res_save_path ) ) . astype ( ' float32' ) NEW_LINE seg_pred = cv2 . resize ( seg_pred , ( seg_gt . shape [ 1 ] , seg_gt . shape [ 0 ] ) , interpolation = cv2 . INTER_NEAREST ) NEW_LINE ignore_index = seg_gt != 255 NEW_LINE seg_gt = seg_gt [ ignore_index ] NEW_LINE seg_pred = seg_pred [ ignore_index ] NEW_LINE confusion_matrix += self . get_confusion_matrix ( seg_gt , seg_pred , self . num_classes ) NEW_LINE DEDENT pos = confusion_matrix . sum ( 1 ) NEW_LINE res = confusion_matrix . sum ( 0 ) NEW_LINE tp = np . diag ( confusion_matrix ) NEW_LINE IU_array = ( tp / np . maximum ( 1.0 , pos + res - tp ) ) NEW_LINE mean_IU = IU_array . mean ( ) NEW_LINE return { ' meanIU ' : mean_IU , ' IU _ array ' : IU_array } NEW_LINE DEDENT\",), (\"def write_segmentation_result ( self , segmentation_results ) : NEW_LINE INDENT res_file_folder = os . path . join ( self . result_path , ' results ' ) NEW_LINE if not os . path . exists ( res_file_folder ) : NEW_LINE INDENT os . mkdir ( res_file_folder ) NEW_LINE DEDENT pallete = self . getpallete ( 256 ) NEW_LINE for i , index in enumerate ( self . image_set_index ) : NEW_LINE INDENT seg_gt_info = self . load_segdb_from_index ( index ) NEW_LINE seg_pathes = os . path . split ( seg_gt_info [ ' seg _ cls _ path ' ] ) NEW_LINE res_image_name = seg_pathes [ 1 ] [ : - len ( ' _ gtFine _ labelTrainIds . png ' ) ] NEW_LINE res_subfolder_name = os . path . split ( seg_pathes [ 0 ] ) [ - 1 ] NEW_LINE res_save_folder = os . path . join ( res_file_folder , res_subfolder_name ) NEW_LINE res_save_path = os . path . join ( res_save_folder , res_image_name + ' . png ' ) NEW_LINE if not os . path . exists ( res_save_folder ) : NEW_LINE INDENT os . makedirs ( res_save_folder ) NEW_LINE DEDENT segmentation_result = np . uint8 ( np . squeeze ( np . copy ( segmentation_results [ i ] ) ) ) NEW_LINE segmentation_result = Image . fromarray ( segmentation_result ) NEW_LINE segmentation_result . putpalette ( pallete ) NEW_LINE segmentation_result . save ( res_save_path ) NEW_LINE DEDENT DEDENT\",), (\"def load_image_set_index ( self ) : NEW_LINE INDENT image_set_index_file = os . path . join ( self . data_path , self . image_set + ' . txt ' ) NEW_LINE assert os . path . exists ( image_set_index_file ) , ' Path ▁ does ▁ not ▁ exist : ▁ { } ' . format ( image_set_index_file ) NEW_LINE with open ( image_set_index_file , ' r ' ) as f : NEW_LINE INDENT lines = f . readlines ( ) NEW_LINE DEDENT image_lists = [ line . strip ( ) for line in lines ] NEW_LINE return image_lists NEW_LINE DEDENT\",), (\"def image_path_from_index ( self , index ) : NEW_LINE INDENT image_file = os . path . join ( self . data_path , ' images ' , index + ' . png ' ) NEW_LINE assert os . path . exists ( image_file ) , ' Path ▁ does ▁ not ▁ exist : ▁ { } ' . format ( image_file ) NEW_LINE return image_file NEW_LINE DEDENT\",), (\"def load_annotation ( self , index ) : NEW_LINE INDENT roi_rec = dict ( ) NEW_LINE roi_rec [ ' image ' ] = self . image_path_from_index ( index ) NEW_LINE img_path = self . image_path_from_index ( index ) NEW_LINE w , h = Image . open ( img_path ) . size NEW_LINE roi_rec [ ' height ' ] = float ( h ) NEW_LINE roi_rec [ ' width ' ] = float ( w ) NEW_LINE if self . image_set == ' train ' : NEW_LINE INDENT filename = os . path . join ( self . data_path , ' labelTxt ' , index + ' . txt ' ) NEW_LINE f = codecs . open ( filename , ' r ' ) NEW_LINE objs = f . readlines ( ) NEW_LINE objs = [ obj . strip ( ) . split ( ' ▁ ' ) for obj in objs ] NEW_LINE if not self . config [ ' use _ diff ' ] : NEW_LINE INDENT non_diff_objs = [ obj for obj in objs if obj [ 9 ] != '1' ] NEW_LINE objs = non_diff_objs NEW_LINE DEDENT num_objs = len ( objs ) NEW_LINE boxes = np . zeros ( ( num_objs , 4 ) , dtype = np . int16 ) NEW_LINE gt_classes = np . zeros ( ( num_objs ) , dtype = np . int32 ) NEW_LINE overlaps = np . zeros ( ( num_objs , self . num_classes ) , dtype = np . float32 ) NEW_LINE class_to_index = dict ( zip ( self . classes , range ( self . num_classes ) ) ) NEW_LINE for ix , obj in enumerate ( objs ) : NEW_LINE INDENT bbox = obj NEW_LINE x1 = float ( bbox [ 0 ] ) - 1 NEW_LINE y1 = float ( bbox [ 1 ] ) - 1 NEW_LINE x2 = float ( bbox [ 2 ] ) - 1 NEW_LINE y2 = float ( bbox [ 3 ] ) - 1 NEW_LINE x3 = float ( bbox [ 4 ] ) - 1 NEW_LINE y3 = float ( bbox [ 5 ] ) - 1 NEW_LINE x4 = float ( bbox [ 6 ] ) - 1 NEW_LINE y4 = float ( bbox [ 7 ] ) - 1 NEW_LINE xmin = max ( min ( x1 , x2 , x3 , x4 ) , 0 ) NEW_LINE xmax = max ( x1 , x2 , x3 , x4 ) NEW_LINE ymin = max ( min ( y1 , y2 , y3 , y4 ) , 0 ) NEW_LINE ymax = max ( y1 , y2 , y3 , y4 ) NEW_LINE xmin = min ( max ( xmin , 0 ) , w - 1 ) NEW_LINE xmax = min ( max ( xmax , 0 ) , w - 1 ) NEW_LINE ymin = min ( max ( ymin , 0 ) , h - 1 ) NEW_LINE ymax = min ( max ( ymax , 0 ) , h - 1 ) NEW_LINE cls = class_to_index [ obj [ 8 ] . lower ( ) . strip ( ) ] NEW_LINE boxes [ ix , : ] = [ xmin , ymin , xmax , ymax ] NEW_LINE gt_classes [ ix ] = cls NEW_LINE overlaps [ ix , cls ] = 1.0 NEW_LINE DEDENT roi_rec . update ( { ' boxes ' : boxes , ' gt _ classes ' : gt_classes , ' gt _ overlaps ' : overlaps , ' max _ classes ' : overlaps . argmax ( axis = 1 ) , ' max _ overlaps ' : overlaps . max ( axis = 1 ) , ' flipped ' : False } ) NEW_LINE DEDENT return roi_rec NEW_LINE DEDENT\",), (\"def evaluate_detections ( self , detections ) : NEW_LINE INDENT detection_results_path = os . path . join ( self . result_path , ' test _ results ' ) NEW_LINE info = ' ' NEW_LINE if not os . path . isdir ( detection_results_path ) : NEW_LINE INDENT os . mkdir ( detection_results_path ) NEW_LINE DEDENT self . write_DOTA_results ( detections , threshold = 0.0 ) NEW_LINE return info NEW_LINE DEDENT\",), (\"def load_image_set_index ( self ) : NEW_LINE INDENT image_set_index_file = os . path . join ( self . data_path , self . image_set + ' . txt ' ) NEW_LINE assert os . path . exists ( image_set_index_file ) , ' Path ▁ does ▁ not ▁ exist : ▁ { } ' . format ( image_set_index_file ) NEW_LINE with open ( image_set_index_file , ' r ' ) as f : NEW_LINE INDENT lines = f . readlines ( ) NEW_LINE DEDENT image_lists = [ line . strip ( ) for line in lines ] NEW_LINE return image_lists NEW_LINE DEDENT\",), (\"def image_path_from_index ( self , index ) : NEW_LINE INDENT image_file = os . path . join ( self . data_path , ' images ' , index + ' . png ' ) NEW_LINE assert os . path . exists ( image_file ) , ' Path ▁ does ▁ not ▁ exist : ▁ { } ' . format ( image_file ) NEW_LINE return image_file NEW_LINE DEDENT\",), (\"def load_annotation ( self , index ) : NEW_LINE INDENT roi_rec = dict ( ) NEW_LINE roi_rec [ ' image ' ] = self . image_path_from_index ( index ) NEW_LINE img_path = self . image_path_from_index ( index ) NEW_LINE w , h = Image . open ( img_path ) . size NEW_LINE roi_rec [ ' height ' ] = float ( h ) NEW_LINE roi_rec [ ' width ' ] = float ( w ) NEW_LINE valid_objs = [ ] NEW_LINE if self . image_set == ' train ' : NEW_LINE INDENT filename = os . path . join ( self . data_path , ' labelTxt ' , index + ' . txt ' ) NEW_LINE f = codecs . open ( filename , ' r ' ) NEW_LINE objs = f . readlines ( ) NEW_LINE objs = [ obj . strip ( ) . split ( ' ▁ ' ) for obj in objs ] NEW_LINE if not self . config [ ' use _ diff ' ] : NEW_LINE INDENT non_diff_objs = [ obj for obj in objs if obj [ 9 ] == '0' ] NEW_LINE objs = non_diff_objs NEW_LINE DEDENT for ix , obj in enumerate ( objs ) : NEW_LINE INDENT bbox = obj NEW_LINE x1 = min ( max ( float ( bbox [ 0 ] ) , 0 ) , w - 1 ) NEW_LINE y1 = min ( max ( float ( bbox [ 1 ] ) , 0 ) , h - 1 ) NEW_LINE x2 = min ( max ( float ( bbox [ 2 ] ) , 0 ) , w - 1 ) NEW_LINE y2 = min ( max ( float ( bbox [ 3 ] ) , 0 ) , h - 1 ) NEW_LINE x3 = min ( max ( float ( bbox [ 4 ] ) , 0 ) , w - 1 ) NEW_LINE y3 = min ( max ( float ( bbox [ 5 ] ) , 0 ) , h - 1 ) NEW_LINE x4 = min ( max ( float ( bbox [ 6 ] ) , 0 ) , w - 1 ) NEW_LINE y4 = min ( max ( float ( bbox [ 7 ] ) , 0 ) , h - 1 ) NEW_LINE xmin = max ( min ( x1 , x2 , x3 , x4 ) , 0 ) NEW_LINE xmax = max ( x1 , x2 , x3 , x4 ) NEW_LINE ymin = max ( min ( y1 , y2 , y3 , y4 ) , 0 ) NEW_LINE ymax = max ( y1 , y2 , y3 , y4 ) NEW_LINE if ( ( xmax - xmin ) > 10 ) and ( ( ymax - ymin ) > 10 ) : NEW_LINE INDENT obj [ : 8 ] = [ x1 , y1 , x2 , y2 , x3 , y3 , x4 , y4 ] NEW_LINE valid_objs . append ( obj ) NEW_LINE DEDENT DEDENT objs = valid_objs NEW_LINE num_objs = len ( objs ) NEW_LINE boxes = np . zeros ( ( num_objs , 8 ) , dtype = np . uint16 ) NEW_LINE gt_classes = np . zeros ( ( num_objs ) , dtype = np . int32 ) NEW_LINE overlaps = np . zeros ( ( num_objs , self . num_classes ) , dtype = np . float32 ) NEW_LINE class_to_index = dict ( zip ( self . classes , range ( self . num_classes ) ) ) NEW_LINE for ix , obj in enumerate ( objs ) : NEW_LINE INDENT cls = class_to_index [ obj [ 8 ] . lower ( ) . strip ( ) ] NEW_LINE if obj [ 8 ] . lower ( ) . strip ( ) in self . angle_agnostic_classes : NEW_LINE INDENT boxes [ ix , : ] = get_best_begin_point_wrapp ( obj [ : 8 ] ) NEW_LINE DEDENT else : NEW_LINE INDENT boxes [ ix , : ] = obj [ : 8 ] NEW_LINE DEDENT gt_classes [ ix ] = cls NEW_LINE overlaps [ ix , cls ] = 1.0 NEW_LINE DEDENT roi_rec . update ( { ' boxes ' : boxes , ' gt _ classes ' : gt_classes , ' gt _ overlaps ' : overlaps , ' max _ classes ' : overlaps . argmax ( axis = 1 ) , ' max _ overlaps ' : overlaps . max ( axis = 1 ) , ' flipped ' : False } ) NEW_LINE DEDENT return roi_rec NEW_LINE DEDENT\",), (\"def evaluate_detections ( self , detections , ignore_cache ) : NEW_LINE INDENT detection_results_path = os . path . join ( self . result_path , ' test _ results ' ) NEW_LINE info = ' ' NEW_LINE if not os . path . isdir ( detection_results_path ) : NEW_LINE INDENT os . mkdir ( detection_results_path ) NEW_LINE DEDENT if ignore_cache : NEW_LINE INDENT self . write_DOTA_results ( detections , threshold = 0.001 ) NEW_LINE DEDENT self . write_DOTA_results_comp4 ( detections , threshold = 0.001 ) NEW_LINE return info NEW_LINE DEDENT\",), ('def validate_clockwise_points ( self , points ) : NEW_LINE INDENT if len ( points ) != 8 : NEW_LINE INDENT raise Exception ( \" Points ▁ list ▁ not ▁ valid . \" + str ( len ( points ) ) ) NEW_LINE DEDENT point = [ [ int ( points [ 0 ] ) , int ( points [ 1 ] ) ] , [ int ( points [ 2 ] ) , int ( points [ 3 ] ) ] , [ int ( points [ 4 ] ) , int ( points [ 5 ] ) ] , [ int ( points [ 6 ] ) , int ( points [ 7 ] ) ] ] NEW_LINE edge = [ ( point [ 1 ] [ 0 ] - point [ 0 ] [ 0 ] ) * ( point [ 1 ] [ 1 ] + point [ 0 ] [ 1 ] ) , ( point [ 2 ] [ 0 ] - point [ 1 ] [ 0 ] ) * ( point [ 2 ] [ 1 ] + point [ 1 ] [ 1 ] ) , ( point [ 3 ] [ 0 ] - point [ 2 ] [ 0 ] ) * ( point [ 3 ] [ 1 ] + point [ 2 ] [ 1 ] ) , ( point [ 0 ] [ 0 ] - point [ 3 ] [ 0 ] ) * ( point [ 0 ] [ 1 ] + point [ 3 ] [ 1 ] ) ] NEW_LINE summatory = edge [ 0 ] + edge [ 1 ] + edge [ 2 ] + edge [ 3 ] ; NEW_LINE if summatory > 0 : NEW_LINE INDENT return False NEW_LINE DEDENT else : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT',), (\"def load_image_set_index ( self ) : NEW_LINE INDENT image_set_index_file = os . path . join ( self . data_path , self . image_set + ' . txt ' ) NEW_LINE assert os . path . exists ( image_set_index_file ) , ' Path ▁ does ▁ not ▁ exist : ▁ { } ' . format ( image_set_index_file ) NEW_LINE with open ( image_set_index_file , ' r ' ) as f : NEW_LINE INDENT lines = f . readlines ( ) NEW_LINE DEDENT image_lists = [ line . strip ( ) for line in lines ] NEW_LINE return image_lists NEW_LINE DEDENT\",), (\"def image_path_from_index ( self , index ) : NEW_LINE INDENT image_file = os . path . join ( self . data_path , ' images ' , index + ' . png ' ) NEW_LINE assert os . path . exists ( image_file ) , ' Path ▁ does ▁ not ▁ exist : ▁ { } ' . format ( image_file ) NEW_LINE return image_file NEW_LINE DEDENT\",), (\"def load_annotation ( self , index ) : NEW_LINE INDENT roi_rec = dict ( ) NEW_LINE roi_rec [ ' image ' ] = self . image_path_from_index ( index ) NEW_LINE img_path = self . image_path_from_index ( index ) NEW_LINE w , h = Image . open ( img_path ) . size NEW_LINE roi_rec [ ' height ' ] = float ( h ) NEW_LINE roi_rec [ ' width ' ] = float ( w ) NEW_LINE valid_objs = [ ] NEW_LINE if self . image_set == ' train ' : NEW_LINE INDENT filename = os . path . join ( self . data_path , ' labelTxt ' , index + ' . txt ' ) NEW_LINE f = codecs . open ( filename , ' r ' ) NEW_LINE objs = f . readlines ( ) NEW_LINE objs = [ obj . strip ( ) . split ( ' ▁ ' ) for obj in objs ] NEW_LINE if not self . config [ ' use _ diff ' ] : NEW_LINE INDENT non_diff_objs = [ obj for obj in objs if obj [ 9 ] == '0' ] NEW_LINE objs = non_diff_objs NEW_LINE DEDENT for ix , obj in enumerate ( objs ) : NEW_LINE INDENT bbox = obj NEW_LINE x1 = min ( max ( float ( bbox [ 0 ] ) , 0 ) , w - 1 ) NEW_LINE y1 = min ( max ( float ( bbox [ 1 ] ) , 0 ) , h - 1 ) NEW_LINE x2 = min ( max ( float ( bbox [ 2 ] ) , 0 ) , w - 1 ) NEW_LINE y2 = min ( max ( float ( bbox [ 3 ] ) , 0 ) , h - 1 ) NEW_LINE x3 = min ( max ( float ( bbox [ 4 ] ) , 0 ) , w - 1 ) NEW_LINE y3 = min ( max ( float ( bbox [ 5 ] ) , 0 ) , h - 1 ) NEW_LINE x4 = min ( max ( float ( bbox [ 6 ] ) , 0 ) , w - 1 ) NEW_LINE y4 = min ( max ( float ( bbox [ 7 ] ) , 0 ) , h - 1 ) NEW_LINE xmin = max ( min ( x1 , x2 , x3 , x4 ) , 0 ) NEW_LINE xmax = max ( x1 , x2 , x3 , x4 ) NEW_LINE ymin = max ( min ( y1 , y2 , y3 , y4 ) , 0 ) NEW_LINE ymax = max ( y1 , y2 , y3 , y4 ) NEW_LINE if ( ( xmax - xmin ) > 10 ) and ( ( ymax - ymin ) > 10 ) : NEW_LINE INDENT obj [ : 8 ] = [ x1 , y1 , x2 , y2 , x3 , y3 , x4 , y4 ] NEW_LINE valid_objs . append ( obj ) NEW_LINE DEDENT DEDENT objs = valid_objs NEW_LINE num_objs = len ( objs ) NEW_LINE boxes = np . zeros ( ( num_objs , 8 ) , dtype = np . uint16 ) NEW_LINE gt_classes = np . zeros ( ( num_objs ) , dtype = np . int32 ) NEW_LINE overlaps = np . zeros ( ( num_objs , self . num_classes ) , dtype = np . float32 ) NEW_LINE class_to_index = dict ( zip ( self . classes , range ( self . num_classes ) ) ) NEW_LINE for ix , obj in enumerate ( objs ) : NEW_LINE INDENT cls = class_to_index [ obj [ 8 ] . lower ( ) . strip ( ) ] NEW_LINE if obj [ 8 ] . lower ( ) . strip ( ) in self . angle_agnostic_classes : NEW_LINE INDENT boxes [ ix , : ] = get_best_begin_point_wrapp ( obj [ : 8 ] ) NEW_LINE DEDENT else : NEW_LINE INDENT boxes [ ix , : ] = obj [ : 8 ] NEW_LINE DEDENT gt_classes [ ix ] = cls NEW_LINE overlaps [ ix , cls ] = 1.0 NEW_LINE DEDENT roi_rec . update ( { ' boxes ' : boxes , ' gt _ classes ' : gt_classes , ' gt _ overlaps ' : overlaps , ' max _ classes ' : overlaps . argmax ( axis = 1 ) , ' max _ overlaps ' : overlaps . max ( axis = 1 ) , ' flipped ' : False } ) NEW_LINE DEDENT return roi_rec NEW_LINE DEDENT\",), (\"def evaluate_detections ( self , detections , ignore_cache ) : NEW_LINE INDENT detection_results_path = os . path . join ( self . result_path , ' test _ results ' ) NEW_LINE info = ' ' NEW_LINE if not os . path . isdir ( detection_results_path ) : NEW_LINE INDENT os . mkdir ( detection_results_path ) NEW_LINE DEDENT self . write_DOTA_results ( detections , threshold = 0.001 ) NEW_LINE self . write_DOTA_results_comp4 ( detections , threshold = 0.001 ) NEW_LINE return info NEW_LINE DEDENT\",), ('def validate_clockwise_points ( self , points ) : NEW_LINE INDENT if len ( points ) != 8 : NEW_LINE INDENT raise Exception ( \" Points ▁ list ▁ not ▁ valid . \" + str ( len ( points ) ) ) NEW_LINE DEDENT point = [ [ int ( points [ 0 ] ) , int ( points [ 1 ] ) ] , [ int ( points [ 2 ] ) , int ( points [ 3 ] ) ] , [ int ( points [ 4 ] ) , int ( points [ 5 ] ) ] , [ int ( points [ 6 ] ) , int ( points [ 7 ] ) ] ] NEW_LINE edge = [ ( point [ 1 ] [ 0 ] - point [ 0 ] [ 0 ] ) * ( point [ 1 ] [ 1 ] + point [ 0 ] [ 1 ] ) , ( point [ 2 ] [ 0 ] - point [ 1 ] [ 0 ] ) * ( point [ 2 ] [ 1 ] + point [ 1 ] [ 1 ] ) , ( point [ 3 ] [ 0 ] - point [ 2 ] [ 0 ] ) * ( point [ 3 ] [ 1 ] + point [ 2 ] [ 1 ] ) , ( point [ 0 ] [ 0 ] - point [ 3 ] [ 0 ] ) * ( point [ 0 ] [ 1 ] + point [ 3 ] [ 1 ] ) ] NEW_LINE summatory = edge [ 0 ] + edge [ 1 ] + edge [ 2 ] + edge [ 3 ] ; NEW_LINE if summatory > 0 : NEW_LINE INDENT return False NEW_LINE DEDENT else : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT',), ('def unique_boxes ( boxes , scale = 1.0 ) : NEW_LINE INDENT v = np . array ( [ 1 , 1e3 , 1e6 , 1e9 ] ) NEW_LINE hashes = np . round ( boxes * scale ) . dot ( v ) NEW_LINE _ , index = np . unique ( hashes , return_index = True ) NEW_LINE return np . sort ( index ) NEW_LINE DEDENT',), ('def filter_small_boxes ( boxes , min_size ) : NEW_LINE INDENT w = boxes [ : , 2 ] - boxes [ : , 0 ] NEW_LINE h = boxes [ : , 3 ] - boxes [ : , 1 ] NEW_LINE keep = np . where ( ( w >= min_size ) & ( h > min_size ) ) [ 0 ] NEW_LINE return keep NEW_LINE DEDENT',), (\"def load_image_set_index ( self ) : NEW_LINE INDENT image_set_index_file = os . path . join ( self . data_path , ' ImageSets ' , ' Main ' , self . image_set + ' . txt ' ) NEW_LINE assert os . path . exists ( image_set_index_file ) , ' Path ▁ does ▁ not ▁ exist : ▁ { } ' . format ( image_set_index_file ) NEW_LINE with open ( image_set_index_file ) as f : NEW_LINE INDENT image_set_index = [ x . strip ( ) for x in f . readlines ( ) ] NEW_LINE DEDENT return image_set_index NEW_LINE DEDENT\",), (\"def image_path_from_index ( self , index ) : NEW_LINE INDENT image_file = os . path . join ( self . data_path , ' JPEGImages ' , index + ' . jpg ' ) NEW_LINE assert os . path . exists ( image_file ) , ' Path ▁ does ▁ not ▁ exist : ▁ { } ' . format ( image_file ) NEW_LINE return image_file NEW_LINE DEDENT\",), (\"def segmentation_path_from_index ( self , index ) : NEW_LINE INDENT seg_class_file = os . path . join ( self . data_path , ' SegmentationClass ' , index + ' . png ' ) NEW_LINE assert os . path . exists ( seg_class_file ) , ' Path ▁ does ▁ not ▁ exist : ▁ { } ' . format ( seg_class_file ) NEW_LINE return seg_class_file NEW_LINE DEDENT\",), (\"def load_pascal_annotation ( self , index ) : NEW_LINE INDENT import xml . etree . ElementTree as ET NEW_LINE roi_rec = dict ( ) NEW_LINE roi_rec [ ' image ' ] = self . image_path_from_index ( index ) NEW_LINE filename = os . path . join ( self . data_path , ' Annotations ' , index + ' . xml ' ) NEW_LINE tree = ET . parse ( filename ) NEW_LINE size = tree . find ( ' size ' ) NEW_LINE roi_rec [ ' height ' ] = float ( size . find ( ' height ' ) . text ) NEW_LINE roi_rec [ ' width ' ] = float ( size . find ( ' width ' ) . text ) NEW_LINE objs = tree . findall ( ' object ' ) NEW_LINE if not self . config [ ' use _ diff ' ] : NEW_LINE INDENT non_diff_objs = [ obj for obj in objs if int ( obj . find ( ' difficult ' ) . text ) == 0 ] NEW_LINE objs = non_diff_objs NEW_LINE DEDENT num_objs = len ( objs ) NEW_LINE boxes = np . zeros ( ( num_objs , 4 ) , dtype = np . uint16 ) NEW_LINE gt_classes = np . zeros ( ( num_objs ) , dtype = np . int32 ) NEW_LINE overlaps = np . zeros ( ( num_objs , self . num_classes ) , dtype = np . float32 ) NEW_LINE class_to_index = dict ( zip ( self . classes , range ( self . num_classes ) ) ) NEW_LINE for ix , obj in enumerate ( objs ) : NEW_LINE INDENT bbox = obj . find ( ' bndbox ' ) NEW_LINE x1 = float ( bbox . find ( ' xmin ' ) . text ) - 1 NEW_LINE y1 = float ( bbox . find ( ' ymin ' ) . text ) - 1 NEW_LINE x2 = float ( bbox . find ( ' xmax ' ) . text ) - 1 NEW_LINE y2 = float ( bbox . find ( ' ymax ' ) . text ) - 1 NEW_LINE cls = class_to_index [ obj . find ( ' name ' ) . text . lower ( ) . strip ( ) ] NEW_LINE boxes [ ix , : ] = [ x1 , y1 , x2 , y2 ] NEW_LINE gt_classes [ ix ] = cls NEW_LINE overlaps [ ix , cls ] = 1.0 NEW_LINE DEDENT roi_rec . update ( { ' boxes ' : boxes , ' gt _ classes ' : gt_classes , ' gt _ overlaps ' : overlaps , ' max _ classes ' : overlaps . argmax ( axis = 1 ) , ' max _ overlaps ' : overlaps . max ( axis = 1 ) , ' flipped ' : False } ) NEW_LINE return roi_rec NEW_LINE DEDENT\",), (\"def load_selective_search_roidb ( self , gt_roidb ) : NEW_LINE INDENT import scipy . io NEW_LINE matfile = os . path . join ( self . root_path , ' selective _ search _ data ' , self . name + ' . mat ' ) NEW_LINE assert os . path . exists ( matfile ) , ' selective ▁ search ▁ data ▁ does ▁ not ▁ exist : ▁ { } ' . format ( matfile ) NEW_LINE raw_data = scipy . io . loadmat ( matfile ) [ ' boxes ' ] . ravel ( ) NEW_LINE box_list = [ ] NEW_LINE for i in range ( raw_data . shape [ 0 ] ) : NEW_LINE INDENT boxes = raw_data [ i ] [ : , ( 1 , 0 , 3 , 2 ) ] - 1 NEW_LINE keep = unique_boxes ( boxes ) NEW_LINE boxes = boxes [ keep , : ] NEW_LINE keep = filter_small_boxes ( boxes , self . config [ ' min _ size ' ] ) NEW_LINE boxes = boxes [ keep , : ] NEW_LINE box_list . append ( boxes ) NEW_LINE DEDENT return self . create_roidb_from_box_list ( box_list , gt_roidb ) NEW_LINE DEDENT\",), (\"def load_pascal_segmentation_annotation ( self , index ) : NEW_LINE INDENT import xml . etree . ElementTree as ET NEW_LINE seg_rec = dict ( ) NEW_LINE seg_rec [ ' image ' ] = self . image_path_from_index ( index ) NEW_LINE size = cv2 . imread ( seg_rec [ ' image ' ] ) . shape NEW_LINE seg_rec [ ' height ' ] = size [ 0 ] NEW_LINE seg_rec [ ' width ' ] = size [ 1 ] NEW_LINE seg_rec [ ' seg _ cls _ path ' ] = self . segmentation_path_from_index ( index ) NEW_LINE seg_rec [ ' flipped ' ] = False NEW_LINE return seg_rec NEW_LINE DEDENT\",), (\"def evaluate_detections ( self , detections ) : NEW_LINE INDENT result_dir = os . path . join ( self . result_path , ' results ' ) NEW_LINE if not os . path . exists ( result_dir ) : NEW_LINE INDENT os . mkdir ( result_dir ) NEW_LINE DEDENT year_folder = os . path . join ( self . result_path , ' results ' , ' VOC ' + self . year ) NEW_LINE if not os . path . exists ( year_folder ) : NEW_LINE INDENT os . mkdir ( year_folder ) NEW_LINE DEDENT res_file_folder = os . path . join ( self . result_path , ' results ' , ' VOC ' + self . year , ' Main ' ) NEW_LINE if not os . path . exists ( res_file_folder ) : NEW_LINE INDENT os . mkdir ( res_file_folder ) NEW_LINE DEDENT self . write_pascal_results ( detections ) NEW_LINE info = self . do_python_eval ( ) NEW_LINE return info NEW_LINE DEDENT\",), ('def evaluate_segmentations ( self , pred_segmentations = None ) : NEW_LINE INDENT if not ( pred_segmentations is None ) : NEW_LINE INDENT self . write_pascal_segmentation_result ( pred_segmentations ) NEW_LINE DEDENT info = self . _py_evaluate_segmentation ( ) NEW_LINE return info NEW_LINE DEDENT',), (\"def write_pascal_segmentation_result ( self , pred_segmentations ) : NEW_LINE INDENT result_dir = os . path . join ( self . result_path , ' results ' ) NEW_LINE if not os . path . exists ( result_dir ) : NEW_LINE INDENT os . mkdir ( result_dir ) NEW_LINE DEDENT year_folder = os . path . join ( self . result_path , ' results ' , ' VOC ' + self . year ) NEW_LINE if not os . path . exists ( year_folder ) : NEW_LINE INDENT os . mkdir ( year_folder ) NEW_LINE DEDENT res_file_folder = os . path . join ( self . result_path , ' results ' , ' VOC ' + self . year , ' Segmentation ' ) NEW_LINE if not os . path . exists ( res_file_folder ) : NEW_LINE INDENT os . mkdir ( res_file_folder ) NEW_LINE DEDENT result_dir = os . path . join ( self . result_path , ' results ' , ' VOC ' + self . year , ' Segmentation ' ) NEW_LINE if not os . path . exists ( result_dir ) : NEW_LINE INDENT os . mkdir ( result_dir ) NEW_LINE DEDENT pallete = self . get_pallete ( 256 ) NEW_LINE for i , index in enumerate ( self . image_set_index ) : NEW_LINE INDENT segmentation_result = np . uint8 ( np . squeeze ( np . copy ( pred_segmentations [ i ] ) ) ) NEW_LINE segmentation_result = PIL . Image . fromarray ( segmentation_result ) NEW_LINE segmentation_result . putpalette ( pallete ) NEW_LINE segmentation_result . save ( os . path . join ( result_dir , ' % s . png ' % ( index ) ) ) NEW_LINE DEDENT DEDENT\",), (\"def get_confusion_matrix ( self , gt_label , pred_label , class_num ) : NEW_LINE INDENT index = ( gt_label * class_num + pred_label ) . astype ( ' int32' ) NEW_LINE label_count = np . bincount ( index ) NEW_LINE confusion_matrix = np . zeros ( ( class_num , class_num ) ) NEW_LINE for i_label in range ( class_num ) : NEW_LINE INDENT for i_pred_label in range ( class_num ) : NEW_LINE INDENT cur_index = i_label * class_num + i_pred_label NEW_LINE if cur_index < len ( label_count ) : NEW_LINE INDENT confusion_matrix [ i_label , i_pred_label ] = label_count [ cur_index ] NEW_LINE DEDENT DEDENT DEDENT return confusion_matrix NEW_LINE DEDENT\",), (\"def _py_evaluate_segmentation ( self ) : NEW_LINE INDENT confusion_matrix = np . zeros ( ( self . num_classes , self . num_classes ) ) NEW_LINE result_dir = os . path . join ( self . result_path , ' results ' , ' VOC ' + self . year , ' Segmentation ' ) NEW_LINE for i , index in enumerate ( self . image_set_index ) : NEW_LINE INDENT seg_gt_info = self . load_pascal_segmentation_annotation ( index ) NEW_LINE seg_gt_path = seg_gt_info [ ' seg _ cls _ path ' ] NEW_LINE seg_gt = np . array ( PIL . Image . open ( seg_gt_path ) ) . astype ( ' float32' ) NEW_LINE seg_pred_path = os . path . join ( result_dir , ' % s . png ' % ( index ) ) NEW_LINE seg_pred = np . array ( PIL . Image . open ( seg_pred_path ) ) . astype ( ' float32' ) NEW_LINE seg_gt = cv2 . resize ( seg_gt , ( seg_pred . shape [ 1 ] , seg_pred . shape [ 0 ] ) , interpolation = cv2 . INTER_NEAREST ) NEW_LINE ignore_index = seg_gt != 255 NEW_LINE seg_gt = seg_gt [ ignore_index ] NEW_LINE seg_pred = seg_pred [ ignore_index ] NEW_LINE confusion_matrix += self . get_confusion_matrix ( seg_gt , seg_pred , self . num_classes ) NEW_LINE DEDENT pos = confusion_matrix . sum ( 1 ) NEW_LINE res = confusion_matrix . sum ( 0 ) NEW_LINE tp = np . diag ( confusion_matrix ) NEW_LINE IU_array = ( tp / np . maximum ( 1.0 , pos + res - tp ) ) NEW_LINE mean_IU = IU_array . mean ( ) NEW_LINE return { ' meanIU ' : mean_IU , ' IU _ array ' : IU_array } NEW_LINE DEDENT\",), (\"def get_result_file_template ( self ) : NEW_LINE INDENT res_file_folder = os . path . join ( self . result_path , ' results ' , ' VOC ' + self . year , ' Main ' ) NEW_LINE comp_id = self . config [ ' comp _ id ' ] NEW_LINE filename = comp_id + ' _ det _ ' + self . image_set + ' _ { : s } . txt ' NEW_LINE path = os . path . join ( res_file_folder , filename ) NEW_LINE return path NEW_LINE DEDENT\",), (\"def load_image_set_index ( self ) : NEW_LINE INDENT image_set_index_file = os . path . join ( self . data_path , self . image_set + ' . txt ' ) NEW_LINE assert os . path . exists ( image_set_index_file ) , ' Path ▁ does ▁ not ▁ exist : ▁ { } ' . format ( image_set_index_file ) NEW_LINE with open ( image_set_index_file , ' r ' ) as f : NEW_LINE INDENT lines = f . readlines ( ) NEW_LINE DEDENT image_lists = [ line . strip ( ) for line in lines ] NEW_LINE return image_lists NEW_LINE DEDENT\",), (\"def image_path_from_index ( self , index ) : NEW_LINE INDENT image_file = os . path . join ( self . data_path , ' images ' , index + ' . png ' ) NEW_LINE assert os . path . exists ( image_file ) , ' Path ▁ does ▁ not ▁ exist : ▁ { } ' . format ( image_file ) NEW_LINE return image_file NEW_LINE DEDENT\",), (\"def load_annotation ( self , index ) : NEW_LINE INDENT roi_rec = dict ( ) NEW_LINE roi_rec [ ' image ' ] = self . image_path_from_index ( index ) NEW_LINE img_path = self . image_path_from_index ( index ) NEW_LINE w , h = Image . open ( img_path ) . size NEW_LINE roi_rec [ ' height ' ] = float ( h ) NEW_LINE roi_rec [ ' width ' ] = float ( w ) NEW_LINE if self . image_set == ' train ' : NEW_LINE INDENT filename = os . path . join ( self . data_path , ' labelTxt ' , index + ' . txt ' ) NEW_LINE f = codecs . open ( filename , ' r ' ) NEW_LINE objs = f . readlines ( ) NEW_LINE objs = [ obj . strip ( ) . split ( ' ▁ ' ) for obj in objs ] NEW_LINE if not self . config [ ' use _ diff ' ] : NEW_LINE INDENT non_diff_objs = [ obj for obj in objs if obj [ 9 ] != '1' ] NEW_LINE objs = non_diff_objs NEW_LINE DEDENT num_objs = len ( objs ) NEW_LINE boxes = np . zeros ( ( num_objs , 4 ) , dtype = np . int16 ) NEW_LINE gt_classes = np . zeros ( ( num_objs ) , dtype = np . int32 ) NEW_LINE overlaps = np . zeros ( ( num_objs , self . num_classes ) , dtype = np . float32 ) NEW_LINE class_to_index = dict ( zip ( self . classes , range ( self . num_classes ) ) ) NEW_LINE for ix , obj in enumerate ( objs ) : NEW_LINE INDENT bbox = obj NEW_LINE x1 = float ( bbox [ 0 ] ) - 1 NEW_LINE y1 = float ( bbox [ 1 ] ) - 1 NEW_LINE x2 = float ( bbox [ 2 ] ) - 1 NEW_LINE y2 = float ( bbox [ 3 ] ) - 1 NEW_LINE x3 = float ( bbox [ 4 ] ) - 1 NEW_LINE y3 = float ( bbox [ 5 ] ) - 1 NEW_LINE x4 = float ( bbox [ 6 ] ) - 1 NEW_LINE y4 = float ( bbox [ 7 ] ) - 1 NEW_LINE xmin = max ( min ( x1 , x2 , x3 , x4 ) , 0 ) NEW_LINE xmax = max ( x1 , x2 , x3 , x4 ) NEW_LINE ymin = max ( min ( y1 , y2 , y3 , y4 ) , 0 ) NEW_LINE ymax = max ( y1 , y2 , y3 , y4 ) NEW_LINE xmin = min ( max ( xmin , 0 ) , w - 1 ) NEW_LINE xmax = min ( max ( xmax , 0 ) , w - 1 ) NEW_LINE ymin = min ( max ( ymin , 0 ) , h - 1 ) NEW_LINE ymax = min ( max ( ymax , 0 ) , h - 1 ) NEW_LINE cls = class_to_index [ obj [ 8 ] . lower ( ) . strip ( ) ] NEW_LINE boxes [ ix , : ] = [ xmin , ymin , xmax , ymax ] NEW_LINE gt_classes [ ix ] = cls NEW_LINE overlaps [ ix , cls ] = 1.0 NEW_LINE DEDENT roi_rec . update ( { ' boxes ' : boxes , ' gt _ classes ' : gt_classes , ' gt _ overlaps ' : overlaps , ' max _ classes ' : overlaps . argmax ( axis = 1 ) , ' max _ overlaps ' : overlaps . max ( axis = 1 ) , ' flipped ' : False } ) NEW_LINE DEDENT return roi_rec NEW_LINE DEDENT\",), (\"def evaluate_detections ( self , detections ) : NEW_LINE INDENT detection_results_path = os . path . join ( self . result_path , ' test _ results ' ) NEW_LINE info = ' ' NEW_LINE if not os . path . isdir ( detection_results_path ) : NEW_LINE INDENT os . mkdir ( detection_results_path ) NEW_LINE DEDENT self . write_DOTA_results ( detections , threshold = 0.0 ) NEW_LINE return info NEW_LINE DEDENT\",), (\"def load_image_set_index ( self ) : NEW_LINE INDENT image_set_index_file = os . path . join ( self . data_path , self . image_set + ' . txt ' ) NEW_LINE assert os . path . exists ( image_set_index_file ) , ' Path ▁ does ▁ not ▁ exist : ▁ { } ' . format ( image_set_index_file ) NEW_LINE with open ( image_set_index_file , ' r ' ) as f : NEW_LINE INDENT lines = f . readlines ( ) NEW_LINE DEDENT image_lists = [ line . strip ( ) for line in lines ] NEW_LINE return image_lists NEW_LINE DEDENT\",), (\"def image_path_from_index ( self , index ) : NEW_LINE INDENT image_file = os . path . join ( self . data_path , ' images ' , index + ' . png ' ) NEW_LINE assert os . path . exists ( image_file ) , ' Path ▁ does ▁ not ▁ exist : ▁ { } ' . format ( image_file ) NEW_LINE return image_file NEW_LINE DEDENT\",), (\"def load_annotation ( self , index ) : NEW_LINE INDENT roi_rec = dict ( ) NEW_LINE roi_rec [ ' image ' ] = self . image_path_from_index ( index ) NEW_LINE img_path = self . image_path_from_index ( index ) NEW_LINE w , h = Image . open ( img_path ) . size NEW_LINE roi_rec [ ' height ' ] = float ( h ) NEW_LINE roi_rec [ ' width ' ] = float ( w ) NEW_LINE if self . image_set == ' train ' : NEW_LINE INDENT filename = os . path . join ( self . data_path , ' labelTxt ' , index + ' . txt ' ) NEW_LINE f = codecs . open ( filename , ' r ' ) NEW_LINE objs = f . readlines ( ) NEW_LINE objs = [ obj . strip ( ) . split ( ' ▁ ' ) for obj in objs ] NEW_LINE if not self . config [ ' use _ diff ' ] : NEW_LINE INDENT non_diff_objs = [ obj for obj in objs if obj [ 9 ] != '1' ] NEW_LINE objs = non_diff_objs NEW_LINE DEDENT num_objs = len ( objs ) NEW_LINE boxes = np . zeros ( ( num_objs , 8 ) , dtype = np . uint16 ) NEW_LINE gt_classes = np . zeros ( ( num_objs ) , dtype = np . int32 ) NEW_LINE overlaps = np . zeros ( ( num_objs , self . num_classes ) , dtype = np . float32 ) NEW_LINE class_to_index = dict ( zip ( self . classes , range ( self . num_classes ) ) ) NEW_LINE for ix , obj in enumerate ( objs ) : NEW_LINE INDENT bbox = obj NEW_LINE x1 = min ( max ( float ( bbox [ 0 ] ) , 0 ) , w - 1 ) NEW_LINE y1 = min ( max ( float ( bbox [ 1 ] ) , 0 ) , h - 1 ) NEW_LINE x2 = min ( max ( float ( bbox [ 2 ] ) , 0 ) , w - 1 ) NEW_LINE y2 = min ( max ( float ( bbox [ 3 ] ) , 0 ) , h - 1 ) NEW_LINE x3 = min ( max ( float ( bbox [ 4 ] ) , 0 ) , w - 1 ) NEW_LINE y3 = min ( max ( float ( bbox [ 5 ] ) , 0 ) , h - 1 ) NEW_LINE x4 = min ( max ( float ( bbox [ 6 ] ) , 0 ) , w - 1 ) NEW_LINE y4 = min ( max ( float ( bbox [ 7 ] ) , 0 ) , h - 1 ) NEW_LINE xmin = max ( min ( x1 , x2 , x3 , x4 ) , 0 ) NEW_LINE xmax = max ( x1 , x2 , x3 , x4 ) NEW_LINE ymin = max ( min ( y1 , y2 , y3 , y4 ) , 0 ) NEW_LINE ymax = max ( y1 , y2 , y3 , y4 ) NEW_LINE cls = class_to_index [ obj [ 8 ] . lower ( ) . strip ( ) ] NEW_LINE boxes [ ix , : ] = [ x1 , y1 , x2 , y2 , x3 , y3 , x4 , y4 ] NEW_LINE gt_classes [ ix ] = cls NEW_LINE overlaps [ ix , cls ] = 1.0 NEW_LINE DEDENT roi_rec . update ( { ' boxes ' : boxes , ' gt _ classes ' : gt_classes , ' gt _ overlaps ' : overlaps , ' max _ classes ' : overlaps . argmax ( axis = 1 ) , ' max _ overlaps ' : overlaps . max ( axis = 1 ) , ' flipped ' : False } ) NEW_LINE DEDENT return roi_rec NEW_LINE DEDENT\",), (\"def evaluate_detections ( self , detections ) : NEW_LINE INDENT detection_results_path = os . path . join ( self . result_path , ' test _ results ' ) NEW_LINE info = ' ' NEW_LINE if not os . path . isdir ( detection_results_path ) : NEW_LINE INDENT os . mkdir ( detection_results_path ) NEW_LINE DEDENT self . write_DOTA_results ( detections , threshold = 0.0 ) NEW_LINE return info NEW_LINE DEDENT\",), ('def validate_clockwise_points ( self , points ) : NEW_LINE INDENT if len ( points ) != 8 : NEW_LINE INDENT raise Exception ( \" Points ▁ list ▁ not ▁ valid . \" + str ( len ( points ) ) ) NEW_LINE DEDENT point = [ [ int ( points [ 0 ] ) , int ( points [ 1 ] ) ] , [ int ( points [ 2 ] ) , int ( points [ 3 ] ) ] , [ int ( points [ 4 ] ) , int ( points [ 5 ] ) ] , [ int ( points [ 6 ] ) , int ( points [ 7 ] ) ] ] NEW_LINE edge = [ ( point [ 1 ] [ 0 ] - point [ 0 ] [ 0 ] ) * ( point [ 1 ] [ 1 ] + point [ 0 ] [ 1 ] ) , ( point [ 2 ] [ 0 ] - point [ 1 ] [ 0 ] ) * ( point [ 2 ] [ 1 ] + point [ 1 ] [ 1 ] ) , ( point [ 3 ] [ 0 ] - point [ 2 ] [ 0 ] ) * ( point [ 3 ] [ 1 ] + point [ 2 ] [ 1 ] ) , ( point [ 0 ] [ 0 ] - point [ 3 ] [ 0 ] ) * ( point [ 0 ] [ 1 ] + point [ 3 ] [ 1 ] ) ] NEW_LINE summatory = edge [ 0 ] + edge [ 1 ] + edge [ 2 ] + edge [ 3 ] ; NEW_LINE if summatory > 0 : NEW_LINE INDENT return False NEW_LINE DEDENT else : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT',), (\"def load_image_set_index ( self ) : NEW_LINE INDENT image_set_index_file = os . path . join ( self . data_path , self . image_set + ' . txt ' ) NEW_LINE assert os . path . exists ( image_set_index_file ) , ' Path ▁ does ▁ not ▁ exist : ▁ { } ' . format ( image_set_index_file ) NEW_LINE with open ( image_set_index_file , ' r ' ) as f : NEW_LINE INDENT lines = f . readlines ( ) NEW_LINE DEDENT image_lists = [ line . strip ( ) for line in lines ] NEW_LINE return image_lists NEW_LINE DEDENT\",), (\"def image_path_from_index ( self , index ) : NEW_LINE INDENT image_file = os . path . join ( self . data_path , ' images ' , index + ' . bmp ' ) NEW_LINE assert os . path . exists ( image_file ) , ' Path ▁ does ▁ not ▁ exist : ▁ { } ' . format ( image_file ) NEW_LINE return image_file NEW_LINE DEDENT\",), (\"def load_annotation ( self , index ) : NEW_LINE INDENT roi_rec = dict ( ) NEW_LINE roi_rec [ ' image ' ] = self . image_path_from_index ( index ) NEW_LINE img_path = self . image_path_from_index ( index ) NEW_LINE w , h = Image . open ( img_path ) . size NEW_LINE roi_rec [ ' height ' ] = float ( h ) NEW_LINE roi_rec [ ' width ' ] = float ( w ) NEW_LINE valid_objs = [ ] NEW_LINE if self . image_set == ' train ' : NEW_LINE INDENT filename = os . path . join ( self . data_path , ' labelTxt _ L1' , index + ' . txt ' ) NEW_LINE f = codecs . open ( filename , ' r ' ) NEW_LINE objs = f . readlines ( ) NEW_LINE objs = [ obj . strip ( ) . split ( ' ▁ ' ) for obj in objs ] NEW_LINE if not self . config [ ' use _ diff ' ] : NEW_LINE INDENT non_diff_objs = [ obj for obj in objs if obj [ 9 ] == '0' ] NEW_LINE objs = non_diff_objs NEW_LINE DEDENT for ix , obj in enumerate ( objs ) : NEW_LINE INDENT bbox = obj NEW_LINE x1 = min ( max ( float ( bbox [ 0 ] ) , 0 ) , w - 1 ) NEW_LINE y1 = min ( max ( float ( bbox [ 1 ] ) , 0 ) , h - 1 ) NEW_LINE x2 = min ( max ( float ( bbox [ 2 ] ) , 0 ) , w - 1 ) NEW_LINE y2 = min ( max ( float ( bbox [ 3 ] ) , 0 ) , h - 1 ) NEW_LINE x3 = min ( max ( float ( bbox [ 4 ] ) , 0 ) , w - 1 ) NEW_LINE y3 = min ( max ( float ( bbox [ 5 ] ) , 0 ) , h - 1 ) NEW_LINE x4 = min ( max ( float ( bbox [ 6 ] ) , 0 ) , w - 1 ) NEW_LINE y4 = min ( max ( float ( bbox [ 7 ] ) , 0 ) , h - 1 ) NEW_LINE xmin = max ( min ( x1 , x2 , x3 , x4 ) , 0 ) NEW_LINE xmax = max ( x1 , x2 , x3 , x4 ) NEW_LINE ymin = max ( min ( y1 , y2 , y3 , y4 ) , 0 ) NEW_LINE ymax = max ( y1 , y2 , y3 , y4 ) NEW_LINE if ( ( xmax - xmin ) > 10 ) and ( ( ymax - ymin ) > 10 ) : NEW_LINE INDENT obj [ : 8 ] = [ x1 , y1 , x2 , y2 , x3 , y3 , x4 , y4 ] NEW_LINE valid_objs . append ( obj ) NEW_LINE DEDENT DEDENT objs = valid_objs NEW_LINE num_objs = len ( objs ) NEW_LINE boxes = np . zeros ( ( num_objs , 8 ) , dtype = np . uint16 ) NEW_LINE gt_classes = np . zeros ( ( num_objs ) , dtype = np . int32 ) NEW_LINE overlaps = np . zeros ( ( num_objs , self . num_classes ) , dtype = np . float32 ) NEW_LINE class_to_index = dict ( zip ( self . classes , range ( self . num_classes ) ) ) NEW_LINE for ix , obj in enumerate ( objs ) : NEW_LINE INDENT cls = class_to_index [ obj [ 8 ] . lower ( ) . strip ( ) ] NEW_LINE if obj [ 8 ] . lower ( ) . strip ( ) in self . angle_agnostic_classes : NEW_LINE INDENT boxes [ ix , : ] = get_best_begin_point_wrapp ( obj [ : 8 ] ) NEW_LINE DEDENT else : NEW_LINE INDENT boxes [ ix , : ] = obj [ : 8 ] NEW_LINE DEDENT gt_classes [ ix ] = cls NEW_LINE overlaps [ ix , cls ] = 1.0 NEW_LINE DEDENT roi_rec . update ( { ' boxes ' : boxes , ' gt _ classes ' : gt_classes , ' gt _ overlaps ' : overlaps , ' max _ classes ' : overlaps . argmax ( axis = 1 ) , ' max _ overlaps ' : overlaps . max ( axis = 1 ) , ' flipped ' : False } ) NEW_LINE DEDENT return roi_rec NEW_LINE DEDENT\",), (\"def evaluate_detections ( self , detections , ignore_cache ) : NEW_LINE INDENT detection_results_path = os . path . join ( self . result_path , ' test _ results ' ) NEW_LINE info = ' ' NEW_LINE if not os . path . isdir ( detection_results_path ) : NEW_LINE INDENT os . mkdir ( detection_results_path ) NEW_LINE DEDENT if ignore_cache : NEW_LINE INDENT self . write_results ( detections , threshold = 0.001 ) NEW_LINE self . write_results_comp4 ( detections , threshold = 0.001 ) NEW_LINE DEDENT detpath = os . path . join ( self . result_path , ' Task1 _ results ' ) + ' / Task1 _ { : s } . txt ' NEW_LINE annopath = r' data / HRSC / labelTxt _ L1 / { : s } . txt ' NEW_LINE imagesetfile = r' data / HRSC / test . txt ' NEW_LINE mAP , classaps = eval_HRSC_L1 ( detpath , annopath , imagesetfile ) NEW_LINE with open ( os . path . join ( self . result_path , ' Task1 _ results ' ) + ' / mAP . txt ' , ' w ' ) as f_out : NEW_LINE INDENT f_out . write ( ' mAP : ▁ ' + str ( mAP ) + ' \\\\n ' ) NEW_LINE f_out . write ( ' classaps : ▁ ' + str ( classaps ) ) NEW_LINE DEDENT return info NEW_LINE DEDENT\",), ('def validate_clockwise_points ( self , points ) : NEW_LINE INDENT if len ( points ) != 8 : NEW_LINE INDENT raise Exception ( \" Points ▁ list ▁ not ▁ valid . \" + str ( len ( points ) ) ) NEW_LINE DEDENT point = [ [ int ( points [ 0 ] ) , int ( points [ 1 ] ) ] , [ int ( points [ 2 ] ) , int ( points [ 3 ] ) ] , [ int ( points [ 4 ] ) , int ( points [ 5 ] ) ] , [ int ( points [ 6 ] ) , int ( points [ 7 ] ) ] ] NEW_LINE edge = [ ( point [ 1 ] [ 0 ] - point [ 0 ] [ 0 ] ) * ( point [ 1 ] [ 1 ] + point [ 0 ] [ 1 ] ) , ( point [ 2 ] [ 0 ] - point [ 1 ] [ 0 ] ) * ( point [ 2 ] [ 1 ] + point [ 1 ] [ 1 ] ) , ( point [ 3 ] [ 0 ] - point [ 2 ] [ 0 ] ) * ( point [ 3 ] [ 1 ] + point [ 2 ] [ 1 ] ) , ( point [ 0 ] [ 0 ] - point [ 3 ] [ 0 ] ) * ( point [ 0 ] [ 1 ] + point [ 3 ] [ 1 ] ) ] NEW_LINE summatory = edge [ 0 ] + edge [ 1 ] + edge [ 2 ] + edge [ 3 ] ; NEW_LINE if summatory > 0 : NEW_LINE INDENT return False NEW_LINE DEDENT else : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT',), (\"def load_image_set_index ( self ) : NEW_LINE INDENT image_set_index_file = os . path . join ( self . data_path , self . image_set + ' . txt ' ) NEW_LINE assert os . path . exists ( image_set_index_file ) , ' Path ▁ does ▁ not ▁ exist : ▁ { } ' . format ( image_set_index_file ) NEW_LINE with open ( image_set_index_file , ' r ' ) as f : NEW_LINE INDENT lines = f . readlines ( ) NEW_LINE DEDENT image_lists = [ line . strip ( ) for line in lines ] NEW_LINE return image_lists NEW_LINE DEDENT\",), (\"def image_path_from_index ( self , index ) : NEW_LINE INDENT image_file = os . path . join ( self . data_path , ' images ' , index + ' . bmp ' ) NEW_LINE assert os . path . exists ( image_file ) , ' Path ▁ does ▁ not ▁ exist : ▁ { } ' . format ( image_file ) NEW_LINE return image_file NEW_LINE DEDENT\",), (\"def load_annotation ( self , index ) : NEW_LINE INDENT roi_rec = dict ( ) NEW_LINE roi_rec [ ' image ' ] = self . image_path_from_index ( index ) NEW_LINE img_path = self . image_path_from_index ( index ) NEW_LINE w , h = Image . open ( img_path ) . size NEW_LINE roi_rec [ ' height ' ] = float ( h ) NEW_LINE roi_rec [ ' width ' ] = float ( w ) NEW_LINE valid_objs = [ ] NEW_LINE if self . image_set == ' train ' : NEW_LINE INDENT filename = os . path . join ( self . data_path , ' labelTxt _ L1' , index + ' . txt ' ) NEW_LINE f = codecs . open ( filename , ' r ' ) NEW_LINE objs = f . readlines ( ) NEW_LINE objs = [ obj . strip ( ) . split ( ' ▁ ' ) for obj in objs ] NEW_LINE if not self . config [ ' use _ diff ' ] : NEW_LINE INDENT non_diff_objs = [ obj for obj in objs if obj [ 9 ] == '0' ] NEW_LINE objs = non_diff_objs NEW_LINE DEDENT for ix , obj in enumerate ( objs ) : NEW_LINE INDENT bbox = obj NEW_LINE x1 = min ( max ( float ( bbox [ 0 ] ) , 0 ) , w - 1 ) NEW_LINE y1 = min ( max ( float ( bbox [ 1 ] ) , 0 ) , h - 1 ) NEW_LINE x2 = min ( max ( float ( bbox [ 2 ] ) , 0 ) , w - 1 ) NEW_LINE y2 = min ( max ( float ( bbox [ 3 ] ) , 0 ) , h - 1 ) NEW_LINE x3 = min ( max ( float ( bbox [ 4 ] ) , 0 ) , w - 1 ) NEW_LINE y3 = min ( max ( float ( bbox [ 5 ] ) , 0 ) , h - 1 ) NEW_LINE x4 = min ( max ( float ( bbox [ 6 ] ) , 0 ) , w - 1 ) NEW_LINE y4 = min ( max ( float ( bbox [ 7 ] ) , 0 ) , h - 1 ) NEW_LINE xmin = max ( min ( x1 , x2 , x3 , x4 ) , 0 ) NEW_LINE xmax = max ( x1 , x2 , x3 , x4 ) NEW_LINE ymin = max ( min ( y1 , y2 , y3 , y4 ) , 0 ) NEW_LINE ymax = max ( y1 , y2 , y3 , y4 ) NEW_LINE if ( ( xmax - xmin ) > 10 ) and ( ( ymax - ymin ) > 10 ) : NEW_LINE INDENT obj [ : 8 ] = [ x1 , y1 , x2 , y2 , x3 , y3 , x4 , y4 ] NEW_LINE valid_objs . append ( obj ) NEW_LINE DEDENT DEDENT objs = valid_objs NEW_LINE num_objs = len ( objs ) NEW_LINE boxes = np . zeros ( ( num_objs , 8 ) , dtype = np . uint16 ) NEW_LINE gt_classes = np . zeros ( ( num_objs ) , dtype = np . int32 ) NEW_LINE overlaps = np . zeros ( ( num_objs , self . num_classes ) , dtype = np . float32 ) NEW_LINE class_to_index = dict ( zip ( self . classes , range ( self . num_classes ) ) ) NEW_LINE for ix , obj in enumerate ( objs ) : NEW_LINE INDENT cls = class_to_index [ obj [ 8 ] . lower ( ) . strip ( ) ] NEW_LINE if obj [ 8 ] . lower ( ) . strip ( ) in self . angle_agnostic_classes : NEW_LINE INDENT boxes [ ix , : ] = get_best_begin_point_wrapp ( obj [ : 8 ] ) NEW_LINE DEDENT else : NEW_LINE INDENT boxes [ ix , : ] = obj [ : 8 ] NEW_LINE DEDENT gt_classes [ ix ] = cls NEW_LINE overlaps [ ix , cls ] = 1.0 NEW_LINE DEDENT roi_rec . update ( { ' boxes ' : boxes , ' gt _ classes ' : gt_classes , ' gt _ overlaps ' : overlaps , ' max _ classes ' : overlaps . argmax ( axis = 1 ) , ' max _ overlaps ' : overlaps . max ( axis = 1 ) , ' flipped ' : False } ) NEW_LINE DEDENT return roi_rec NEW_LINE DEDENT\",), (\"def evaluate_detections ( self , detections , ignore_cache ) : NEW_LINE INDENT detection_results_path = os . path . join ( self . result_path , ' test _ results ' ) NEW_LINE info = ' ' NEW_LINE if not os . path . isdir ( detection_results_path ) : NEW_LINE INDENT os . mkdir ( detection_results_path ) NEW_LINE DEDENT if ignore_cache : NEW_LINE INDENT self . write_results ( detections , threshold = 0.001 ) NEW_LINE DEDENT self . write_results_comp4 ( detections , threshold = 0.001 ) NEW_LINE detpath = os . path . join ( self . result_path , ' Task1 _ results ' ) + ' / Task1 _ { : s } . txt ' NEW_LINE annopath = r' data / HRSC / labelTxt _ L1 / { : s } . txt ' NEW_LINE imagesetfile = r' data / HRSC / test . txt ' NEW_LINE mAP , classaps = eval_HRSC_L1 ( detpath , annopath , imagesetfile ) NEW_LINE with open ( os . path . join ( self . result_path , ' Task1 _ results ' ) + ' / mAP . txt ' , ' w ' ) as f_out : NEW_LINE INDENT f_out . write ( ' mAP : ▁ ' + str ( mAP ) + ' \\\\n ' ) NEW_LINE f_out . write ( ' classaps : ▁ ' + str ( classaps ) ) NEW_LINE DEDENT return info NEW_LINE DEDENT\",), ('def validate_clockwise_points ( self , points ) : NEW_LINE INDENT if len ( points ) != 8 : NEW_LINE INDENT raise Exception ( \" Points ▁ list ▁ not ▁ valid . \" + str ( len ( points ) ) ) NEW_LINE DEDENT point = [ [ int ( points [ 0 ] ) , int ( points [ 1 ] ) ] , [ int ( points [ 2 ] ) , int ( points [ 3 ] ) ] , [ int ( points [ 4 ] ) , int ( points [ 5 ] ) ] , [ int ( points [ 6 ] ) , int ( points [ 7 ] ) ] ] NEW_LINE edge = [ ( point [ 1 ] [ 0 ] - point [ 0 ] [ 0 ] ) * ( point [ 1 ] [ 1 ] + point [ 0 ] [ 1 ] ) , ( point [ 2 ] [ 0 ] - point [ 1 ] [ 0 ] ) * ( point [ 2 ] [ 1 ] + point [ 1 ] [ 1 ] ) , ( point [ 3 ] [ 0 ] - point [ 2 ] [ 0 ] ) * ( point [ 3 ] [ 1 ] + point [ 2 ] [ 1 ] ) , ( point [ 0 ] [ 0 ] - point [ 3 ] [ 0 ] ) * ( point [ 0 ] [ 1 ] + point [ 3 ] [ 1 ] ) ] NEW_LINE summatory = edge [ 0 ] + edge [ 1 ] + edge [ 2 ] + edge [ 3 ] ; NEW_LINE if summatory > 0 : NEW_LINE INDENT return False NEW_LINE DEDENT else : NEW_LINE INDENT return True NEW_LINE DEDENT DEDENT',), (\"def decodeMask ( R ) : NEW_LINE INDENT N = len ( R [ ' counts ' ] ) NEW_LINE M = np . zeros ( ( R [ ' size ' ] [ 0 ] * R [ ' size ' ] [ 1 ] , ) ) NEW_LINE n = 0 NEW_LINE val = 1 NEW_LINE for pos in range ( N ) : NEW_LINE INDENT val = not val NEW_LINE for c in range ( R [ ' counts ' ] [ pos ] ) : NEW_LINE INDENT R [ ' counts ' ] [ pos ] NEW_LINE M [ n ] = val NEW_LINE n += 1 NEW_LINE DEDENT DEDENT return M . reshape ( ( R [ ' size ' ] ) , order = ' F ' ) NEW_LINE DEDENT\",), (\"def encodeMask ( M ) : NEW_LINE INDENT [ h , w ] = M . shape NEW_LINE M = M . flatten ( order = ' F ' ) NEW_LINE N = len ( M ) NEW_LINE counts_list = [ ] NEW_LINE pos = 0 NEW_LINE counts_list . append ( 1 ) NEW_LINE diffs = np . logical_xor ( M [ 0 : N - 1 ] , M [ 1 : N ] ) NEW_LINE for diff in diffs : NEW_LINE INDENT if diff : NEW_LINE INDENT pos += 1 NEW_LINE counts_list . append ( 1 ) NEW_LINE DEDENT else : NEW_LINE INDENT counts_list [ pos ] += 1 NEW_LINE DEDENT DEDENT if M [ 0 ] == 1 : NEW_LINE INDENT counts_list = [ 0 ] + counts_list NEW_LINE DEDENT return { ' size ' : [ h , w ] , ' counts ' : counts_list , } NEW_LINE DEDENT\",), ('def segToMask ( S , h , w ) : NEW_LINE INDENT M = np . zeros ( ( h , w ) , dtype = np . bool ) NEW_LINE for s in S : NEW_LINE INDENT N = len ( s ) NEW_LINE rr , cc = polygon ( np . array ( s [ 1 : N : 2 ] ) . clip ( max = h - 1 ) , np . array ( s [ 0 : N : 2 ] ) . clip ( max = w - 1 ) ) NEW_LINE M [ rr , cc ] = 1 NEW_LINE DEDENT return M NEW_LINE DEDENT',), (\"def getAnnIds ( self , imgIds = [ ] , catIds = [ ] , areaRng = [ ] , iscrowd = None ) : NEW_LINE INDENT imgIds = imgIds if type ( imgIds ) == list else [ imgIds ] NEW_LINE catIds = catIds if type ( catIds ) == list else [ catIds ] NEW_LINE if len ( imgIds ) == len ( catIds ) == len ( areaRng ) == 0 : NEW_LINE INDENT anns = self . dataset [ ' annotations ' ] NEW_LINE DEDENT else : NEW_LINE INDENT if not len ( imgIds ) == 0 : NEW_LINE INDENT lists = [ self . imgToAnns [ imgId ] for imgId in imgIds if imgId in self . imgToAnns ] NEW_LINE anns = list ( itertools . chain . from_iterable ( lists ) ) NEW_LINE DEDENT else : NEW_LINE INDENT anns = self . dataset [ ' annotations ' ] NEW_LINE DEDENT anns = anns if len ( catIds ) == 0 else [ ann for ann in anns if ann [ ' category _ id ' ] in catIds ] NEW_LINE anns = anns if len ( areaRng ) == 0 else [ ann for ann in anns if ann [ ' area ' ] > areaRng [ 0 ] and ann [ ' area ' ] < areaRng [ 1 ] ] NEW_LINE DEDENT if not iscrowd == None : NEW_LINE INDENT ids = [ ann [ ' id ' ] for ann in anns if ann [ ' iscrowd ' ] == iscrowd ] NEW_LINE DEDENT else : NEW_LINE INDENT ids = [ ann [ ' id ' ] for ann in anns ] NEW_LINE DEDENT return ids NEW_LINE DEDENT\",), (\"def getCatIds ( self , catNms = [ ] , supNms = [ ] , catIds = [ ] ) : NEW_LINE INDENT catNms = catNms if type ( catNms ) == list else [ catNms ] NEW_LINE supNms = supNms if type ( supNms ) == list else [ supNms ] NEW_LINE catIds = catIds if type ( catIds ) == list else [ catIds ] NEW_LINE if len ( catNms ) == len ( supNms ) == len ( catIds ) == 0 : NEW_LINE INDENT cats = self . dataset [ ' categories ' ] NEW_LINE DEDENT else : NEW_LINE INDENT cats = self . dataset [ ' categories ' ] NEW_LINE cats = cats if len ( catNms ) == 0 else [ cat for cat in cats if cat [ ' name ' ] in catNms ] NEW_LINE cats = cats if len ( supNms ) == 0 else [ cat for cat in cats if cat [ ' supercategory ' ] in supNms ] NEW_LINE cats = cats if len ( catIds ) == 0 else [ cat for cat in cats if cat [ ' id ' ] in catIds ] NEW_LINE DEDENT ids = [ cat [ ' id ' ] for cat in cats ] NEW_LINE return ids NEW_LINE DEDENT\",), ('def getImgIds ( self , imgIds = [ ] , catIds = [ ] ) : NEW_LINE INDENT imgIds = imgIds if type ( imgIds ) == list else [ imgIds ] NEW_LINE catIds = catIds if type ( catIds ) == list else [ catIds ] NEW_LINE if len ( imgIds ) == len ( catIds ) == 0 : NEW_LINE INDENT ids = self . imgs . keys ( ) NEW_LINE DEDENT else : NEW_LINE INDENT ids = set ( imgIds ) NEW_LINE for i , catId in enumerate ( catIds ) : NEW_LINE INDENT if i == 0 and len ( ids ) == 0 : NEW_LINE INDENT ids = set ( self . catToImgs [ catId ] ) NEW_LINE DEDENT else : NEW_LINE INDENT ids &= set ( self . catToImgs [ catId ] ) NEW_LINE DEDENT DEDENT DEDENT return list ( ids ) NEW_LINE DEDENT',), ('def loadAnns ( self , ids = [ ] ) : NEW_LINE INDENT if type ( ids ) == list : NEW_LINE INDENT return [ self . anns [ id ] for id in ids ] NEW_LINE DEDENT elif type ( ids ) == int : NEW_LINE INDENT return [ self . anns [ ids ] ] NEW_LINE DEDENT DEDENT',), ('def loadCats ( self , ids = [ ] ) : NEW_LINE INDENT if type ( ids ) == list : NEW_LINE INDENT return [ self . cats [ id ] for id in ids ] NEW_LINE DEDENT elif type ( ids ) == int : NEW_LINE INDENT return [ self . cats [ ids ] ] NEW_LINE DEDENT DEDENT',), ('def loadImgs ( self , ids = [ ] ) : NEW_LINE INDENT if type ( ids ) == list : NEW_LINE INDENT return [ self . imgs [ id ] for id in ids ] NEW_LINE DEDENT elif type ( ids ) == int : NEW_LINE INDENT return [ self . imgs [ ids ] ] NEW_LINE DEDENT DEDENT',), (\"def annToRLE ( self , ann ) : NEW_LINE INDENT t = self . imgs [ ann [ ' image _ id ' ] ] NEW_LINE h , w = t [ ' height ' ] , t [ ' width ' ] NEW_LINE segm = ann [ ' segmentation ' ] NEW_LINE if type ( segm ) == list : NEW_LINE INDENT rles = mask . frPyObjects ( segm , h , w ) NEW_LINE rle = mask . merge ( rles ) NEW_LINE DEDENT elif type ( segm [ ' counts ' ] ) == list : NEW_LINE INDENT rle = mask . frPyObjects ( segm , h , w ) NEW_LINE DEDENT else : NEW_LINE INDENT rle = ann [ ' segmentation ' ] NEW_LINE DEDENT return rle NEW_LINE DEDENT\",), ('def annToMask ( self , ann ) : NEW_LINE INDENT rle = self . annToRLE ( ann ) NEW_LINE m = mask . decode ( rle ) NEW_LINE return m NEW_LINE DEDENT',), ('def __init__ ( self , cocoGt = None , cocoDt = None ) : NEW_LINE INDENT self . cocoGt = cocoGt NEW_LINE self . cocoDt = cocoDt NEW_LINE self . params = { } NEW_LINE self . evalImgs = defaultdict ( list ) NEW_LINE self . eval = { } NEW_LINE self . _gts = defaultdict ( list ) NEW_LINE self . _dts = defaultdict ( list ) NEW_LINE self . params = Params ( ) NEW_LINE self . _paramsEval = { } NEW_LINE self . stats = [ ] NEW_LINE self . ious = { } NEW_LINE if not cocoGt is None : NEW_LINE INDENT self . params . imgIds = sorted ( cocoGt . getImgIds ( ) ) NEW_LINE self . params . catIds = sorted ( cocoGt . getCatIds ( ) ) NEW_LINE DEDENT DEDENT',), (\"def computeIoU ( self , imgId , catId ) : NEW_LINE INDENT p = self . params NEW_LINE if p . useCats : NEW_LINE INDENT gt = self . _gts [ imgId , catId ] NEW_LINE dt = self . _dts [ imgId , catId ] NEW_LINE DEDENT else : NEW_LINE INDENT gt = [ _ for cId in p . catIds for _ in self . _gts [ imgId , cId ] ] NEW_LINE dt = [ _ for cId in p . catIds for _ in self . _dts [ imgId , cId ] ] NEW_LINE DEDENT if len ( gt ) == 0 and len ( dt ) == 0 : NEW_LINE INDENT return [ ] NEW_LINE DEDENT dt = sorted ( dt , key = lambda x : - x [ ' score ' ] ) NEW_LINE if len ( dt ) > p . maxDets [ - 1 ] : NEW_LINE INDENT dt = dt [ 0 : p . maxDets [ - 1 ] ] NEW_LINE DEDENT if p . useSegm : NEW_LINE INDENT g = [ g [ ' segmentation ' ] for g in gt ] NEW_LINE d = [ d [ ' segmentation ' ] for d in dt ] NEW_LINE DEDENT else : NEW_LINE INDENT g = [ g [ ' bbox ' ] for g in gt ] NEW_LINE d = [ d [ ' bbox ' ] for d in dt ] NEW_LINE DEDENT iscrowd = [ int ( o [ ' iscrowd ' ] ) for o in gt ] NEW_LINE ious = mask . iou ( d , g , iscrowd ) NEW_LINE return ious NEW_LINE DEDENT\",), (\"def evaluateImg ( self , imgId , catId , aRng , maxDet ) : NEW_LINE INDENT p = self . params NEW_LINE if p . useCats : NEW_LINE INDENT gt = self . _gts [ imgId , catId ] NEW_LINE dt = self . _dts [ imgId , catId ] NEW_LINE DEDENT else : NEW_LINE INDENT gt = [ _ for cId in p . catIds for _ in self . _gts [ imgId , cId ] ] NEW_LINE dt = [ _ for cId in p . catIds for _ in self . _dts [ imgId , cId ] ] NEW_LINE DEDENT if len ( gt ) == 0 and len ( dt ) == 0 : NEW_LINE INDENT return None NEW_LINE DEDENT for g in gt : NEW_LINE INDENT if ' ignore ' not in g : NEW_LINE INDENT g [ ' ignore ' ] = 0 NEW_LINE DEDENT if g [ ' iscrowd ' ] == 1 or g [ ' ignore ' ] or ( g [ ' area ' ] < aRng [ 0 ] or g [ ' area ' ] > aRng [ 1 ] ) : NEW_LINE INDENT g [ ' _ ignore ' ] = 1 NEW_LINE DEDENT else : NEW_LINE INDENT g [ ' _ ignore ' ] = 0 NEW_LINE DEDENT DEDENT gtind = [ ind for ( ind , g ) in sorted ( enumerate ( gt ) , key = lambda ( ind , g ) : g [ ' _ ignore ' ] ) ] NEW_LINE gt = [ gt [ ind ] for ind in gtind ] NEW_LINE dt = sorted ( dt , key = lambda x : - x [ ' score ' ] ) [ 0 : maxDet ] NEW_LINE iscrowd = [ int ( o [ ' iscrowd ' ] ) for o in gt ] NEW_LINE N_iou = len ( self . ious [ imgId , catId ] ) NEW_LINE ious = self . ious [ imgId , catId ] [ 0 : maxDet , np . array ( gtind ) ] if N_iou > 0 else self . ious [ imgId , catId ] NEW_LINE T = len ( p . iouThrs ) NEW_LINE G = len ( gt ) NEW_LINE D = len ( dt ) NEW_LINE gtm = np . zeros ( ( T , G ) ) NEW_LINE dtm = np . zeros ( ( T , D ) ) NEW_LINE gtIg = np . array ( [ g [ ' _ ignore ' ] for g in gt ] ) NEW_LINE dtIg = np . zeros ( ( T , D ) ) NEW_LINE if not len ( ious ) == 0 : NEW_LINE INDENT for tind , t in enumerate ( p . iouThrs ) : NEW_LINE INDENT for dind , d in enumerate ( dt ) : NEW_LINE INDENT iou = min ( [ t , 1 - 1e-10 ] ) NEW_LINE m = - 1 NEW_LINE for gind , g in enumerate ( gt ) : NEW_LINE INDENT if gtm [ tind , gind ] > 0 and not iscrowd [ gind ] : NEW_LINE INDENT continue NEW_LINE DEDENT if m > - 1 and gtIg [ m ] == 0 and gtIg [ gind ] == 1 : NEW_LINE INDENT break NEW_LINE DEDENT if ious [ dind , gind ] < iou : NEW_LINE INDENT continue NEW_LINE DEDENT iou = ious [ dind , gind ] NEW_LINE m = gind NEW_LINE DEDENT if m == - 1 : NEW_LINE INDENT continue NEW_LINE DEDENT dtIg [ tind , dind ] = gtIg [ m ] NEW_LINE dtm [ tind , dind ] = gt [ m ] [ ' id ' ] NEW_LINE gtm [ tind , m ] = d [ ' id ' ] NEW_LINE DEDENT DEDENT DEDENT a = np . array ( [ d [ ' area ' ] < aRng [ 0 ] or d [ ' area ' ] > aRng [ 1 ] for d in dt ] ) . reshape ( ( 1 , len ( dt ) ) ) NEW_LINE dtIg = np . logical_or ( dtIg , np . logical_and ( dtm == 0 , np . repeat ( a , T , 0 ) ) ) NEW_LINE return { ' image _ id ' : imgId , ' category _ id ' : catId , ' aRng ' : aRng , ' maxDet ' : maxDet , ' dtIds ' : [ d [ ' id ' ] for d in dt ] , ' gtIds ' : [ g [ ' id ' ] for g in gt ] , ' dtMatches ' : dtm , ' gtMatches ' : gtm , ' dtScores ' : [ d [ ' score ' ] for d in dt ] , ' gtIgnore ' : gtIg , ' dtIgnore ' : dtIg , } NEW_LINE DEDENT\",), ('def __str__ ( self ) : NEW_LINE INDENT self . summarize ( ) NEW_LINE DEDENT',), ('def __init__ ( self ) : NEW_LINE INDENT self . imgIds = [ ] NEW_LINE self . catIds = [ ] NEW_LINE self . iouThrs = np . linspace ( .5 , 0.95 , np . round ( ( 0.95 - .5 ) / .05 ) + 1 , endpoint = True ) NEW_LINE self . recThrs = np . linspace ( .0 , 1.00 , np . round ( ( 1.00 - .0 ) / .01 ) + 1 , endpoint = True ) NEW_LINE self . maxDets = [ 1 , 10 , 100 ] NEW_LINE self . areaRng = [ [ 0 ** 2 , 1e5 ** 2 ] , [ 0 ** 2 , 32 ** 2 ] , [ 32 ** 2 , 96 ** 2 ] , [ 96 ** 2 , 1e5 ** 2 ] ] NEW_LINE self . useSegm = 0 NEW_LINE self . useCats = 1 NEW_LINE DEDENT',), ('def decode ( rleObjs ) : NEW_LINE INDENT if type ( rleObjs ) == list : NEW_LINE INDENT return _mask . decode ( rleObjs ) NEW_LINE DEDENT else : NEW_LINE INDENT return _mask . decode ( [ rleObjs ] ) [ : , : , 0 ] NEW_LINE DEDENT DEDENT',), (\"def build_extensions ( self ) : NEW_LINE INDENT self . compiler . src_extensions . append ( ' . cu ' ) NEW_LINE self . compiler . set_executable ( ' compiler _ so ' , ' nvcc ' ) NEW_LINE self . compiler . set_executable ( ' linker _ so ' , ' nvcc ▁ - - shared ' ) NEW_LINE if hasattr ( self . compiler , ' _ c _ extensions ' ) : NEW_LINE INDENT self . compiler . _c_extensions . append ( ' . cu ' ) NEW_LINE DEDENT self . compiler . spawn = self . spawn NEW_LINE build_ext . build_extensions ( self ) NEW_LINE DEDENT\",), ('def spawn ( self , cmd , search_path = 1 , verbose = 0 , dry_run = 0 ) : NEW_LINE INDENT if ( sys . platform == \\' darwin \\' and len ( cmd ) >= 2 and cmd [ 0 ] == \\' nvcc \\' and cmd [ 1 ] == \\' - - shared \\' and cmd . count ( \\' - arch \\' ) > 0 ) : NEW_LINE INDENT while True : NEW_LINE INDENT try : NEW_LINE INDENT index = cmd . index ( \\' - arch \\' ) NEW_LINE del cmd [ index : index + 2 ] NEW_LINE DEDENT except ValueError : NEW_LINE INDENT break NEW_LINE DEDENT DEDENT DEDENT elif self . compiler . compiler_type == \\' msvc \\' : NEW_LINE INDENT cmd [ : 1 ] = [ \\' nvcc \\' , \\' - - compiler - bindir \\' , os . path . dirname ( find_executable ( \" cl . exe \" , PATH ) ) or cmd [ 0 ] ] NEW_LINE for idx , c in enumerate ( cmd ) : NEW_LINE INDENT if c == \\' / c \\' : cmd [ idx ] = \\' - c \\' NEW_LINE elif c == \\' / DLL \\' : cmd [ idx ] = \\' - - shared \\' NEW_LINE elif \\' - fPIC \\' in c : del cmd [ idx ] NEW_LINE elif c . startswith ( \\' / Tc \\' ) : cmd [ idx ] = c [ 3 : ] NEW_LINE elif c . startswith ( \\' / Fo \\' ) : cmd [ idx : idx + 1 ] = [ \\' - o \\' , c [ 3 : ] ] NEW_LINE elif c . startswith ( \\' / LIBPATH : \\' ) : cmd [ idx ] = \\' - L \\' + c [ 9 : ] NEW_LINE elif c . startswith ( \\' / OUT : \\' ) : cmd [ idx : idx + 1 ] = [ \\' - o \\' , c [ 5 : ] ] NEW_LINE elif c . startswith ( \\' / EXPORT : \\' ) : del cmd [ idx ] NEW_LINE elif c == \\' cublas . lib \\' : cmd [ idx ] = \\' - lcublas \\' NEW_LINE DEDENT if \\' - - shared \\' in cmd : NEW_LINE INDENT pass_on = \\' - - linker - options = \\' NEW_LINE cmd . append ( \\' / NODEFAULTLIB : libcmt . lib \\' ) NEW_LINE DEDENT else : NEW_LINE INDENT pass_on = \\' - - compiler - options = \\' NEW_LINE DEDENT cmd = ( [ c for c in cmd if c [ 0 ] != \\' / \\' ] + [ pass_on + \\' , \\' . join ( c for c in cmd if c [ 0 ] == \\' / \\' ) ] ) NEW_LINE DEDENT spawn ( cmd , search_path , verbose , dry_run ) NEW_LINE DEDENT',), ('def py_nms_wrapper ( thresh ) : NEW_LINE INDENT def _nms ( dets ) : NEW_LINE INDENT return nms ( dets , thresh ) NEW_LINE DEDENT return _nms NEW_LINE DEDENT',), ('def py_softnms_wrapper ( thresh , max_dets = - 1 ) : NEW_LINE INDENT def _nms ( dets ) : NEW_LINE INDENT return soft_nms ( dets , thresh , max_dets ) NEW_LINE DEDENT return _nms NEW_LINE DEDENT',), ('def cpu_nms_wrapper ( thresh ) : NEW_LINE INDENT def _nms ( dets ) : NEW_LINE INDENT return cpu_nms ( dets , thresh ) NEW_LINE DEDENT return _nms NEW_LINE DEDENT',), ('def gpu_nms_wrapper ( thresh , device_id ) : NEW_LINE INDENT def _nms ( dets ) : NEW_LINE INDENT return gpu_nms ( dets , thresh , device_id ) NEW_LINE DEDENT return _nms NEW_LINE DEDENT',), ('def nms ( dets , thresh ) : NEW_LINE INDENT if dets . shape [ 0 ] == 0 : NEW_LINE INDENT return [ ] NEW_LINE DEDENT x1 = dets [ : , 0 ] NEW_LINE y1 = dets [ : , 1 ] NEW_LINE x2 = dets [ : , 2 ] NEW_LINE y2 = dets [ : , 3 ] NEW_LINE scores = dets [ : , 4 ] NEW_LINE areas = ( x2 - x1 + 1 ) * ( y2 - y1 + 1 ) NEW_LINE order = scores . argsort ( ) [ : : - 1 ] NEW_LINE keep = [ ] NEW_LINE while order . size > 0 : NEW_LINE INDENT i = order [ 0 ] NEW_LINE keep . append ( i ) NEW_LINE xx1 = np . maximum ( x1 [ i ] , x1 [ order [ 1 : ] ] ) NEW_LINE yy1 = np . maximum ( y1 [ i ] , y1 [ order [ 1 : ] ] ) NEW_LINE xx2 = np . minimum ( x2 [ i ] , x2 [ order [ 1 : ] ] ) NEW_LINE yy2 = np . minimum ( y2 [ i ] , y2 [ order [ 1 : ] ] ) NEW_LINE w = np . maximum ( 0.0 , xx2 - xx1 + 1 ) NEW_LINE h = np . maximum ( 0.0 , yy2 - yy1 + 1 ) NEW_LINE inter = w * h NEW_LINE ovr = inter / ( areas [ i ] + areas [ order [ 1 : ] ] - inter ) NEW_LINE inds = np . where ( ovr <= thresh ) [ 0 ] NEW_LINE order = order [ inds + 1 ] NEW_LINE DEDENT return keep NEW_LINE DEDENT',), (\"def rescore ( overlap , scores , thresh , type = ' gaussian ' ) : NEW_LINE INDENT assert overlap . shape [ 0 ] == scores . shape [ 0 ] NEW_LINE if type == ' linear ' : NEW_LINE INDENT inds = np . where ( overlap >= thresh ) [ 0 ] NEW_LINE scores [ inds ] = scores [ inds ] * ( 1 - overlap [ inds ] ) NEW_LINE DEDENT else : NEW_LINE INDENT scores = scores * np . exp ( - overlap ** 2 / thresh ) NEW_LINE DEDENT return scores NEW_LINE DEDENT\",), ('def soft_nms ( dets , thresh , max_dets ) : NEW_LINE INDENT if dets . shape [ 0 ] == 0 : NEW_LINE INDENT return np . zeros ( ( 0 , 5 ) ) NEW_LINE DEDENT x1 = dets [ : , 0 ] NEW_LINE y1 = dets [ : , 1 ] NEW_LINE x2 = dets [ : , 2 ] NEW_LINE y2 = dets [ : , 3 ] NEW_LINE scores = dets [ : , 4 ] NEW_LINE areas = ( x2 - x1 + 1 ) * ( y2 - y1 + 1 ) NEW_LINE order = scores . argsort ( ) [ : : - 1 ] NEW_LINE scores = scores [ order ] NEW_LINE if max_dets == - 1 : NEW_LINE INDENT max_dets = order . size NEW_LINE DEDENT keep = np . zeros ( max_dets , dtype = np . intp ) NEW_LINE keep_cnt = 0 NEW_LINE while order . size > 0 and keep_cnt < max_dets : NEW_LINE INDENT i = order [ 0 ] NEW_LINE dets [ i , 4 ] = scores [ 0 ] NEW_LINE xx1 = np . maximum ( x1 [ i ] , x1 [ order [ 1 : ] ] ) NEW_LINE yy1 = np . maximum ( y1 [ i ] , y1 [ order [ 1 : ] ] ) NEW_LINE xx2 = np . minimum ( x2 [ i ] , x2 [ order [ 1 : ] ] ) NEW_LINE yy2 = np . minimum ( y2 [ i ] , y2 [ order [ 1 : ] ] ) NEW_LINE w = np . maximum ( 0.0 , xx2 - xx1 + 1 ) NEW_LINE h = np . maximum ( 0.0 , yy2 - yy1 + 1 ) NEW_LINE inter = w * h NEW_LINE ovr = inter / ( areas [ i ] + areas [ order [ 1 : ] ] - inter ) NEW_LINE order = order [ 1 : ] NEW_LINE scores = rescore ( ovr , scores [ 1 : ] , thresh ) NEW_LINE tmp = scores . argsort ( ) [ : : - 1 ] NEW_LINE order = order [ tmp ] NEW_LINE scores = scores [ tmp ] NEW_LINE keep [ keep_cnt ] = i NEW_LINE keep_cnt += 1 NEW_LINE DEDENT keep = keep [ : keep_cnt ] NEW_LINE dets = dets [ keep , : ] NEW_LINE return dets NEW_LINE DEDENT',), ('def find_in_path ( name , path ) : NEW_LINE INDENT for dir in path . split ( os . pathsep ) : NEW_LINE INDENT binpath = pjoin ( dir , name ) NEW_LINE if os . path . exists ( binpath ) : NEW_LINE INDENT return os . path . abspath ( binpath ) NEW_LINE DEDENT DEDENT return None NEW_LINE DEDENT',), (\"def customize_compiler_for_nvcc ( self ) : NEW_LINE INDENT self . src_extensions . append ( ' . cu ' ) NEW_LINE default_compiler_so = self . compiler_so NEW_LINE super = self . _compile NEW_LINE def _compile ( obj , src , ext , cc_args , extra_postargs , pp_opts ) : NEW_LINE INDENT if os . path . splitext ( src ) [ 1 ] == ' . cu ' : NEW_LINE INDENT self . set_executable ( ' compiler _ so ' , CUDA [ ' nvcc ' ] ) NEW_LINE postargs = extra_postargs [ ' nvcc ' ] NEW_LINE DEDENT else : NEW_LINE INDENT postargs = extra_postargs [ ' gcc ' ] NEW_LINE DEDENT super ( obj , src , ext , cc_args , postargs , pp_opts ) NEW_LINE self . compiler_so = default_compiler_so NEW_LINE DEDENT self . _compile = _compile NEW_LINE DEDENT\",), ('def build_extensions ( self ) : NEW_LINE INDENT customize_compiler_for_nvcc ( self . compiler ) NEW_LINE build_ext . build_extensions ( self ) NEW_LINE DEDENT',), ('def find_in_path ( name , path ) : NEW_LINE INDENT for dir in path . split ( os . pathsep ) : NEW_LINE INDENT binpath = pjoin ( dir , name ) NEW_LINE if os . path . exists ( binpath ) : NEW_LINE INDENT return os . path . abspath ( binpath ) NEW_LINE DEDENT DEDENT return None NEW_LINE DEDENT',), (\"def customize_compiler_for_nvcc ( self ) : NEW_LINE INDENT super = self . compile NEW_LINE def compile ( sources , output_dir = None , macros = None , include_dirs = None , debug = 0 , extra_preargs = None , extra_postargs = None , depends = None ) : NEW_LINE INDENT postfix = os . path . splitext ( sources [ 0 ] ) [ 1 ] NEW_LINE if postfix == ' . cu ' : NEW_LINE INDENT postargs = extra_postargs [ ' nvcc ' ] NEW_LINE DEDENT else : NEW_LINE INDENT postargs = extra_postargs [ ' gcc ' ] NEW_LINE DEDENT return super ( sources , output_dir , macros , include_dirs , debug , extra_preargs , postargs , depends ) NEW_LINE DEDENT self . compile = compile NEW_LINE DEDENT\",), ('def build_extensions ( self ) : NEW_LINE INDENT customize_compiler_for_nvcc ( self . compiler ) NEW_LINE build_ext . build_extensions ( self ) NEW_LINE DEDENT',), (\"def get_rpn_testbatch ( roidb , cfg ) : NEW_LINE INDENT imgs , roidb = get_test_image ( roidb , cfg ) NEW_LINE im_array = imgs NEW_LINE im_info = [ np . array ( [ roidb [ i ] [ ' im _ info ' ] ] , dtype = np . float32 ) for i in range ( len ( roidb ) ) ] NEW_LINE data = [ { ' data ' : im_array [ i ] , ' im _ info ' : im_info [ i ] } for i in range ( len ( roidb ) ) ] NEW_LINE label = { } NEW_LINE return data , label , im_info NEW_LINE DEDENT\",), (\"def get_rpn_batch ( roidb , cfg ) : NEW_LINE INDENT assert len ( roidb ) == 1 , ' Single ▁ batch ▁ only ' NEW_LINE imgs , roidb = get_image ( roidb , cfg ) NEW_LINE im_array = imgs [ 0 ] NEW_LINE im_info = np . array ( [ roidb [ 0 ] [ ' im _ info ' ] ] , dtype = np . float32 ) NEW_LINE if roidb [ 0 ] [ ' gt _ classes ' ] . size > 0 : NEW_LINE INDENT gt_inds = np . where ( roidb [ 0 ] [ ' gt _ classes ' ] != 0 ) [ 0 ] NEW_LINE gt_boxes = np . empty ( ( roidb [ 0 ] [ ' boxes ' ] . shape [ 0 ] , 5 ) , dtype = np . float32 ) NEW_LINE gt_boxes [ : , 0 : 4 ] = roidb [ 0 ] [ ' boxes ' ] [ gt_inds , : ] NEW_LINE gt_boxes [ : , 4 ] = roidb [ 0 ] [ ' gt _ classes ' ] [ gt_inds ] NEW_LINE DEDENT else : NEW_LINE INDENT gt_boxes = np . empty ( ( 0 , 5 ) , dtype = np . float32 ) NEW_LINE DEDENT data = { ' data ' : im_array , ' im _ info ' : im_info } NEW_LINE label = { ' gt _ boxes ' : gt_boxes } NEW_LINE return data , label NEW_LINE DEDENT\",), (\"def get_rpn_batch_poly ( roidb , cfg ) : NEW_LINE INDENT assert len ( roidb ) == 1 , ' Single ▁ batch ▁ only ' NEW_LINE imgs , roidb = get_image ( roidb , cfg ) NEW_LINE im_array = imgs [ 0 ] NEW_LINE im_info = np . array ( [ roidb [ 0 ] [ ' im _ info ' ] ] , dtype = np . float32 ) NEW_LINE if roidb [ 0 ] [ ' gt _ classes ' ] . size > 0 : NEW_LINE INDENT gt_inds = np . where ( roidb [ 0 ] [ ' gt _ classes ' ] != 0 ) [ 0 ] NEW_LINE gt_boxes = np . empty ( ( roidb [ 0 ] [ ' boxes ' ] . shape [ 0 ] , 9 ) , dtype = np . float32 ) NEW_LINE gt_boxes [ : , 0 : 8 ] = roidb [ 0 ] [ ' boxes ' ] [ gt_inds , : ] NEW_LINE gt_boxes [ : , 8 ] = roidb [ 0 ] [ ' gt _ classes ' ] [ gt_inds ] NEW_LINE DEDENT else : NEW_LINE INDENT gt_boxes = np . empty ( ( 0 , 9 ) , dtype = np . float32 ) NEW_LINE DEDENT data = { ' data ' : im_array , ' im _ info ' : im_info } NEW_LINE label = { ' gt _ boxes ' : gt_boxes } NEW_LINE return data , label NEW_LINE DEDENT\",), (\"def assign_pyramid_anchor ( feat_shapes , gt_boxes , im_info , cfg , feat_strides = ( 4 , 8 , 16 , 32 , 64 ) , scales = ( 8 , ) , ratios = ( 0.5 , 1 , 2 ) , allowed_border = 0 , balance_scale_bg = False , ) : NEW_LINE INDENT def _unmap ( data , count , inds , fill = 0 ) : NEW_LINE INDENT if len ( data . shape ) == 1 : NEW_LINE INDENT ret = np . empty ( ( count , ) , dtype = np . float32 ) NEW_LINE ret . fill ( fill ) NEW_LINE ret [ inds ] = data NEW_LINE DEDENT else : NEW_LINE INDENT ret = np . empty ( ( count , ) + data . shape [ 1 : ] , dtype = np . float32 ) NEW_LINE ret . fill ( fill ) NEW_LINE ret [ inds , : ] = data NEW_LINE DEDENT return ret NEW_LINE DEDENT DEBUG = False NEW_LINE im_info = im_info [ 0 ] NEW_LINE scales = np . array ( scales , dtype = np . float32 ) NEW_LINE ratios = np . array ( ratios , dtype = np . float32 ) NEW_LINE assert ( len ( feat_shapes ) == len ( feat_strides ) ) NEW_LINE fpn_args = [ ] NEW_LINE fpn_anchors_fid = np . zeros ( 0 ) . astype ( int ) NEW_LINE fpn_anchors = np . zeros ( [ 0 , 4 ] ) NEW_LINE fpn_labels = np . zeros ( 0 ) NEW_LINE fpn_inds_inside = [ ] NEW_LINE for feat_id in range ( len ( feat_strides ) ) : NEW_LINE INDENT if len ( scales . shape ) == 1 : NEW_LINE INDENT base_anchors = generate_anchors ( base_size = feat_strides [ feat_id ] , ratios = ratios , scales = scales ) NEW_LINE DEDENT else : NEW_LINE INDENT assert len ( scales . shape ) == len ( ratios . shape ) == 2 NEW_LINE base_anchors = generate_anchors ( base_size = feat_strides [ feat_id ] , ratios = ratios [ feat_id ] , scales = scales [ feat_id ] ) NEW_LINE DEDENT num_anchors = base_anchors . shape [ 0 ] NEW_LINE feat_height , feat_width = feat_shapes [ feat_id ] [ 0 ] [ - 2 : ] NEW_LINE shift_x = np . arange ( 0 , feat_width ) * feat_strides [ feat_id ] NEW_LINE shift_y = np . arange ( 0 , feat_height ) * feat_strides [ feat_id ] NEW_LINE shift_x , shift_y = np . meshgrid ( shift_x , shift_y ) NEW_LINE shifts = np . vstack ( ( shift_x . ravel ( ) , shift_y . ravel ( ) , shift_x . ravel ( ) , shift_y . ravel ( ) ) ) . transpose ( ) NEW_LINE A = num_anchors NEW_LINE K = shifts . shape [ 0 ] NEW_LINE all_anchors = base_anchors . reshape ( ( 1 , A , 4 ) ) + shifts . reshape ( ( 1 , K , 4 ) ) . transpose ( ( 1 , 0 , 2 ) ) NEW_LINE all_anchors = all_anchors . reshape ( ( K * A , 4 ) ) NEW_LINE total_anchors = int ( K * A ) NEW_LINE inds_inside = np . where ( ( all_anchors [ : , 0 ] >= - allowed_border ) & ( all_anchors [ : , 1 ] >= - allowed_border ) & ( all_anchors [ : , 2 ] < im_info [ 1 ] + allowed_border ) & ( all_anchors [ : , 3 ] < im_info [ 0 ] + allowed_border ) ) [ 0 ] NEW_LINE anchors = all_anchors [ inds_inside , : ] NEW_LINE labels = np . empty ( ( len ( inds_inside ) , ) , dtype = np . float32 ) NEW_LINE labels . fill ( - 1 ) NEW_LINE fpn_anchors_fid = np . hstack ( ( fpn_anchors_fid , len ( inds_inside ) ) ) NEW_LINE fpn_anchors = np . vstack ( ( fpn_anchors , anchors ) ) NEW_LINE fpn_labels = np . hstack ( ( fpn_labels , labels ) ) NEW_LINE fpn_inds_inside . append ( inds_inside ) NEW_LINE fpn_args . append ( [ feat_height , feat_width , A , total_anchors ] ) NEW_LINE DEDENT if gt_boxes . size > 0 : NEW_LINE INDENT overlaps = bbox_overlaps ( fpn_anchors . astype ( np . float ) , gt_boxes . astype ( np . float ) ) NEW_LINE argmax_overlaps = overlaps . argmax ( axis = 1 ) NEW_LINE max_overlaps = overlaps [ np . arange ( len ( fpn_anchors ) ) , argmax_overlaps ] NEW_LINE gt_argmax_overlaps = overlaps . argmax ( axis = 0 ) NEW_LINE gt_max_overlaps = overlaps [ gt_argmax_overlaps , np . arange ( overlaps . shape [ 1 ] ) ] NEW_LINE gt_argmax_overlaps = np . where ( overlaps == gt_max_overlaps ) [ 0 ] NEW_LINE if not cfg . TRAIN . RPN_CLOBBER_POSITIVES : NEW_LINE INDENT fpn_labels [ max_overlaps < cfg . TRAIN . RPN_NEGATIVE_OVERLAP ] = 0 NEW_LINE DEDENT fpn_labels [ gt_argmax_overlaps ] = 1 NEW_LINE fpn_labels [ max_overlaps >= cfg . TRAIN . RPN_POSITIVE_OVERLAP ] = 1 NEW_LINE if cfg . TRAIN . RPN_CLOBBER_POSITIVES : NEW_LINE INDENT fpn_labels [ max_overlaps < cfg . TRAIN . RPN_NEGATIVE_OVERLAP ] = 0 NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT fpn_labels [ : ] = 0 NEW_LINE DEDENT num_fg = fpn_labels . shape [ 0 ] if cfg . TRAIN . RPN_BATCH_SIZE == - 1 else int ( cfg . TRAIN . RPN_FG_FRACTION * cfg . TRAIN . RPN_BATCH_SIZE ) NEW_LINE fg_inds = np . where ( fpn_labels >= 1 ) [ 0 ] NEW_LINE if len ( fg_inds ) > num_fg : NEW_LINE INDENT disable_inds = npr . choice ( fg_inds , size = ( len ( fg_inds ) - num_fg ) , replace = False ) NEW_LINE if DEBUG : NEW_LINE INDENT disable_inds = fg_inds [ : ( len ( fg_inds ) - num_fg ) ] NEW_LINE DEDENT fpn_labels [ disable_inds ] = - 1 NEW_LINE DEDENT num_bg = fpn_labels . shape [ 0 ] if cfg . TRAIN . RPN_BATCH_SIZE == - 1 else cfg . TRAIN . RPN_BATCH_SIZE - np . sum ( fpn_labels >= 1 ) NEW_LINE bg_inds = np . where ( fpn_labels == 0 ) [ 0 ] NEW_LINE fpn_anchors_fid = np . hstack ( ( 0 , fpn_anchors_fid . cumsum ( ) ) ) NEW_LINE if balance_scale_bg : NEW_LINE INDENT num_bg_scale = num_bg / len ( feat_strides ) NEW_LINE for feat_id in range ( 0 , len ( feat_strides ) ) : NEW_LINE INDENT bg_ind_scale = bg_inds [ ( bg_inds >= fpn_anchors_fid [ feat_id ] ) & ( bg_inds < fpn_anchors_fid [ feat_id + 1 ] ) ] NEW_LINE if len ( bg_ind_scale ) > num_bg_scale : NEW_LINE INDENT disable_inds = npr . choice ( bg_ind_scale , size = ( len ( bg_ind_scale ) - num_bg_scale ) , replace = False ) NEW_LINE fpn_labels [ disable_inds ] = - 1 NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT if len ( bg_inds ) > num_bg : NEW_LINE INDENT disable_inds = npr . choice ( bg_inds , size = ( len ( bg_inds ) - num_bg ) , replace = False ) NEW_LINE if DEBUG : NEW_LINE INDENT disable_inds = bg_inds [ : ( len ( bg_inds ) - num_bg ) ] NEW_LINE DEDENT fpn_labels [ disable_inds ] = - 1 NEW_LINE DEDENT DEDENT fpn_bbox_targets = np . zeros ( ( len ( fpn_anchors ) , 4 ) , dtype = np . float32 ) NEW_LINE if gt_boxes . size > 0 : NEW_LINE INDENT fpn_bbox_targets [ fpn_labels >= 1 , : ] = bbox_transform ( fpn_anchors [ fpn_labels >= 1 , : ] , gt_boxes [ argmax_overlaps [ fpn_labels >= 1 ] , : 4 ] ) NEW_LINE DEDENT fpn_bbox_weights = np . zeros ( ( len ( fpn_anchors ) , 4 ) , dtype = np . float32 ) NEW_LINE fpn_bbox_weights [ fpn_labels >= 1 , : ] = np . array ( cfg . TRAIN . RPN_BBOX_WEIGHTS ) NEW_LINE label_list = [ ] NEW_LINE bbox_target_list = [ ] NEW_LINE bbox_weight_list = [ ] NEW_LINE for feat_id in range ( 0 , len ( feat_strides ) ) : NEW_LINE INDENT feat_height , feat_width , A , total_anchors = fpn_args [ feat_id ] NEW_LINE labels = _unmap ( fpn_labels [ fpn_anchors_fid [ feat_id ] : fpn_anchors_fid [ feat_id + 1 ] ] , total_anchors , fpn_inds_inside [ feat_id ] , fill = - 1 ) NEW_LINE bbox_targets = _unmap ( fpn_bbox_targets [ fpn_anchors_fid [ feat_id ] : fpn_anchors_fid [ feat_id + 1 ] ] , total_anchors , fpn_inds_inside [ feat_id ] , fill = 0 ) NEW_LINE bbox_weights = _unmap ( fpn_bbox_weights [ fpn_anchors_fid [ feat_id ] : fpn_anchors_fid [ feat_id + 1 ] ] , total_anchors , fpn_inds_inside [ feat_id ] , fill = 0 ) NEW_LINE labels = labels . reshape ( ( 1 , feat_height , feat_width , A ) ) . transpose ( 0 , 3 , 1 , 2 ) NEW_LINE labels = labels . reshape ( ( 1 , A * feat_height * feat_width ) ) NEW_LINE bbox_targets = bbox_targets . reshape ( ( 1 , feat_height , feat_width , A * 4 ) ) . transpose ( 0 , 3 , 1 , 2 ) NEW_LINE bbox_targets = bbox_targets . reshape ( ( 1 , A * 4 , - 1 ) ) NEW_LINE bbox_weights = bbox_weights . reshape ( ( 1 , feat_height , feat_width , A * 4 ) ) . transpose ( ( 0 , 3 , 1 , 2 ) ) NEW_LINE bbox_weights = bbox_weights . reshape ( ( 1 , A * 4 , - 1 ) ) NEW_LINE label_list . append ( labels ) NEW_LINE bbox_target_list . append ( bbox_targets ) NEW_LINE bbox_weight_list . append ( bbox_weights ) NEW_LINE DEDENT label = { ' label ' : np . concatenate ( label_list , axis = 1 ) , ' bbox _ target ' : np . concatenate ( bbox_target_list , axis = 2 ) , ' bbox _ weight ' : np . concatenate ( bbox_weight_list , axis = 2 ) } NEW_LINE return label NEW_LINE DEDENT\",), (\"def assign_pyramid_anchor_poly ( feat_shapes , gt_boxes , im_info , cfg , feat_strides = ( 4 , 8 , 16 , 32 , 64 ) , scales = ( 8 , ) , ratios = ( 0.5 , 1 , 2 ) , allowed_border = 0 , balance_scale_bg = False , ) : NEW_LINE INDENT def _unmap ( data , count , inds , fill = 0 ) : NEW_LINE INDENT if len ( data . shape ) == 1 : NEW_LINE INDENT ret = np . empty ( ( count , ) , dtype = np . float32 ) NEW_LINE ret . fill ( fill ) NEW_LINE ret [ inds ] = data NEW_LINE DEDENT else : NEW_LINE INDENT ret = np . empty ( ( count , ) + data . shape [ 1 : ] , dtype = np . float32 ) NEW_LINE ret . fill ( fill ) NEW_LINE ret [ inds , : ] = data NEW_LINE DEDENT return ret NEW_LINE DEDENT DEBUG = False NEW_LINE im_info = im_info [ 0 ] NEW_LINE scales = np . array ( scales , dtype = np . float32 ) NEW_LINE ratios = np . array ( ratios , dtype = np . float32 ) NEW_LINE assert ( len ( feat_shapes ) == len ( feat_strides ) ) NEW_LINE fpn_args = [ ] NEW_LINE fpn_anchors_fid = np . zeros ( 0 ) . astype ( int ) NEW_LINE fpn_anchors = np . zeros ( [ 0 , 4 ] ) NEW_LINE fpn_labels = np . zeros ( 0 ) NEW_LINE fpn_inds_inside = [ ] NEW_LINE for feat_id in range ( len ( feat_strides ) ) : NEW_LINE INDENT if len ( scales . shape ) == 1 : NEW_LINE INDENT base_anchors = generate_anchors ( base_size = feat_strides [ feat_id ] , ratios = ratios , scales = scales ) NEW_LINE DEDENT else : NEW_LINE INDENT assert len ( scales . shape ) == len ( ratios . shape ) == 2 NEW_LINE base_anchors = generate_anchors ( base_size = feat_strides [ feat_id ] , ratios = ratios [ feat_id ] , scales = scales [ feat_id ] ) NEW_LINE DEDENT num_anchors = base_anchors . shape [ 0 ] NEW_LINE feat_height , feat_width = feat_shapes [ feat_id ] [ 0 ] [ - 2 : ] NEW_LINE shift_x = np . arange ( 0 , feat_width ) * feat_strides [ feat_id ] NEW_LINE shift_y = np . arange ( 0 , feat_height ) * feat_strides [ feat_id ] NEW_LINE shift_x , shift_y = np . meshgrid ( shift_x , shift_y ) NEW_LINE shifts = np . vstack ( ( shift_x . ravel ( ) , shift_y . ravel ( ) , shift_x . ravel ( ) , shift_y . ravel ( ) ) ) . transpose ( ) NEW_LINE A = num_anchors NEW_LINE K = shifts . shape [ 0 ] NEW_LINE all_anchors = base_anchors . reshape ( ( 1 , A , 4 ) ) + shifts . reshape ( ( 1 , K , 4 ) ) . transpose ( ( 1 , 0 , 2 ) ) NEW_LINE all_anchors = all_anchors . reshape ( ( K * A , 4 ) ) NEW_LINE total_anchors = int ( K * A ) NEW_LINE inds_inside = np . where ( ( all_anchors [ : , 0 ] >= - allowed_border ) & ( all_anchors [ : , 1 ] >= - allowed_border ) & ( all_anchors [ : , 2 ] < im_info [ 1 ] + allowed_border ) & ( all_anchors [ : , 3 ] < im_info [ 0 ] + allowed_border ) ) [ 0 ] NEW_LINE anchors = all_anchors [ inds_inside , : ] NEW_LINE labels = np . empty ( ( len ( inds_inside ) , ) , dtype = np . float32 ) NEW_LINE labels . fill ( - 1 ) NEW_LINE fpn_anchors_fid = np . hstack ( ( fpn_anchors_fid , len ( inds_inside ) ) ) NEW_LINE fpn_anchors = np . vstack ( ( fpn_anchors , anchors ) ) NEW_LINE fpn_labels = np . hstack ( ( fpn_labels , labels ) ) NEW_LINE fpn_inds_inside . append ( inds_inside ) NEW_LINE fpn_args . append ( [ feat_height , feat_width , A , total_anchors ] ) NEW_LINE DEDENT gt_boxes = bbox_poly2hbb ( gt_boxes ) NEW_LINE if gt_boxes . size > 0 : NEW_LINE INDENT overlaps = bbox_overlaps ( fpn_anchors . astype ( np . float ) , gt_boxes . astype ( np . float ) ) NEW_LINE argmax_overlaps = overlaps . argmax ( axis = 1 ) NEW_LINE max_overlaps = overlaps [ np . arange ( len ( fpn_anchors ) ) , argmax_overlaps ] NEW_LINE gt_argmax_overlaps = overlaps . argmax ( axis = 0 ) NEW_LINE gt_max_overlaps = overlaps [ gt_argmax_overlaps , np . arange ( overlaps . shape [ 1 ] ) ] NEW_LINE gt_argmax_overlaps = np . where ( overlaps == gt_max_overlaps ) [ 0 ] NEW_LINE if not cfg . TRAIN . RPN_CLOBBER_POSITIVES : NEW_LINE INDENT fpn_labels [ max_overlaps < cfg . TRAIN . RPN_NEGATIVE_OVERLAP ] = 0 NEW_LINE DEDENT fpn_labels [ gt_argmax_overlaps ] = 1 NEW_LINE fpn_labels [ max_overlaps >= cfg . TRAIN . RPN_POSITIVE_OVERLAP ] = 1 NEW_LINE if cfg . TRAIN . RPN_CLOBBER_POSITIVES : NEW_LINE INDENT fpn_labels [ max_overlaps < cfg . TRAIN . RPN_NEGATIVE_OVERLAP ] = 0 NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT fpn_labels [ : ] = 0 NEW_LINE DEDENT num_fg = fpn_labels . shape [ 0 ] if cfg . TRAIN . RPN_BATCH_SIZE == - 1 else int ( cfg . TRAIN . RPN_FG_FRACTION * cfg . TRAIN . RPN_BATCH_SIZE ) NEW_LINE fg_inds = np . where ( fpn_labels >= 1 ) [ 0 ] NEW_LINE if len ( fg_inds ) > num_fg : NEW_LINE INDENT disable_inds = npr . choice ( fg_inds , size = ( len ( fg_inds ) - num_fg ) , replace = False ) NEW_LINE if DEBUG : NEW_LINE INDENT disable_inds = fg_inds [ : ( len ( fg_inds ) - num_fg ) ] NEW_LINE DEDENT fpn_labels [ disable_inds ] = - 1 NEW_LINE DEDENT num_bg = fpn_labels . shape [ 0 ] if cfg . TRAIN . RPN_BATCH_SIZE == - 1 else cfg . TRAIN . RPN_BATCH_SIZE - np . sum ( fpn_labels >= 1 ) NEW_LINE bg_inds = np . where ( fpn_labels == 0 ) [ 0 ] NEW_LINE fpn_anchors_fid = np . hstack ( ( 0 , fpn_anchors_fid . cumsum ( ) ) ) NEW_LINE if balance_scale_bg : NEW_LINE INDENT num_bg_scale = num_bg / len ( feat_strides ) NEW_LINE for feat_id in range ( 0 , len ( feat_strides ) ) : NEW_LINE INDENT bg_ind_scale = bg_inds [ ( bg_inds >= fpn_anchors_fid [ feat_id ] ) & ( bg_inds < fpn_anchors_fid [ feat_id + 1 ] ) ] NEW_LINE if len ( bg_ind_scale ) > num_bg_scale : NEW_LINE INDENT disable_inds = npr . choice ( bg_ind_scale , size = ( len ( bg_ind_scale ) - num_bg_scale ) , replace = False ) NEW_LINE fpn_labels [ disable_inds ] = - 1 NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT if len ( bg_inds ) > num_bg : NEW_LINE INDENT disable_inds = npr . choice ( bg_inds , size = ( len ( bg_inds ) - num_bg ) , replace = False ) NEW_LINE if DEBUG : NEW_LINE INDENT disable_inds = bg_inds [ : ( len ( bg_inds ) - num_bg ) ] NEW_LINE DEDENT fpn_labels [ disable_inds ] = - 1 NEW_LINE DEDENT DEDENT fpn_bbox_targets = np . zeros ( ( len ( fpn_anchors ) , 4 ) , dtype = np . float32 ) NEW_LINE if gt_boxes . size > 0 : NEW_LINE INDENT fpn_bbox_targets [ fpn_labels >= 1 , : ] = bbox_transform ( fpn_anchors [ fpn_labels >= 1 , : ] , gt_boxes [ argmax_overlaps [ fpn_labels >= 1 ] , : 4 ] ) NEW_LINE DEDENT fpn_bbox_weights = np . zeros ( ( len ( fpn_anchors ) , 4 ) , dtype = np . float32 ) NEW_LINE fpn_bbox_weights [ fpn_labels >= 1 , : ] = np . array ( cfg . TRAIN . RPN_BBOX_WEIGHTS ) NEW_LINE label_list = [ ] NEW_LINE bbox_target_list = [ ] NEW_LINE bbox_weight_list = [ ] NEW_LINE for feat_id in range ( 0 , len ( feat_strides ) ) : NEW_LINE INDENT feat_height , feat_width , A , total_anchors = fpn_args [ feat_id ] NEW_LINE labels = _unmap ( fpn_labels [ fpn_anchors_fid [ feat_id ] : fpn_anchors_fid [ feat_id + 1 ] ] , total_anchors , fpn_inds_inside [ feat_id ] , fill = - 1 ) NEW_LINE bbox_targets = _unmap ( fpn_bbox_targets [ fpn_anchors_fid [ feat_id ] : fpn_anchors_fid [ feat_id + 1 ] ] , total_anchors , fpn_inds_inside [ feat_id ] , fill = 0 ) NEW_LINE bbox_weights = _unmap ( fpn_bbox_weights [ fpn_anchors_fid [ feat_id ] : fpn_anchors_fid [ feat_id + 1 ] ] , total_anchors , fpn_inds_inside [ feat_id ] , fill = 0 ) NEW_LINE labels = labels . reshape ( ( 1 , feat_height , feat_width , A ) ) . transpose ( 0 , 3 , 1 , 2 ) NEW_LINE labels = labels . reshape ( ( 1 , A * feat_height * feat_width ) ) NEW_LINE bbox_targets = bbox_targets . reshape ( ( 1 , feat_height , feat_width , A * 4 ) ) . transpose ( 0 , 3 , 1 , 2 ) NEW_LINE bbox_targets = bbox_targets . reshape ( ( 1 , A * 4 , - 1 ) ) NEW_LINE bbox_weights = bbox_weights . reshape ( ( 1 , feat_height , feat_width , A * 4 ) ) . transpose ( ( 0 , 3 , 1 , 2 ) ) NEW_LINE bbox_weights = bbox_weights . reshape ( ( 1 , A * 4 , - 1 ) ) NEW_LINE label_list . append ( labels ) NEW_LINE bbox_target_list . append ( bbox_targets ) NEW_LINE bbox_weight_list . append ( bbox_weights ) NEW_LINE DEDENT label = { ' label ' : np . concatenate ( label_list , axis = 1 ) , ' bbox _ target ' : np . concatenate ( bbox_target_list , axis = 2 ) , ' bbox _ weight ' : np . concatenate ( bbox_weight_list , axis = 2 ) } NEW_LINE return label NEW_LINE DEDENT\",), ('def _whctrs ( anchor ) : NEW_LINE INDENT w = anchor [ 2 ] - anchor [ 0 ] + 1 NEW_LINE h = anchor [ 3 ] - anchor [ 1 ] + 1 NEW_LINE x_ctr = anchor [ 0 ] + 0.5 * ( w - 1 ) NEW_LINE y_ctr = anchor [ 1 ] + 0.5 * ( h - 1 ) NEW_LINE return w , h , x_ctr , y_ctr NEW_LINE DEDENT',), ('def _mkanchors ( ws , hs , x_ctr , y_ctr ) : NEW_LINE INDENT ws = ws [ : , np . newaxis ] NEW_LINE hs = hs [ : , np . newaxis ] NEW_LINE anchors = np . hstack ( ( x_ctr - 0.5 * ( ws - 1 ) , y_ctr - 0.5 * ( hs - 1 ) , x_ctr + 0.5 * ( ws - 1 ) , y_ctr + 0.5 * ( hs - 1 ) ) ) NEW_LINE return anchors NEW_LINE DEDENT',), ('def _ratio_enum ( anchor , ratios ) : NEW_LINE INDENT w , h , x_ctr , y_ctr = _whctrs ( anchor ) NEW_LINE size = w * h NEW_LINE size_ratios = size / ratios NEW_LINE ws = np . round ( np . sqrt ( size_ratios ) ) NEW_LINE hs = np . round ( ws * ratios ) NEW_LINE anchors = _mkanchors ( ws , hs , x_ctr , y_ctr ) NEW_LINE return anchors NEW_LINE DEDENT',), ('def _scale_enum ( anchor , scales ) : NEW_LINE INDENT w , h , x_ctr , y_ctr = _whctrs ( anchor ) NEW_LINE ws = w * scales NEW_LINE hs = h * scales NEW_LINE anchors = _mkanchors ( ws , hs , x_ctr , y_ctr ) NEW_LINE return anchors NEW_LINE DEDENT',), ('def setUpClass ( cls ) : NEW_LINE INDENT cfg . CLASS_AGNOSTIC = False NEW_LINE cfg . TRAIN . BBOX_WEIGHTS = np . array ( [ 1.0 , 1.0 , 1.0 , 1.0 ] ) NEW_LINE DEDENT',), ('def test_expand_bbox_regression_targets ( self ) : NEW_LINE INDENT pass NEW_LINE DEDENT',), ('def test_expand_bbox_regression_targets_base_4 ( self ) : NEW_LINE INDENT num_classes = 3 NEW_LINE bbox_targets_data = np . array ( [ [ 0 , 3 , 4 , 10 , 20 ] , [ 2 , 7 , 11 , 23 , 2 ] ] ) NEW_LINE expected_targets = np . array ( [ [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ] , [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 7 , 11 , 23 , 2 ] ] ) NEW_LINE expected_weights = np . array ( [ [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ] , [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 1 , 1 , 1 ] ] ) NEW_LINE calc_targets , calc_weights = expand_bbox_regression_targets ( bbox_targets_data , num_classes , cfg ) NEW_LINE calc_targets2 , calc_weights2 = expand_bbox_regression_targets_base ( bbox_targets_data , num_classes , cfg ) NEW_LINE np . testing . assert_array_almost_equal ( calc_targets , expected_targets ) NEW_LINE np . testing . assert_array_almost_equal ( calc_weights , expected_weights ) NEW_LINE np . testing . assert_array_almost_equal ( calc_targets2 , expected_targets ) NEW_LINE np . testing . assert_array_almost_equal ( calc_weights2 , expected_weights ) NEW_LINE DEDENT',), ('def test_expand_bbox_regression_targets_base_8 ( self ) : NEW_LINE INDENT num_classes = 3 NEW_LINE bbox_targets_data = np . array ( [ [ 1 , 3 , 4 , 2 , 2 , 2 , 1 , 9 , 1 ] , [ 0 , 2 , 2 , 3 , 1 , 3 , 6 , 3 , 1 ] ] ) NEW_LINE expected_targets = np . array ( [ [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 4 , 2 , 2 , 2 , 1 , 9 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ] , [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ] ] ) NEW_LINE expected_weights = np . array ( [ [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 1 , 1 , 1 , 1 , 1 , 1 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ] , [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ] ] ) NEW_LINE calc_targets , calc_weights = expand_bbox_regression_targets_base ( bbox_targets_data , num_classes , cfg ) NEW_LINE np . testing . assert_array_almost_equal ( calc_targets , expected_targets ) NEW_LINE np . testing . assert_array_almost_equal ( calc_weights , expected_weights ) NEW_LINE DEDENT',), (\"def customize_compiler_for_nvcc ( self ) : NEW_LINE INDENT self . src_extensions . append ( ' . cu ' ) NEW_LINE default_compiler_so = self . compiler_so NEW_LINE super = self . _compile NEW_LINE def _compile ( obj , src , ext , cc_args , extra_postargs , pp_opts ) : NEW_LINE INDENT if os . path . splitext ( src ) [ 1 ] == ' . cu ' : NEW_LINE INDENT self . set_executable ( ' compiler _ so ' , CUDA [ ' nvcc ' ] ) NEW_LINE postargs = extra_postargs [ ' nvcc ' ] NEW_LINE DEDENT else : NEW_LINE INDENT postargs = extra_postargs [ ' gcc ' ] NEW_LINE DEDENT super ( obj , src , ext , cc_args , postargs , pp_opts ) NEW_LINE self . compiler_so = default_compiler_so NEW_LINE DEDENT self . _compile = _compile NEW_LINE DEDENT\",), ('def build_extensions ( self ) : NEW_LINE INDENT customize_compiler_for_nvcc ( self . compiler ) NEW_LINE build_ext . build_extensions ( self ) NEW_LINE DEDENT',), ('def test_bbox_poly2hbb ( self ) : NEW_LINE INDENT polys = np . array ( [ [ 1 , 3 , 21 , 3 , 21 , 83 , 1 , 83 , 1 ] , [ 50 , 100 , 65 , 100 , 65 , 145 , 50 , 145 , 3 ] ] ) NEW_LINE expected = np . array ( [ [ 1 , 3 , 21 , 83 , 1 ] , [ 50 , 100 , 65 , 145 , 3 ] ] ) NEW_LINE polys = mx . nd . array ( polys ) NEW_LINE expected = mx . nd . array ( expected ) NEW_LINE output = bbox_poly2hbb_nd ( polys ) NEW_LINE np . testing . assert_array_almost_equal ( output . asnumpy ( ) , expected . asnumpy ( ) ) NEW_LINE DEDENT',), (\"def test_dbbox_transform2_nd ( self ) : NEW_LINE INDENT boxlist1 = np . array ( [ [ 1 , 1 , 10 , 5 , 0 ] , [ 1 , 1 , 10 , 5 , np . pi / 10 ] , [ 1 , 1 , 10 , 5 , 0 ] , [ 30 , 100 , 60 , 34 , np . pi / 2 ] ] ) NEW_LINE boxlist2 = np . array ( [ [ 1 , 1 , 5 , 8 , np . pi / 16 ] , [ 1 , 1 , 5 , 8 , np . pi / 16 + np . pi / 10 ] , [ 1 , 1 , 10 , 5 , 0 ] , [ 30 , 90 , 12 , 45 , np . pi / 10 ] ] ) NEW_LINE expected_targets = np . array ( [ [ 0.0000 , 0.0000 , - 0.6931 , 0.4700 , 0.0312 ] , [ 0.0000 , 0.0000 , - 0.6931 , 0.4700 , 0.0313 ] , [ 0.0000 , 0.0000 , 0.0000 , 0.0000 , 0.0000 ] , [ - 0.1667 , 0.0000 , - 1.6094 , 0.2803 , 0.8 ] ] ) NEW_LINE output = dbbox_transform2 ( boxlist1 , boxlist2 ) NEW_LINE np . testing . assert_almost_equal ( expected_targets , output , decimal = 4 ) NEW_LINE expected_targets_nd = dbbox_transform2_nd ( mx . nd . array ( boxlist1 , dtype = ' float32' ) , mx . nd . array ( boxlist2 , dtype = ' float32' ) ) NEW_LINE np . testing . assert_almost_equal ( expected_targets , expected_targets_nd . asnumpy ( ) , decimal = 4 ) NEW_LINE DEDENT\",), ('def test_dbbox_transform2_warp ( self ) : NEW_LINE INDENT boxlist1 = np . array ( [ [ - 1 , - 2.5 , 3 , 4.5 ] , [ 24.5 , 68.0 , 35.5 , 112.0 ] , [ - 9.8 , 0.5 , 13.8 , 7.5 ] ] ) NEW_LINE boxlist2 = np . array ( [ [ 1 , 1 , 5 , 8 , np . pi / 16 ] , [ 30 , 90 , 12 , 45 , np . pi / 10 ] , [ 5 , 4 , 26 , 8.2 , np . pi / 2 + np . pi / 10. ] ] ) NEW_LINE polys2 = RotBox2Polys ( boxlist2 ) NEW_LINE targets = dbbox_transform2_warp ( boxlist1 , polys2 ) NEW_LINE expected_targets = np . array ( [ [ 0 , 0 , 0 , 0 , 0.78125 ] , [ 0 , 0 , 0 , 0 , 0.8 ] , [ 0. , - 3 / 8. , np . log ( 26 / 24.6 ) , np . log ( 8.2 / 8. ) , np . pi / 10. / ( 2 * np . pi ) ] ] ) NEW_LINE np . testing . assert_almost_equal ( expected_targets , targets , decimal = 4 ) NEW_LINE targets_nd = dbbox_transform2_warp_nd ( mx . nd . array ( boxlist1 ) , mx . nd . array ( polys2 ) ) NEW_LINE np . testing . assert_almost_equal ( expected_targets , targets_nd . asnumpy ( ) , decimal = 4 ) NEW_LINE DEDENT',), ('def test_bbox_overlaps ( self ) : NEW_LINE INDENT pass NEW_LINE DEDENT',), ('def test_bbox_poly2hbb ( self ) : NEW_LINE INDENT polys = np . array ( [ [ 1 , 3 , 21 , 3 , 21 , 83 , 1 , 83 , 1 ] , [ 50 , 100 , 65 , 100 , 65 , 145 , 50 , 145 , 3 ] ] ) NEW_LINE expected = np . array ( [ [ 1 , 3 , 21 , 83 , 1 ] , [ 50 , 100 , 65 , 145 , 3 ] ] ) NEW_LINE output = bbox_poly2hbb ( polys ) NEW_LINE np . testing . assert_array_almost_equal ( output , expected ) NEW_LINE DEDENT',), ('def test_poly2bbox ( self ) : NEW_LINE INDENT polys = np . array ( [ [ 1 , 3 , 21 , 3 , 21 , 83 , 1 , 83 ] , [ 50 , 100 , 65 , 100 , 65 , 145 , 50 , 145 ] ] ) NEW_LINE expected = np . array ( [ [ 1 , 3 , 21 , 83 ] , [ 50 , 100 , 65 , 145 ] ] ) NEW_LINE output = poly2bbox ( polys ) NEW_LINE np . testing . assert_array_almost_equal ( output , expected ) NEW_LINE DEDENT',), ('def test_poly2bbox_nd ( self ) : NEW_LINE INDENT polys = np . array ( [ [ 1 , 3 , 21 , 3 , 21 , 83 , 1 , 83 ] , [ 50 , 100 , 65 , 100 , 65 , 145 , 50 , 145 ] ] ) NEW_LINE expected = np . array ( [ [ 1 , 3 , 21 , 83 ] , [ 50 , 100 , 65 , 145 ] ] ) NEW_LINE polys_nd = mx . nd . array ( polys ) NEW_LINE output = poly2bbox_nd ( polys_nd ) NEW_LINE np . testing . assert_array_almost_equal ( output . asnumpy ( ) , expected ) NEW_LINE DEDENT',), ('def test_box2poly ( self ) : NEW_LINE INDENT ext_rois = np . array ( [ [ 11 , 43 , 20 , 80 ] , [ 115 / 2.0 , 245 / 2.0 , 15 , 45 ] ] ) NEW_LINE expected = np . array ( [ [ 1 , 3 , 21 , 3 , 21 , 83 , 1 , 83 ] , [ 50 , 100 , 65 , 100 , 65 , 145 , 50 , 145 ] ] ) NEW_LINE calculated = box2poly ( ext_rois ) NEW_LINE np . testing . assert_array_almost_equal ( calculated , expected ) NEW_LINE DEDENT',), ('def test_dbbox_transform ( self ) : NEW_LINE INDENT ext_rois = np . array ( [ [ 1 , 3 , 21 , 83 ] , [ 50 , 100 , 65 , 145 ] , ] ) NEW_LINE gt_boxes = np . array ( [ [ 1 , 3 , 22 , 4 , 21 , 84 , 0 , 83 ] , [ 50 , 100 , 60 , 90 , 65 , 145 , 54 , 120 ] , ] ) NEW_LINE targets = dbbox_transform ( ext_rois , gt_boxes ) NEW_LINE expected = np . array ( [ [ 0 , 0 , 1 / 21.0 , 1 / 81.0 , 0 , 1 / 81.0 , - 1 / 21.0 , 0 ] , [ 0 , 0 , - 5 / 16.0 , - 10 / 46.0 , 0 , 0 , 4 / 16.0 , - 25 / 46.0 ] , ] , dtype = np . float ) NEW_LINE np . testing . assert_array_almost_equal ( targets , expected ) NEW_LINE DEDENT',), ('def test_box_pred_multiclass ( self ) : NEW_LINE INDENT ext_rois = np . array ( [ [ 1 , 3 , 21 , 83 ] , [ 50 , 100 , 65 , 145 ] ] ) NEW_LINE expect_results = np . array ( [ [ 1 , 3 , 21 , 83 , 4 , 5 , 39 , 30 , 1 , 3 , 21 , 83 ] , [ 50 , 100 , 65 , 145 , 50 , 100 , 65 , 145 , 40 , 105 , 50 , 120 ] ] ) NEW_LINE targets = np . array ( [ [ 0. , 0. , 0. , 0. , 0.5 , - 0.31481481 , 0.5389965 , - 1.13635262 , 0. , 0. , 0. , 0. ] , [ 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , - 0.78125 , - 0.2173913 , - 0.37469345 , - 1.05605267 ] ] ) NEW_LINE outputs = bbox_pred ( ext_rois , targets ) NEW_LINE np . testing . assert_array_almost_equal ( expect_results , outputs ) NEW_LINE DEDENT',), ('def test_dbbox_pred_multiclass ( self ) : NEW_LINE INDENT ext_rois = np . array ( [ [ 1 , 3 , 21 , 83 ] , [ 50 , 100 , 65 , 145 ] ] ) NEW_LINE expect_results = np . array ( [ [ 1. , 3. , 21. , 3. , 21. , 83. , 1. , 83. , 1 , 3 , 22 , 4 , 21 , 84 , 0 , 83 , 1. , 3. , 21. , 3. , 21. , 83. , 1. , 83. ] , [ 50. , 100. , 65. , 100. , 65. , 145. , 50. , 145. , 50. , 100. , 65. , 100. , 65. , 145. , 50. , 145. , 50 , 100 , 60 , 90 , 65 , 145 , 54 , 120 ] ] ) NEW_LINE targets = np . array ( [ [ 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.04761905 , 0.01234568 , 0. , 0.01234568 , - 0.04761905 , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ] , [ 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , - 0.3125 , - 0.2173913 , 0. , 0. , 0.25 , - 0.54347826 ] ] ) NEW_LINE outputs = dbbox_pred ( ext_rois , targets ) NEW_LINE np . testing . assert_array_almost_equal ( expect_results , outputs ) NEW_LINE DEDENT',), ('def test_clip_polys ( self ) : NEW_LINE INDENT polys = np . array ( [ [ - 1 , 3 , 4 , 7 , 102 , 150 , 50 , 205 ] , [ 3 , 10 , 30 , 50 , 70 , 90 , 80 , 90 ] , [ 0 , 0 , 0 , 200 , 100 , 200 , 100 , 0 ] ] ) NEW_LINE im_shape = ( 200 , 100 ) NEW_LINE expected_outputs = np . array ( [ [ 0 , 3 , 4 , 7 , 99 , 150 , 50 , 199 ] , [ 3 , 10 , 30 , 50 , 70 , 90 , 80 , 90 ] , [ 0 , 0 , 0 , 199 , 99 , 199 , 99 , 0 ] ] ) NEW_LINE outputs = clip_polys ( polys , im_shape ) NEW_LINE np . testing . assert_array_almost_equal ( outputs , expected_outputs ) NEW_LINE DEDENT',), ('def test_clip ( self ) : NEW_LINE INDENT x1 , y1 , x2 , y2 , x3 , y3 , x4 , y4 = np . array ( [ 1 , 3 , 21 , 3 , 21 , 83 , 1 , 83 ] , ) NEW_LINE w , h = np . array ( [ 100 , 70 ] ) NEW_LINE expected = np . array ( [ 1 , 3 , 21 , 69 ] ) NEW_LINE xmin = min ( max ( min ( x1 , x2 , x3 , x4 ) , 0 ) , w - 1 ) NEW_LINE xmax = min ( max ( max ( x1 , x2 , x3 , x4 ) , 0 ) , w - 1 ) NEW_LINE ymin = min ( max ( min ( y1 , y2 , y3 , y4 ) , 0 ) , h - 1 ) NEW_LINE ymax = min ( max ( max ( y1 , y2 , y3 , y4 ) , 0 ) , h - 1 ) NEW_LINE results = np . array ( [ xmin , ymin , xmax , ymax ] ) NEW_LINE np . testing . assert_array_almost_equal ( expected , results ) NEW_LINE DEDENT',), ('def test_clip2 ( self ) : NEW_LINE INDENT bbox = np . array ( [ - 1 , 3 , 21 , 3 , 21 , 83 , 1 , 83 ] ) NEW_LINE w , h = np . array ( [ 100 , 70 ] ) NEW_LINE expected = np . array ( [ 0 , 3 , 21 , 3 , 21 , 69 , 1 , 69 ] ) NEW_LINE x1 = min ( max ( float ( bbox [ 0 ] ) , 0 ) , w - 1 ) NEW_LINE y1 = min ( max ( float ( bbox [ 1 ] ) , 0 ) , h - 1 ) NEW_LINE x2 = min ( max ( float ( bbox [ 2 ] ) , 0 ) , w - 1 ) NEW_LINE y2 = min ( max ( float ( bbox [ 3 ] ) , 0 ) , h - 1 ) NEW_LINE x3 = min ( max ( float ( bbox [ 4 ] ) , 0 ) , w - 1 ) NEW_LINE y3 = min ( max ( float ( bbox [ 5 ] ) , 0 ) , h - 1 ) NEW_LINE x4 = min ( max ( float ( bbox [ 6 ] ) , 0 ) , w - 1 ) NEW_LINE y4 = min ( max ( float ( bbox [ 7 ] ) , 0 ) , h - 1 ) NEW_LINE results = np . array ( [ x1 , y1 , x2 , y2 , x3 , y3 , x4 , y4 ] ) NEW_LINE np . testing . assert_allclose ( expected , results ) NEW_LINE DEDENT',), ('def test_filter_shape ( self ) : NEW_LINE def test_xy2wh ( self ) : NEW_LINE INDENT boxes = np . array ( [ [ 1 , 3 , 45 , 10 ] , [ 24.4 , 3. , 44.5 , 52.2 ] ] ) NEW_LINE outputs = xy2wh ( boxes ) NEW_LINE expected_outputs = np . array ( [ [ 23 , 6.5 , 45 , 8 ] , [ 34.45 , 27.6 , 21.1 , 50.2 ] ] ) NEW_LINE np . testing . assert_almost_equal ( expected_outputs , outputs ) NEW_LINE DEDENT',), ('def test_wh2xy ( self ) : NEW_LINE INDENT boxes = np . array ( [ [ 1 , 3 , 45 , 10 ] , [ 24.4 , 3. , 44.5 , 52.2 ] ] ) NEW_LINE outputs = xy2wh ( boxes ) NEW_LINE outputs = wh2xy ( outputs ) NEW_LINE np . testing . assert_almost_equal ( boxes , outputs ) NEW_LINE DEDENT',), ('def test_dbbox_transform2_inv ( self ) : NEW_LINE INDENT boxlist1 = np . array ( [ [ 1 , 1 , 10 , 5 , 0 ] , [ 1 , 1 , 10 , 5 , np . pi / 10 ] , [ 1 , 1 , 10 , 5 , 0 ] , [ 30 , 100 , 60 , 34 , np . pi / 2 ] ] ) NEW_LINE boxlist2 = np . array ( [ [ 1 , 1 , 5 , 8 , np . pi / 16 ] , [ 1 , 1 , 5 , 8 , np . pi / 16 + np . pi / 10 ] , [ 1 , 1 , 10 , 5 , 0 ] , [ 30 , 90 , 12 , 45 , np . pi / 10 ] ] ) NEW_LINE expected_targets = dbbox_transform2 ( boxlist1 , boxlist2 ) NEW_LINE expected_boxlist2 = dbbox_transform2_inv ( boxlist1 , expected_targets ) NEW_LINE np . testing . assert_almost_equal ( expected_boxlist2 , boxlist2 ) NEW_LINE DEDENT',), ('def test_rotation_invariant_encoding ( self ) : NEW_LINE INDENT boxlist1 = np . array ( [ [ 1 , 1 , 10 , 5 , 0 ] , [ 1 , 1 , 10 , 5 , np . pi / 10 ] , [ 1 , 1 , 10 , 5 , 0 ] , [ 30 , 90.8 , 60 , 34 , np . pi / 2 ] ] ) NEW_LINE boxlist2 = np . array ( [ [ 1 , 1 , 5 , 8 , np . pi / 16 ] , [ 1 , 1 , 5 , 8 , np . pi / 16 + np . pi / 10 ] , [ 1 , 1 , 10 , 5 , 0 ] , [ 30 , 90.8 , 12 , 45 , np . pi / 10 ] ] ) NEW_LINE boxlist3 = copy . deepcopy ( boxlist1 ) NEW_LINE boxlist3 [ : , 4 ] = boxlist1 [ : , 4 ] + np . pi / 10. NEW_LINE boxlist4 = copy . deepcopy ( boxlist2 ) NEW_LINE boxlist4 [ : , 4 ] = boxlist2 [ : , 4 ] + np . pi / 10. NEW_LINE targets1 = dbbox_transform2 ( boxlist1 , boxlist2 ) NEW_LINE targets2 = dbbox_transform2 ( boxlist3 , boxlist4 ) NEW_LINE np . testing . assert_almost_equal ( targets1 , targets2 , decimal = 4 ) NEW_LINE DEDENT',), ('def test_rotation_invariant_encoding2 ( self ) : NEW_LINE INDENT boxlist1 = np . array ( [ [ 1 , 1 , 10 , 5 , 0 ] , [ 2 , 4 , 7 , 8 , np . pi / 10. ] ] ) NEW_LINE boxlist2 = np . array ( [ [ 3 , 4 , 9.2 , 4.8 , np . pi / 6.0 ] , [ 2.3 , 4.3 , 8 , 9 , np . pi / 9.0 ] ] ) NEW_LINE boxlist3 = copy . deepcopy ( boxlist1 ) NEW_LINE boxlist4 = copy . deepcopy ( boxlist2 ) NEW_LINE angle = np . random . rand ( ) NEW_LINE boxlist3 [ : , 4 ] = boxlist1 [ : , 4 ] + angle NEW_LINE boxlist4 [ : , 4 ] = boxlist4 [ : , 4 ] + angle NEW_LINE boxlist3 [ : , 0 ] = np . cos ( angle ) * boxlist1 [ : , 0 ] - np . sin ( angle ) * boxlist1 [ : , 1 ] NEW_LINE boxlist3 [ : , 1 ] = np . sin ( angle ) * boxlist1 [ : , 0 ] + np . cos ( angle ) * boxlist1 [ : , 1 ] NEW_LINE boxlist4 [ : , 0 ] = np . cos ( angle ) * boxlist2 [ : , 0 ] - np . sin ( angle ) * boxlist2 [ : , 1 ] NEW_LINE boxlist4 [ : , 1 ] = np . sin ( angle ) * boxlist2 [ : , 0 ] + np . cos ( angle ) * boxlist2 [ : , 1 ] NEW_LINE targets1 = dbbox_transform2 ( boxlist1 , boxlist2 ) NEW_LINE targets2 = dbbox_transform2 ( boxlist3 , boxlist4 ) NEW_LINE np . testing . assert_almost_equal ( targets1 , targets2 , decimal = 4 ) NEW_LINE DEDENT',), ('def test_dbbox_transform2_warp ( self ) : NEW_LINE INDENT boxlist1 = np . array ( [ [ - 1 , - 2.5 , 3 , 4.5 ] , [ 24.5 , 68.0 , 35.5 , 112.0 ] , [ - 9.8 , 0.5 , 13.8 , 7.5 ] ] ) NEW_LINE boxlist2 = np . array ( [ [ 1 , 1 , 5 , 8 , np . pi / 16 ] , [ 30 , 90 , 12 , 45 , np . pi / 10 ] , [ 5 , 4 , 26 , 8.2 , np . pi / 2 + np . pi / 10. ] ] ) NEW_LINE polys2 = RotBox2Polys ( boxlist2 ) NEW_LINE targets = dbbox_transform2_warp ( boxlist1 , polys2 ) NEW_LINE expected_targets = np . array ( [ [ 0 , 0 , 0 , 0 , 0.78125 ] , [ 0 , 0 , 0 , 0 , 0.8 ] , [ 0. , - 3 / 8. , np . log ( 26 / 24.6 ) , np . log ( 8.2 / 8. ) , np . pi / 10. / ( 2 * np . pi ) ] ] ) NEW_LINE np . testing . assert_almost_equal ( expected_targets , targets , decimal = 4 ) NEW_LINE DEDENT',), ('def test_dbbox_transform2_inv_warp_multiclass ( self ) : NEW_LINE INDENT ext_rois = np . array ( [ [ - 1 , - 2.5 , 3 , 4.5 ] , [ 24.5 , 68.0 , 35.5 , 112.0 ] , [ - 9.8 , 0.5 , 13.8 , 7.5 ] ] ) NEW_LINE expected_results = np . array ( [ [ 1 , 1 , 5 , 8 , np . pi / 2 , 1 , 1 , 5 , 8 , np . pi / 16 ] , [ 30 , 90 , 12 , 45 , np . pi / 10 , 30 , 90 , 12 , 45 , np . pi / 2 ] , [ 2 , 4 , 24.6 , 8 , np . pi / 2 , 5 , 4 , 26 , 8.2 , np . pi / 2 + np . pi / 10. ] ] ) NEW_LINE targets = np . array ( [ [ 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0.78125 ] , [ 0 , 0 , 0 , 0 , 0.8 , 0 , 0 , 0 , 0 , 0 ] , [ 0 , 0 , 0 , 0 , 0 , 0 , - 3 / 8. , np . log ( 26 / 24.6 ) , np . log ( 8.2 / 8. ) , np . pi / 10. / ( 2 * np . pi ) ] ] ) NEW_LINE outputs = dbbox_transform2_inv_warp ( ext_rois , targets ) NEW_LINE np . testing . assert_almost_equal ( outputs , expected_results , decimal = 4 ) NEW_LINE DEDENT',), ('def test_dbbox_transform2_encode_decode ( self ) : NEW_LINE INDENT boxlist2 = np . array ( [ [ 1 , 1 , 5 , 8 , np . pi / 16 ] , [ 1 , 1 , 5 , 8 , np . pi / 16 + np . pi / 10 ] , [ 1 , 1 , 10 , 5 , 0 ] , [ 30 , 90 , 12 , 45 , np . pi / 10 ] ] ) NEW_LINE polys2 = RotBox2Polys ( boxlist2 ) NEW_LINE ex_rois = poly2bbox ( polys2 ) NEW_LINE targets = dbbox_transform2_warp ( ex_rois , polys2 ) NEW_LINE outputs = dbbox_transform2_inv_warp ( ex_rois , targets ) NEW_LINE np . testing . assert_almost_equal ( outputs , boxlist2 , decimal = 5 ) NEW_LINE DEDENT',), ('def test_RotBox2Polys ( self ) : NEW_LINE INDENT rotboxes = np . array ( [ [ 1 , 1 , 5 , 8 , np . pi / 2 , 1 , 1 , 5 , 8 , np . pi / 16 ] , [ 30 , 90 , 12 , 45 , np . pi / 10 , 30 , 90 , 12 , 45 , np . pi / 2 ] , [ 2 , 4 , 24.6 , 8 , np . pi / 2 , 5 , 4 , 26 , 8.2 , np . pi / 2 + np . pi / 10. ] ] ) NEW_LINE expected_polys = np . concatenate ( ( RotBox2Polys ( rotboxes [ : , 0 : 5 ] ) , RotBox2Polys ( rotboxes [ : , 5 : 10 ] ) ) , axis = 1 ) NEW_LINE polys = RotBox2Polys_multi_class ( rotboxes ) NEW_LINE self . assertTrue ( polys . shape == ( 3 , 16 ) ) NEW_LINE np . testing . assert_almost_equal ( expected_polys , polys ) NEW_LINE DEDENT',), ('def test_polys2xyhs ( self ) : NEW_LINE INDENT pass NEW_LINE DEDENT',), ('def test_xyhs2polys ( self ) : NEW_LINE INDENT xyhs = np . array ( [ [ 2 , 1 , 6 , 3 , 3 ] , [ 1.4 , 8 , 4.2 , 6.3 , 7.4 ] ] ) NEW_LINE polys = xyhs2polys ( xyhs ) NEW_LINE inverse_xyhs = polys2xyhs ( polys ) NEW_LINE inverse_polys = xyhs2polys ( inverse_xyhs ) NEW_LINE np . testing . assert_almost_equal ( xyhs , inverse_xyhs , decimal = 6 ) NEW_LINE np . testing . assert_almost_equal ( polys , inverse_polys , decimal = 6 ) NEW_LINE DEDENT',), ('def test_dbbox_transform3 ( self ) : NEW_LINE INDENT boxlist1 = np . array ( [ [ np . sqrt ( 3 ) , 1 , 2 * np . sqrt ( 3 ) , 2 , 2 ] , [ np . sqrt ( 3 ) , 1 , 1 + np . sqrt ( 3 ) , 1 + np . sqrt ( 3 ) , 2 ] ] ) NEW_LINE boxlist2 = np . array ( [ [ ( 3 * np . sqrt ( 3 ) - 1 ) / 2. , ( 3 + np . sqrt ( 3 ) ) / 2. , ( 4 * np . sqrt ( 3 ) - 1 ) / 2. , ( 4 + np . sqrt ( 3 ) ) / 2. , 1 ] , [ ( np . sqrt ( 3 ) + 1 ) / 2. , ( np . sqrt ( 3 ) + 3 ) / 2. , ( np . sqrt ( 3 ) + 2 ) / 2. , ( 3 + 2 * np . sqrt ( 3 ) ) / 2. , 1 ] ] ) NEW_LINE targets = dbboxtransform3 ( boxlist1 , boxlist2 ) NEW_LINE trans_boxlist1 = np . array ( [ [ 0 , 0 , 2 , 0 , 2 ] ] ) NEW_LINE expected_targets = np . array ( [ [ 0.5 , 0.5 , 0 , 0.5 , np . log ( 1 / 2. ) ] , [ 0.5 , 0.5 , 0 , 0.5 , np . log ( 1 / 2. ) ] ] ) NEW_LINE np . testing . assert_almost_equal ( expected_targets , targets ) NEW_LINE DEDENT',), ('def test_dbbox_transform3_inv_warp ( self ) : NEW_LINE INDENT ext_rois = np . array ( [ [ 2 , 5 , 6 , 10.3 ] ] ) NEW_LINE targets = np . array ( [ [ 1 / 4. , 0.2 / 5.3 , 0 , 0.2 / 5.3 , np . log ( 5.1 / 5.3 ) ] ] ) NEW_LINE outputs = dbboxtransform3_inv_warp ( ext_rois , targets ) NEW_LINE expected_results = np . array ( [ [ 3 , 5.2 , 6 , 5.2 , 5.1 ] ] ) NEW_LINE np . testing . assert_almost_equal ( outputs , expected_results ) NEW_LINE DEDENT',), ('def test_dbbox_transform3_warp_encode_decode ( self ) : NEW_LINE INDENT boxlist1 = np . array ( [ [ - 1 , - 2.5 , 3 , 4.5 ] , [ 24.5 , 68.0 , 35.5 , 112.0 ] , [ - 9.8 , 0.5 , 13.8 , 7.5 ] ] ) NEW_LINE boxlist2 = np . array ( [ [ 1 , 1 , 5 , 8 , np . pi / 16 ] , [ 30 , 90 , 12 , 45 , np . pi / 10 ] , [ 5 , 4 , 26 , 8.2 , np . pi / 2 + np . pi / 10. ] ] ) NEW_LINE polys2 = RotBox2Polys ( boxlist2 ) NEW_LINE gt_xyhs = polys2xyhs ( polys2 ) NEW_LINE targets = dbboxtransform3_warp ( boxlist1 , polys2 ) NEW_LINE targets_inverse = dbboxtransform3_inv_warp ( boxlist1 , targets ) NEW_LINE np . testing . assert_almost_equal ( gt_xyhs , targets_inverse ) NEW_LINE DEDENT',), ('def test_dbbox_transform3_rotation_invariant ( self ) : NEW_LINE INDENT boxlist1 = np . array ( [ [ 1000 , 1000.8 , 8000.767 , 12500 , np . pi / 6. ] , [ 24.5 , 68.0 , 23 , 89.2 , np . pi ] , ] ) NEW_LINE boxlist2 = np . array ( [ [ 1000 , 1000.8 , 5000.767 , 8000 , np . pi / 16 ] , [ 24.5 , 68.0 , 12 , 45.5 , np . pi / 10 ] , ] ) NEW_LINE polys1 = RotBox2Polys ( boxlist1 ) NEW_LINE polys2 = RotBox2Polys ( boxlist2 ) NEW_LINE xyhs1 = polys2xyhs ( polys1 ) NEW_LINE xyhs2 = polys2xyhs ( polys2 ) NEW_LINE randangle = np . random . rand ( ) NEW_LINE boxlist3 = copy . deepcopy ( boxlist1 ) NEW_LINE boxlist3 [ : , 4 ] = boxlist3 [ : , 4 ] + randangle NEW_LINE polys3 = RotBox2Polys ( boxlist3 ) NEW_LINE xyhs3 = polys2xyhs ( polys3 ) NEW_LINE boxlist4 = copy . deepcopy ( boxlist2 ) NEW_LINE boxlist4 [ : , 4 ] = boxlist4 [ : , 4 ] + randangle NEW_LINE polys4 = RotBox2Polys ( boxlist4 ) NEW_LINE xyhs4 = polys2xyhs ( polys4 ) NEW_LINE targets1 = dbboxtransform3 ( xyhs1 , xyhs2 ) NEW_LINE targets2 = dbboxtransform3 ( xyhs3 , xyhs4 ) NEW_LINE np . testing . assert_almost_equal ( targets1 , targets2 , decimal = 6 ) NEW_LINE DEDENT',), ('def test_dbbox_transform3_inv_multi_class ( self ) : NEW_LINE INDENT pass NEW_LINE DEDENT',), ('def test_dbbox_transform3_inv_warp_multi_class ( self ) : NEW_LINE INDENT ext_rois = np . array ( [ [ 2 , 5 , 6 , 10.3 ] , ] ) NEW_LINE targets = np . array ( [ [ 0 , 0 , 0 , 0 , 0 , 1 / 4. , 0.2 / 5.3 , 0 , 0.2 / 5.3 , np . log ( 5.1 / 5.3 ) , 0 , 0 , 0 , 0 , 0 ] ] ) NEW_LINE outputs = dbboxtransform3_inv_warp ( ext_rois , targets ) NEW_LINE expected_results = np . array ( [ [ 2 , 5 , 6 , 5 , 5.3 , 3 , 5.2 , 6 , 5.2 , 5.1 , 2 , 5 , 6 , 5 , 5.3 ] ] ) NEW_LINE np . testing . assert_almost_equal ( outputs , expected_results ) NEW_LINE DEDENT',), ('def test_bbox_transformxyh ( self ) : NEW_LINE INDENT ext_rois = np . array ( [ [ - 1 , - 2.5 , 3 , 4.5 ] , [ 24.5 , 68.0 , 35.5 , 112.0 ] , [ - 9.8 , 0.5 , 13.8 , 7.5 ] ] ) NEW_LINE DEDENT',), ('def test_xyhs2polys_muli_class ( self ) : NEW_LINE INDENT xyhs = np . array ( [ [ 0 , 0 , 2 , 0 , 3 , 3 , 4.3 , 6 , 7 , 8.4 ] , [ 2 , 0 , 2 , 3 , 2 , 4.4 , 5.5 , 7.6 , 8.2 , 9 ] ] ) NEW_LINE polys = xyhs2polys_muli_class ( xyhs ) NEW_LINE expected_polys = np . concatenate ( ( xyhs2polys ( xyhs [ : , 0 : 5 ] ) , xyhs2polys ( xyhs [ : , 5 : 10 ] ) ) , axis = 1 ) NEW_LINE self . assertTrue ( polys . shape == ( 2 , 16 ) ) NEW_LINE np . testing . assert_almost_equal ( polys , expected_polys ) NEW_LINE DEDENT',), ('def test_choose_best_Rroi_batch ( self ) : NEW_LINE INDENT Rrois = np . array ( [ [ 3 , 4 , 2 , 10 , np . pi / 6. ] , [ 3 , 4 , 10 , 2 , np . pi / 6. + np . pi / 2. ] , [ 3 , 4 , 2 , 10 , np . pi / 6. + np . pi ] , [ 3 , 4 , 10 , 2 , np . pi / 6. + np . pi + np . pi / 2. ] ] ) NEW_LINE results = choose_best_Rroi_batch ( Rrois ) NEW_LINE expected_results = np . array ( [ [ 3 , 4 , 10 , 2 , np . pi / 6. + np . pi / 2. ] , [ 3 , 4 , 10 , 2 , np . pi / 6. + np . pi / 2. ] , [ 3 , 4 , 10 , 2 , np . pi / 6. + np . pi / 2. ] , [ 3 , 4 , 10 , 2 , np . pi / 6. + np . pi / 2. ] ] ) NEW_LINE np . testing . assert_almost_equal ( results , expected_results , decimal = 6 ) NEW_LINE DEDENT',), ('def test_choose_best_match_batch ( self ) : NEW_LINE INDENT Rrois = np . array ( [ [ 3 , 4 , 2 , 10 , np . pi / 6. ] , [ 3 , 4 , 10 , 2 , np . pi / 6. + np . pi / 2. ] , [ 3 , 4 , 2 , 10 , np . pi / 6. ] , [ 3 , 4 , 10 , 2 , np . pi / 6. + np . pi / 2. ] ] ) NEW_LINE gt_rois = np . array ( [ [ 3 , 4 , 10 , 2 , np . pi / 6. + np . pi / 2. ] , [ 3 , 4 , 10 , 2 , np . pi / 6. + np . pi / 2. ] , [ 3 , 4 , 2 , 10 , np . pi / 6. + np . pi ] , [ 3 , 4 , 10 , 2 , np . pi / 6. + np . pi * 3 / 2. ] ] ) NEW_LINE results = choose_best_match_batch ( Rrois , gt_rois ) NEW_LINE expected_results = np . array ( [ [ 3 , 4 , 2 , 10 , np . pi / 6. ] , [ 3 , 4 , 10 , 2 , np . pi / 6. + np . pi / 2. ] , [ 3 , 4 , 2 , 10 , np . pi / 6. ] , [ 3 , 4 , 10 , 2 , np . pi / 6. + np . pi / 2. ] ] ) NEW_LINE np . testing . assert_almost_equal ( results , expected_results , decimal = 6 ) NEW_LINE DEDENT',), ('def test_dbbox_transform2_new ( self ) : NEW_LINE INDENT boxlist1 = np . array ( [ [ 1 , 1 , 10 , 5 , 0 ] , [ 1 , 1 , 10 , 5 , 0 ] , [ 1 , 1 , 10 , 5 , np . pi - np . pi / 10. ] , [ 1 , 1 , 10 , 5 , np . pi - np . pi / 10. ] ] ) NEW_LINE boxlist2 = np . array ( [ [ 1 , 1 , 10 , 5 , - np . pi / 10. ] , [ 1 , 1 , 10 , 5 , np . pi / 10 ] , [ 1 , 1 , 10 , 5 , np . pi - np . pi / 10. - np . pi / 20. ] , [ 1 , 1 , 10 , 5 , np . pi - np . pi / 10. - np . pi / 20. + 10 * np . pi ] ] ) NEW_LINE norm = np . pi / 2. NEW_LINE expected_results = np . array ( [ [ 0 , 0 , 0 , 0 , - np . pi / 10. / norm ] , [ 0 , 0 , 0 , 0 , np . pi / 10. / norm ] , [ 0 , 0 , 0 , 0 , - np . pi / 20. / norm ] , [ 0 , 0 , 0 , 0 , - np . pi / 20. / norm ] ] ) NEW_LINE results = dbbox_transform2_new ( boxlist1 , boxlist2 ) NEW_LINE np . testing . assert_almost_equal ( results , expected_results ) NEW_LINE DEDENT',), ('def bbox_overlaps ( boxes , query_boxes ) : NEW_LINE INDENT return bbox_overlaps_cython ( boxes , query_boxes ) NEW_LINE DEDENT',), ('def bbox_poly2hbb ( boxes ) : NEW_LINE INDENT n = boxes . shape [ 0 ] NEW_LINE hbbs = np . zeros ( ( n , 4 ) ) NEW_LINE xs = np . reshape ( boxes [ : , : - 1 ] , ( n , 4 , 2 ) ) [ : , : , 0 ] NEW_LINE ys = np . reshape ( boxes [ : , : - 1 ] , ( n , 4 , 2 ) ) [ : , : , 1 ] NEW_LINE hbbs [ : , 0 ] = np . min ( xs , axis = 1 ) NEW_LINE hbbs [ : , 1 ] = np . min ( ys , axis = 1 ) NEW_LINE hbbs [ : , 2 ] = np . max ( xs , axis = 1 ) NEW_LINE hbbs [ : , 3 ] = np . max ( ys , axis = 1 ) NEW_LINE hbbs = np . hstack ( ( hbbs , boxes [ : , - 1 , np . newaxis ] ) ) NEW_LINE return hbbs NEW_LINE DEDENT',), ('def bbox_poly2hbb_nd ( boxes ) : NEW_LINE INDENT n = boxes . shape [ 0 ] NEW_LINE hbbs = mx . nd . zeros ( ( n , 4 ) ) NEW_LINE xs = boxes [ : , : - 1 ] . reshape ( ( n , 4 , 2 ) ) [ : , : , 0 ] NEW_LINE ys = boxes [ : , : - 1 ] . reshape ( ( n , 4 , 2 ) ) [ : , : , 1 ] NEW_LINE hbbs [ : , 0 ] = mx . nd . min ( xs , axis = 1 ) NEW_LINE hbbs [ : , 1 ] = mx . nd . min ( ys , axis = 1 ) NEW_LINE hbbs [ : , 2 ] = mx . nd . max ( xs , axis = 1 ) NEW_LINE hbbs [ : , 3 ] = mx . nd . max ( ys , axis = 1 ) NEW_LINE hbbs = mx . nd . concat ( hbbs , mx . nd . expand_dims ( boxes [ : , - 1 ] , 1 ) , dim = 1 ) NEW_LINE return hbbs NEW_LINE DEDENT',), ('def box2poly ( boxes ) : NEW_LINE INDENT xs = boxes [ : , 0 ] NEW_LINE ys = boxes [ : , 1 ] NEW_LINE ws = boxes [ : , 2 ] NEW_LINE hs = boxes [ : , 3 ] NEW_LINE n = len ( xs ) NEW_LINE polys = np . zeros ( ( n , 8 ) ) NEW_LINE polys [ : , 0 ] = xs - ws / 2.0 NEW_LINE polys [ : , 1 ] = ys - hs / 2.0 NEW_LINE polys [ : , 2 ] = xs + ws / 2.0 NEW_LINE polys [ : , 3 ] = ys - hs / 2.0 NEW_LINE polys [ : , 4 ] = xs + ws / 2.0 NEW_LINE polys [ : , 5 ] = ys + hs / 2.0 NEW_LINE polys [ : , 6 ] = xs - ws / 2.0 NEW_LINE polys [ : , 7 ] = ys + hs / 2.0 NEW_LINE return polys NEW_LINE DEDENT',), ('def xy2wh ( boxes ) : NEW_LINE INDENT num_boxes = boxes . shape [ 0 ] NEW_LINE ex_widths = boxes [ : , 2 ] - boxes [ : , 0 ] + 1.0 NEW_LINE ex_heights = boxes [ : , 3 ] - boxes [ : , 1 ] + 1.0 NEW_LINE ex_ctr_x = boxes [ : , 0 ] + 0.5 * ( ex_widths - 1.0 ) NEW_LINE ex_ctr_y = boxes [ : , 1 ] + 0.5 * ( ex_heights - 1.0 ) NEW_LINE return np . concatenate ( ( ex_ctr_x [ : , np . newaxis ] , ex_ctr_y [ : , np . newaxis ] , ex_widths [ : , np . newaxis ] , ex_heights [ : , np . newaxis ] ) , axis = 1 ) NEW_LINE DEDENT',), ('def xy2wh_nd ( boxes ) : NEW_LINE INDENT num_boxes = boxes . shape [ 0 ] NEW_LINE ex_widths = boxes [ : , 2 ] - boxes [ : , 0 ] + 1.0 NEW_LINE ex_heights = boxes [ : , 3 ] - boxes [ : , 1 ] + 1.0 NEW_LINE ex_ctr_x = boxes [ : , 0 ] + 0.5 * ( ex_widths - 1.0 ) NEW_LINE ex_ctr_y = boxes [ : , 1 ] + 0.5 * ( ex_heights - 1.0 ) NEW_LINE return mx . nd . concat ( ex_ctr_x . expand_dims ( 1 ) , ex_ctr_y . expand_dims ( 1 ) , ex_widths . expand_dims ( 1 ) , ex_heights . expand_dims ( 1 ) , dim = 1 ) NEW_LINE DEDENT',), ('def wh2xy ( boxes ) : NEW_LINE INDENT num_boxes = boxes . shape [ 0 ] NEW_LINE xmin = boxes [ : , 0 ] - ( boxes [ : , 2 ] - 1 ) / 2.0 NEW_LINE ymin = boxes [ : , 1 ] - ( boxes [ : , 3 ] - 1 ) / 2.0 NEW_LINE xmax = boxes [ : , 0 ] + ( boxes [ : , 2 ] - 1 ) / 2.0 NEW_LINE ymax = boxes [ : , 1 ] + ( boxes [ : , 3 ] - 1 ) / 2.0 NEW_LINE return np . concatenate ( ( xmin [ : , np . newaxis ] , ymin [ : , np . newaxis ] , xmax [ : , np . newaxis ] , ymax [ : , np . newaxis ] ) , axis = 1 ) NEW_LINE DEDENT',), ('def poly2bbox ( polys ) : NEW_LINE INDENT n = polys . shape [ 0 ] NEW_LINE xs = np . reshape ( polys , ( n , 4 , 2 ) ) [ : , : , 0 ] NEW_LINE ys = np . reshape ( polys , ( n , 4 , 2 ) ) [ : , : , 1 ] NEW_LINE xmin = np . min ( xs , axis = 1 ) NEW_LINE ymin = np . min ( ys , axis = 1 ) NEW_LINE xmax = np . max ( xs , axis = 1 ) NEW_LINE ymax = np . max ( ys , axis = 1 ) NEW_LINE xmin = xmin [ : , np . newaxis ] NEW_LINE ymin = ymin [ : , np . newaxis ] NEW_LINE xmax = xmax [ : , np . newaxis ] NEW_LINE ymax = ymax [ : , np . newaxis ] NEW_LINE return np . concatenate ( ( xmin , ymin , xmax , ymax ) , 1 ) NEW_LINE DEDENT',), ('def poly2bbox_nd ( polys ) : NEW_LINE INDENT n = polys . shape [ 0 ] NEW_LINE xs = polys . reshape ( n , 4 , 2 ) [ : , : , 0 ] NEW_LINE ys = polys . reshape ( n , 4 , 2 ) [ : , : , 1 ] NEW_LINE xmin = mx . nd . min ( xs , axis = 1 ) NEW_LINE ymin = mx . nd . min ( ys , axis = 1 ) NEW_LINE xmax = mx . nd . max ( xs , axis = 1 ) NEW_LINE ymax = mx . nd . max ( ys , axis = 1 ) NEW_LINE xmin = xmin . expand_dims ( 1 ) NEW_LINE ymin = ymin . expand_dims ( 1 ) NEW_LINE xmax = xmax . expand_dims ( 1 ) NEW_LINE ymax = ymax . expand_dims ( 1 ) NEW_LINE return mx . nd . concat ( xmin , ymin , xmax , ymax , dim = 1 ) NEW_LINE DEDENT',), ('def dbbox_transform ( ex_rois , gt_rois ) : NEW_LINE INDENT ws = ex_rois [ : , 2 ] - ex_rois [ : , 0 ] + 1.0 NEW_LINE hs = ex_rois [ : , 3 ] - ex_rois [ : , 1 ] + 1.0 NEW_LINE xmin , ymin , xmax , ymax = ex_rois [ : , 0 ] , ex_rois [ : , 1 ] , ex_rois [ : , 2 ] , ex_rois [ : , 3 ] NEW_LINE roi_polys = np . concatenate ( ( xmin [ : , np . newaxis ] , ymin [ : , np . newaxis ] , xmax [ : , np . newaxis ] , ymin [ : , np . newaxis ] , xmax [ : , np . newaxis ] , ymax [ : , np . newaxis ] , xmin [ : , np . newaxis ] , ymax [ : , np . newaxis ] ) , 1 ) NEW_LINE n = len ( ws ) NEW_LINE targets = np . zeros ( ( n , 8 ) ) NEW_LINE for i in range ( 8 ) : NEW_LINE INDENT if i % 2 == 0 : NEW_LINE INDENT targets [ : , i ] = ( gt_rois [ : , i ] - roi_polys [ : , i ] ) / ws NEW_LINE DEDENT else : NEW_LINE INDENT targets [ : , i ] = ( gt_rois [ : , i ] - roi_polys [ : , i ] ) / hs NEW_LINE DEDENT DEDENT return targets NEW_LINE DEDENT',), ('def dbbox_pred ( boxes , box_deltas ) : NEW_LINE INDENT if boxes . shape [ 0 ] == 0 : NEW_LINE INDENT return np . zeros ( ( 0 , box_deltas . shape [ 1 ] ) ) NEW_LINE DEDENT boxes = boxes . astype ( np . float , copy = False ) NEW_LINE widths = boxes [ : , 2 ] - boxes [ : , 0 ] + 1.0 NEW_LINE heights = boxes [ : , 3 ] - boxes [ : , 1 ] + 1.0 NEW_LINE xmin , ymin , xmax , ymax = boxes [ : , 0 ] , boxes [ : , 1 ] , boxes [ : , 2 ] , boxes [ : , 3 ] NEW_LINE rois = np . concatenate ( ( xmin [ : , np . newaxis ] , ymin [ : , np . newaxis ] , xmax [ : , np . newaxis ] , ymin [ : , np . newaxis ] , xmax [ : , np . newaxis ] , ymax [ : , np . newaxis ] , xmin [ : , np . newaxis ] , ymax [ : , np . newaxis ] ) , axis = 1 ) NEW_LINE box_pred = np . zeros ( box_deltas . shape ) NEW_LINE for i in range ( 8 ) : NEW_LINE INDENT if i % 2 == 0 : NEW_LINE INDENT box_pred [ : , i : : 8 ] = box_deltas [ : , i : : 8 ] * widths [ : , np . newaxis ] + rois [ : , i , np . newaxis ] NEW_LINE DEDENT else : NEW_LINE INDENT box_pred [ : , i : : 8 ] = box_deltas [ : , i : : 8 ] * heights [ : , np . newaxis ] + rois [ : , i , np . newaxis ] NEW_LINE DEDENT DEDENT return box_pred NEW_LINE DEDENT',), (\"def polygonToRotRectangle_batch ( bbox ) : NEW_LINE INDENT bbox = np . array ( bbox , dtype = np . float32 ) NEW_LINE bbox = np . reshape ( bbox , newshape = ( - 1 , 2 , 4 ) , order = ' F ' ) NEW_LINE angle = np . arctan2 ( - ( bbox [ : , 0 , 1 ] - bbox [ : , 0 , 0 ] ) , bbox [ : , 1 , 1 ] - bbox [ : , 1 , 0 ] ) NEW_LINE center = np . zeros ( ( bbox . shape [ 0 ] , 2 , 1 ) ) NEW_LINE for i in range ( 4 ) : NEW_LINE INDENT center [ : , 0 , 0 ] += bbox [ : , 0 , i ] NEW_LINE center [ : , 1 , 0 ] += bbox [ : , 1 , i ] NEW_LINE DEDENT center = np . array ( center , dtype = np . float32 ) / 4.0 NEW_LINE R = np . array ( [ [ np . cos ( angle ) , - np . sin ( angle ) ] , [ np . sin ( angle ) , np . cos ( angle ) ] ] , dtype = np . float32 ) NEW_LINE normalized = np . matmul ( R . transpose ( ( 2 , 1 , 0 ) ) , bbox - center ) NEW_LINE xmin = np . min ( normalized [ : , 0 , : ] , axis = 1 ) NEW_LINE xmax = np . max ( normalized [ : , 0 , : ] , axis = 1 ) NEW_LINE ymin = np . min ( normalized [ : , 1 , : ] , axis = 1 ) NEW_LINE ymax = np . max ( normalized [ : , 1 , : ] , axis = 1 ) NEW_LINE w = xmax - xmin + 1 NEW_LINE h = ymax - ymin + 1 NEW_LINE w = w [ : , np . newaxis ] NEW_LINE h = h [ : , np . newaxis ] NEW_LINE angle = angle [ : , np . newaxis ] % ( 2 * np . pi ) NEW_LINE dboxes = np . concatenate ( ( center [ : , 0 ] . astype ( np . float ) , center [ : , 1 ] . astype ( np . float ) , w , h , angle ) , axis = 1 ) NEW_LINE return dboxes NEW_LINE DEDENT\",), ('def RotBox2Polys ( dboxes ) : NEW_LINE INDENT cs = np . cos ( dboxes [ : , 4 ] ) NEW_LINE ss = np . sin ( dboxes [ : , 4 ] ) NEW_LINE w = dboxes [ : , 2 ] - 1 NEW_LINE h = dboxes [ : , 3 ] - 1 NEW_LINE x_ctr = dboxes [ : , 0 ] NEW_LINE y_ctr = dboxes [ : , 1 ] NEW_LINE x1 = x_ctr + cs * ( w / 2.0 ) - ss * ( - h / 2.0 ) NEW_LINE x2 = x_ctr + cs * ( w / 2.0 ) - ss * ( h / 2.0 ) NEW_LINE x3 = x_ctr + cs * ( - w / 2.0 ) - ss * ( h / 2.0 ) NEW_LINE x4 = x_ctr + cs * ( - w / 2.0 ) - ss * ( - h / 2.0 ) NEW_LINE y1 = y_ctr + ss * ( w / 2.0 ) + cs * ( - h / 2.0 ) NEW_LINE y2 = y_ctr + ss * ( w / 2.0 ) + cs * ( h / 2.0 ) NEW_LINE y3 = y_ctr + ss * ( - w / 2.0 ) + cs * ( h / 2.0 ) NEW_LINE y4 = y_ctr + ss * ( - w / 2.0 ) + cs * ( - h / 2.0 ) NEW_LINE x1 = x1 [ : , np . newaxis ] NEW_LINE y1 = y1 [ : , np . newaxis ] NEW_LINE x2 = x2 [ : , np . newaxis ] NEW_LINE y2 = y2 [ : , np . newaxis ] NEW_LINE x3 = x3 [ : , np . newaxis ] NEW_LINE y3 = y3 [ : , np . newaxis ] NEW_LINE x4 = x4 [ : , np . newaxis ] NEW_LINE y4 = y4 [ : , np . newaxis ] NEW_LINE polys = np . concatenate ( ( x1 , y1 , x2 , y2 , x3 , y3 , x4 , y4 ) , axis = 1 ) NEW_LINE return polys NEW_LINE DEDENT',), ('def xyhs2polys ( xyhs ) : NEW_LINE INDENT x1 = xyhs [ : , 0 ] NEW_LINE y1 = xyhs [ : , 1 ] NEW_LINE x2 = xyhs [ : , 2 ] NEW_LINE y2 = xyhs [ : , 3 ] NEW_LINE h = xyhs [ : , 4 ] NEW_LINE A = - ( y2 - y1 ) NEW_LINE B = ( x2 - x1 ) NEW_LINE x3 = x2 + A / ( np . sqrt ( A * A + B * B ) ) * h NEW_LINE y3 = y2 + B / ( np . sqrt ( A * A + B * B ) ) * h NEW_LINE x4 = x1 + A / ( np . sqrt ( A * A + B * B ) ) * h NEW_LINE y4 = y1 + B / ( np . sqrt ( A * A + B * B ) ) * h NEW_LINE return np . concatenate ( ( x1 [ : , np . newaxis ] , y1 [ : , np . newaxis ] , x2 [ : , np . newaxis ] , y2 [ : , np . newaxis ] , x3 [ : , np . newaxis ] , y3 [ : , np . newaxis ] , x4 [ : , np . newaxis ] , y4 [ : , np . newaxis ] ) , axis = 1 ) NEW_LINE DEDENT',), ('def xyhs2polys_muli_class ( xyhs ) : NEW_LINE INDENT num_boxes = xyhs . shape [ 0 ] NEW_LINE numclasses = int ( xyhs . shape [ 1 ] / 5 ) NEW_LINE quadrangles = np . zeros ( ( num_boxes , 8 * numclasses ) ) NEW_LINE x1 = xyhs [ : , 0 : : 5 ] NEW_LINE y1 = xyhs [ : , 1 : : 5 ] NEW_LINE x2 = xyhs [ : , 2 : : 5 ] NEW_LINE y2 = xyhs [ : , 3 : : 5 ] NEW_LINE h = xyhs [ : , 4 : : 5 ] NEW_LINE A = - ( y2 - y1 ) NEW_LINE B = ( x2 - x1 ) NEW_LINE x3 = x2 + A / ( np . sqrt ( A * A + B * B ) ) * h NEW_LINE y3 = y2 + B / ( np . sqrt ( A * A + B * B ) ) * h NEW_LINE x4 = x1 + A / ( np . sqrt ( A * A + B * B ) ) * h NEW_LINE y4 = y1 + B / ( np . sqrt ( A * A + B * B ) ) * h NEW_LINE quadrangles [ : , 0 : : 8 ] = x1 NEW_LINE quadrangles [ : , 1 : : 8 ] = y1 NEW_LINE quadrangles [ : , 2 : : 8 ] = x2 NEW_LINE quadrangles [ : , 3 : : 8 ] = y2 NEW_LINE quadrangles [ : , 4 : : 8 ] = x3 NEW_LINE quadrangles [ : , 5 : : 8 ] = y3 NEW_LINE quadrangles [ : , 6 : : 8 ] = x4 NEW_LINE quadrangles [ : , 7 : : 8 ] = y4 NEW_LINE return quadrangles NEW_LINE DEDENT',), ('def polys2xyhs ( polys ) : NEW_LINE INDENT rotboxes = polygonToRotRectangle_batch ( polys ) NEW_LINE polys = RotBox2Polys ( rotboxes ) NEW_LINE x1 = polys [ : , 0 ] NEW_LINE y1 = polys [ : , 1 ] NEW_LINE x2 = polys [ : , 2 ] NEW_LINE y2 = polys [ : , 3 ] NEW_LINE h = np . sqrt ( ( polys [ : , 2 ] - polys [ : , 4 ] ) ** 2 + ( polys [ : , 3 ] - polys [ : , 5 ] ) ** 2 ) NEW_LINE return np . concatenate ( ( x1 [ : , np . newaxis ] , y1 [ : , np . newaxis ] , x2 [ : , np . newaxis ] , y2 [ : , np . newaxis ] , h [ : , np . newaxis ] ) , axis = 1 ) NEW_LINE DEDENT',), ('def polys2xyhs_nd ( polys ) : NEW_LINE INDENT x1 = polys [ : , 0 ] NEW_LINE y1 = polys [ : , 1 ] NEW_LINE x2 = polys [ : , 2 ] NEW_LINE y2 = polys [ : , 3 ] NEW_LINE h = np . sqrt ( ( polys [ : , 2 ] - polys [ : , 4 ] ) ** 2 + ( polys [ : , 3 ] - polys [ : , 5 ] ) ** 2 ) NEW_LINE return mx . nd . concat ( ( mx . nd . expand_dims ( x1 , 1 ) , mx . nd . expand_dims ( y1 , 1 ) , mx . nd . expand_dims ( x2 , 1 ) , mx . nd . expand_dims ( y2 , 1 ) , mx . nd . expand_dims ( h , 1 ) ) , 1 ) NEW_LINE DEDENT',), ('def dbboxtransform3_warp ( ex_rois , gts ) : NEW_LINE INDENT boxes_x1s = ex_rois [ : , 0 ] NEW_LINE boxes_y1s = ex_rois [ : , 1 ] NEW_LINE boxes_x2s = ex_rois [ : , 2 ] NEW_LINE boxes_y2s = ex_rois [ : , 1 ] NEW_LINE hs = ex_rois [ : , 3 ] - ex_rois [ : , 1 ] NEW_LINE boxes_xyhs = np . concatenate ( ( boxes_x1s [ : , np . newaxis ] , boxes_y1s [ : , np . newaxis ] , boxes_x2s [ : , np . newaxis ] , boxes_y2s [ : , np . newaxis ] , hs [ : , np . newaxis ] ) , axis = 1 ) NEW_LINE gts_xyhs = polys2xyhs ( gts ) NEW_LINE targets = dbboxtransform3 ( boxes_xyhs , gts_xyhs ) NEW_LINE return targets NEW_LINE DEDENT',), ('def dbbox_transform3_warp_nd ( ex_rois , gts ) : NEW_LINE INDENT boxes_x1s = ex_rois [ : , 0 ] NEW_LINE boxes_y1s = ex_rois [ : , 1 ] NEW_LINE boxes_x2s = ex_rois [ : , 2 ] NEW_LINE boxes_y2s = ex_rois [ : , 1 ] NEW_LINE hs = ex_rois [ : , 3 ] - ex_rois [ : , 1 ] NEW_LINE boxes_xyhs = mx . nd . concat ( ( mx . nd . expand_dims ( boxes_x1s , 1 ) , mx . nd . expand_dims ( boxes_y1s , 1 ) , mx . nd . expand_dims ( boxes_x2s , 1 ) , mx . nd . expand_dims ( boxes_y2s , 1 ) , mx . nd . expand_dims ( hs , 1 ) ) , dim = 1 ) NEW_LINE gts_xyhs = polys2xyhs_nd ( gts ) NEW_LINE targets = dbboxtransform3_nd ( boxes_xyhs , gts_xyhs ) NEW_LINE return targets NEW_LINE DEDENT',), ('def dbboxtransform3_inv_warp ( ex_rois , deltas ) : NEW_LINE INDENT boxes_x1s = ex_rois [ : , 0 ] NEW_LINE boxes_y1s = ex_rois [ : , 1 ] NEW_LINE boxes_x2s = ex_rois [ : , 2 ] NEW_LINE boxes_y2s = ex_rois [ : , 1 ] NEW_LINE hs = ex_rois [ : , 3 ] - ex_rois [ : , 1 ] NEW_LINE boxes_xyhs = np . concatenate ( ( boxes_x1s [ : , np . newaxis ] , boxes_y1s [ : , np . newaxis ] , boxes_x2s [ : , np . newaxis ] , boxes_y2s [ : , np . newaxis ] , hs [ : , np . newaxis ] ) , axis = 1 ) NEW_LINE pred_boxes = dbboxtransform3_inv ( boxes_xyhs , deltas ) NEW_LINE return pred_boxes NEW_LINE DEDENT',), ('def rotation_translation_trans ( boxes , thetas , translations ) : NEW_LINE INDENT boxes [ : , 0 ] = boxes [ : , 0 ] - translations [ : , 0 ] NEW_LINE boxes [ : , 1 ] = boxes [ : , 1 ] - translations [ : , 1 ] NEW_LINE xs , ys = copy . deepcopy ( boxes [ : , 0 ] ) , copy . deepcopy ( boxes [ : , 1 ] ) NEW_LINE boxes [ : , 0 ] = np . cos ( thetas ) * xs - np . sin ( thetas ) * ys NEW_LINE boxes [ : , 1 ] = np . sin ( thetas ) * xs + np . cos ( thetas ) * ys NEW_LINE boxes [ : , 2 ] = boxes [ : , 2 ] - translations [ : , 0 ] NEW_LINE boxes [ : , 3 ] = boxes [ : , 3 ] - translations [ : , 1 ] NEW_LINE xs2 , ys2 = copy . deepcopy ( boxes [ : , 2 ] ) , copy . deepcopy ( boxes [ : , 3 ] ) NEW_LINE boxes [ : , 2 ] = np . cos ( thetas ) * xs2 - np . sin ( thetas ) * ys2 NEW_LINE boxes [ : , 3 ] = np . sin ( thetas ) * xs2 + np . cos ( thetas ) * ys2 NEW_LINE return boxes NEW_LINE DEDENT',), ('def rotation_translation_trans_multi_class ( boxes , thetas , translations ) : NEW_LINE INDENT boxes [ : , 0 : : 5 ] = boxes [ : , 0 : : 5 ] - translations [ : , 0 ] [ : , np . newaxis ] NEW_LINE boxes [ : , 1 : : 5 ] = boxes [ : , 1 : : 5 ] - translations [ : , 1 ] [ : , np . newaxis ] NEW_LINE xs , ys = boxes [ : , 0 : : 5 ] , boxes [ : , 1 : : 5 ] NEW_LINE boxes [ : , 0 : : 5 ] = np . cos ( thetas ) [ : , np . newaxis ] * xs - np . sin ( thetas ) [ : , np . newaxis ] * ys NEW_LINE boxes [ : , 1 : : 5 ] = np . sin ( thetas ) [ : , np . newaxis ] * xs + np . cos ( thetas ) [ : , np . newaxis ] * ys NEW_LINE boxes [ : , 2 : : 5 ] = boxes [ : , 2 : : 5 ] - translations [ : , 0 ] [ : , np . newaxis ] NEW_LINE boxes [ : , 3 : : 5 ] = boxes [ : , 3 : : 5 ] - translations [ : , 1 ] [ : , np . newaxis ] NEW_LINE xs2 , ys2 = boxes [ : , 2 : : 5 ] , boxes [ : , 3 : : 5 ] NEW_LINE boxes [ : , 2 : : 5 ] = np . cos ( thetas ) [ : , np . newaxis ] * xs2 - np . sin ( thetas ) [ : , np . newaxis ] * ys2 NEW_LINE boxes [ : , 3 : : 5 ] = np . sin ( thetas ) [ : , np . newaxis ] * xs2 + np . cos ( thetas ) [ : , np . newaxis ] * ys2 NEW_LINE return boxes NEW_LINE DEDENT',), ('def dbboxtransform3 ( boxes , gts ) : NEW_LINE INDENT thetas = - np . arctan2 ( ( boxes [ : , 3 ] - boxes [ : , 1 ] ) , ( boxes [ : , 2 ] - boxes [ : , 0 ] ) ) NEW_LINE ext_widhts = np . sqrt ( ( boxes [ : , 0 ] - boxes [ : , 2 ] ) ** 2 + ( boxes [ : , 1 ] - boxes [ : , 3 ] ) ** 2 ) NEW_LINE hs = boxes [ : , 4 ] NEW_LINE transformed_gts = copy . deepcopy ( gts ) NEW_LINE transformed_gts = rotation_translation_trans ( transformed_gts , thetas , boxes [ : , 0 : 2 ] ) NEW_LINE transformed_boxes = copy . deepcopy ( boxes ) NEW_LINE transformed_boxes [ : , 0 ] = 0 NEW_LINE transformed_boxes [ : , 1 ] = 0 NEW_LINE transformed_boxes [ : , 2 ] = ext_widhts NEW_LINE transformed_boxes [ : , 3 ] = 0 NEW_LINE transformed_boxes [ : , 4 ] = hs NEW_LINE dx1 = ( transformed_gts [ : , 0 ] - transformed_boxes [ : , 0 ] ) / ext_widhts NEW_LINE dy1 = ( transformed_gts [ : , 1 ] - transformed_boxes [ : , 1 ] ) / hs NEW_LINE dx2 = ( transformed_gts [ : , 2 ] - transformed_boxes [ : , 2 ] ) / ext_widhts NEW_LINE dy2 = ( transformed_gts [ : , 3 ] - transformed_boxes [ : , 3 ] ) / hs NEW_LINE dh = np . log ( transformed_gts [ : , 4 ] / hs ) NEW_LINE return np . concatenate ( ( dx1 [ : , np . newaxis ] , dy1 [ : , np . newaxis ] , dx2 [ : , np . newaxis ] , dy2 [ : , np . newaxis ] , dh [ : , np . newaxis ] ) , axis = 1 ) NEW_LINE DEDENT',), ('def dbboxtransform3_nd ( boxes , gts ) : NEW_LINE def dbboxtransform3_inv ( boxes , targets ) : NEW_LINE INDENT thetas = - np . arctan2 ( ( boxes [ : , 3 ] - boxes [ : , 1 ] ) , ( boxes [ : , 2 ] - boxes [ : , 0 ] ) ) NEW_LINE ext_widhts = np . sqrt ( ( boxes [ : , 0 ] - boxes [ : , 2 ] ) ** 2 + ( boxes [ : , 1 ] - boxes [ : , 3 ] ) ** 2 ) NEW_LINE hs = boxes [ : , 4 ] NEW_LINE transformed_boxes = copy . deepcopy ( boxes ) NEW_LINE transformed_boxes [ : , 0 ] = 0 NEW_LINE transformed_boxes [ : , 1 ] = 0 NEW_LINE transformed_boxes [ : , 2 ] = ext_widhts NEW_LINE transformed_boxes [ : , 3 ] = 0 NEW_LINE transformed_boxes [ : , 4 ] = hs NEW_LINE transformed_gts = copy . deepcopy ( targets ) NEW_LINE transformed_gts [ : , 0 : : 5 ] = targets [ : , 0 : : 5 ] * ext_widhts [ : , np . newaxis ] + transformed_boxes [ : , 0 ] [ : , np . newaxis ] NEW_LINE transformed_gts [ : , 1 : : 5 ] = targets [ : , 1 : : 5 ] * hs [ : , np . newaxis ] + transformed_boxes [ : , 1 ] [ : , np . newaxis ] NEW_LINE transformed_gts [ : , 2 : : 5 ] = targets [ : , 2 : : 5 ] * ext_widhts [ : , np . newaxis ] + transformed_boxes [ : , 2 ] [ : , np . newaxis ] NEW_LINE transformed_gts [ : , 3 : : 5 ] = targets [ : , 3 : : 5 ] * hs [ : , np . newaxis ] + transformed_boxes [ : , 3 ] [ : , np . newaxis ] NEW_LINE transformed_gts [ : , 4 : : 5 ] = np . exp ( targets [ : , 4 : : 5 ] ) * hs [ : , np . newaxis ] NEW_LINE pred_boxes = rotation_translation_trans_multi_class ( transformed_gts , - thetas , - boxes [ : , 0 : 2 ] ) NEW_LINE return pred_boxes NEW_LINE DEDENT',), ('def RotBox2Polys_multi_class ( dboxes ) : NEW_LINE INDENT num_boxes = dboxes . shape [ 0 ] NEW_LINE numclasses = int ( dboxes . shape [ 1 ] / 5 ) NEW_LINE quadrangles = np . zeros ( ( num_boxes , 8 * numclasses ) ) NEW_LINE cs = np . cos ( dboxes [ : , 4 : : 5 ] ) NEW_LINE ss = np . sin ( dboxes [ : , 4 : : 5 ] ) NEW_LINE w = dboxes [ : , 2 : : 5 ] - 1 NEW_LINE h = dboxes [ : , 3 : : 5 ] - 1 NEW_LINE x_ctr = dboxes [ : , 0 : : 5 ] NEW_LINE y_ctr = dboxes [ : , 1 : : 5 ] NEW_LINE x1 = x_ctr + cs * ( w / 2.0 ) - ss * ( - h / 2.0 ) NEW_LINE x2 = x_ctr + cs * ( w / 2.0 ) - ss * ( h / 2.0 ) NEW_LINE x3 = x_ctr + cs * ( - w / 2.0 ) - ss * ( h / 2.0 ) NEW_LINE x4 = x_ctr + cs * ( - w / 2.0 ) - ss * ( - h / 2.0 ) NEW_LINE y1 = y_ctr + ss * ( w / 2.0 ) + cs * ( - h / 2.0 ) NEW_LINE y2 = y_ctr + ss * ( w / 2.0 ) + cs * ( h / 2.0 ) NEW_LINE y3 = y_ctr + ss * ( - w / 2.0 ) + cs * ( h / 2.0 ) NEW_LINE y4 = y_ctr + ss * ( - w / 2.0 ) + cs * ( - h / 2.0 ) NEW_LINE quadrangles [ : , 0 : : 8 ] = x1 NEW_LINE quadrangles [ : , 1 : : 8 ] = y1 NEW_LINE quadrangles [ : , 2 : : 8 ] = x2 NEW_LINE quadrangles [ : , 3 : : 8 ] = y2 NEW_LINE quadrangles [ : , 4 : : 8 ] = x3 NEW_LINE quadrangles [ : , 5 : : 8 ] = y3 NEW_LINE quadrangles [ : , 6 : : 8 ] = x4 NEW_LINE quadrangles [ : , 7 : : 8 ] = y4 NEW_LINE return quadrangles NEW_LINE DEDENT',), ('def dbbox_transform2_warp ( ex_rois , gt_rois ) : NEW_LINE INDENT num_rois = ex_rois . shape [ 0 ] NEW_LINE initial_angles = - np . ones ( ( num_rois , 1 ) ) * np . pi / 2. NEW_LINE ex_rois = xy2wh ( ex_rois ) NEW_LINE ex_rois = np . hstack ( ( ex_rois , initial_angles ) ) NEW_LINE gt_rotboxes = polygonToRotRectangle_batch ( gt_rois ) NEW_LINE targets = dbbox_transform2 ( ex_rois , gt_rotboxes ) NEW_LINE return targets NEW_LINE DEDENT',), ('def dbbox_transform2_warp_nd ( ex_rois , gt_rois ) : NEW_LINE INDENT num_rois = ex_rois . shape [ 0 ] NEW_LINE initial_angles = - mx . nd . ones ( ( num_rois , 1 ) ) * np . pi / 2 NEW_LINE ex_rois = xy2wh_nd ( ex_rois ) NEW_LINE ex_rois = mx . nd . concat ( ex_rois , initial_angles , dim = 1 ) NEW_LINE gt_rotboxes = mx . nd . array ( polygonToRotRectangle_batch ( gt_rois . asnumpy ( ) ) ) NEW_LINE targets = dbbox_transform2_nd ( ex_rois , gt_rotboxes ) NEW_LINE return targets NEW_LINE DEDENT',), ('def dbbox_transform2_inv_warp ( ex_rois , deltas ) : NEW_LINE INDENT num_rois = ex_rois . shape [ 0 ] NEW_LINE initial_angles = - np . ones ( ( num_rois , 1 ) ) * np . pi / 2. NEW_LINE ex_rois = xy2wh ( ex_rois ) NEW_LINE ex_rois = np . hstack ( ( ex_rois , initial_angles ) ) NEW_LINE pred_rotboxes = dbbox_transform2_inv ( ex_rois , deltas ) NEW_LINE return pred_rotboxes NEW_LINE DEDENT',), ('def dbbox_transform2 ( ex_drois , gt_rois ) : NEW_LINE INDENT gt_widths = gt_rois [ : , 2 ] NEW_LINE gt_heights = gt_rois [ : , 3 ] NEW_LINE gt_angle = gt_rois [ : , 4 ] NEW_LINE ex_widths = ex_drois [ : , 2 ] NEW_LINE ex_heights = ex_drois [ : , 3 ] NEW_LINE ex_angle = ex_drois [ : , 4 ] NEW_LINE coord = gt_rois [ : , 0 : 2 ] - ex_drois [ : , 0 : 2 ] NEW_LINE targets_dx = ( np . cos ( ex_drois [ : , 4 ] ) * coord [ : , 0 ] + np . sin ( ex_drois [ : , 4 ] ) * coord [ : , 1 ] ) / ex_widths NEW_LINE targets_dy = ( - np . sin ( ex_drois [ : , 4 ] ) * coord [ : , 0 ] + np . cos ( ex_drois [ : , 4 ] ) * coord [ : , 1 ] ) / ex_heights NEW_LINE targets_dw = np . log ( gt_widths / ex_widths ) NEW_LINE targets_dh = np . log ( gt_heights / ex_heights ) NEW_LINE targets_dangle = ( gt_angle - ex_angle ) % ( 2 * np . pi ) / ( 2 * np . pi ) NEW_LINE targets = np . stack ( ( targets_dx , targets_dy , targets_dw , targets_dh , targets_dangle ) , 1 ) NEW_LINE return targets NEW_LINE DEDENT',), ('def dbbox_transform2_new ( ex_drois , gt_rois ) : NEW_LINE INDENT gt_widths = gt_rois [ : , 2 ] NEW_LINE gt_heights = gt_rois [ : , 3 ] NEW_LINE gt_angle = gt_rois [ : , 4 ] NEW_LINE ex_widths = ex_drois [ : , 2 ] NEW_LINE ex_heights = ex_drois [ : , 3 ] NEW_LINE ex_angle = ex_drois [ : , 4 ] NEW_LINE coord = gt_rois [ : , 0 : 2 ] - ex_drois [ : , 0 : 2 ] NEW_LINE targets_dx = ( np . cos ( ex_drois [ : , 4 ] ) * coord [ : , 0 ] + np . sin ( ex_drois [ : , 4 ] ) * coord [ : , 1 ] ) / ex_widths NEW_LINE targets_dy = ( - np . sin ( ex_drois [ : , 4 ] ) * coord [ : , 0 ] + np . cos ( ex_drois [ : , 4 ] ) * coord [ : , 1 ] ) / ex_heights NEW_LINE targets_dw = np . log ( gt_widths / ex_widths ) NEW_LINE targets_dh = np . log ( gt_heights / ex_heights ) NEW_LINE targets_dangle = ( gt_angle - ex_angle ) NEW_LINE dist = targets_dangle % ( 2 * np . pi ) NEW_LINE dist = np . minimum ( dist , np . pi * 2 - dist ) NEW_LINE try : NEW_LINE INDENT assert np . all ( dist <= ( np . pi / 2. + 0.001 ) ) NEW_LINE DEDENT except : NEW_LINE INDENT pdb . set_trace ( ) NEW_LINE DEDENT mask = np . sin ( targets_dangle ) < 0 NEW_LINE dist [ mask ] = - dist [ mask ] NEW_LINE dist = dist / ( np . pi / 2. ) NEW_LINE targets = np . stack ( ( targets_dx , targets_dy , targets_dw , targets_dh , dist ) , 1 ) NEW_LINE return targets NEW_LINE DEDENT',), ('def dbbox_transform2_inv_new ( ex_drois , deltas , norm_angle ) : NEW_LINE INDENT widths = ex_drois [ : , 2 ] NEW_LINE heights = ex_drois [ : , 3 ] NEW_LINE angles = ex_drois [ : , 4 ] NEW_LINE ctr_x = ex_drois [ : , 0 ] NEW_LINE ctr_y = ex_drois [ : , 1 ] NEW_LINE dx = deltas [ : , 0 : : 5 ] NEW_LINE dy = deltas [ : , 1 : : 5 ] NEW_LINE dw = deltas [ : , 2 : : 5 ] NEW_LINE dh = deltas [ : , 3 : : 5 ] NEW_LINE dangle = deltas [ : , 4 : : 5 ] NEW_LINE pred_ctr_x = dx * widths [ : , np . newaxis ] * np . cos ( angles [ : , np . newaxis ] ) - dy * heights [ : , np . newaxis ] * np . sin ( angles [ : , np . newaxis ] ) + ctr_x [ : , np . newaxis ] NEW_LINE pred_ctr_y = dx * widths [ : , np . newaxis ] * np . sin ( angles [ : , np . newaxis ] ) + dy * heights [ : , np . newaxis ] * np . cos ( angles [ : , np . newaxis ] ) + ctr_y [ : , np . newaxis ] NEW_LINE pred_w = np . exp ( dw ) * widths [ : , np . newaxis ] NEW_LINE pred_h = np . exp ( dh ) * heights [ : , np . newaxis ] NEW_LINE pred_angle = ( norm_angle ) * dangle + angles [ : , np . newaxis ] NEW_LINE pred_dboxes = np . ones_like ( deltas ) NEW_LINE pred_dboxes [ : , 0 : : 5 ] = pred_ctr_x NEW_LINE pred_dboxes [ : , 1 : : 5 ] = pred_ctr_y NEW_LINE pred_dboxes [ : , 2 : : 5 ] = pred_w NEW_LINE pred_dboxes [ : , 3 : : 5 ] = pred_h NEW_LINE pred_dboxes [ : , 4 : : 5 ] = pred_angle NEW_LINE return pred_dboxes NEW_LINE DEDENT',), ('def choose_best_match ( Rroi , gt_roi ) : NEW_LINE INDENT assert Rroi [ 4 ] <= ( np . pi ) NEW_LINE assert Rroi [ 4 ] >= 0 NEW_LINE assert gt_roi [ 4 ] <= ( 2 * np . pi ) NEW_LINE assert gt_roi [ 4 ] >= 0 NEW_LINE Rroi_angle = Rroi [ 4 ] NEW_LINE gt_x , gt_y , gt_w , gt_h , gt_angle = gt_roi NEW_LINE gt_roi_extent = np . array ( [ [ gt_x , gt_y , gt_w , gt_h , gt_angle ] , [ gt_x , gt_y , gt_h , gt_w , gt_angle + np . pi / 2. ] , [ gt_x , gt_y , gt_w , gt_h , gt_angle + np . pi ] , [ gt_x , gt_y , gt_h , gt_w , gt_angle + np . pi * 3 / 2. ] ] ) NEW_LINE gt_angle_extent = np . array ( [ gt_angle , gt_angle + np . pi / 2. , gt_angle + np . pi , gt_angle + np . pi * 3 / 2. ] ) NEW_LINE dist = ( gt_angle_extent - Rroi_angle ) % ( 2 * np . pi ) NEW_LINE dist = np . min ( dist , np . pi * 2 - dist ) NEW_LINE min_index = np . argmin ( dist ) NEW_LINE gt_roi_new = gt_roi_extent [ min_index ] NEW_LINE return gt_roi_new NEW_LINE DEDENT',), ('def choose_best_match_batch ( Rrois , gt_rois ) : NEW_LINE INDENT Rroi_anlges = Rrois [ : , 4 ] [ : , np . newaxis ] NEW_LINE gt_xs , gt_ys , gt_ws , gt_hs , gt_angles = copy . deepcopy ( gt_rois [ : , 0 ] ) , copy . deepcopy ( gt_rois [ : , 1 ] ) , copy . deepcopy ( gt_rois [ : , 2 ] ) , copy . deepcopy ( gt_rois [ : , 3 ] ) , copy . deepcopy ( gt_rois [ : , 4 ] ) NEW_LINE gt_angle_extent = np . concatenate ( ( gt_angles [ : , np . newaxis ] , ( gt_angles + np . pi / 2. ) [ : , np . newaxis ] , ( gt_angles + np . pi ) [ : , np . newaxis ] , ( gt_angles + np . pi * 3 / 2. ) [ : , np . newaxis ] ) , axis = 1 ) NEW_LINE dist = ( Rroi_anlges - gt_angle_extent ) % ( 2 * np . pi ) NEW_LINE dist = np . minimum ( dist , np . pi * 2 - dist ) NEW_LINE min_index = np . argmin ( dist , axis = 1 ) NEW_LINE gt_rois_extent0 = copy . deepcopy ( gt_rois ) NEW_LINE gt_rois_extent1 = np . hstack ( ( gt_xs [ : , np . newaxis ] , gt_ys [ : , np . newaxis ] , gt_hs [ : , np . newaxis ] , gt_ws [ : , np . newaxis ] , gt_angles [ : , np . newaxis ] + np . pi / 2. ) ) NEW_LINE gt_rois_extent2 = np . hstack ( ( gt_xs [ : , np . newaxis ] , gt_ys [ : , np . newaxis ] , gt_ws [ : , np . newaxis ] , gt_hs [ : , np . newaxis ] , gt_angles [ : , np . newaxis ] + np . pi ) ) NEW_LINE gt_rois_extent3 = np . hstack ( ( gt_xs [ : , np . newaxis ] , gt_ys [ : , np . newaxis ] , gt_hs [ : , np . newaxis ] , gt_ws [ : , np . newaxis ] , gt_angles [ : , np . newaxis ] + np . pi * 3 / 2. ) ) NEW_LINE gt_rois_extent = np . concatenate ( ( gt_rois_extent0 [ : , np . newaxis , : ] , gt_rois_extent1 [ : , np . newaxis , : ] , gt_rois_extent2 [ : , np . newaxis , : ] , gt_rois_extent3 [ : , np . newaxis , : ] ) , axis = 1 ) NEW_LINE gt_rois_new = np . zeros_like ( gt_rois ) NEW_LINE for curiter , index in enumerate ( min_index ) : NEW_LINE INDENT gt_rois_new [ curiter , : ] = gt_rois_extent [ curiter , index , : ] NEW_LINE DEDENT gt_rois_new [ : , 4 ] = gt_rois_new [ : , 4 ] % ( 2 * np . pi ) NEW_LINE return gt_rois_new NEW_LINE DEDENT',), ('def choose_bset_Rroi_grad_batch ( Rroi ) : NEW_LINE INDENT x_ctr , y_ctr , w , h , angle = copy . deepcopy ( Rroi [ : , 0 ] ) , copy . deepcopy ( Rroi [ : , 1 ] ) , copy . deepcopy ( Rroi [ : , 2 ] ) , copy . deepcopy ( Rroi [ : , 3 ] ) , copy . deepcopy ( Rroi [ : , 4 ] ) NEW_LINE indexes = w < h NEW_LINE Rroi [ indexes , 2 ] = h [ indexes ] NEW_LINE Rroi [ indexes , 3 ] = w [ indexes ] NEW_LINE Rroi [ indexes , 4 ] = Rroi [ indexes , 4 ] + np . pi / 2. NEW_LINE Rroi [ : , 4 ] = Rroi [ : , 4 ] % np . pi NEW_LINE return Rroi , indexes NEW_LINE DEDENT',), ('def choose_best_Rroi_batch ( Rroi ) : NEW_LINE INDENT x_ctr , y_ctr , w , h , angle = copy . deepcopy ( Rroi [ : , 0 ] ) , copy . deepcopy ( Rroi [ : , 1 ] ) , copy . deepcopy ( Rroi [ : , 2 ] ) , copy . deepcopy ( Rroi [ : , 3 ] ) , copy . deepcopy ( Rroi [ : , 4 ] ) NEW_LINE indexes = w < h NEW_LINE Rroi [ indexes , 2 ] = h [ indexes ] NEW_LINE Rroi [ indexes , 3 ] = w [ indexes ] NEW_LINE Rroi [ indexes , 4 ] = Rroi [ indexes , 4 ] + np . pi / 2. NEW_LINE Rroi [ : , 4 ] = Rroi [ : , 4 ] % np . pi NEW_LINE return Rroi NEW_LINE DEDENT',), ('def dbbox_transform2_best_match_warp ( Rrois , gt_boxes ) : NEW_LINE INDENT gt_boxes_new = choose_best_match_batch ( Rrois , gt_boxes ) NEW_LINE try : NEW_LINE INDENT assert np . all ( Rrois [ : , 4 ] <= ( np . pi + 0.001 ) ) NEW_LINE DEDENT except : NEW_LINE INDENT pdb . set_trace ( ) NEW_LINE DEDENT bbox_targets = dbbox_transform2_new ( Rrois , gt_boxes_new ) NEW_LINE return bbox_targets NEW_LINE DEDENT',), ('def dbbox_transform2_nd ( ex_drois , gt_rois ) : NEW_LINE INDENT gt_widths = gt_rois [ : , 2 ] NEW_LINE gt_heights = gt_rois [ : , 3 ] NEW_LINE gt_angle = gt_rois [ : , 4 ] NEW_LINE ex_widths = ex_drois [ : , 2 ] NEW_LINE ex_heights = ex_drois [ : , 3 ] NEW_LINE ex_angle = ex_drois [ : , 4 ] NEW_LINE coord = gt_rois [ : , 0 : 2 ] - ex_drois [ : , 0 : 2 ] NEW_LINE targets_dx = ( mx . nd . cos ( ex_drois [ : , 4 ] ) * coord [ : , 0 ] + mx . nd . sin ( ex_drois [ : , 4 ] ) * coord [ : , 1 ] ) / ex_widths NEW_LINE targets_dy = ( - mx . nd . sin ( ex_drois [ : , 4 ] ) * coord [ : , 0 ] + mx . nd . cos ( ex_drois [ : , 4 ] ) * coord [ : , 1 ] ) / ex_heights NEW_LINE targets_dw = mx . nd . log ( gt_widths / ex_widths ) NEW_LINE targets_dh = mx . nd . log ( gt_heights / ex_heights ) NEW_LINE targets_dangle = ( gt_angle - ex_angle ) % ( 2 * np . pi ) / ( 2 * np . pi ) NEW_LINE targets = mx . nd . concat ( targets_dx . expand_dims ( 1 ) , targets_dy . expand_dims ( 1 ) , targets_dw . expand_dims ( 1 ) , targets_dh . expand_dims ( 1 ) , targets_dangle . expand_dims ( 1 ) , dim = 1 ) NEW_LINE return targets NEW_LINE DEDENT',), ('def dbbox_transform2_inv ( ex_drois , deltas ) : NEW_LINE INDENT widths = ex_drois [ : , 2 ] NEW_LINE heights = ex_drois [ : , 3 ] NEW_LINE angles = ex_drois [ : , 4 ] NEW_LINE ctr_x = ex_drois [ : , 0 ] NEW_LINE ctr_y = ex_drois [ : , 1 ] NEW_LINE dx = deltas [ : , 0 : : 5 ] NEW_LINE dy = deltas [ : , 1 : : 5 ] NEW_LINE dw = deltas [ : , 2 : : 5 ] NEW_LINE dh = deltas [ : , 3 : : 5 ] NEW_LINE dw = np . minimum ( dw , 4 ) NEW_LINE dh = np . minimum ( dh , 4 ) NEW_LINE dangle = deltas [ : , 4 : : 5 ] NEW_LINE pred_ctr_x = dx * widths [ : , np . newaxis ] * np . cos ( angles [ : , np . newaxis ] ) - dy * heights [ : , np . newaxis ] * np . sin ( angles [ : , np . newaxis ] ) + ctr_x [ : , np . newaxis ] NEW_LINE pred_ctr_y = dx * widths [ : , np . newaxis ] * np . sin ( angles [ : , np . newaxis ] ) + dy * heights [ : , np . newaxis ] * np . cos ( angles [ : , np . newaxis ] ) + ctr_y [ : , np . newaxis ] NEW_LINE pred_w = np . exp ( dw ) * widths [ : , np . newaxis ] NEW_LINE pred_h = np . exp ( dh ) * heights [ : , np . newaxis ] NEW_LINE pred_angle = ( 2 * np . pi ) * dangle + angles [ : , np . newaxis ] NEW_LINE pred_angle = pred_angle % ( 2 * np . pi ) NEW_LINE pred_dboxes = np . ones_like ( deltas ) NEW_LINE pred_dboxes [ : , 0 : : 5 ] = pred_ctr_x NEW_LINE pred_dboxes [ : , 1 : : 5 ] = pred_ctr_y NEW_LINE pred_dboxes [ : , 2 : : 5 ] = pred_w NEW_LINE pred_dboxes [ : , 3 : : 5 ] = pred_h NEW_LINE pred_dboxes [ : , 4 : : 5 ] = pred_angle NEW_LINE return pred_dboxes NEW_LINE DEDENT',), ('def bbox_overlaps_py ( boxes , query_boxes ) : NEW_LINE INDENT n_ = boxes . shape [ 0 ] NEW_LINE k_ = query_boxes . shape [ 0 ] NEW_LINE overlaps = np . zeros ( ( n_ , k_ ) , dtype = np . float ) NEW_LINE for k in range ( k_ ) : NEW_LINE INDENT query_box_area = ( query_boxes [ k , 2 ] - query_boxes [ k , 0 ] + 1 ) * ( query_boxes [ k , 3 ] - query_boxes [ k , 1 ] + 1 ) NEW_LINE for n in range ( n_ ) : NEW_LINE INDENT iw = min ( boxes [ n , 2 ] , query_boxes [ k , 2 ] ) - max ( boxes [ n , 0 ] , query_boxes [ k , 0 ] ) + 1 NEW_LINE if iw > 0 : NEW_LINE INDENT ih = min ( boxes [ n , 3 ] , query_boxes [ k , 3 ] ) - max ( boxes [ n , 1 ] , query_boxes [ k , 1 ] ) + 1 NEW_LINE if ih > 0 : NEW_LINE INDENT box_area = ( boxes [ n , 2 ] - boxes [ n , 0 ] + 1 ) * ( boxes [ n , 3 ] - boxes [ n , 1 ] + 1 ) NEW_LINE all_area = float ( box_area + query_box_area - iw * ih ) NEW_LINE overlaps [ n , k ] = iw * ih / all_area NEW_LINE DEDENT DEDENT DEDENT DEDENT return overlaps NEW_LINE DEDENT',), ('def clip_polys ( polys , im_shape ) : NEW_LINE INDENT def clip_wh ( coords , wh ) : NEW_LINE INDENT return np . maximum ( np . minimum ( coords , wh - 1 ) , 0 ) NEW_LINE DEDENT polys [ : , 0 : : 8 ] = np . maximum ( np . minimum ( polys [ : , 0 : : 8 ] , im_shape [ 1 ] - 1 ) , 0 ) NEW_LINE polys [ : , 1 : : 8 ] = np . maximum ( np . minimum ( polys [ : , 1 : : 8 ] , im_shape [ 0 ] - 1 ) , 0 ) NEW_LINE polys [ : , 2 : : 8 ] = np . maximum ( np . minimum ( polys [ : , 2 : : 8 ] , im_shape [ 1 ] - 1 ) , 0 ) NEW_LINE polys [ : , 3 : : 8 ] = np . maximum ( np . minimum ( polys [ : , 3 : : 8 ] , im_shape [ 0 ] - 1 ) , 0 ) NEW_LINE polys [ : , 4 : : 8 ] = clip_wh ( polys [ : , 4 : : 8 ] , im_shape [ 1 ] ) NEW_LINE polys [ : , 5 : : 8 ] = clip_wh ( polys [ : , 5 : : 8 ] , im_shape [ 0 ] ) NEW_LINE polys [ : , 6 : : 8 ] = clip_wh ( polys [ : , 6 : : 8 ] , im_shape [ 1 ] ) NEW_LINE polys [ : , 7 : : 8 ] = clip_wh ( polys [ : , 7 : : 8 ] , im_shape [ 0 ] ) NEW_LINE return polys NEW_LINE DEDENT',), ('def clip_boxes ( boxes , im_shape ) : NEW_LINE INDENT boxes [ : , 0 : : 4 ] = np . maximum ( np . minimum ( boxes [ : , 0 : : 4 ] , im_shape [ 1 ] - 1 ) , 0 ) NEW_LINE boxes [ : , 1 : : 4 ] = np . maximum ( np . minimum ( boxes [ : , 1 : : 4 ] , im_shape [ 0 ] - 1 ) , 0 ) NEW_LINE boxes [ : , 2 : : 4 ] = np . maximum ( np . minimum ( boxes [ : , 2 : : 4 ] , im_shape [ 1 ] - 1 ) , 0 ) NEW_LINE boxes [ : , 3 : : 4 ] = np . maximum ( np . minimum ( boxes [ : , 3 : : 4 ] , im_shape [ 0 ] - 1 ) , 0 ) NEW_LINE return boxes NEW_LINE DEDENT',), ('def filter_boxes ( boxes , min_size ) : NEW_LINE INDENT ws = boxes [ : , 2 ] - boxes [ : , 0 ] + 1 NEW_LINE hs = boxes [ : , 3 ] - boxes [ : , 1 ] + 1 NEW_LINE keep = np . where ( ( ws >= min_size ) & ( hs >= min_size ) ) [ 0 ] NEW_LINE return keep NEW_LINE DEDENT',), (\"def nonlinear_transform ( ex_rois , gt_rois ) : NEW_LINE INDENT assert ex_rois . shape [ 0 ] == gt_rois . shape [ 0 ] , ' inconsistent ▁ rois ▁ number ' NEW_LINE ex_widths = ex_rois [ : , 2 ] - ex_rois [ : , 0 ] + 1.0 NEW_LINE ex_heights = ex_rois [ : , 3 ] - ex_rois [ : , 1 ] + 1.0 NEW_LINE ex_ctr_x = ex_rois [ : , 0 ] + 0.5 * ( ex_widths - 1.0 ) NEW_LINE ex_ctr_y = ex_rois [ : , 1 ] + 0.5 * ( ex_heights - 1.0 ) NEW_LINE gt_widths = gt_rois [ : , 2 ] - gt_rois [ : , 0 ] + 1.0 NEW_LINE gt_heights = gt_rois [ : , 3 ] - gt_rois [ : , 1 ] + 1.0 NEW_LINE gt_ctr_x = gt_rois [ : , 0 ] + 0.5 * ( gt_widths - 1.0 ) NEW_LINE gt_ctr_y = gt_rois [ : , 1 ] + 0.5 * ( gt_heights - 1.0 ) NEW_LINE targets_dx = ( gt_ctr_x - ex_ctr_x ) / ( ex_widths + 1e-14 ) NEW_LINE targets_dy = ( gt_ctr_y - ex_ctr_y ) / ( ex_heights + 1e-14 ) NEW_LINE targets_dw = np . log ( gt_widths / ex_widths ) NEW_LINE targets_dh = np . log ( gt_heights / ex_heights ) NEW_LINE targets = np . vstack ( ( targets_dx , targets_dy , targets_dw , targets_dh ) ) . transpose ( ) NEW_LINE return targets NEW_LINE DEDENT\",), ('def cal_line_length ( point1 , point2 ) : NEW_LINE INDENT return math . sqrt ( math . pow ( point1 [ 0 ] - point2 [ 0 ] , 2 ) + math . pow ( point1 [ 1 ] - point2 [ 1 ] , 2 ) ) NEW_LINE DEDENT',), ('def get_best_begin_point_wrapp ( coordinate ) : NEW_LINE INDENT coordinate = np . array ( coordinate ) . reshape ( 4 , 2 ) NEW_LINE output = get_best_begin_point ( coordinate ) NEW_LINE output = np . array ( output ) . reshape ( 8 ) NEW_LINE return output NEW_LINE DEDENT',), ('def get_best_begin_point ( coordinate ) : NEW_LINE INDENT x1 = coordinate [ 0 ] [ 0 ] NEW_LINE y1 = coordinate [ 0 ] [ 1 ] NEW_LINE x2 = coordinate [ 1 ] [ 0 ] NEW_LINE y2 = coordinate [ 1 ] [ 1 ] NEW_LINE x3 = coordinate [ 2 ] [ 0 ] NEW_LINE y3 = coordinate [ 2 ] [ 1 ] NEW_LINE x4 = coordinate [ 3 ] [ 0 ] NEW_LINE y4 = coordinate [ 3 ] [ 1 ] NEW_LINE xmin = min ( x1 , x2 , x3 , x4 ) NEW_LINE ymin = min ( y1 , y2 , y3 , y4 ) NEW_LINE xmax = max ( x1 , x2 , x3 , x4 ) NEW_LINE ymax = max ( y1 , y2 , y3 , y4 ) NEW_LINE combinate = [ [ [ x1 , y1 ] , [ x2 , y2 ] , [ x3 , y3 ] , [ x4 , y4 ] ] , [ [ x2 , y2 ] , [ x3 , y3 ] , [ x4 , y4 ] , [ x1 , y1 ] ] , [ [ x3 , y3 ] , [ x4 , y4 ] , [ x1 , y1 ] , [ x2 , y2 ] ] , [ [ x4 , y4 ] , [ x1 , y1 ] , [ x2 , y2 ] , [ x3 , y3 ] ] ] NEW_LINE dst_coordinate = [ [ xmin , ymin ] , [ xmax , ymin ] , [ xmax , ymax ] , [ xmin , ymax ] ] NEW_LINE force = 100000000.0 NEW_LINE force_flag = 0 NEW_LINE for i in range ( 4 ) : NEW_LINE INDENT temp_force = cal_line_length ( combinate [ i ] [ 0 ] , dst_coordinate [ 0 ] ) + cal_line_length ( combinate [ i ] [ 1 ] , dst_coordinate [ 1 ] ) + cal_line_length ( combinate [ i ] [ 2 ] , dst_coordinate [ 2 ] ) + cal_line_length ( combinate [ i ] [ 3 ] , dst_coordinate [ 3 ] ) NEW_LINE if temp_force < force : NEW_LINE INDENT force = temp_force NEW_LINE force_flag = i NEW_LINE DEDENT DEDENT if force_flag != 0 : NEW_LINE INDENT print ( \" choose ▁ one ▁ direction ! \" ) NEW_LINE DEDENT return combinate [ force_flag ] NEW_LINE DEDENT',), ('def nonlinear_pred ( boxes , box_deltas ) : NEW_LINE INDENT if boxes . shape [ 0 ] == 0 : NEW_LINE INDENT return np . zeros ( ( 0 , box_deltas . shape [ 1 ] ) ) NEW_LINE DEDENT boxes = boxes . astype ( np . float , copy = False ) NEW_LINE widths = boxes [ : , 2 ] - boxes [ : , 0 ] + 1.0 NEW_LINE heights = boxes [ : , 3 ] - boxes [ : , 1 ] + 1.0 NEW_LINE ctr_x = boxes [ : , 0 ] + 0.5 * ( widths - 1.0 ) NEW_LINE ctr_y = boxes [ : , 1 ] + 0.5 * ( heights - 1.0 ) NEW_LINE dx = box_deltas [ : , 0 : : 4 ] NEW_LINE dy = box_deltas [ : , 1 : : 4 ] NEW_LINE dw = box_deltas [ : , 2 : : 4 ] NEW_LINE dh = box_deltas [ : , 3 : : 4 ] NEW_LINE pred_ctr_x = dx * widths [ : , np . newaxis ] + ctr_x [ : , np . newaxis ] NEW_LINE pred_ctr_y = dy * heights [ : , np . newaxis ] + ctr_y [ : , np . newaxis ] NEW_LINE pred_w = np . clip ( np . exp ( dw ) , - 60 , 60 ) * widths [ : , np . newaxis ] NEW_LINE pred_h = np . clip ( np . exp ( dh ) , - 60 , 60 ) * heights [ : , np . newaxis ] NEW_LINE pred_boxes = np . zeros ( box_deltas . shape ) NEW_LINE pred_boxes [ : , 0 : : 4 ] = pred_ctr_x - 0.5 * ( pred_w - 1.0 ) NEW_LINE pred_boxes [ : , 1 : : 4 ] = pred_ctr_y - 0.5 * ( pred_h - 1.0 ) NEW_LINE pred_boxes [ : , 2 : : 4 ] = pred_ctr_x + 0.5 * ( pred_w - 1.0 ) NEW_LINE pred_boxes [ : , 3 : : 4 ] = pred_ctr_y + 0.5 * ( pred_h - 1.0 ) NEW_LINE return pred_boxes NEW_LINE DEDENT',), (\"def iou_transform ( ex_rois , gt_rois ) : NEW_LINE INDENT assert ex_rois . shape [ 0 ] == gt_rois . shape [ 0 ] , ' inconsistent ▁ rois ▁ number ' NEW_LINE return gt_rois NEW_LINE DEDENT\",), ('def iou_pred ( boxes , box_deltas ) : NEW_LINE INDENT if boxes . shape [ 0 ] == 0 : NEW_LINE INDENT return np . zeros ( ( 0 , box_deltas . shape [ 1 ] ) ) NEW_LINE DEDENT boxes = boxes . astype ( np . float , copy = False ) NEW_LINE x1 = boxes [ : , 0 ] NEW_LINE y1 = boxes [ : , 1 ] NEW_LINE x2 = boxes [ : , 2 ] NEW_LINE y2 = boxes [ : , 3 ] NEW_LINE dx1 = box_deltas [ : , 0 : : 4 ] NEW_LINE dy1 = box_deltas [ : , 1 : : 4 ] NEW_LINE dx2 = box_deltas [ : , 2 : : 4 ] NEW_LINE dy2 = box_deltas [ : , 3 : : 4 ] NEW_LINE pred_boxes = np . zeros ( box_deltas . shape ) NEW_LINE pred_boxes [ : , 0 : : 4 ] = dx1 + x1 [ : , np . newaxis ] NEW_LINE pred_boxes [ : , 1 : : 4 ] = dy1 + y1 [ : , np . newaxis ] NEW_LINE pred_boxes [ : , 2 : : 4 ] = dx2 + x2 [ : , np . newaxis ] NEW_LINE pred_boxes [ : , 3 : : 4 ] = dy2 + y2 [ : , np . newaxis ] NEW_LINE return pred_boxes NEW_LINE DEDENT',), ('def expand_bbox_regression_targets ( bbox_targets_data , num_classes , cfg ) : NEW_LINE INDENT classes = bbox_targets_data [ : , 0 ] NEW_LINE if cfg . CLASS_AGNOSTIC : NEW_LINE INDENT num_classes = 2 NEW_LINE DEDENT bbox_targets = np . zeros ( ( classes . size , 4 * num_classes ) , dtype = np . float32 ) NEW_LINE bbox_weights = np . zeros ( bbox_targets . shape , dtype = np . float32 ) NEW_LINE indexes = np . where ( classes > 0 ) [ 0 ] NEW_LINE for index in indexes : NEW_LINE INDENT cls = classes [ index ] NEW_LINE start = int ( 4 * 1 if cls > 0 else 0 ) if cfg . CLASS_AGNOSTIC else int ( 4 * cls ) NEW_LINE end = start + 4 NEW_LINE bbox_targets [ index , start : end ] = bbox_targets_data [ index , 1 : ] NEW_LINE bbox_weights [ index , start : end ] = cfg . TRAIN . BBOX_WEIGHTS NEW_LINE DEDENT return bbox_targets , bbox_weights NEW_LINE DEDENT',), ('def expand_bbox_regression_targets_base ( bbox_targets_data , num_classes , cfg ) : NEW_LINE INDENT classes = bbox_targets_data [ : , 0 ] NEW_LINE if cfg . CLASS_AGNOSTIC : NEW_LINE INDENT num_classes = 2 NEW_LINE DEDENT coord_len = len ( bbox_targets_data [ 0 ] ) - 1 NEW_LINE bbox_targets = np . zeros ( ( classes . size , coord_len * num_classes ) , dtype = np . float32 ) NEW_LINE bbox_weights = np . zeros ( bbox_targets . shape , dtype = np . float32 ) NEW_LINE indexes = np . where ( classes > 0 ) [ 0 ] NEW_LINE for index in indexes : NEW_LINE INDENT cls = classes [ index ] NEW_LINE start = int ( coord_len * 1 if cls > 0 else 0 ) if cfg . CLASS_AGNOSTIC else int ( coord_len * cls ) NEW_LINE end = start + coord_len NEW_LINE bbox_targets [ index , start : end ] = bbox_targets_data [ index , 1 : ] NEW_LINE bbox_weights [ index , start : end ] = np . ones ( coord_len ) NEW_LINE DEDENT return bbox_targets , bbox_weights NEW_LINE DEDENT',), ('def expand_bbox_regression_targets_base_new ( bbox_targets_data , num_classes , class_agnostic ) : NEW_LINE INDENT classes = bbox_targets_data [ : , 0 ] NEW_LINE if class_agnostic : NEW_LINE INDENT num_classes = 2 NEW_LINE DEDENT coord_len = len ( bbox_targets_data [ 0 ] ) - 1 NEW_LINE bbox_targets = np . zeros ( ( classes . size , coord_len * num_classes ) , dtype = np . float32 ) NEW_LINE bbox_weights = np . zeros ( bbox_targets . shape , dtype = np . float32 ) NEW_LINE indexes = np . where ( classes > 0 ) [ 0 ] NEW_LINE for index in indexes : NEW_LINE INDENT cls = classes [ index ] NEW_LINE start = int ( coord_len * 1 if cls > 0 else 0 ) if class_agnostic else int ( coord_len * cls ) NEW_LINE end = start + coord_len NEW_LINE bbox_targets [ index , start : end ] = bbox_targets_data [ index , 1 : ] NEW_LINE bbox_weights [ index , start : end ] = np . ones ( coord_len ) NEW_LINE DEDENT return bbox_targets , bbox_weights NEW_LINE DEDENT',), ('def intersect_box_mask ( ex_box , gt_box , gt_mask ) : NEW_LINE INDENT x1 = max ( ex_box [ 0 ] , gt_box [ 0 ] ) NEW_LINE y1 = max ( ex_box [ 1 ] , gt_box [ 1 ] ) NEW_LINE x2 = min ( ex_box [ 2 ] , gt_box [ 2 ] ) NEW_LINE y2 = min ( ex_box [ 3 ] , gt_box [ 3 ] ) NEW_LINE if x1 > x2 or y1 > y2 : NEW_LINE INDENT return np . zeros ( ( 21 , 21 ) , dtype = bool ) NEW_LINE DEDENT w = x2 - x1 + 1 NEW_LINE h = y2 - y1 + 1 NEW_LINE ex_starty = y1 - ex_box [ 1 ] NEW_LINE ex_startx = x1 - ex_box [ 0 ] NEW_LINE inter_maskb = gt_mask [ y1 : y2 + 1 , x1 : x2 + 1 ] NEW_LINE regression_target = np . zeros ( ( ex_box [ 3 ] - ex_box [ 1 ] + 1 , ex_box [ 2 ] - ex_box [ 0 ] + 1 ) ) NEW_LINE regression_target [ ex_starty : ex_starty + h , ex_startx : ex_startx + w ] = inter_maskb NEW_LINE return regression_target NEW_LINE DEDENT',), ('def mask_overlap ( box1 , box2 , mask1 , mask2 ) : NEW_LINE INDENT x1 = max ( box1 [ 0 ] , box2 [ 0 ] ) NEW_LINE y1 = max ( box1 [ 1 ] , box2 [ 1 ] ) NEW_LINE x2 = min ( box1 [ 2 ] , box2 [ 2 ] ) NEW_LINE y2 = min ( box1 [ 3 ] , box2 [ 3 ] ) NEW_LINE if x1 > x2 or y1 > y2 : NEW_LINE INDENT return 0 NEW_LINE DEDENT w = x2 - x1 + 1 NEW_LINE h = y2 - y1 + 1 NEW_LINE start_ya = y1 - box1 [ 1 ] NEW_LINE start_xa = x1 - box1 [ 0 ] NEW_LINE inter_maska = mask1 [ start_ya : start_ya + h , start_xa : start_xa + w ] NEW_LINE start_yb = y1 - box2 [ 1 ] NEW_LINE start_xb = x1 - box2 [ 0 ] NEW_LINE inter_maskb = mask2 [ start_yb : start_yb + h , start_xb : start_xb + w ] NEW_LINE assert inter_maska . shape == inter_maskb . shape NEW_LINE inter = np . logical_and ( inter_maskb , inter_maska ) . sum ( ) NEW_LINE union = mask1 . sum ( ) + mask2 . sum ( ) - inter NEW_LINE if union < 1.0 : NEW_LINE INDENT return 0 NEW_LINE DEDENT return float ( inter ) / float ( union ) NEW_LINE DEDENT',), ('def choose_best_pointorder_fit_another ( poly1 , poly2 ) : NEW_LINE INDENT x1 = poly1 [ 0 ] NEW_LINE y1 = poly1 [ 1 ] NEW_LINE x2 = poly1 [ 2 ] NEW_LINE y2 = poly1 [ 3 ] NEW_LINE x3 = poly1 [ 4 ] NEW_LINE y3 = poly1 [ 5 ] NEW_LINE x4 = poly1 [ 6 ] NEW_LINE y4 = poly1 [ 7 ] NEW_LINE combinate = [ np . array ( [ x1 , y1 , x2 , y2 , x3 , y3 , x4 , y4 ] ) , np . array ( [ x2 , y2 , x3 , y3 , x4 , y4 , x1 , y1 ] ) , np . array ( [ x3 , y3 , x4 , y4 , x1 , y1 , x2 , y2 ] ) , np . array ( [ x4 , y4 , x1 , y1 , x2 , y2 , x3 , y3 ] ) ] NEW_LINE dst_coordinate = np . array ( poly2 ) NEW_LINE distances = np . array ( [ np . sum ( ( coord - dst_coordinate ) ** 2 ) for coord in combinate ] ) NEW_LINE sorted = distances . argsort ( ) NEW_LINE return combinate [ sorted [ 0 ] ] NEW_LINE DEDENT',), ('def cal_line_length ( point1 , point2 ) : NEW_LINE INDENT return math . sqrt ( math . pow ( point1 [ 0 ] - point2 [ 0 ] , 2 ) + math . pow ( point1 [ 1 ] - point2 [ 1 ] , 2 ) ) NEW_LINE DEDENT',), ('def split_single_warp ( name , split_base , rate , extent ) : NEW_LINE INDENT split_base . SplitSingle ( name , rate , extent ) NEW_LINE DEDENT',), (\"def __init__ ( self , basepath , outpath , code = ' utf - 8' , gap = 512 , subsize = 1024 , thresh = 0.7 , choosebestpoint = True , ext = ' . png ' , padding = True , num_process = 8 ) : NEW_LINE INDENT self . basepath = basepath NEW_LINE self . outpath = outpath NEW_LINE self . code = code NEW_LINE self . gap = gap NEW_LINE self . subsize = subsize NEW_LINE self . slide = self . subsize - self . gap NEW_LINE self . thresh = thresh NEW_LINE self . imagepath = os . path . join ( self . basepath , ' images ' ) NEW_LINE self . labelpath = os . path . join ( self . basepath , ' labelTxt ' ) NEW_LINE self . outimagepath = os . path . join ( self . outpath , ' images ' ) NEW_LINE self . outlabelpath = os . path . join ( self . outpath , ' labelTxt ' ) NEW_LINE self . choosebestpoint = choosebestpoint NEW_LINE self . ext = ext NEW_LINE self . padding = padding NEW_LINE self . num_process = num_process NEW_LINE self . pool = Pool ( num_process ) NEW_LINE print ( ' padding : ' , padding ) NEW_LINE if not os . path . isdir ( self . outpath ) : NEW_LINE INDENT os . mkdir ( self . outpath ) NEW_LINE DEDENT if not os . path . isdir ( self . outimagepath ) : NEW_LINE INDENT os . mkdir ( self . outimagepath ) NEW_LINE DEDENT if not os . path . isdir ( self . outlabelpath ) : NEW_LINE INDENT os . mkdir ( self . outlabelpath ) NEW_LINE DEDENT DEDENT\",), ('def polyorig2sub ( self , left , up , poly ) : NEW_LINE INDENT polyInsub = np . zeros ( len ( poly ) ) NEW_LINE for i in range ( int ( len ( poly ) / 2 ) ) : NEW_LINE INDENT polyInsub [ i * 2 ] = int ( poly [ i * 2 ] - left ) NEW_LINE polyInsub [ i * 2 + 1 ] = int ( poly [ i * 2 + 1 ] - up ) NEW_LINE DEDENT return polyInsub NEW_LINE DEDENT',), ('def calchalf_iou ( self , poly1 , poly2 ) : NEW_LINE INDENT inter_poly = poly1 . intersection ( poly2 ) NEW_LINE inter_area = inter_poly . area NEW_LINE poly1_area = poly1 . area NEW_LINE half_iou = inter_area / poly1_area NEW_LINE return inter_poly , half_iou NEW_LINE DEDENT',), ('def saveimagepatches ( self , img , subimgname , left , up ) : NEW_LINE INDENT subimg = copy . deepcopy ( img [ up : ( up + self . subsize ) , left : ( left + self . subsize ) ] ) NEW_LINE outdir = os . path . join ( self . outimagepath , subimgname + self . ext ) NEW_LINE h , w , c = np . shape ( subimg ) NEW_LINE if ( self . padding ) : NEW_LINE INDENT outimg = np . zeros ( ( self . subsize , self . subsize , 3 ) ) NEW_LINE outimg [ 0 : h , 0 : w , : ] = subimg NEW_LINE cv2 . imwrite ( outdir , outimg ) NEW_LINE DEDENT else : NEW_LINE INDENT cv2 . imwrite ( outdir , subimg ) NEW_LINE DEDENT DEDENT',), ('def GetPoly4FromPoly5 ( self , poly ) : NEW_LINE INDENT distances = [ cal_line_length ( ( poly [ i * 2 ] , poly [ i * 2 + 1 ] ) , ( poly [ ( i + 1 ) * 2 ] , poly [ ( i + 1 ) * 2 + 1 ] ) ) for i in range ( int ( len ( poly ) / 2 - 1 ) ) ] NEW_LINE distances . append ( cal_line_length ( ( poly [ 0 ] , poly [ 1 ] ) , ( poly [ 8 ] , poly [ 9 ] ) ) ) NEW_LINE pos = np . array ( distances ) . argsort ( ) [ 0 ] NEW_LINE count = 0 NEW_LINE outpoly = [ ] NEW_LINE while count < 5 : NEW_LINE INDENT if ( count == pos ) : NEW_LINE INDENT outpoly . append ( ( poly [ count * 2 ] + poly [ ( count * 2 + 2 ) % 10 ] ) / 2 ) NEW_LINE outpoly . append ( ( poly [ ( count * 2 + 1 ) % 10 ] + poly [ ( count * 2 + 3 ) % 10 ] ) / 2 ) NEW_LINE count = count + 1 NEW_LINE DEDENT elif ( count == ( pos + 1 ) % 5 ) : NEW_LINE INDENT count = count + 1 NEW_LINE continue NEW_LINE DEDENT else : NEW_LINE INDENT outpoly . append ( poly [ count * 2 ] ) NEW_LINE outpoly . append ( poly [ count * 2 + 1 ] ) NEW_LINE count = count + 1 NEW_LINE DEDENT DEDENT return outpoly NEW_LINE DEDENT',), (\"def savepatches ( self , resizeimg , objects , subimgname , left , up , right , down ) : NEW_LINE INDENT outdir = os . path . join ( self . outlabelpath , subimgname + ' . txt ' ) NEW_LINE mask_poly = [ ] NEW_LINE imgpoly = shgeo . Polygon ( [ ( left , up ) , ( right , up ) , ( right , down ) , ( left , down ) ] ) NEW_LINE with codecs . open ( outdir , ' w ' , self . code ) as f_out : NEW_LINE INDENT for obj in objects : NEW_LINE INDENT gtpoly = shgeo . Polygon ( [ ( obj [ ' poly ' ] [ 0 ] , obj [ ' poly ' ] [ 1 ] ) , ( obj [ ' poly ' ] [ 2 ] , obj [ ' poly ' ] [ 3 ] ) , ( obj [ ' poly ' ] [ 4 ] , obj [ ' poly ' ] [ 5 ] ) , ( obj [ ' poly ' ] [ 6 ] , obj [ ' poly ' ] [ 7 ] ) ] ) NEW_LINE if ( gtpoly . area <= 0 ) : NEW_LINE INDENT continue NEW_LINE DEDENT inter_poly , half_iou = self . calchalf_iou ( gtpoly , imgpoly ) NEW_LINE if ( half_iou == 1 ) : NEW_LINE INDENT polyInsub = self . polyorig2sub ( left , up , obj [ ' poly ' ] ) NEW_LINE outline = ' ▁ ' . join ( list ( map ( str , polyInsub ) ) ) NEW_LINE outline = outline + ' ▁ ' + obj [ ' name ' ] + ' ▁ ' + str ( obj [ ' difficult ' ] ) NEW_LINE f_out . write ( outline + ' \\\\n ' ) NEW_LINE DEDENT elif ( half_iou > 0 ) : NEW_LINE INDENT inter_poly = shgeo . polygon . orient ( inter_poly , sign = 1 ) NEW_LINE out_poly = list ( inter_poly . exterior . coords ) [ 0 : - 1 ] NEW_LINE if len ( out_poly ) < 4 : NEW_LINE INDENT continue NEW_LINE DEDENT out_poly2 = [ ] NEW_LINE for i in range ( len ( out_poly ) ) : NEW_LINE INDENT out_poly2 . append ( out_poly [ i ] [ 0 ] ) NEW_LINE out_poly2 . append ( out_poly [ i ] [ 1 ] ) NEW_LINE DEDENT if ( len ( out_poly ) == 5 ) : NEW_LINE INDENT out_poly2 = self . GetPoly4FromPoly5 ( out_poly2 ) NEW_LINE DEDENT elif ( len ( out_poly ) > 5 ) : NEW_LINE INDENT continue NEW_LINE DEDENT if ( self . choosebestpoint ) : NEW_LINE INDENT out_poly2 = choose_best_pointorder_fit_another ( out_poly2 , obj [ ' poly ' ] ) NEW_LINE DEDENT polyInsub = self . polyorig2sub ( left , up , out_poly2 ) NEW_LINE for index , item in enumerate ( polyInsub ) : NEW_LINE INDENT if ( item <= 1 ) : NEW_LINE INDENT polyInsub [ index ] = 1 NEW_LINE DEDENT elif ( item >= self . subsize ) : NEW_LINE INDENT polyInsub [ index ] = self . subsize NEW_LINE DEDENT DEDENT outline = ' ▁ ' . join ( list ( map ( str , polyInsub ) ) ) NEW_LINE if ( half_iou > self . thresh ) : NEW_LINE INDENT outline = outline + ' ▁ ' + obj [ ' name ' ] + ' ▁ ' + str ( obj [ ' difficult ' ] ) NEW_LINE DEDENT else : NEW_LINE INDENT outline = outline + ' ▁ ' + obj [ ' name ' ] + ' ▁ ' + '2' NEW_LINE DEDENT f_out . write ( outline + ' \\\\n ' ) NEW_LINE DEDENT DEDENT DEDENT self . saveimagepatches ( resizeimg , subimgname , left , up ) NEW_LINE DEDENT\",), (\"def SplitSingle ( self , name , rate , extent ) : NEW_LINE INDENT img = cv2 . imread ( os . path . join ( self . imagepath , name + extent ) ) NEW_LINE if np . shape ( img ) == ( ) : NEW_LINE INDENT return NEW_LINE DEDENT fullname = os . path . join ( self . labelpath , name + ' . txt ' ) NEW_LINE objects = util . parse_dota_poly2 ( fullname ) NEW_LINE for obj in objects : NEW_LINE INDENT obj [ ' poly ' ] = list ( map ( lambda x : rate * x , obj [ ' poly ' ] ) ) NEW_LINE DEDENT if ( rate != 1 ) : NEW_LINE INDENT resizeimg = cv2 . resize ( img , None , fx = rate , fy = rate , interpolation = cv2 . INTER_CUBIC ) NEW_LINE DEDENT else : NEW_LINE INDENT resizeimg = img NEW_LINE DEDENT outbasename = name + ' _ _ ' + str ( rate ) + ' _ _ ' NEW_LINE weight = np . shape ( resizeimg ) [ 1 ] NEW_LINE height = np . shape ( resizeimg ) [ 0 ] NEW_LINE left , up = 0 , 0 NEW_LINE while ( left < weight ) : NEW_LINE INDENT if ( left + self . subsize >= weight ) : NEW_LINE INDENT left = max ( weight - self . subsize , 0 ) NEW_LINE DEDENT up = 0 NEW_LINE while ( up < height ) : NEW_LINE INDENT if ( up + self . subsize >= height ) : NEW_LINE INDENT up = max ( height - self . subsize , 0 ) NEW_LINE DEDENT right = min ( left + self . subsize , weight - 1 ) NEW_LINE down = min ( up + self . subsize , height - 1 ) NEW_LINE subimgname = outbasename + str ( left ) + ' _ _ _ ' + str ( up ) NEW_LINE self . savepatches ( resizeimg , objects , subimgname , left , up , right , down ) NEW_LINE if ( up + self . subsize >= height ) : NEW_LINE INDENT break NEW_LINE DEDENT else : NEW_LINE INDENT up = up + self . slide NEW_LINE DEDENT DEDENT if ( left + self . subsize >= weight ) : NEW_LINE INDENT break NEW_LINE DEDENT else : NEW_LINE INDENT left = left + self . slide NEW_LINE DEDENT DEDENT DEDENT\",), (\"def splitdata ( self , rate ) : NEW_LINE INDENT imagelist = GetFileFromThisRootDir ( self . imagepath ) NEW_LINE imagenames = [ util . custombasename ( x ) for x in imagelist if ( util . custombasename ( x ) != ' Thumbs ' ) ] NEW_LINE if self . num_process == 1 : NEW_LINE INDENT for name in imagenames : NEW_LINE INDENT self . SplitSingle ( name , rate , self . ext ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT worker = partial ( split_single_warp , split_base = self , rate = rate , extent = self . ext ) NEW_LINE self . pool . map ( worker , imagenames ) NEW_LINE DEDENT DEDENT\",), (\"def __getstate__ ( self ) : NEW_LINE INDENT self_dict = self . __dict__ . copy ( ) NEW_LINE del self_dict [ ' pool ' ] NEW_LINE return self_dict NEW_LINE DEDENT\",), ('def __setstate__ ( self , state ) : NEW_LINE INDENT self . __dict__ . update ( state ) NEW_LINE DEDENT',), ('def split_single_warp ( name , split_base , rate , extent ) : NEW_LINE INDENT split_base . SplitSingle ( name , rate , extent ) NEW_LINE DEDENT',), (\"def __init__ ( self , srcpath , dstpath , gap = 100 , subsize = 1024 , ext = ' . png ' , padding = True , num_process = 32 ) : NEW_LINE INDENT self . srcpath = srcpath NEW_LINE self . outpath = dstpath NEW_LINE self . gap = gap NEW_LINE self . subsize = subsize NEW_LINE self . slide = self . subsize - self . gap NEW_LINE self . srcpath = srcpath NEW_LINE self . dstpath = dstpath NEW_LINE self . ext = ext NEW_LINE self . padding = padding NEW_LINE self . pool = Pool ( num_process ) NEW_LINE if not os . path . isdir ( self . outpath ) : NEW_LINE INDENT os . mkdir ( self . outpath ) NEW_LINE DEDENT DEDENT\",), (\"def saveimagepatches ( self , img , subimgname , left , up , ext = ' . png ' ) : NEW_LINE INDENT subimg = copy . deepcopy ( img [ up : ( up + self . subsize ) , left : ( left + self . subsize ) ] ) NEW_LINE outdir = os . path . join ( self . dstpath , subimgname + ext ) NEW_LINE h , w , c = np . shape ( subimg ) NEW_LINE if ( self . padding ) : NEW_LINE INDENT outimg = np . zeros ( ( self . subsize , self . subsize , 3 ) ) NEW_LINE outimg [ 0 : h , 0 : w , : ] = subimg NEW_LINE cv2 . imwrite ( outdir , outimg ) NEW_LINE DEDENT else : NEW_LINE INDENT cv2 . imwrite ( outdir , subimg ) NEW_LINE DEDENT DEDENT\",), (\"def SplitSingle ( self , name , rate , extent ) : NEW_LINE INDENT img = cv2 . imread ( os . path . join ( self . srcpath , name + extent ) ) NEW_LINE assert np . shape ( img ) != ( ) NEW_LINE if ( rate != 1 ) : NEW_LINE INDENT resizeimg = cv2 . resize ( img , None , fx = rate , fy = rate , interpolation = cv2 . INTER_CUBIC ) NEW_LINE DEDENT else : NEW_LINE INDENT resizeimg = img NEW_LINE DEDENT outbasename = name + ' _ _ ' + str ( rate ) + ' _ _ ' NEW_LINE weight = np . shape ( resizeimg ) [ 1 ] NEW_LINE height = np . shape ( resizeimg ) [ 0 ] NEW_LINE left , up = 0 , 0 NEW_LINE while ( left < weight ) : NEW_LINE INDENT if ( left + self . subsize >= weight ) : NEW_LINE INDENT left = max ( weight - self . subsize , 0 ) NEW_LINE DEDENT up = 0 NEW_LINE while ( up < height ) : NEW_LINE INDENT if ( up + self . subsize >= height ) : NEW_LINE INDENT up = max ( height - self . subsize , 0 ) NEW_LINE DEDENT subimgname = outbasename + str ( left ) + ' _ _ _ ' + str ( up ) NEW_LINE self . saveimagepatches ( resizeimg , subimgname , left , up ) NEW_LINE if ( up + self . subsize >= height ) : NEW_LINE INDENT break NEW_LINE DEDENT else : NEW_LINE INDENT up = up + self . slide NEW_LINE DEDENT DEDENT if ( left + self . subsize >= weight ) : NEW_LINE INDENT break NEW_LINE DEDENT else : NEW_LINE INDENT left = left + self . slide NEW_LINE DEDENT DEDENT DEDENT\",), (\"def splitdata ( self , rate ) : NEW_LINE INDENT imagelist = util . GetFileFromThisRootDir ( self . srcpath ) NEW_LINE imagenames = [ util . custombasename ( x ) for x in imagelist if ( util . custombasename ( x ) != ' Thumbs ' ) ] NEW_LINE worker = partial ( split_single_warp , split_base = self , rate = rate , extent = self . ext ) NEW_LINE self . pool . map ( worker , imagenames ) NEW_LINE DEDENT\",), (\"def __getstate__ ( self ) : NEW_LINE INDENT self_dict = self . __dict__ . copy ( ) NEW_LINE del self_dict [ ' pool ' ] NEW_LINE return self_dict NEW_LINE DEDENT\",), ('def __setstate__ ( self , state ) : NEW_LINE INDENT self . __dict__ . update ( state ) NEW_LINE DEDENT',), ('def custombasename ( fullname ) : NEW_LINE INDENT return os . path . basename ( os . path . splitext ( fullname ) [ 0 ] ) NEW_LINE DEDENT',), ('def GetFileFromThisRootDir ( dir , ext = None ) : NEW_LINE INDENT allfiles = [ ] NEW_LINE needExtFilter = ( ext != None ) NEW_LINE for root , dirs , files in os . walk ( dir ) : NEW_LINE INDENT for filespath in files : NEW_LINE INDENT filepath = os . path . join ( root , filespath ) NEW_LINE extension = os . path . splitext ( filepath ) [ 1 ] [ 1 : ] NEW_LINE if needExtFilter and extension in ext : NEW_LINE INDENT allfiles . append ( filepath ) NEW_LINE DEDENT elif not needExtFilter : NEW_LINE INDENT allfiles . append ( filepath ) NEW_LINE DEDENT DEDENT DEDENT return allfiles NEW_LINE DEDENT',), ('def TuplePoly2Poly ( poly ) : NEW_LINE INDENT outpoly = [ poly [ 0 ] [ 0 ] , poly [ 0 ] [ 1 ] , poly [ 1 ] [ 0 ] , poly [ 1 ] [ 1 ] , poly [ 2 ] [ 0 ] , poly [ 2 ] [ 1 ] , poly [ 3 ] [ 0 ] , poly [ 3 ] [ 1 ] ] NEW_LINE return outpoly NEW_LINE DEDENT',), (\"def parse_dota_poly ( filename ) : NEW_LINE INDENT objects = [ ] NEW_LINE f = [ ] NEW_LINE if ( sys . version_info >= ( 3 , 5 ) ) : NEW_LINE INDENT fd = open ( filename , ' r ' ) NEW_LINE f = fd NEW_LINE DEDENT elif ( sys . version_info >= 2.7 ) : NEW_LINE INDENT fd = codecs . open ( filename , ' r ' ) NEW_LINE f = fd NEW_LINE DEDENT while True : NEW_LINE INDENT line = f . readline ( ) NEW_LINE if line : NEW_LINE INDENT splitlines = line . strip ( ) . split ( ' ▁ ' ) NEW_LINE object_struct = { } NEW_LINE if ( len ( splitlines ) < 9 ) : NEW_LINE INDENT continue NEW_LINE DEDENT if ( len ( splitlines ) >= 9 ) : NEW_LINE INDENT object_struct [ ' name ' ] = splitlines [ 8 ] NEW_LINE DEDENT if ( len ( splitlines ) == 9 ) : NEW_LINE INDENT object_struct [ ' difficult ' ] = '0' NEW_LINE DEDENT elif ( len ( splitlines ) >= 10 ) : NEW_LINE INDENT object_struct [ ' difficult ' ] = splitlines [ 9 ] NEW_LINE DEDENT object_struct [ ' poly ' ] = [ ( float ( splitlines [ 0 ] ) , float ( splitlines [ 1 ] ) ) , ( float ( splitlines [ 2 ] ) , float ( splitlines [ 3 ] ) ) , ( float ( splitlines [ 4 ] ) , float ( splitlines [ 5 ] ) ) , ( float ( splitlines [ 6 ] ) , float ( splitlines [ 7 ] ) ) ] NEW_LINE gtpoly = shgeo . Polygon ( object_struct [ ' poly ' ] ) NEW_LINE object_struct [ ' area ' ] = gtpoly . area NEW_LINE objects . append ( object_struct ) NEW_LINE DEDENT else : NEW_LINE INDENT break NEW_LINE DEDENT DEDENT return objects NEW_LINE DEDENT\",), (\"def parse_dota_poly2 ( filename ) : NEW_LINE INDENT objects = parse_dota_poly ( filename ) NEW_LINE for obj in objects : NEW_LINE INDENT obj [ ' poly ' ] = TuplePoly2Poly ( obj [ ' poly ' ] ) NEW_LINE obj [ ' poly ' ] = list ( map ( int , obj [ ' poly ' ] ) ) NEW_LINE DEDENT return objects NEW_LINE DEDENT\",), (\"def parse_dota_rec ( filename ) : NEW_LINE INDENT objects = parse_dota_poly ( filename ) NEW_LINE for obj in objects : NEW_LINE INDENT poly = obj [ ' poly ' ] NEW_LINE bbox = dots4ToRec4 ( poly ) NEW_LINE obj [ ' bndbox ' ] = bbox NEW_LINE DEDENT return objects NEW_LINE DEDENT\",), ('def dots4ToRec4 ( poly ) : NEW_LINE INDENT xmin , xmax , ymin , ymax = min ( poly [ 0 ] [ 0 ] , min ( poly [ 1 ] [ 0 ] , min ( poly [ 2 ] [ 0 ] , poly [ 3 ] [ 0 ] ) ) ) , max ( poly [ 0 ] [ 0 ] , max ( poly [ 1 ] [ 0 ] , max ( poly [ 2 ] [ 0 ] , poly [ 3 ] [ 0 ] ) ) ) , min ( poly [ 0 ] [ 1 ] , min ( poly [ 1 ] [ 1 ] , min ( poly [ 2 ] [ 1 ] , poly [ 3 ] [ 1 ] ) ) ) , max ( poly [ 0 ] [ 1 ] , max ( poly [ 1 ] [ 1 ] , max ( poly [ 2 ] [ 1 ] , poly [ 3 ] [ 1 ] ) ) ) NEW_LINE return xmin , ymin , xmax , ymax NEW_LINE DEDENT',), ('def dots4ToRec8 ( poly ) : NEW_LINE INDENT xmin , ymin , xmax , ymax = dots4ToRec4 ( poly ) NEW_LINE return xmin , ymin , xmax , ymin , xmax , ymax , xmin , ymax NEW_LINE DEDENT',), ('def dots2ToRec8 ( rec ) : NEW_LINE INDENT xmin , ymin , xmax , ymax = rec [ 0 ] , rec [ 1 ] , rec [ 2 ] , rec [ 3 ] NEW_LINE return xmin , ymin , xmax , ymin , xmax , ymax , xmin , ymax NEW_LINE DEDENT',), (\"def groundtruth2Task1 ( srcpath , dstpath ) : NEW_LINE INDENT filelist = GetFileFromThisRootDir ( srcpath ) NEW_LINE filedict = { } NEW_LINE for cls in wordname_15 : NEW_LINE INDENT fd = open ( os . path . join ( dstpath , ' Task1 _ ' ) + cls + r' . txt ' , ' w ' ) NEW_LINE filedict [ cls ] = fd NEW_LINE DEDENT for filepath in filelist : NEW_LINE INDENT objects = parse_dota_poly2 ( filepath ) NEW_LINE subname = custombasename ( filepath ) NEW_LINE pattern2 = re . compile ( r' _ _ ( [ \\\\d + \\\\ . ] + ) _ _ \\\\d + _ _ _ ' ) NEW_LINE rate = re . findall ( pattern2 , subname ) [ 0 ] NEW_LINE for obj in objects : NEW_LINE INDENT category = obj [ ' name ' ] NEW_LINE difficult = obj [ ' difficult ' ] NEW_LINE poly = obj [ ' poly ' ] NEW_LINE if difficult == '2' : NEW_LINE INDENT continue NEW_LINE DEDENT if rate == '0.5' : NEW_LINE INDENT outline = custombasename ( filepath ) + ' ▁ ' + '1' + ' ▁ ' + ' ▁ ' . join ( map ( str , poly ) ) NEW_LINE DEDENT elif rate == '1' : NEW_LINE INDENT outline = custombasename ( filepath ) + ' ▁ ' + '0.8' + ' ▁ ' + ' ▁ ' . join ( map ( str , poly ) ) NEW_LINE DEDENT elif rate == '2' : NEW_LINE INDENT outline = custombasename ( filepath ) + ' ▁ ' + '0.6' + ' ▁ ' + ' ▁ ' . join ( map ( str , poly ) ) NEW_LINE DEDENT filedict [ category ] . write ( outline + ' \\\\n ' ) NEW_LINE DEDENT DEDENT DEDENT\",), (\"def Task2groundtruth_poly ( srcpath , dstpath ) : NEW_LINE INDENT thresh = 0.1 NEW_LINE filedict = { } NEW_LINE Tasklist = GetFileFromThisRootDir ( srcpath , ' . txt ' ) NEW_LINE for Taskfile in Tasklist : NEW_LINE INDENT idname = custombasename ( Taskfile ) . split ( ' _ ' ) [ - 1 ] NEW_LINE f = open ( Taskfile , ' r ' ) NEW_LINE lines = f . readlines ( ) NEW_LINE for line in lines : NEW_LINE INDENT if len ( line ) == 0 : NEW_LINE INDENT continue NEW_LINE DEDENT splitline = line . strip ( ) . split ( ' ▁ ' ) NEW_LINE filename = splitline [ 0 ] NEW_LINE confidence = splitline [ 1 ] NEW_LINE bbox = splitline [ 2 : ] NEW_LINE if float ( confidence ) > thresh : NEW_LINE INDENT if filename not in filedict : NEW_LINE INDENT filedict [ filename ] = codecs . open ( os . path . join ( dstpath , filename + ' . txt ' ) , ' w ' ) NEW_LINE DEDENT poly = bbox NEW_LINE filedict [ filename ] . write ( ' ▁ ' . join ( poly ) + ' ▁ ' + idname + ' \\\\n ' ) NEW_LINE DEDENT DEDENT DEDENT DEDENT\",), (\"def polygonToRotRectangle ( bbox ) : NEW_LINE INDENT bbox = np . array ( bbox , dtype = np . float32 ) NEW_LINE bbox = np . reshape ( bbox , newshape = ( 2 , 4 ) , order = ' F ' ) NEW_LINE angle = math . atan2 ( - ( bbox [ 0 , 1 ] - bbox [ 0 , 0 ] ) , bbox [ 1 , 1 ] - bbox [ 1 , 0 ] ) NEW_LINE center = [ [ 0 ] , [ 0 ] ] NEW_LINE for i in range ( 4 ) : NEW_LINE INDENT center [ 0 ] += bbox [ 0 , i ] NEW_LINE center [ 1 ] += bbox [ 1 , i ] NEW_LINE DEDENT center = np . array ( center , dtype = np . float32 ) / 4.0 NEW_LINE R = np . array ( [ [ math . cos ( angle ) , - math . sin ( angle ) ] , [ math . sin ( angle ) , math . cos ( angle ) ] ] , dtype = np . float32 ) NEW_LINE normalized = np . matmul ( R . transpose ( ) , bbox - center ) NEW_LINE xmin = np . min ( normalized [ 0 , : ] ) NEW_LINE xmax = np . max ( normalized [ 0 , : ] ) NEW_LINE ymin = np . min ( normalized [ 1 , : ] ) NEW_LINE ymax = np . max ( normalized [ 1 , : ] ) NEW_LINE w = xmax - xmin + 1 NEW_LINE h = ymax - ymin + 1 NEW_LINE return [ float ( center [ 0 ] ) , float ( center [ 1 ] ) , w , h , angle ] NEW_LINE DEDENT\",), ('def cal_line_length ( point1 , point2 ) : NEW_LINE INDENT return math . sqrt ( math . pow ( point1 [ 0 ] - point2 [ 0 ] , 2 ) + math . pow ( point1 [ 1 ] - point2 [ 1 ] , 2 ) ) NEW_LINE DEDENT',), ('def get_best_begin_point ( coordinate ) : NEW_LINE INDENT x1 = coordinate [ 0 ] [ 0 ] NEW_LINE y1 = coordinate [ 0 ] [ 1 ] NEW_LINE x2 = coordinate [ 1 ] [ 0 ] NEW_LINE y2 = coordinate [ 1 ] [ 1 ] NEW_LINE x3 = coordinate [ 2 ] [ 0 ] NEW_LINE y3 = coordinate [ 2 ] [ 1 ] NEW_LINE x4 = coordinate [ 3 ] [ 0 ] NEW_LINE y4 = coordinate [ 3 ] [ 1 ] NEW_LINE xmin = min ( x1 , x2 , x3 , x4 ) NEW_LINE ymin = min ( y1 , y2 , y3 , y4 ) NEW_LINE xmax = max ( x1 , x2 , x3 , x4 ) NEW_LINE ymax = max ( y1 , y2 , y3 , y4 ) NEW_LINE combinate = [ [ [ x1 , y1 ] , [ x2 , y2 ] , [ x3 , y3 ] , [ x4 , y4 ] ] , [ [ x2 , y2 ] , [ x3 , y3 ] , [ x4 , y4 ] , [ x1 , y1 ] ] , [ [ x3 , y3 ] , [ x4 , y4 ] , [ x1 , y1 ] , [ x2 , y2 ] ] , [ [ x4 , y4 ] , [ x1 , y1 ] , [ x2 , y2 ] , [ x3 , y3 ] ] ] NEW_LINE dst_coordinate = [ [ xmin , ymin ] , [ xmax , ymin ] , [ xmax , ymax ] , [ xmin , ymax ] ] NEW_LINE force = 100000000.0 NEW_LINE force_flag = 0 NEW_LINE for i in range ( 4 ) : NEW_LINE INDENT temp_force = cal_line_length ( combinate [ i ] [ 0 ] , dst_coordinate [ 0 ] ) + cal_line_length ( combinate [ i ] [ 1 ] , dst_coordinate [ 1 ] ) + cal_line_length ( combinate [ i ] [ 2 ] , dst_coordinate [ 2 ] ) + cal_line_length ( combinate [ i ] [ 3 ] , dst_coordinate [ 3 ] ) NEW_LINE if temp_force < force : NEW_LINE INDENT force = temp_force NEW_LINE force_flag = i NEW_LINE DEDENT DEDENT if force_flag != 0 : NEW_LINE INDENT print ( \" choose ▁ one ▁ direction ! \" ) NEW_LINE DEDENT return combinate [ force_flag ] NEW_LINE DEDENT',), (\"def parse_args ( ) : NEW_LINE INDENT parser = argparse . ArgumentParser ( description = ' Preprae ▁ data ' ) NEW_LINE parser . add_argument ( ' - - data _ path ' , help = ' the ▁ root ▁ ▁ ▁ ▁ path ▁ stored ▁ the ▁ dota ▁ data ' ) NEW_LINE parser . add_argument ( ' - - num _ process ' , type = int , help = ' the ▁ num ▁ of ▁ process ▁ used ▁ to ▁ prepare ▁ data ' ) NEW_LINE args = parser . parse_args ( ) NEW_LINE return args NEW_LINE DEDENT\",), ('def filecopy_single ( path_tuple ) : NEW_LINE INDENT srcdir , dstdir = path_tuple [ 0 ] , path_tuple [ 1 ] NEW_LINE if os . path . exists ( srcdir ) : NEW_LINE INDENT shutil . copyfile ( srcdir , dstdir ) NEW_LINE DEDENT DEDENT',), ('def filecopy ( srcpath , dstpath , filenames , extent , num_process = 32 ) : NEW_LINE INDENT path_pair_list = [ ] NEW_LINE for name in filenames : NEW_LINE INDENT srcdir = os . path . join ( srcpath , name + extent ) NEW_LINE dstdir = os . path . join ( dstpath , name + extent ) NEW_LINE path_pair_list . append ( ( srcdir , dstdir ) ) NEW_LINE DEDENT copy_pool = Pool ( num_process ) NEW_LINE copy_pool . map ( filecopy_single , path_pair_list ) NEW_LINE DEDENT',), ('def filecopy_v2 ( srcpath , dstpath , num_process = 32 ) : NEW_LINE INDENT filenames = util . GetFileFromThisRootDir ( srcpath ) NEW_LINE filenames = [ os . path . basename ( x . strip ( ) ) for x in filenames ] NEW_LINE path_pair_list = [ ] NEW_LINE for name in filenames : NEW_LINE INDENT srcdir = os . path . join ( srcpath , name ) NEW_LINE dstdir = os . path . join ( dstpath , name ) NEW_LINE path_pair_list . append ( ( srcdir , dstdir ) ) NEW_LINE DEDENT copy_pool = Pool ( num_process ) NEW_LINE copy_pool . map ( filecopy_single , path_pair_list ) NEW_LINE DEDENT',), ('def filemove_single ( path_tuple ) : NEW_LINE INDENT srcdir , dstdir = path_tuple [ 0 ] , path_tuple [ 1 ] NEW_LINE if os . path . exists ( srcdir ) : NEW_LINE INDENT shutil . move ( srcdir , dstdir ) NEW_LINE DEDENT DEDENT',), ('def filemove ( srcpath , dstpath , filenames , extent , num_process = 32 ) : NEW_LINE INDENT path_pair_list = [ ] NEW_LINE for name in filenames : NEW_LINE INDENT srcdir = os . path . join ( srcpath , name + extent ) NEW_LINE dstdir = os . path . join ( dstpath , name + extent ) NEW_LINE path_pair_list . append ( ( srcdir , dstdir ) ) NEW_LINE DEDENT move_pool = Pool ( num_process ) NEW_LINE move_pool . map ( filemove_single , path_pair_list ) NEW_LINE DEDENT',), (\"def filemove_v2 ( srcpath , dstpath , extent , num_process = 32 ) : NEW_LINE INDENT filelist = util . GetFileFromThisRootDir ( srcpath ) NEW_LINE filenames = [ util . custombasename ( x . strip ( ) ) for x in filelist ] NEW_LINE print ( ' srcpath : ▁ ' , srcpath ) NEW_LINE print ( ' num : ▁ ' , len ( filenames ) ) NEW_LINE filemove ( srcpath , dstpath , filenames , extent , num_process ) NEW_LINE DEDENT\",), (\"def extract_largesize_index ( labelpath ) : NEW_LINE INDENT filenames = util . GetFileFromThisRootDir ( labelpath ) NEW_LINE large_size_index = [ ] NEW_LINE for name in filenames : NEW_LINE INDENT objs = util . parse_dota_poly ( name ) NEW_LINE flag = 0 NEW_LINE for obj in objs : NEW_LINE INDENT poly = np . array ( obj [ ' poly ' ] ) NEW_LINE xmin , ymin , xmax , ymax = np . min ( poly [ : , 0 ] ) , np . min ( poly [ : , 1 ] ) , np . max ( poly [ : , 0 ] ) , np . max ( poly [ : , 1 ] ) NEW_LINE w = xmax - xmin NEW_LINE h = ymax - ymin NEW_LINE max_side = max ( w , h ) NEW_LINE if max_side > 400 : NEW_LINE INDENT flag = 1 NEW_LINE break NEW_LINE DEDENT DEDENT if flag : NEW_LINE INDENT large_size_index . append ( util . custombasename ( name ) ) NEW_LINE DEDENT DEDENT return large_size_index NEW_LINE DEDENT\",), ('def rotate_matrix ( theta ) : NEW_LINE INDENT return np . array ( [ [ np . cos ( theta ) , np . sin ( theta ) ] , [ - np . sin ( theta ) , np . cos ( theta ) ] ] ) NEW_LINE DEDENT',), (\"def rotate_single_run ( name , srcpath , dstpath ) : NEW_LINE INDENT src_imgpath = os . path . join ( srcpath , ' images ' ) NEW_LINE dst_imgpath = os . path . join ( dstpath , ' images ' ) NEW_LINE src_labelTxt = os . path . join ( srcpath , ' labelTxt ' ) NEW_LINE dst_labelTxt = os . path . join ( dstpath , ' labelTxt ' ) NEW_LINE objs = util . parse_dota_poly2 ( os . path . join ( src_labelTxt , name + ' . txt ' ) ) NEW_LINE img = cv2 . imread ( os . path . join ( src_imgpath , name + ' . png ' ) ) NEW_LINE angle = [ np . pi / 2 , np . pi , np . pi / 2 * 3 ] NEW_LINE img_90 = np . rot90 ( img , 1 ) NEW_LINE img_180 = np . rot90 ( img , 2 ) NEW_LINE img_270 = np . rot90 ( img , 3 ) NEW_LINE cv2 . imwrite ( os . path . join ( dst_imgpath , name + ' _ 90 . png ' ) , img_90 ) NEW_LINE cv2 . imwrite ( os . path . join ( dst_imgpath , name + ' _ 180 . png ' ) , img_180 ) NEW_LINE cv2 . imwrite ( os . path . join ( dst_imgpath , name + ' _ 270 . png ' ) , img_270 ) NEW_LINE h , w , c = img . shape NEW_LINE angles = [ np . pi / 2 , np . pi , np . pi / 2 * 3 ] NEW_LINE rotate_90 = rotate_matrix ( np . pi / 2 ) NEW_LINE rotate_180 = rotate_matrix ( np . pi ) NEW_LINE rotate_270 = rotate_matrix ( np . pi / 2 * 3 ) NEW_LINE rotate_90_polys = [ ] NEW_LINE rotate_180_polys = [ ] NEW_LINE rotate_270_polys = [ ] NEW_LINE for obj in objs : NEW_LINE INDENT poly = np . array ( obj [ ' poly ' ] ) NEW_LINE poly = np . reshape ( poly , newshape = ( 2 , 4 ) , order = ' F ' ) NEW_LINE centered_poly = poly - np . array ( [ [ w / 2. ] , [ h / 2. ] ] ) NEW_LINE rotated_poly_90 = np . matmul ( rotate_90 , centered_poly ) + np . array ( [ [ h / 2. ] , [ w / 2. ] ] ) NEW_LINE rotated_poly_180 = np . matmul ( rotate_180 , centered_poly ) + np . array ( [ [ w / 2. ] , [ h / 2. ] ] ) NEW_LINE rotated_poly_270 = np . matmul ( rotate_270 , centered_poly ) + np . array ( [ [ h / 2. ] , [ w / 2. ] ] ) NEW_LINE rotate_90_polys . append ( np . reshape ( rotated_poly_90 , newshape = ( 8 ) , order = ' F ' ) ) NEW_LINE rotate_180_polys . append ( np . reshape ( rotated_poly_180 , newshape = ( 8 ) , order = ' F ' ) ) NEW_LINE rotate_270_polys . append ( np . reshape ( rotated_poly_270 , newshape = ( 8 ) , order = ' F ' ) ) NEW_LINE DEDENT with open ( os . path . join ( dst_labelTxt , name + ' _ 90 . txt ' ) , ' w ' ) as f_out : NEW_LINE INDENT for index , poly in enumerate ( rotate_90_polys ) : NEW_LINE INDENT cls = objs [ index ] [ ' name ' ] NEW_LINE diff = objs [ index ] [ ' difficult ' ] NEW_LINE outline = ' ▁ ' . join ( map ( str , list ( poly ) ) ) + ' ▁ ' + cls + ' ▁ ' + diff NEW_LINE f_out . write ( outline + ' \\\\n ' ) NEW_LINE DEDENT DEDENT with open ( os . path . join ( dst_labelTxt , name + ' _ 180 . txt ' ) , ' w ' ) as f_out : NEW_LINE INDENT for index , poly in enumerate ( rotate_180_polys ) : NEW_LINE INDENT cls = objs [ index ] [ ' name ' ] NEW_LINE diff = objs [ index ] [ ' difficult ' ] NEW_LINE outline = ' ▁ ' . join ( map ( str , list ( poly ) ) ) + ' ▁ ' + cls + ' ▁ ' + diff NEW_LINE f_out . write ( outline + ' \\\\n ' ) NEW_LINE DEDENT DEDENT with open ( os . path . join ( dst_labelTxt , name + ' _ 270 . txt ' ) , ' w ' ) as f_out : NEW_LINE INDENT for index , poly in enumerate ( rotate_270_polys ) : NEW_LINE INDENT cls = objs [ index ] [ ' name ' ] NEW_LINE diff = objs [ index ] [ ' difficult ' ] NEW_LINE outline = ' ▁ ' . join ( map ( str , list ( poly ) ) ) + ' ▁ ' + cls + ' ▁ ' + diff NEW_LINE f_out . write ( outline + ' \\\\n ' ) NEW_LINE DEDENT DEDENT DEDENT\",), (\"def rotate_augment ( srcpath , dstpath ) : NEW_LINE INDENT pool = Pool ( 32 ) NEW_LINE imgnames = util . GetFileFromThisRootDir ( os . path . join ( srcpath , ' images ' ) ) NEW_LINE names = [ util . custombasename ( x ) for x in imgnames ] NEW_LINE dst_imgpath = os . path . join ( dstpath , ' images ' ) NEW_LINE dst_labelTxt = os . path . join ( dstpath , ' labelTxt ' ) NEW_LINE if not os . path . exists ( dst_imgpath ) : NEW_LINE INDENT os . makedirs ( dst_imgpath ) NEW_LINE DEDENT if not os . path . exists ( dst_labelTxt ) : NEW_LINE INDENT os . makedirs ( dst_labelTxt ) NEW_LINE DEDENT rotate_fun = partial ( rotate_single_run , srcpath = srcpath , dstpath = dstpath ) NEW_LINE pool . map ( rotate_fun , names ) NEW_LINE DEDENT\",), (\"def prepare ( ) : NEW_LINE INDENT args = parse_args ( ) NEW_LINE data_root_path = args . data_path NEW_LINE train_path = os . path . join ( data_root_path , ' train ' ) NEW_LINE val_path = os . path . join ( data_root_path , ' val ' ) NEW_LINE test_path = os . path . join ( data_root_path , ' test ' ) NEW_LINE if not os . path . exists ( os . path . join ( data_root_path , ' trainval _ large ' ) ) : NEW_LINE INDENT os . makedirs ( os . path . join ( data_root_path , ' trainval _ large ' ) ) NEW_LINE DEDENT if not os . path . exists ( os . path . join ( data_root_path , ' trainval _ large ' , ' images ' ) ) : NEW_LINE INDENT os . makedirs ( os . path . join ( data_root_path , ' trainval _ large ' , ' images ' ) ) NEW_LINE DEDENT if not os . path . exists ( os . path . join ( data_root_path , ' trainval _ large ' , ' labelTxt ' ) ) : NEW_LINE INDENT os . makedirs ( os . path . join ( data_root_path , ' trainval _ large ' , ' labelTxt ' ) ) NEW_LINE DEDENT if not os . path . exists ( os . path . join ( data_root_path , ' trainval1024_1' ) ) : NEW_LINE INDENT os . makedirs ( os . path . join ( data_root_path , ' trainval1024_1' ) ) NEW_LINE DEDENT split_train = ImgSplit_multi_process . splitbase ( train_path , os . path . join ( data_root_path , ' trainval1024_1' ) , gap = 200 , subsize = 1024 , num_process = args . num_process ) NEW_LINE split_train . splitdata ( 1 ) NEW_LINE split_val = ImgSplit_multi_process . splitbase ( val_path , os . path . join ( data_root_path , ' trainval1024_1' ) , gap = 200 , subsize = 1024 , num_process = args . num_process ) NEW_LINE split_val . splitdata ( 1 ) NEW_LINE train_large_names = extract_largesize_index ( os . path . join ( data_root_path , ' train ' , ' labelTxt ' ) ) NEW_LINE filecopy ( os . path . join ( data_root_path , ' train ' , ' labelTxt ' ) , os . path . join ( data_root_path , ' trainval _ large ' , ' labelTxt ' ) , train_large_names , ' . txt ' , num_process = args . num_process ) NEW_LINE filecopy ( os . path . join ( data_root_path , ' train ' , ' images ' ) , os . path . join ( data_root_path , ' trainval _ large ' , ' images ' ) , train_large_names , ' . png ' , num_process = args . num_process ) NEW_LINE val_large_names = extract_largesize_index ( os . path . join ( data_root_path , ' val ' , ' labelTxt ' ) ) NEW_LINE filecopy ( os . path . join ( data_root_path , ' val ' , ' labelTxt ' ) , os . path . join ( data_root_path , ' trainval _ large ' , ' labelTxt ' ) , val_large_names , ' . txt ' , num_process = args . num_process ) NEW_LINE filecopy ( os . path . join ( data_root_path , ' val ' , ' images ' ) , os . path . join ( data_root_path , ' trainval _ large ' , ' images ' ) , val_large_names , ' . png ' , num_process = args . num_process ) NEW_LINE if not os . path . exists ( os . path . join ( data_root_path , ' trainval _ large _ 1024_0.4' ) ) : NEW_LINE INDENT os . makedirs ( os . path . join ( data_root_path , ' trainval _ large _ 1024_0.4' ) ) NEW_LINE DEDENT split_trainval_large = ImgSplit_multi_process . splitbase ( os . path . join ( data_root_path , ' trainval _ large ' ) , os . path . join ( data_root_path , ' trainval _ large _ 1024_0.4' ) , gap = 512 , subsize = 1024 , num_process = args . num_process ) NEW_LINE split_trainval_large . splitdata ( 0.4 ) NEW_LINE rotate_augment ( os . path . join ( data_root_path , ' trainval _ large _ 1024_0.4' ) , os . path . join ( data_root_path , ' trainval _ large _ 1024_0.4 _ rotate ' ) ) NEW_LINE if not os . path . exists ( os . path . join ( data_root_path , ' images ' ) ) : NEW_LINE INDENT os . makedirs ( os . path . join ( data_root_path , ' images ' ) ) NEW_LINE DEDENT if not os . path . exists ( os . path . join ( data_root_path , ' labelTxt ' ) ) : NEW_LINE INDENT os . makedirs ( os . path . join ( data_root_path , ' labelTxt ' ) ) NEW_LINE DEDENT filemove_v2 ( os . path . join ( data_root_path , ' trainval1024_1' , ' images ' ) , os . path . join ( data_root_path , ' images ' ) , ' . png ' , num_process = args . num_process ) NEW_LINE filemove_v2 ( os . path . join ( data_root_path , ' trainval1024_1' , ' labelTxt ' ) , os . path . join ( data_root_path , ' labelTxt ' ) , ' . txt ' , num_process = args . num_process ) NEW_LINE filemove_v2 ( os . path . join ( data_root_path , ' trainval _ large _ 1024_0.4' , ' images ' ) , os . path . join ( data_root_path , ' images ' ) , ' . png ' , num_process = args . num_process ) NEW_LINE filemove_v2 ( os . path . join ( data_root_path , ' trainval _ large _ 1024_0.4' , ' labelTxt ' ) , os . path . join ( data_root_path , ' labelTxt ' ) , ' . txt ' , num_process = args . num_process ) NEW_LINE filemove_v2 ( os . path . join ( data_root_path , ' trainval _ large _ 1024_0.4 _ rotate ' , ' images ' ) , os . path . join ( data_root_path , ' images ' ) , ' . png ' , num_process = args . num_process ) NEW_LINE filemove_v2 ( os . path . join ( data_root_path , ' trainval _ large _ 1024_0.4 _ rotate ' , ' labelTxt ' ) , os . path . join ( data_root_path , ' labelTxt ' ) , ' . txt ' , num_process = args . num_process ) NEW_LINE train_without_balance = util . GetFileFromThisRootDir ( os . path . join ( data_root_path , ' labelTxt ' ) ) NEW_LINE train_without_balance_names = [ util . custombasename ( x . strip ( ) ) for x in train_without_balance ] NEW_LINE with open ( ' train _ balance _ extend . txt ' , ' r ' ) as f_in : NEW_LINE INDENT train_balance_names = f_in . readlines ( ) NEW_LINE train_balance_names = [ x . strip ( ) for x in train_balance_names ] NEW_LINE DEDENT train_names = train_without_balance_names + train_balance_names NEW_LINE with open ( os . path . join ( data_root_path , ' train . txt ' ) , ' w ' ) as f_out : NEW_LINE INDENT for index , name in enumerate ( train_names ) : NEW_LINE INDENT if index == ( len ( train_names ) - 1 ) : NEW_LINE INDENT f_out . write ( name ) NEW_LINE DEDENT else : NEW_LINE INDENT f_out . write ( name + ' \\\\n ' ) NEW_LINE DEDENT DEDENT DEDENT if not os . path . exists ( os . path . join ( data_root_path , ' test1024' ) ) : NEW_LINE INDENT os . makedirs ( os . path . join ( data_root_path , ' test1024' ) ) NEW_LINE DEDENT split_test = SplitOnlyImage_multi_process . splitbase ( os . path . join ( test_path , ' images ' ) , os . path . join ( data_root_path , ' test1024' , ' images ' ) , gap = 512 , subsize = 1024 , num_process = args . num_process ) NEW_LINE split_test . splitdata ( 1 ) NEW_LINE split_test . splitdata ( 0.5 ) NEW_LINE test_names = util . GetFileFromThisRootDir ( os . path . join ( data_root_path , ' test1024' , ' images ' ) ) NEW_LINE test_names = [ util . custombasename ( x . strip ( ) ) for x in test_names ] NEW_LINE with open ( os . path . join ( data_root_path , ' test . txt ' ) , ' w ' ) as f_out : NEW_LINE INDENT for index , name in enumerate ( test_names ) : NEW_LINE INDENT if index == ( len ( test_names ) - 1 ) : NEW_LINE INDENT f_out . write ( name ) NEW_LINE DEDENT else : NEW_LINE INDENT f_out . write ( name + ' \\\\n ' ) NEW_LINE DEDENT DEDENT DEDENT filemove_v2 ( os . path . join ( data_root_path , ' test1024' , ' images ' ) , os . path . join ( data_root_path , ' images ' ) , ' . png ' , num_process = args . num_process ) NEW_LINE shutil . rmtree ( os . path . join ( data_root_path , r' trainval _ large _ 1024_0.4' ) ) NEW_LINE shutil . rmtree ( os . path . join ( data_root_path , r' trainval _ large _ 1024_0.4 _ rotate ' ) ) NEW_LINE shutil . rmtree ( os . path . join ( data_root_path , r' test1024' ) ) NEW_LINE shutil . rmtree ( os . path . join ( data_root_path , r' trainval1024_1' ) ) NEW_LINE shutil . rmtree ( os . path . join ( data_root_path , r' trainval _ large ' ) ) NEW_LINE DEDENT\",), (\"def parse_args ( ) : NEW_LINE INDENT parser = argparse . ArgumentParser ( description = ' Train ▁ Faster - RCNN ▁ network ' ) NEW_LINE parser . add_argument ( ' - - cfg ' , help = ' experiment ▁ configure ▁ file ▁ name ' , required = True , type = str ) NEW_LINE args , rest = parser . parse_known_args ( ) NEW_LINE update_config ( args . cfg ) NEW_LINE parser . add_argument ( ' - - frequent ' , help = ' frequency ▁ of ▁ logging ' , default = config . default . frequent , type = int ) NEW_LINE args = parser . parse_args ( ) NEW_LINE return args NEW_LINE DEDENT\",), (\"def main ( ) : NEW_LINE INDENT print ( ' Called ▁ with ▁ argument : ' , args ) NEW_LINE ctx = [ mx . gpu ( int ( i ) ) for i in config . gpus . split ( ' , ' ) ] NEW_LINE train_net ( args , ctx , config . network . pretrained , config . network . pretrained_epoch , config . TRAIN . model_prefix , config . TRAIN . begin_epoch , config . TRAIN . end_epoch , config . TRAIN . lr , config . TRAIN . lr_step ) NEW_LINE DEDENT\",), (\"def parse_args ( ) : NEW_LINE INDENT parser = argparse . ArgumentParser ( description = ' Train ▁ Faster - RCNN ▁ network ' ) NEW_LINE parser . add_argument ( ' - - cfg ' , help = ' experiment ▁ configure ▁ file ▁ name ' , required = True , type = str ) NEW_LINE args , rest = parser . parse_known_args ( ) NEW_LINE update_config ( args . cfg ) NEW_LINE parser . add_argument ( ' - - frequent ' , help = ' frequency ▁ of ▁ logging ' , default = config . default . frequent , type = int ) NEW_LINE args = parser . parse_args ( ) NEW_LINE return args NEW_LINE DEDENT\",), (\"def main ( ) : NEW_LINE INDENT print ( ' Called ▁ with ▁ argument : ' , args ) NEW_LINE ctx = [ mx . gpu ( int ( i ) ) for i in config . gpus . split ( ' , ' ) ] NEW_LINE train_net ( args , ctx , config . network . pretrained , config . network . pretrained_epoch , config . TRAIN . model_prefix , config . TRAIN . begin_epoch , config . TRAIN . end_epoch , config . TRAIN . lr , config . TRAIN . lr_step ) NEW_LINE DEDENT\",), (\"def parse_args ( ) : NEW_LINE INDENT parser = argparse . ArgumentParser ( description = ' Train ▁ Faster - RCNN ▁ network ' ) NEW_LINE parser . add_argument ( ' - - cfg ' , help = ' experiment ▁ configure ▁ file ▁ name ' , required = True , type = str ) NEW_LINE args , rest = parser . parse_known_args ( ) NEW_LINE update_config ( args . cfg ) NEW_LINE parser . add_argument ( ' - - frequent ' , help = ' frequency ▁ of ▁ logging ' , default = config . default . frequent , type = int ) NEW_LINE args = parser . parse_args ( ) NEW_LINE return args NEW_LINE DEDENT\",), (\"def main ( ) : NEW_LINE INDENT print ( ' Called ▁ with ▁ argument : ' , args ) NEW_LINE ctx = [ mx . gpu ( int ( i ) ) for i in config . gpus . split ( ' , ' ) ] NEW_LINE train_net ( args , ctx , config . network . pretrained , config . network . pretrained_epoch , config . TRAIN . model_prefix , config . TRAIN . begin_epoch , config . TRAIN . end_epoch , config . TRAIN . lr , config . TRAIN . lr_step ) NEW_LINE DEDENT\",), (\"def parse_args ( ) : NEW_LINE INDENT parser = argparse . ArgumentParser ( description = ' Train ▁ Faster - RCNN ▁ network ' ) NEW_LINE parser . add_argument ( ' - - cfg ' , help = ' experiment ▁ configure ▁ file ▁ name ' , required = True , type = str ) NEW_LINE args , rest = parser . parse_known_args ( ) NEW_LINE update_config ( args . cfg ) NEW_LINE parser . add_argument ( ' - - frequent ' , help = ' frequency ▁ of ▁ logging ' , default = config . default . frequent , type = int ) NEW_LINE args = parser . parse_args ( ) NEW_LINE return args NEW_LINE DEDENT\",), (\"def main ( ) : NEW_LINE INDENT print ( ' Called ▁ with ▁ argument : ' , args ) NEW_LINE ctx = [ mx . gpu ( int ( i ) ) for i in config . gpus . split ( ' , ' ) ] NEW_LINE logger , output_path = create_logger ( config . output_path , args . cfg , config . dataset . image_set ) NEW_LINE shutil . copy2 ( os . path . join ( curr_path , ' symbols ' , config . symbol + ' . py ' ) , output_path ) NEW_LINE prefix = os . path . join ( output_path , ' rcnn ' ) NEW_LINE logging . info ( ' # # # # # # # # # # ▁ TRAIN ▁ rcnn ▁ WITH ▁ IMAGENET ▁ INIT ▁ AND ▁ RPN ▁ DETECTION ' ) NEW_LINE train_rcnn ( config , config . dataset . dataset , config . dataset . image_set , config . dataset . root_path , config . dataset . dataset_path , args . frequent , config . default . kvstore , config . TRAIN . FLIP , config . TRAIN . SHUFFLE , config . TRAIN . RESUME , ctx , config . network . pretrained , config . network . pretrained_epoch , prefix , config . TRAIN . begin_epoch , config . TRAIN . end_epoch , train_shared = False , lr = config . TRAIN . lr , lr_step = config . TRAIN . lr_step , proposal = config . dataset . proposal , logger = logger ) NEW_LINE DEDENT\",), (\"def parse_args ( ) : NEW_LINE INDENT parser = argparse . ArgumentParser ( description = ' Test ▁ a ▁ Faster ▁ R - CNN ▁ network ' ) NEW_LINE parser . add_argument ( ' - - cfg ' , help = ' experiment ▁ configure ▁ file ▁ name ' , required = True , type = str ) NEW_LINE args , rest = parser . parse_known_args ( ) NEW_LINE update_config ( args . cfg ) NEW_LINE parser . add_argument ( ' - - vis ' , help = ' turn ▁ on ▁ visualization ' , action = ' store _ true ' ) NEW_LINE parser . add_argument ( ' - - ignore _ cache ' , help = ' ignore ▁ cached ▁ results ▁ boxes ' , action = ' store _ true ' ) NEW_LINE parser . add_argument ( ' - - thresh ' , help = ' valid ▁ detection ▁ threshold ' , default = 1e-3 , type = float ) NEW_LINE parser . add_argument ( ' - - shuffle ' , help = ' shuffle ▁ data ▁ on ▁ visualization ' , action = ' store _ true ' ) NEW_LINE args = parser . parse_args ( ) NEW_LINE return args NEW_LINE DEDENT\",), (\"def parse_args ( ) : NEW_LINE INDENT parser = argparse . ArgumentParser ( description = ' Test ▁ a ▁ Faster ▁ R - CNN ▁ network ' ) NEW_LINE parser . add_argument ( ' - - cfg ' , help = ' experiment ▁ configure ▁ file ▁ name ' , required = True , type = str ) NEW_LINE args , rest = parser . parse_known_args ( ) NEW_LINE update_config ( args . cfg ) NEW_LINE parser . add_argument ( ' - - vis ' , help = ' turn ▁ on ▁ visualization ' , action = ' store _ true ' ) NEW_LINE parser . add_argument ( ' - - draw ' , help = ' turn ▁ on ▁ draw ▁ visualization ' , action = ' store _ true ' ) NEW_LINE parser . add_argument ( ' - - ignore _ cache ' , help = ' ignore ▁ cached ▁ results ▁ boxes ' , action = ' store _ true ' ) NEW_LINE parser . add_argument ( ' - - thresh ' , help = ' valid ▁ detection ▁ threshold ' , default = 1e-3 , type = float ) NEW_LINE parser . add_argument ( ' - - shuffle ' , help = ' shuffle ▁ data ▁ on ▁ visualization ' , action = ' store _ true ' ) NEW_LINE args = parser . parse_args ( ) NEW_LINE return args NEW_LINE DEDENT\",), ('def add_path ( path ) : NEW_LINE INDENT if path not in sys . path : NEW_LINE INDENT sys . path . insert ( 0 , path ) NEW_LINE DEDENT DEDENT',), ('def __init__ ( self , num_classes , batch_images , batch_rois , cfg , fg_fraction ) : NEW_LINE INDENT super ( RRoITargetRotBox_v2Operator , self ) . __init__ ( ) NEW_LINE self . _num_classes = num_classes NEW_LINE self . _batch_images = batch_images NEW_LINE self . _batch_rois = batch_rois NEW_LINE self . _cfg = cfg NEW_LINE self . _fg_fraction = fg_fraction NEW_LINE if DEBUG : NEW_LINE INDENT self . _count = 0 NEW_LINE self . _fg_num = 0 NEW_LINE self . _bg_num = 0 NEW_LINE DEDENT DEDENT',), ('def backward ( self , req , out_grad , in_data , out_data , in_grad , aux ) : NEW_LINE INDENT for i in range ( len ( in_grad ) ) : NEW_LINE INDENT self . assign ( in_grad [ i ] , req [ i ] , 0 ) NEW_LINE DEDENT DEDENT',), (\"def __init__ ( self , num_classes , batch_images , batch_rois , cfg , fg_fraction = '0.25' ) : NEW_LINE INDENT super ( RRoITargetRotbox_v2Prop , self ) . __init__ ( need_top_grad = False ) NEW_LINE self . _num_classes = int ( num_classes ) NEW_LINE self . _batch_images = int ( batch_images ) NEW_LINE self . _batch_rois = int ( batch_rois ) NEW_LINE self . _cfg = cPickle . loads ( cfg ) NEW_LINE self . _fg_fraction = float ( fg_fraction ) NEW_LINE DEDENT\",), (\"def list_arguments ( self ) : NEW_LINE INDENT return [ ' Rrois ' , ' gt _ boxes ' ] NEW_LINE DEDENT\",), (\"def list_outputs ( self ) : NEW_LINE INDENT return [ ' Rrois _ output ' , ' Rrois _ output _ elarge ' , ' Rlabel ' , ' Rbbox _ target ' , ' Rbbox _ weight ' ] NEW_LINE DEDENT\",), ('def infer_shape ( self , in_shape ) : NEW_LINE INDENT rpn_rois_shape = in_shape [ 0 ] NEW_LINE gt_boxes_shape = in_shape [ 1 ] NEW_LINE rois = rpn_rois_shape [ 0 ] + gt_boxes_shape [ 0 ] if self . _batch_rois == - 1 else self . _batch_rois NEW_LINE output_rois_shape = ( rois , 6 ) NEW_LINE label_shape = ( rois , ) NEW_LINE bbox_target_shape = ( rois , 5 * self . _num_classes ) NEW_LINE bbox_weight_shape = ( rois , 5 * self . _num_classes ) NEW_LINE return [ rpn_rois_shape , gt_boxes_shape ] , [ output_rois_shape , output_rois_shape , label_shape , bbox_target_shape , bbox_weight_shape ] NEW_LINE DEDENT',), ('def create_operator ( self , ctx , shapes , dtypes ) : NEW_LINE INDENT return RRoITargetRotBox_v2Operator ( self . _num_classes , self . _batch_images , self . _batch_rois , self . _cfg , self . _fg_fraction ) NEW_LINE DEDENT',), ('def declare_backward_dependency ( self , out_grad , in_data , out_data ) : NEW_LINE INDENT return [ ] NEW_LINE DEDENT',), ('def _filter_boxes ( boxes , min_size ) : NEW_LINE INDENT ws = boxes [ : , 2 ] - boxes [ : , 0 ] + 1 NEW_LINE hs = boxes [ : , 3 ] - boxes [ : , 1 ] + 1 NEW_LINE keep = np . where ( ( ws >= min_size ) & ( hs >= min_size ) ) [ 0 ] NEW_LINE return keep NEW_LINE DEDENT',), ('def _clip_pad ( tensor , pad_shape ) : NEW_LINE INDENT H , W = tensor . shape [ 2 : ] NEW_LINE h , w = pad_shape NEW_LINE if h < H or w < W : NEW_LINE INDENT tensor = tensor [ : , : , : h , : w ] . copy ( ) NEW_LINE DEDENT return tensor NEW_LINE DEDENT',), ('def backward ( self , req , out_grad , in_data , out_data , in_grad , aux ) : NEW_LINE INDENT self . assign ( in_grad [ 0 ] , req [ 0 ] , 0 ) NEW_LINE self . assign ( in_grad [ 1 ] , req [ 1 ] , 0 ) NEW_LINE self . assign ( in_grad [ 2 ] , req [ 2 ] , 0 ) NEW_LINE DEDENT',), (\"def __init__ ( self , feat_stride = '16' , scales = ' ( 8 , ▁ 16 , ▁ 32 ) ' , ratios = ' ( 0.5 , ▁ 1 , ▁ 2 ) ' , output_score = ' False ' , rpn_pre_nms_top_n = '6000' , rpn_post_nms_top_n = '300' , threshold = '0.3' , rpn_min_size = '16' ) : NEW_LINE INDENT super ( ProposalProp , self ) . __init__ ( need_top_grad = False ) NEW_LINE self . _feat_stride = int ( feat_stride ) NEW_LINE self . _scales = scales NEW_LINE self . _ratios = ratios NEW_LINE self . _output_score = strtobool ( output_score ) NEW_LINE self . _rpn_pre_nms_top_n = int ( rpn_pre_nms_top_n ) NEW_LINE self . _rpn_post_nms_top_n = int ( rpn_post_nms_top_n ) NEW_LINE self . _threshold = float ( threshold ) NEW_LINE self . _rpn_min_size = int ( rpn_min_size ) NEW_LINE DEDENT\",), (\"def list_arguments ( self ) : NEW_LINE INDENT return [ ' cls _ prob ' , ' bbox _ pred ' , ' im _ info ' ] NEW_LINE DEDENT\",), (\"def list_outputs ( self ) : NEW_LINE INDENT if self . _output_score : NEW_LINE INDENT return [ ' output ' , ' score ' ] NEW_LINE DEDENT else : NEW_LINE INDENT return [ ' output ' ] NEW_LINE DEDENT DEDENT\",), (\"def infer_shape ( self , in_shape ) : NEW_LINE INDENT cls_prob_shape = in_shape [ 0 ] NEW_LINE bbox_pred_shape = in_shape [ 1 ] NEW_LINE assert cls_prob_shape [ 0 ] == bbox_pred_shape [ 0 ] , ' ROI ▁ number ▁ does ▁ not ▁ equal ▁ in ▁ cls ▁ and ▁ reg ' NEW_LINE batch_size = cls_prob_shape [ 0 ] NEW_LINE im_info_shape = ( batch_size , 3 ) NEW_LINE output_shape = ( self . _rpn_post_nms_top_n , 5 ) NEW_LINE score_shape = ( self . _rpn_post_nms_top_n , 1 ) NEW_LINE if self . _output_score : NEW_LINE INDENT return [ cls_prob_shape , bbox_pred_shape , im_info_shape ] , [ output_shape , score_shape ] NEW_LINE DEDENT else : NEW_LINE INDENT return [ cls_prob_shape , bbox_pred_shape , im_info_shape ] , [ output_shape ] NEW_LINE DEDENT DEDENT\",), ('def create_operator ( self , ctx , shapes , dtypes ) : NEW_LINE INDENT return ProposalOperator ( self . _feat_stride , self . _scales , self . _ratios , self . _output_score , self . _rpn_pre_nms_top_n , self . _rpn_post_nms_top_n , self . _threshold , self . _rpn_min_size ) NEW_LINE DEDENT',), ('def declare_backward_dependency ( self , out_grad , in_data , out_data ) : NEW_LINE INDENT return [ ] NEW_LINE DEDENT',), ('def __init__ ( self , num_classes , num_reg_classes , roi_per_img ) : NEW_LINE INDENT super ( BoxAnnotatorOHEMOperator , self ) . __init__ ( ) NEW_LINE self . _num_classes = num_classes NEW_LINE self . _num_reg_classes = num_reg_classes NEW_LINE self . _roi_per_img = roi_per_img NEW_LINE DEDENT',), (\"def forward ( self , is_train , req , in_data , out_data , aux ) : NEW_LINE INDENT cls_score = in_data [ 0 ] NEW_LINE bbox_pred = in_data [ 1 ] NEW_LINE labels = in_data [ 2 ] . asnumpy ( ) NEW_LINE bbox_targets = in_data [ 3 ] NEW_LINE bbox_weights = in_data [ 4 ] NEW_LINE per_roi_loss_cls = mx . nd . SoftmaxActivation ( cls_score ) + 1e-14 NEW_LINE per_roi_loss_cls = per_roi_loss_cls . asnumpy ( ) NEW_LINE per_roi_loss_cls = per_roi_loss_cls [ np . arange ( per_roi_loss_cls . shape [ 0 ] , dtype = ' int ' ) , labels . astype ( ' int ' ) ] NEW_LINE per_roi_loss_cls = - 1 * np . log ( per_roi_loss_cls ) NEW_LINE per_roi_loss_cls = np . reshape ( per_roi_loss_cls , newshape = ( - 1 , ) ) NEW_LINE per_roi_loss_bbox = bbox_weights * mx . nd . smooth_l1 ( ( bbox_pred - bbox_targets ) , scalar = 1.0 ) NEW_LINE per_roi_loss_bbox = mx . nd . sum ( per_roi_loss_bbox , axis = 1 ) . asnumpy ( ) NEW_LINE top_k_per_roi_loss = np . argsort ( per_roi_loss_cls + per_roi_loss_bbox ) NEW_LINE labels_ohem = labels NEW_LINE labels_ohem [ top_k_per_roi_loss [ : : - 1 ] [ self . _roi_per_img : ] ] = - 1 NEW_LINE bbox_weights_ohem = bbox_weights . asnumpy ( ) NEW_LINE bbox_weights_ohem [ top_k_per_roi_loss [ : : - 1 ] [ self . _roi_per_img : ] ] = 0 NEW_LINE labels_ohem = mx . nd . array ( labels_ohem ) NEW_LINE bbox_weights_ohem = mx . nd . array ( bbox_weights_ohem ) NEW_LINE for ind , val in enumerate ( [ labels_ohem , bbox_weights_ohem ] ) : NEW_LINE INDENT self . assign ( out_data [ ind ] , req [ ind ] , val ) NEW_LINE DEDENT DEDENT\",), ('def backward ( self , req , out_grad , in_data , out_data , in_grad , aux ) : NEW_LINE INDENT for i in range ( len ( in_grad ) ) : NEW_LINE INDENT self . assign ( in_grad [ i ] , req [ i ] , 0 ) NEW_LINE DEDENT DEDENT',), ('def __init__ ( self , num_classes , num_reg_classes , roi_per_img ) : NEW_LINE INDENT super ( BoxAnnotatorOHEMProp , self ) . __init__ ( need_top_grad = False ) NEW_LINE self . _num_classes = int ( num_classes ) NEW_LINE self . _num_reg_classes = int ( num_reg_classes ) NEW_LINE self . _roi_per_img = int ( roi_per_img ) NEW_LINE DEDENT',), (\"def list_arguments ( self ) : NEW_LINE INDENT return [ ' cls _ score ' , ' bbox _ pred ' , ' labels ' , ' bbox _ targets ' , ' bbox _ weights ' ] NEW_LINE DEDENT\",), (\"def list_outputs ( self ) : NEW_LINE INDENT return [ ' labels _ ohem ' , ' bbox _ weights _ ohem ' ] NEW_LINE DEDENT\",), ('def infer_shape ( self , in_shape ) : NEW_LINE INDENT labels_shape = in_shape [ 2 ] NEW_LINE bbox_weights_shape = in_shape [ 4 ] NEW_LINE return in_shape , [ labels_shape , bbox_weights_shape ] NEW_LINE DEDENT',), ('def create_operator ( self , ctx , shapes , dtypes ) : NEW_LINE INDENT return BoxAnnotatorOHEMOperator ( self . _num_classes , self . _num_reg_classes , self . _roi_per_img ) NEW_LINE DEDENT',), ('def declare_backward_dependency ( self , out_grad , in_data , out_data ) : NEW_LINE INDENT return [ ] NEW_LINE DEDENT',), ('def __init__ ( self , num_classes , batch_images , batch_rois , cfg , fg_fraction ) : NEW_LINE INDENT super ( ProposalTargetOperator , self ) . __init__ ( ) NEW_LINE self . _num_classes = num_classes NEW_LINE self . _batch_images = batch_images NEW_LINE self . _batch_rois = batch_rois NEW_LINE self . _cfg = cfg NEW_LINE self . _fg_fraction = fg_fraction NEW_LINE if DEBUG : NEW_LINE INDENT self . _count = 0 NEW_LINE self . _fg_num = 0 NEW_LINE self . _bg_num = 0 NEW_LINE DEDENT DEDENT',), ('def backward ( self , req , out_grad , in_data , out_data , in_grad , aux ) : NEW_LINE INDENT self . assign ( in_grad [ 0 ] , req [ 0 ] , 0 ) NEW_LINE self . assign ( in_grad [ 1 ] , req [ 1 ] , 0 ) NEW_LINE DEDENT',), (\"def __init__ ( self , num_classes , batch_images , batch_rois , cfg , fg_fraction = '0.25' ) : NEW_LINE INDENT super ( ProposalTargetProp , self ) . __init__ ( need_top_grad = False ) NEW_LINE self . _num_classes = int ( num_classes ) NEW_LINE self . _batch_images = int ( batch_images ) NEW_LINE self . _batch_rois = int ( batch_rois ) NEW_LINE self . _cfg = cPickle . loads ( cfg ) NEW_LINE self . _fg_fraction = float ( fg_fraction ) NEW_LINE DEDENT\",), (\"def list_arguments ( self ) : NEW_LINE INDENT return [ ' rois ' , ' gt _ boxes ' ] NEW_LINE DEDENT\",), (\"def list_outputs ( self ) : NEW_LINE INDENT return [ ' rois _ output ' , ' label ' , ' bbox _ target ' , ' bbox _ weight ' ] NEW_LINE DEDENT\",), ('def infer_shape ( self , in_shape ) : NEW_LINE INDENT rpn_rois_shape = in_shape [ 0 ] NEW_LINE gt_boxes_shape = in_shape [ 1 ] NEW_LINE rois = rpn_rois_shape [ 0 ] + gt_boxes_shape [ 0 ] if self . _batch_rois == - 1 else self . _batch_rois NEW_LINE output_rois_shape = ( rois , 5 ) NEW_LINE label_shape = ( rois , ) NEW_LINE bbox_target_shape = ( rois , self . _num_classes * 4 ) NEW_LINE bbox_weight_shape = ( rois , self . _num_classes * 4 ) NEW_LINE return [ rpn_rois_shape , gt_boxes_shape ] , [ output_rois_shape , label_shape , bbox_target_shape , bbox_weight_shape ] NEW_LINE DEDENT',), ('def create_operator ( self , ctx , shapes , dtypes ) : NEW_LINE INDENT return ProposalTargetOperator ( self . _num_classes , self . _batch_images , self . _batch_rois , self . _cfg , self . _fg_fraction ) NEW_LINE DEDENT',), ('def declare_backward_dependency ( self , out_grad , in_data , out_data ) : NEW_LINE INDENT return [ ] NEW_LINE DEDENT',), ('def __init__ ( self , num_classes , batch_images , batch_rois , cfg , fg_fraction , fg_class_agnostic ) : NEW_LINE INDENT super ( ProposalTargetRotBoxOperator , self ) . __init__ ( ) NEW_LINE self . _num_classes = num_classes NEW_LINE self . _batch_images = batch_images NEW_LINE self . _batch_rois = batch_rois NEW_LINE self . _cfg = cfg NEW_LINE self . _fg_fraction = fg_fraction NEW_LINE self . _fg_class_agnostic = fg_class_agnostic NEW_LINE if DEBUG : NEW_LINE INDENT self . _count = 0 NEW_LINE self . _fg_num = 0 NEW_LINE self . _bg_num = 0 NEW_LINE DEDENT DEDENT',), ('def backward ( self , req , out_grad , in_data , out_data , in_grad , aux ) : NEW_LINE INDENT for i in range ( len ( in_grad ) ) : NEW_LINE INDENT self . assign ( in_grad [ i ] , req [ i ] , 0 ) NEW_LINE DEDENT DEDENT',), (\"def __init__ ( self , num_classes , batch_images , batch_rois , cfg , fg_class_agnostic = ' False ' , fg_fraction = '0.25' ) : NEW_LINE INDENT super ( ProposalTargetRotboxtProp , self ) . __init__ ( need_top_grad = False ) NEW_LINE self . _num_classes = int ( num_classes ) NEW_LINE self . _batch_images = int ( batch_images ) NEW_LINE self . _batch_rois = int ( batch_rois ) NEW_LINE self . _cfg = cPickle . loads ( cfg ) NEW_LINE self . _fg_class_agnostic = fg_class_agnostic == ' True ' NEW_LINE self . _fg_fraction = float ( fg_fraction ) NEW_LINE DEDENT\",), (\"def list_arguments ( self ) : NEW_LINE INDENT return [ ' rois ' , ' gt _ boxes ' ] NEW_LINE DEDENT\",), (\"def list_outputs ( self ) : NEW_LINE INDENT return [ ' rois _ output ' , ' label ' , ' bbox _ target ' , ' bbox _ weight ' ] NEW_LINE DEDENT\",), ('def infer_shape ( self , in_shape ) : NEW_LINE INDENT rpn_rois_shape = in_shape [ 0 ] NEW_LINE gt_boxes_shape = in_shape [ 1 ] NEW_LINE rois = rpn_rois_shape [ 0 ] + gt_boxes_shape [ 0 ] if self . _batch_rois == - 1 else self . _batch_rois NEW_LINE output_rois_shape = ( rois , 5 ) NEW_LINE label_shape = ( rois , ) NEW_LINE bbox_target_shape = ( rois , 5 * self . _num_classes ) NEW_LINE bbox_weight_shape = ( rois , 5 * self . _num_classes ) NEW_LINE return [ rpn_rois_shape , gt_boxes_shape ] , [ output_rois_shape , label_shape , bbox_target_shape , bbox_weight_shape ] NEW_LINE DEDENT',), ('def create_operator ( self , ctx , shapes , dtypes ) : NEW_LINE INDENT return ProposalTargetRotBoxOperator ( self . _num_classes , self . _batch_images , self . _batch_rois , self . _cfg , self . _fg_fraction , self . _fg_class_agnostic ) NEW_LINE DEDENT',), ('def declare_backward_dependency ( self , out_grad , in_data , out_data ) : NEW_LINE INDENT return [ ] NEW_LINE DEDENT',), ('def _filter_boxes ( boxes , min_size ) : NEW_LINE INDENT ws = boxes [ : , 2 ] NEW_LINE hs = boxes [ : , 3 ] NEW_LINE keep = np . where ( ( ws >= min_size ) & ( hs >= min_size ) ) [ 0 ] NEW_LINE return keep NEW_LINE DEDENT',), ('def _filter_boxes_v2 ( boxes , area ) : NEW_LINE INDENT ws = boxes [ : , 2 ] NEW_LINE hs = boxes [ : , 3 ] NEW_LINE keep = np . where ( ws * hs >= area ) [ 0 ] NEW_LINE return keep NEW_LINE DEDENT',), ('def __init__ ( self , pre_nms_top_n , post_nms_top_n , threshold , min_size , cfg ) : NEW_LINE INDENT super ( RRoIDecoderOperator , self ) . __init__ ( ) NEW_LINE self . _pre_nms_top_n = pre_nms_top_n NEW_LINE self . _post_nms_top_n = post_nms_top_n NEW_LINE self . _threshold = threshold NEW_LINE self . _min_size = min_size NEW_LINE self . _cfg = cfg NEW_LINE DEDENT',), ('def forward ( self , is_train , req , in_data , out_data , aux ) : NEW_LINE INDENT batch_size = in_data [ 0 ] [ 0 ] [ 0 ] NEW_LINE if batch_size . asnumpy ( ) > 1 : NEW_LINE INDENT raise ValueError ( \" Sorry , ▁ multiple ▁ images ▁ each ▁ device ▁ is ▁ not ▁ implemented \" ) NEW_LINE DEDENT rois = in_data [ 0 ] . asnumpy ( ) NEW_LINE st_pred = in_data [ 1 ] . asnumpy ( ) NEW_LINE st_score = in_data [ 2 ] . asnumpy ( ) [ : , : , 1 ] . reshape ( - 1 , 1 ) NEW_LINE im_info = in_data [ - 1 ] . asnumpy ( ) [ 0 , : ] NEW_LINE pre_nms_topN = self . _pre_nms_top_n NEW_LINE post_nms_topN = self . _post_nms_top_n NEW_LINE min_size = self . _min_size NEW_LINE cfg = self . _cfg NEW_LINE if is_train : NEW_LINE INDENT if cfg . TRAIN . BBOX_NORMALIZATION_PRECOMPUTED : NEW_LINE INDENT means = np . tile ( np . array ( cfg . TRAIN . BBOX_MEANS ) , 2 if cfg . CLASS_AGNOSTIC else cfg . dataset . NUM_CLASSES ) NEW_LINE stds = np . tile ( np . array ( cfg . TRAIN . BBOX_STDS ) , 2 if cfg . CLASS_AGNOSTIC else cfg . dataset . NUM_CLASSES ) NEW_LINE st_pred = st_pred * stds + means NEW_LINE DEDENT DEDENT Rrois = dbbox_transform2_inv_warp ( rois [ : , 1 : ] , st_pred ) [ : , 5 : ] NEW_LINE if ( len ( Rrois ) == 0 ) : NEW_LINE INDENT pdb . set_trace ( ) NEW_LINE DEDENT keep = self . _filter_boxes_v2 ( Rrois , min_size * im_info [ 2 ] * min_size * im_info [ 2 ] ) NEW_LINE keep_Rrois = Rrois [ keep ] NEW_LINE scores = st_score [ keep ] NEW_LINE if len ( keep_Rrois ) == 0 : NEW_LINE INDENT Rrois [ : , 2 ] = np . maximum ( Rrois [ : , 2 ] , min_size * im_info [ 2 ] ) NEW_LINE Rrois [ : , 3 ] = np . maximum ( Rrois [ : , 3 ] , min_size * im_info [ 2 ] ) NEW_LINE keep_Rrois = Rrois NEW_LINE scores = st_score NEW_LINE DEDENT proposals = RotBox2Polys ( keep_Rrois ) NEW_LINE order = scores . ravel ( ) . argsort ( ) [ : : - 1 ] NEW_LINE if pre_nms_topN > 0 : NEW_LINE INDENT order = order [ : pre_nms_topN ] NEW_LINE DEDENT proposals = proposals [ order , : ] NEW_LINE scores = scores [ order ] NEW_LINE det = np . hstack ( ( proposals , scores ) ) . astype ( np . float32 ) NEW_LINE keep = np . arange ( len ( det ) ) NEW_LINE if post_nms_topN > 0 : NEW_LINE INDENT keep = keep [ : post_nms_topN ] NEW_LINE DEDENT if len ( keep ) < post_nms_topN : NEW_LINE INDENT pad = npr . choice ( keep , size = post_nms_topN - len ( keep ) ) NEW_LINE keep = np . hstack ( ( keep , pad ) ) NEW_LINE DEDENT proposals = proposals [ keep , : ] NEW_LINE scores = scores [ keep ] NEW_LINE proposals = polygonToRotRectangle_batch ( proposals ) NEW_LINE proposals = choose_best_Rroi_batch ( proposals ) NEW_LINE batch_inds = np . zeros ( ( proposals . shape [ 0 ] , 1 ) , dtype = np . float32 ) NEW_LINE blob = np . hstack ( ( batch_inds , proposals . astype ( np . float32 , copy = False ) ) ) NEW_LINE self . assign ( out_data [ 0 ] , req [ 0 ] , blob ) NEW_LINE elarge_proposals = copy . deepcopy ( proposals ) NEW_LINE elarge_proposals [ : , 2 ] = proposals [ : , 2 ] * 1.2 NEW_LINE elarge_proposals [ : , 3 ] = proposals [ : , 3 ] * 1.4 NEW_LINE elarge_blob = np . hstack ( ( batch_inds , elarge_proposals . astype ( np . float32 , copy = False ) ) ) NEW_LINE self . assign ( out_data [ 1 ] , req [ 1 ] , elarge_blob ) NEW_LINE DEDENT',), ('def backward ( self , req , out_grad , in_data , out_data , in_grad , aux ) : NEW_LINE INDENT for i in range ( len ( in_grad ) ) : NEW_LINE INDENT self . assign ( in_grad [ i ] , req [ i ] , 0 ) NEW_LINE DEDENT DEDENT',), (\"def __init__ ( self , cfg , Rroi_pre_nms_top_n = '12000' , Rroi_post_nms_top_n = '2000' , threshold = '0.5' , min_size = '10' ) : NEW_LINE INDENT super ( RRoIDecoderProp , self ) . __init__ ( need_top_grad = False ) NEW_LINE self . _cfg = cPickle . loads ( cfg ) NEW_LINE self . _Rroi_pre_nms_top_n = int ( Rroi_pre_nms_top_n ) NEW_LINE self . _Rroi_post_nms_top_n = int ( Rroi_post_nms_top_n ) NEW_LINE self . _threshold = float ( threshold ) NEW_LINE self . _min_size = int ( min_size ) NEW_LINE DEDENT\",), (\"def list_arguments ( self ) : NEW_LINE INDENT return [ ' rois ' , ' bbox _ pred ' , ' cls _ prob ' , ' im _ info ' ] NEW_LINE DEDENT\",), (\"def list_outputs ( self ) : NEW_LINE INDENT return [ ' output ' , ' output _ rois _ L ' ] NEW_LINE DEDENT\",), ('def infer_shape ( self , in_shape ) : NEW_LINE INDENT output_shape = ( self . _Rroi_post_nms_top_n , 6 ) NEW_LINE return in_shape , [ output_shape , output_shape ] NEW_LINE DEDENT',), ('def create_operator ( self , ctx , shapes , dtypes ) : NEW_LINE INDENT return RRoIDecoderOperator ( self . _Rroi_pre_nms_top_n , self . _Rroi_post_nms_top_n , self . _threshold , self . _min_size , self . _cfg ) NEW_LINE DEDENT',), ('def declare_backward_dependency ( self , out_grad , in_data , out_data ) : NEW_LINE INDENT return [ ] NEW_LINE DEDENT',), ('def update_config ( config_file ) : NEW_LINE INDENT exp_config = None NEW_LINE with open ( config_file ) as f : NEW_LINE INDENT exp_config = edict ( yaml . load ( f ) ) NEW_LINE for k , v in exp_config . items ( ) : NEW_LINE INDENT if k in config : NEW_LINE INDENT if isinstance ( v , dict ) : NEW_LINE INDENT if k == \\' TRAIN \\' : NEW_LINE INDENT if \\' BBOX _ WEIGHTS \\' in v : NEW_LINE INDENT v [ \\' BBOX _ WEIGHTS \\' ] = np . array ( v [ \\' BBOX _ WEIGHTS \\' ] ) NEW_LINE DEDENT DEDENT elif k == \\' network \\' : NEW_LINE INDENT if \\' PIXEL _ MEANS \\' in v : NEW_LINE INDENT v [ \\' PIXEL _ MEANS \\' ] = np . array ( v [ \\' PIXEL _ MEANS \\' ] ) NEW_LINE DEDENT DEDENT for vk , vv in v . items ( ) : NEW_LINE INDENT config [ k ] [ vk ] = vv NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT if k == \\' SCALES \\' : NEW_LINE INDENT config [ k ] [ 0 ] = ( tuple ( v ) ) NEW_LINE DEDENT else : NEW_LINE INDENT config [ k ] = v NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT raise ValueError ( \" key ▁ must ▁ exist ▁ in ▁ config . py \" ) NEW_LINE DEDENT DEDENT DEDENT DEDENT',), ('def __init__ ( self ) : NEW_LINE INDENT self . eps = 1e-5 NEW_LINE self . use_global_stats = True NEW_LINE self . workspace = 512 NEW_LINE self . units = ( 3 , 4 , 23 , 3 ) NEW_LINE self . filter_list = [ 256 , 512 , 1024 , 2048 ] NEW_LINE DEDENT',), (\"def get_resnet_v1_conv4 ( self , data ) : NEW_LINE INDENT conv1 = mx . symbol . Convolution ( name = ' conv1' , data = data , num_filter = 64 , pad = ( 3 , 3 ) , kernel = ( 7 , 7 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn_conv1 = mx . symbol . BatchNorm ( name = ' bn _ conv1' , data = conv1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale_conv1 = bn_conv1 NEW_LINE conv1_relu = mx . symbol . Activation ( name = ' conv1 _ relu ' , data = scale_conv1 , act_type = ' relu ' ) NEW_LINE pool1 = mx . symbol . Pooling ( name = ' pool1' , data = conv1_relu , pooling_convention = ' full ' , pad = ( 0 , 0 ) , kernel = ( 3 , 3 ) , stride = ( 2 , 2 ) , pool_type = ' max ' ) NEW_LINE res2a_branch1 = mx . symbol . Convolution ( name = ' res2a _ branch1' , data = pool1 , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch1 = mx . symbol . BatchNorm ( name = ' bn2a _ branch1' , data = res2a_branch1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2a_branch1 = bn2a_branch1 NEW_LINE res2a_branch2a = mx . symbol . Convolution ( name = ' res2a _ branch2a ' , data = pool1 , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2a = mx . symbol . BatchNorm ( name = ' bn2a _ branch2a ' , data = res2a_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2a_branch2a = bn2a_branch2a NEW_LINE res2a_branch2a_relu = mx . symbol . Activation ( name = ' res2a _ branch2a _ relu ' , data = scale2a_branch2a , act_type = ' relu ' ) NEW_LINE res2a_branch2b = mx . symbol . Convolution ( name = ' res2a _ branch2b ' , data = res2a_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2b = mx . symbol . BatchNorm ( name = ' bn2a _ branch2b ' , data = res2a_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2a_branch2b = bn2a_branch2b NEW_LINE res2a_branch2b_relu = mx . symbol . Activation ( name = ' res2a _ branch2b _ relu ' , data = scale2a_branch2b , act_type = ' relu ' ) NEW_LINE res2a_branch2c = mx . symbol . Convolution ( name = ' res2a _ branch2c ' , data = res2a_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2c = mx . symbol . BatchNorm ( name = ' bn2a _ branch2c ' , data = res2a_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2a_branch2c = bn2a_branch2c NEW_LINE res2a = mx . symbol . broadcast_add ( name = ' res2a ' , * [ scale2a_branch1 , scale2a_branch2c ] ) NEW_LINE res2a_relu = mx . symbol . Activation ( name = ' res2a _ relu ' , data = res2a , act_type = ' relu ' ) NEW_LINE res2b_branch2a = mx . symbol . Convolution ( name = ' res2b _ branch2a ' , data = res2a_relu , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2a = mx . symbol . BatchNorm ( name = ' bn2b _ branch2a ' , data = res2b_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2b_branch2a = bn2b_branch2a NEW_LINE res2b_branch2a_relu = mx . symbol . Activation ( name = ' res2b _ branch2a _ relu ' , data = scale2b_branch2a , act_type = ' relu ' ) NEW_LINE res2b_branch2b = mx . symbol . Convolution ( name = ' res2b _ branch2b ' , data = res2b_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2b = mx . symbol . BatchNorm ( name = ' bn2b _ branch2b ' , data = res2b_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2b_branch2b = bn2b_branch2b NEW_LINE res2b_branch2b_relu = mx . symbol . Activation ( name = ' res2b _ branch2b _ relu ' , data = scale2b_branch2b , act_type = ' relu ' ) NEW_LINE res2b_branch2c = mx . symbol . Convolution ( name = ' res2b _ branch2c ' , data = res2b_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2c = mx . symbol . BatchNorm ( name = ' bn2b _ branch2c ' , data = res2b_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2b_branch2c = bn2b_branch2c NEW_LINE res2b = mx . symbol . broadcast_add ( name = ' res2b ' , * [ res2a_relu , scale2b_branch2c ] ) NEW_LINE res2b_relu = mx . symbol . Activation ( name = ' res2b _ relu ' , data = res2b , act_type = ' relu ' ) NEW_LINE res2c_branch2a = mx . symbol . Convolution ( name = ' res2c _ branch2a ' , data = res2b_relu , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2a = mx . symbol . BatchNorm ( name = ' bn2c _ branch2a ' , data = res2c_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2c_branch2a = bn2c_branch2a NEW_LINE res2c_branch2a_relu = mx . symbol . Activation ( name = ' res2c _ branch2a _ relu ' , data = scale2c_branch2a , act_type = ' relu ' ) NEW_LINE res2c_branch2b = mx . symbol . Convolution ( name = ' res2c _ branch2b ' , data = res2c_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2b = mx . symbol . BatchNorm ( name = ' bn2c _ branch2b ' , data = res2c_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2c_branch2b = bn2c_branch2b NEW_LINE res2c_branch2b_relu = mx . symbol . Activation ( name = ' res2c _ branch2b _ relu ' , data = scale2c_branch2b , act_type = ' relu ' ) NEW_LINE res2c_branch2c = mx . symbol . Convolution ( name = ' res2c _ branch2c ' , data = res2c_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2c = mx . symbol . BatchNorm ( name = ' bn2c _ branch2c ' , data = res2c_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2c_branch2c = bn2c_branch2c NEW_LINE res2c = mx . symbol . broadcast_add ( name = ' res2c ' , * [ res2b_relu , scale2c_branch2c ] ) NEW_LINE res2c_relu = mx . symbol . Activation ( name = ' res2c _ relu ' , data = res2c , act_type = ' relu ' ) NEW_LINE res3a_branch1 = mx . symbol . Convolution ( name = ' res3a _ branch1' , data = res2c_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn3a_branch1 = mx . symbol . BatchNorm ( name = ' bn3a _ branch1' , data = res3a_branch1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3a_branch1 = bn3a_branch1 NEW_LINE res3a_branch2a = mx . symbol . Convolution ( name = ' res3a _ branch2a ' , data = res2c_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn3a_branch2a = mx . symbol . BatchNorm ( name = ' bn3a _ branch2a ' , data = res3a_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3a_branch2a = bn3a_branch2a NEW_LINE res3a_branch2a_relu = mx . symbol . Activation ( name = ' res3a _ branch2a _ relu ' , data = scale3a_branch2a , act_type = ' relu ' ) NEW_LINE res3a_branch2b = mx . symbol . Convolution ( name = ' res3a _ branch2b ' , data = res3a_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3a_branch2b = mx . symbol . BatchNorm ( name = ' bn3a _ branch2b ' , data = res3a_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3a_branch2b = bn3a_branch2b NEW_LINE res3a_branch2b_relu = mx . symbol . Activation ( name = ' res3a _ branch2b _ relu ' , data = scale3a_branch2b , act_type = ' relu ' ) NEW_LINE res3a_branch2c = mx . symbol . Convolution ( name = ' res3a _ branch2c ' , data = res3a_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3a_branch2c = mx . symbol . BatchNorm ( name = ' bn3a _ branch2c ' , data = res3a_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3a_branch2c = bn3a_branch2c NEW_LINE res3a = mx . symbol . broadcast_add ( name = ' res3a ' , * [ scale3a_branch1 , scale3a_branch2c ] ) NEW_LINE res3a_relu = mx . symbol . Activation ( name = ' res3a _ relu ' , data = res3a , act_type = ' relu ' ) NEW_LINE res3b1_branch2a = mx . symbol . Convolution ( name = ' res3b1 _ branch2a ' , data = res3a_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2a = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2a ' , data = res3b1_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b1_branch2a = bn3b1_branch2a NEW_LINE res3b1_branch2a_relu = mx . symbol . Activation ( name = ' res3b1 _ branch2a _ relu ' , data = scale3b1_branch2a , act_type = ' relu ' ) NEW_LINE res3b1_branch2b = mx . symbol . Convolution ( name = ' res3b1 _ branch2b ' , data = res3b1_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2b = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2b ' , data = res3b1_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b1_branch2b = bn3b1_branch2b NEW_LINE res3b1_branch2b_relu = mx . symbol . Activation ( name = ' res3b1 _ branch2b _ relu ' , data = scale3b1_branch2b , act_type = ' relu ' ) NEW_LINE res3b1_branch2c = mx . symbol . Convolution ( name = ' res3b1 _ branch2c ' , data = res3b1_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2c = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2c ' , data = res3b1_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b1_branch2c = bn3b1_branch2c NEW_LINE res3b1 = mx . symbol . broadcast_add ( name = ' res3b1' , * [ res3a_relu , scale3b1_branch2c ] ) NEW_LINE res3b1_relu = mx . symbol . Activation ( name = ' res3b1 _ relu ' , data = res3b1 , act_type = ' relu ' ) NEW_LINE res3b2_branch2a = mx . symbol . Convolution ( name = ' res3b2 _ branch2a ' , data = res3b1_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2a = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2a ' , data = res3b2_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b2_branch2a = bn3b2_branch2a NEW_LINE res3b2_branch2a_relu = mx . symbol . Activation ( name = ' res3b2 _ branch2a _ relu ' , data = scale3b2_branch2a , act_type = ' relu ' ) NEW_LINE res3b2_branch2b = mx . symbol . Convolution ( name = ' res3b2 _ branch2b ' , data = res3b2_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2b = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2b ' , data = res3b2_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b2_branch2b = bn3b2_branch2b NEW_LINE res3b2_branch2b_relu = mx . symbol . Activation ( name = ' res3b2 _ branch2b _ relu ' , data = scale3b2_branch2b , act_type = ' relu ' ) NEW_LINE res3b2_branch2c = mx . symbol . Convolution ( name = ' res3b2 _ branch2c ' , data = res3b2_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2c = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2c ' , data = res3b2_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b2_branch2c = bn3b2_branch2c NEW_LINE res3b2 = mx . symbol . broadcast_add ( name = ' res3b2' , * [ res3b1_relu , scale3b2_branch2c ] ) NEW_LINE res3b2_relu = mx . symbol . Activation ( name = ' res3b2 _ relu ' , data = res3b2 , act_type = ' relu ' ) NEW_LINE res3b3_branch2a = mx . symbol . Convolution ( name = ' res3b3 _ branch2a ' , data = res3b2_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b3_branch2a = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2a ' , data = res3b3_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b3_branch2a = bn3b3_branch2a NEW_LINE res3b3_branch2a_relu = mx . symbol . Activation ( name = ' res3b3 _ branch2a _ relu ' , data = scale3b3_branch2a , act_type = ' relu ' ) NEW_LINE res3b3_branch2b = mx . symbol . Convolution ( name = ' res3b3 _ branch2b ' , data = res3b3_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b3_branch2b = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2b ' , data = res3b3_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b3_branch2b = bn3b3_branch2b NEW_LINE res3b3_branch2b_relu = mx . symbol . Activation ( name = ' res3b3 _ branch2b _ relu ' , data = scale3b3_branch2b , act_type = ' relu ' ) NEW_LINE res3b3_branch2c = mx . symbol . Convolution ( name = ' res3b3 _ branch2c ' , data = res3b3_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b3_branch2c = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2c ' , data = res3b3_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b3_branch2c = bn3b3_branch2c NEW_LINE res3b3 = mx . symbol . broadcast_add ( name = ' res3b3' , * [ res3b2_relu , scale3b3_branch2c ] ) NEW_LINE res3b3_relu = mx . symbol . Activation ( name = ' res3b3 _ relu ' , data = res3b3 , act_type = ' relu ' ) NEW_LINE res4a_branch1 = mx . symbol . Convolution ( name = ' res4a _ branch1' , data = res3b3_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn4a_branch1 = mx . symbol . BatchNorm ( name = ' bn4a _ branch1' , data = res4a_branch1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4a_branch1 = bn4a_branch1 NEW_LINE res4a_branch2a = mx . symbol . Convolution ( name = ' res4a _ branch2a ' , data = res3b3_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn4a_branch2a = mx . symbol . BatchNorm ( name = ' bn4a _ branch2a ' , data = res4a_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4a_branch2a = bn4a_branch2a NEW_LINE res4a_branch2a_relu = mx . symbol . Activation ( name = ' res4a _ branch2a _ relu ' , data = scale4a_branch2a , act_type = ' relu ' ) NEW_LINE res4a_branch2b = mx . symbol . Convolution ( name = ' res4a _ branch2b ' , data = res4a_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4a_branch2b = mx . symbol . BatchNorm ( name = ' bn4a _ branch2b ' , data = res4a_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4a_branch2b = bn4a_branch2b NEW_LINE res4a_branch2b_relu = mx . symbol . Activation ( name = ' res4a _ branch2b _ relu ' , data = scale4a_branch2b , act_type = ' relu ' ) NEW_LINE res4a_branch2c = mx . symbol . Convolution ( name = ' res4a _ branch2c ' , data = res4a_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4a_branch2c = mx . symbol . BatchNorm ( name = ' bn4a _ branch2c ' , data = res4a_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4a_branch2c = bn4a_branch2c NEW_LINE res4a = mx . symbol . broadcast_add ( name = ' res4a ' , * [ scale4a_branch1 , scale4a_branch2c ] ) NEW_LINE res4a_relu = mx . symbol . Activation ( name = ' res4a _ relu ' , data = res4a , act_type = ' relu ' ) NEW_LINE res4b1_branch2a = mx . symbol . Convolution ( name = ' res4b1 _ branch2a ' , data = res4a_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2a = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2a ' , data = res4b1_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b1_branch2a = bn4b1_branch2a NEW_LINE res4b1_branch2a_relu = mx . symbol . Activation ( name = ' res4b1 _ branch2a _ relu ' , data = scale4b1_branch2a , act_type = ' relu ' ) NEW_LINE res4b1_branch2b = mx . symbol . Convolution ( name = ' res4b1 _ branch2b ' , data = res4b1_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2b = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2b ' , data = res4b1_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b1_branch2b = bn4b1_branch2b NEW_LINE res4b1_branch2b_relu = mx . symbol . Activation ( name = ' res4b1 _ branch2b _ relu ' , data = scale4b1_branch2b , act_type = ' relu ' ) NEW_LINE res4b1_branch2c = mx . symbol . Convolution ( name = ' res4b1 _ branch2c ' , data = res4b1_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2c = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2c ' , data = res4b1_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b1_branch2c = bn4b1_branch2c NEW_LINE res4b1 = mx . symbol . broadcast_add ( name = ' res4b1' , * [ res4a_relu , scale4b1_branch2c ] ) NEW_LINE res4b1_relu = mx . symbol . Activation ( name = ' res4b1 _ relu ' , data = res4b1 , act_type = ' relu ' ) NEW_LINE res4b2_branch2a = mx . symbol . Convolution ( name = ' res4b2 _ branch2a ' , data = res4b1_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2a = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2a ' , data = res4b2_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b2_branch2a = bn4b2_branch2a NEW_LINE res4b2_branch2a_relu = mx . symbol . Activation ( name = ' res4b2 _ branch2a _ relu ' , data = scale4b2_branch2a , act_type = ' relu ' ) NEW_LINE res4b2_branch2b = mx . symbol . Convolution ( name = ' res4b2 _ branch2b ' , data = res4b2_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2b = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2b ' , data = res4b2_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b2_branch2b = bn4b2_branch2b NEW_LINE res4b2_branch2b_relu = mx . symbol . Activation ( name = ' res4b2 _ branch2b _ relu ' , data = scale4b2_branch2b , act_type = ' relu ' ) NEW_LINE res4b2_branch2c = mx . symbol . Convolution ( name = ' res4b2 _ branch2c ' , data = res4b2_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2c = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2c ' , data = res4b2_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b2_branch2c = bn4b2_branch2c NEW_LINE res4b2 = mx . symbol . broadcast_add ( name = ' res4b2' , * [ res4b1_relu , scale4b2_branch2c ] ) NEW_LINE res4b2_relu = mx . symbol . Activation ( name = ' res4b2 _ relu ' , data = res4b2 , act_type = ' relu ' ) NEW_LINE res4b3_branch2a = mx . symbol . Convolution ( name = ' res4b3 _ branch2a ' , data = res4b2_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2a = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2a ' , data = res4b3_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b3_branch2a = bn4b3_branch2a NEW_LINE res4b3_branch2a_relu = mx . symbol . Activation ( name = ' res4b3 _ branch2a _ relu ' , data = scale4b3_branch2a , act_type = ' relu ' ) NEW_LINE res4b3_branch2b = mx . symbol . Convolution ( name = ' res4b3 _ branch2b ' , data = res4b3_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2b = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2b ' , data = res4b3_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b3_branch2b = bn4b3_branch2b NEW_LINE res4b3_branch2b_relu = mx . symbol . Activation ( name = ' res4b3 _ branch2b _ relu ' , data = scale4b3_branch2b , act_type = ' relu ' ) NEW_LINE res4b3_branch2c = mx . symbol . Convolution ( name = ' res4b3 _ branch2c ' , data = res4b3_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2c = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2c ' , data = res4b3_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b3_branch2c = bn4b3_branch2c NEW_LINE res4b3 = mx . symbol . broadcast_add ( name = ' res4b3' , * [ res4b2_relu , scale4b3_branch2c ] ) NEW_LINE res4b3_relu = mx . symbol . Activation ( name = ' res4b3 _ relu ' , data = res4b3 , act_type = ' relu ' ) NEW_LINE res4b4_branch2a = mx . symbol . Convolution ( name = ' res4b4 _ branch2a ' , data = res4b3_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2a = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2a ' , data = res4b4_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b4_branch2a = bn4b4_branch2a NEW_LINE res4b4_branch2a_relu = mx . symbol . Activation ( name = ' res4b4 _ branch2a _ relu ' , data = scale4b4_branch2a , act_type = ' relu ' ) NEW_LINE res4b4_branch2b = mx . symbol . Convolution ( name = ' res4b4 _ branch2b ' , data = res4b4_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2b = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2b ' , data = res4b4_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b4_branch2b = bn4b4_branch2b NEW_LINE res4b4_branch2b_relu = mx . symbol . Activation ( name = ' res4b4 _ branch2b _ relu ' , data = scale4b4_branch2b , act_type = ' relu ' ) NEW_LINE res4b4_branch2c = mx . symbol . Convolution ( name = ' res4b4 _ branch2c ' , data = res4b4_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2c = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2c ' , data = res4b4_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b4_branch2c = bn4b4_branch2c NEW_LINE res4b4 = mx . symbol . broadcast_add ( name = ' res4b4' , * [ res4b3_relu , scale4b4_branch2c ] ) NEW_LINE res4b4_relu = mx . symbol . Activation ( name = ' res4b4 _ relu ' , data = res4b4 , act_type = ' relu ' ) NEW_LINE res4b5_branch2a = mx . symbol . Convolution ( name = ' res4b5 _ branch2a ' , data = res4b4_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2a = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2a ' , data = res4b5_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b5_branch2a = bn4b5_branch2a NEW_LINE res4b5_branch2a_relu = mx . symbol . Activation ( name = ' res4b5 _ branch2a _ relu ' , data = scale4b5_branch2a , act_type = ' relu ' ) NEW_LINE res4b5_branch2b = mx . symbol . Convolution ( name = ' res4b5 _ branch2b ' , data = res4b5_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2b = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2b ' , data = res4b5_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b5_branch2b = bn4b5_branch2b NEW_LINE res4b5_branch2b_relu = mx . symbol . Activation ( name = ' res4b5 _ branch2b _ relu ' , data = scale4b5_branch2b , act_type = ' relu ' ) NEW_LINE res4b5_branch2c = mx . symbol . Convolution ( name = ' res4b5 _ branch2c ' , data = res4b5_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2c = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2c ' , data = res4b5_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b5_branch2c = bn4b5_branch2c NEW_LINE res4b5 = mx . symbol . broadcast_add ( name = ' res4b5' , * [ res4b4_relu , scale4b5_branch2c ] ) NEW_LINE res4b5_relu = mx . symbol . Activation ( name = ' res4b5 _ relu ' , data = res4b5 , act_type = ' relu ' ) NEW_LINE res4b6_branch2a = mx . symbol . Convolution ( name = ' res4b6 _ branch2a ' , data = res4b5_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2a = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2a ' , data = res4b6_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b6_branch2a = bn4b6_branch2a NEW_LINE res4b6_branch2a_relu = mx . symbol . Activation ( name = ' res4b6 _ branch2a _ relu ' , data = scale4b6_branch2a , act_type = ' relu ' ) NEW_LINE res4b6_branch2b = mx . symbol . Convolution ( name = ' res4b6 _ branch2b ' , data = res4b6_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2b = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2b ' , data = res4b6_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b6_branch2b = bn4b6_branch2b NEW_LINE res4b6_branch2b_relu = mx . symbol . Activation ( name = ' res4b6 _ branch2b _ relu ' , data = scale4b6_branch2b , act_type = ' relu ' ) NEW_LINE res4b6_branch2c = mx . symbol . Convolution ( name = ' res4b6 _ branch2c ' , data = res4b6_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2c = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2c ' , data = res4b6_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b6_branch2c = bn4b6_branch2c NEW_LINE res4b6 = mx . symbol . broadcast_add ( name = ' res4b6' , * [ res4b5_relu , scale4b6_branch2c ] ) NEW_LINE res4b6_relu = mx . symbol . Activation ( name = ' res4b6 _ relu ' , data = res4b6 , act_type = ' relu ' ) NEW_LINE res4b7_branch2a = mx . symbol . Convolution ( name = ' res4b7 _ branch2a ' , data = res4b6_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2a = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2a ' , data = res4b7_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b7_branch2a = bn4b7_branch2a NEW_LINE res4b7_branch2a_relu = mx . symbol . Activation ( name = ' res4b7 _ branch2a _ relu ' , data = scale4b7_branch2a , act_type = ' relu ' ) NEW_LINE res4b7_branch2b = mx . symbol . Convolution ( name = ' res4b7 _ branch2b ' , data = res4b7_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2b = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2b ' , data = res4b7_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b7_branch2b = bn4b7_branch2b NEW_LINE res4b7_branch2b_relu = mx . symbol . Activation ( name = ' res4b7 _ branch2b _ relu ' , data = scale4b7_branch2b , act_type = ' relu ' ) NEW_LINE res4b7_branch2c = mx . symbol . Convolution ( name = ' res4b7 _ branch2c ' , data = res4b7_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2c = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2c ' , data = res4b7_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b7_branch2c = bn4b7_branch2c NEW_LINE res4b7 = mx . symbol . broadcast_add ( name = ' res4b7' , * [ res4b6_relu , scale4b7_branch2c ] ) NEW_LINE res4b7_relu = mx . symbol . Activation ( name = ' res4b7 _ relu ' , data = res4b7 , act_type = ' relu ' ) NEW_LINE res4b8_branch2a = mx . symbol . Convolution ( name = ' res4b8 _ branch2a ' , data = res4b7_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2a = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2a ' , data = res4b8_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b8_branch2a = bn4b8_branch2a NEW_LINE res4b8_branch2a_relu = mx . symbol . Activation ( name = ' res4b8 _ branch2a _ relu ' , data = scale4b8_branch2a , act_type = ' relu ' ) NEW_LINE res4b8_branch2b = mx . symbol . Convolution ( name = ' res4b8 _ branch2b ' , data = res4b8_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2b = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2b ' , data = res4b8_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b8_branch2b = bn4b8_branch2b NEW_LINE res4b8_branch2b_relu = mx . symbol . Activation ( name = ' res4b8 _ branch2b _ relu ' , data = scale4b8_branch2b , act_type = ' relu ' ) NEW_LINE res4b8_branch2c = mx . symbol . Convolution ( name = ' res4b8 _ branch2c ' , data = res4b8_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2c = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2c ' , data = res4b8_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b8_branch2c = bn4b8_branch2c NEW_LINE res4b8 = mx . symbol . broadcast_add ( name = ' res4b8' , * [ res4b7_relu , scale4b8_branch2c ] ) NEW_LINE res4b8_relu = mx . symbol . Activation ( name = ' res4b8 _ relu ' , data = res4b8 , act_type = ' relu ' ) NEW_LINE res4b9_branch2a = mx . symbol . Convolution ( name = ' res4b9 _ branch2a ' , data = res4b8_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2a = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2a ' , data = res4b9_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b9_branch2a = bn4b9_branch2a NEW_LINE res4b9_branch2a_relu = mx . symbol . Activation ( name = ' res4b9 _ branch2a _ relu ' , data = scale4b9_branch2a , act_type = ' relu ' ) NEW_LINE res4b9_branch2b = mx . symbol . Convolution ( name = ' res4b9 _ branch2b ' , data = res4b9_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2b = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2b ' , data = res4b9_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b9_branch2b = bn4b9_branch2b NEW_LINE res4b9_branch2b_relu = mx . symbol . Activation ( name = ' res4b9 _ branch2b _ relu ' , data = scale4b9_branch2b , act_type = ' relu ' ) NEW_LINE res4b9_branch2c = mx . symbol . Convolution ( name = ' res4b9 _ branch2c ' , data = res4b9_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2c = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2c ' , data = res4b9_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b9_branch2c = bn4b9_branch2c NEW_LINE res4b9 = mx . symbol . broadcast_add ( name = ' res4b9' , * [ res4b8_relu , scale4b9_branch2c ] ) NEW_LINE res4b9_relu = mx . symbol . Activation ( name = ' res4b9 _ relu ' , data = res4b9 , act_type = ' relu ' ) NEW_LINE res4b10_branch2a = mx . symbol . Convolution ( name = ' res4b10 _ branch2a ' , data = res4b9_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2a = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2a ' , data = res4b10_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b10_branch2a = bn4b10_branch2a NEW_LINE res4b10_branch2a_relu = mx . symbol . Activation ( name = ' res4b10 _ branch2a _ relu ' , data = scale4b10_branch2a , act_type = ' relu ' ) NEW_LINE res4b10_branch2b = mx . symbol . Convolution ( name = ' res4b10 _ branch2b ' , data = res4b10_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2b = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2b ' , data = res4b10_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b10_branch2b = bn4b10_branch2b NEW_LINE res4b10_branch2b_relu = mx . symbol . Activation ( name = ' res4b10 _ branch2b _ relu ' , data = scale4b10_branch2b , act_type = ' relu ' ) NEW_LINE res4b10_branch2c = mx . symbol . Convolution ( name = ' res4b10 _ branch2c ' , data = res4b10_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2c = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2c ' , data = res4b10_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b10_branch2c = bn4b10_branch2c NEW_LINE res4b10 = mx . symbol . broadcast_add ( name = ' res4b10' , * [ res4b9_relu , scale4b10_branch2c ] ) NEW_LINE res4b10_relu = mx . symbol . Activation ( name = ' res4b10 _ relu ' , data = res4b10 , act_type = ' relu ' ) NEW_LINE res4b11_branch2a = mx . symbol . Convolution ( name = ' res4b11 _ branch2a ' , data = res4b10_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2a = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2a ' , data = res4b11_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b11_branch2a = bn4b11_branch2a NEW_LINE res4b11_branch2a_relu = mx . symbol . Activation ( name = ' res4b11 _ branch2a _ relu ' , data = scale4b11_branch2a , act_type = ' relu ' ) NEW_LINE res4b11_branch2b = mx . symbol . Convolution ( name = ' res4b11 _ branch2b ' , data = res4b11_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2b = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2b ' , data = res4b11_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b11_branch2b = bn4b11_branch2b NEW_LINE res4b11_branch2b_relu = mx . symbol . Activation ( name = ' res4b11 _ branch2b _ relu ' , data = scale4b11_branch2b , act_type = ' relu ' ) NEW_LINE res4b11_branch2c = mx . symbol . Convolution ( name = ' res4b11 _ branch2c ' , data = res4b11_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2c = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2c ' , data = res4b11_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b11_branch2c = bn4b11_branch2c NEW_LINE res4b11 = mx . symbol . broadcast_add ( name = ' res4b11' , * [ res4b10_relu , scale4b11_branch2c ] ) NEW_LINE res4b11_relu = mx . symbol . Activation ( name = ' res4b11 _ relu ' , data = res4b11 , act_type = ' relu ' ) NEW_LINE res4b12_branch2a = mx . symbol . Convolution ( name = ' res4b12 _ branch2a ' , data = res4b11_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2a = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2a ' , data = res4b12_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b12_branch2a = bn4b12_branch2a NEW_LINE res4b12_branch2a_relu = mx . symbol . Activation ( name = ' res4b12 _ branch2a _ relu ' , data = scale4b12_branch2a , act_type = ' relu ' ) NEW_LINE res4b12_branch2b = mx . symbol . Convolution ( name = ' res4b12 _ branch2b ' , data = res4b12_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2b = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2b ' , data = res4b12_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b12_branch2b = bn4b12_branch2b NEW_LINE res4b12_branch2b_relu = mx . symbol . Activation ( name = ' res4b12 _ branch2b _ relu ' , data = scale4b12_branch2b , act_type = ' relu ' ) NEW_LINE res4b12_branch2c = mx . symbol . Convolution ( name = ' res4b12 _ branch2c ' , data = res4b12_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2c = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2c ' , data = res4b12_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b12_branch2c = bn4b12_branch2c NEW_LINE res4b12 = mx . symbol . broadcast_add ( name = ' res4b12' , * [ res4b11_relu , scale4b12_branch2c ] ) NEW_LINE res4b12_relu = mx . symbol . Activation ( name = ' res4b12 _ relu ' , data = res4b12 , act_type = ' relu ' ) NEW_LINE res4b13_branch2a = mx . symbol . Convolution ( name = ' res4b13 _ branch2a ' , data = res4b12_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2a = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2a ' , data = res4b13_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b13_branch2a = bn4b13_branch2a NEW_LINE res4b13_branch2a_relu = mx . symbol . Activation ( name = ' res4b13 _ branch2a _ relu ' , data = scale4b13_branch2a , act_type = ' relu ' ) NEW_LINE res4b13_branch2b = mx . symbol . Convolution ( name = ' res4b13 _ branch2b ' , data = res4b13_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2b = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2b ' , data = res4b13_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b13_branch2b = bn4b13_branch2b NEW_LINE res4b13_branch2b_relu = mx . symbol . Activation ( name = ' res4b13 _ branch2b _ relu ' , data = scale4b13_branch2b , act_type = ' relu ' ) NEW_LINE res4b13_branch2c = mx . symbol . Convolution ( name = ' res4b13 _ branch2c ' , data = res4b13_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2c = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2c ' , data = res4b13_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b13_branch2c = bn4b13_branch2c NEW_LINE res4b13 = mx . symbol . broadcast_add ( name = ' res4b13' , * [ res4b12_relu , scale4b13_branch2c ] ) NEW_LINE res4b13_relu = mx . symbol . Activation ( name = ' res4b13 _ relu ' , data = res4b13 , act_type = ' relu ' ) NEW_LINE res4b14_branch2a = mx . symbol . Convolution ( name = ' res4b14 _ branch2a ' , data = res4b13_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2a = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2a ' , data = res4b14_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b14_branch2a = bn4b14_branch2a NEW_LINE res4b14_branch2a_relu = mx . symbol . Activation ( name = ' res4b14 _ branch2a _ relu ' , data = scale4b14_branch2a , act_type = ' relu ' ) NEW_LINE res4b14_branch2b = mx . symbol . Convolution ( name = ' res4b14 _ branch2b ' , data = res4b14_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2b = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2b ' , data = res4b14_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b14_branch2b = bn4b14_branch2b NEW_LINE res4b14_branch2b_relu = mx . symbol . Activation ( name = ' res4b14 _ branch2b _ relu ' , data = scale4b14_branch2b , act_type = ' relu ' ) NEW_LINE res4b14_branch2c = mx . symbol . Convolution ( name = ' res4b14 _ branch2c ' , data = res4b14_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2c = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2c ' , data = res4b14_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b14_branch2c = bn4b14_branch2c NEW_LINE res4b14 = mx . symbol . broadcast_add ( name = ' res4b14' , * [ res4b13_relu , scale4b14_branch2c ] ) NEW_LINE res4b14_relu = mx . symbol . Activation ( name = ' res4b14 _ relu ' , data = res4b14 , act_type = ' relu ' ) NEW_LINE res4b15_branch2a = mx . symbol . Convolution ( name = ' res4b15 _ branch2a ' , data = res4b14_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2a = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2a ' , data = res4b15_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b15_branch2a = bn4b15_branch2a NEW_LINE res4b15_branch2a_relu = mx . symbol . Activation ( name = ' res4b15 _ branch2a _ relu ' , data = scale4b15_branch2a , act_type = ' relu ' ) NEW_LINE res4b15_branch2b = mx . symbol . Convolution ( name = ' res4b15 _ branch2b ' , data = res4b15_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2b = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2b ' , data = res4b15_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b15_branch2b = bn4b15_branch2b NEW_LINE res4b15_branch2b_relu = mx . symbol . Activation ( name = ' res4b15 _ branch2b _ relu ' , data = scale4b15_branch2b , act_type = ' relu ' ) NEW_LINE res4b15_branch2c = mx . symbol . Convolution ( name = ' res4b15 _ branch2c ' , data = res4b15_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2c = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2c ' , data = res4b15_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b15_branch2c = bn4b15_branch2c NEW_LINE res4b15 = mx . symbol . broadcast_add ( name = ' res4b15' , * [ res4b14_relu , scale4b15_branch2c ] ) NEW_LINE res4b15_relu = mx . symbol . Activation ( name = ' res4b15 _ relu ' , data = res4b15 , act_type = ' relu ' ) NEW_LINE res4b16_branch2a = mx . symbol . Convolution ( name = ' res4b16 _ branch2a ' , data = res4b15_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2a = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2a ' , data = res4b16_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b16_branch2a = bn4b16_branch2a NEW_LINE res4b16_branch2a_relu = mx . symbol . Activation ( name = ' res4b16 _ branch2a _ relu ' , data = scale4b16_branch2a , act_type = ' relu ' ) NEW_LINE res4b16_branch2b = mx . symbol . Convolution ( name = ' res4b16 _ branch2b ' , data = res4b16_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2b = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2b ' , data = res4b16_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b16_branch2b = bn4b16_branch2b NEW_LINE res4b16_branch2b_relu = mx . symbol . Activation ( name = ' res4b16 _ branch2b _ relu ' , data = scale4b16_branch2b , act_type = ' relu ' ) NEW_LINE res4b16_branch2c = mx . symbol . Convolution ( name = ' res4b16 _ branch2c ' , data = res4b16_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2c = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2c ' , data = res4b16_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b16_branch2c = bn4b16_branch2c NEW_LINE res4b16 = mx . symbol . broadcast_add ( name = ' res4b16' , * [ res4b15_relu , scale4b16_branch2c ] ) NEW_LINE res4b16_relu = mx . symbol . Activation ( name = ' res4b16 _ relu ' , data = res4b16 , act_type = ' relu ' ) NEW_LINE res4b17_branch2a = mx . symbol . Convolution ( name = ' res4b17 _ branch2a ' , data = res4b16_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2a = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2a ' , data = res4b17_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b17_branch2a = bn4b17_branch2a NEW_LINE res4b17_branch2a_relu = mx . symbol . Activation ( name = ' res4b17 _ branch2a _ relu ' , data = scale4b17_branch2a , act_type = ' relu ' ) NEW_LINE res4b17_branch2b = mx . symbol . Convolution ( name = ' res4b17 _ branch2b ' , data = res4b17_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2b = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2b ' , data = res4b17_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b17_branch2b = bn4b17_branch2b NEW_LINE res4b17_branch2b_relu = mx . symbol . Activation ( name = ' res4b17 _ branch2b _ relu ' , data = scale4b17_branch2b , act_type = ' relu ' ) NEW_LINE res4b17_branch2c = mx . symbol . Convolution ( name = ' res4b17 _ branch2c ' , data = res4b17_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2c = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2c ' , data = res4b17_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b17_branch2c = bn4b17_branch2c NEW_LINE res4b17 = mx . symbol . broadcast_add ( name = ' res4b17' , * [ res4b16_relu , scale4b17_branch2c ] ) NEW_LINE res4b17_relu = mx . symbol . Activation ( name = ' res4b17 _ relu ' , data = res4b17 , act_type = ' relu ' ) NEW_LINE res4b18_branch2a = mx . symbol . Convolution ( name = ' res4b18 _ branch2a ' , data = res4b17_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2a = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2a ' , data = res4b18_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b18_branch2a = bn4b18_branch2a NEW_LINE res4b18_branch2a_relu = mx . symbol . Activation ( name = ' res4b18 _ branch2a _ relu ' , data = scale4b18_branch2a , act_type = ' relu ' ) NEW_LINE res4b18_branch2b = mx . symbol . Convolution ( name = ' res4b18 _ branch2b ' , data = res4b18_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2b = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2b ' , data = res4b18_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b18_branch2b = bn4b18_branch2b NEW_LINE res4b18_branch2b_relu = mx . symbol . Activation ( name = ' res4b18 _ branch2b _ relu ' , data = scale4b18_branch2b , act_type = ' relu ' ) NEW_LINE res4b18_branch2c = mx . symbol . Convolution ( name = ' res4b18 _ branch2c ' , data = res4b18_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2c = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2c ' , data = res4b18_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b18_branch2c = bn4b18_branch2c NEW_LINE res4b18 = mx . symbol . broadcast_add ( name = ' res4b18' , * [ res4b17_relu , scale4b18_branch2c ] ) NEW_LINE res4b18_relu = mx . symbol . Activation ( name = ' res4b18 _ relu ' , data = res4b18 , act_type = ' relu ' ) NEW_LINE res4b19_branch2a = mx . symbol . Convolution ( name = ' res4b19 _ branch2a ' , data = res4b18_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2a = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2a ' , data = res4b19_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b19_branch2a = bn4b19_branch2a NEW_LINE res4b19_branch2a_relu = mx . symbol . Activation ( name = ' res4b19 _ branch2a _ relu ' , data = scale4b19_branch2a , act_type = ' relu ' ) NEW_LINE res4b19_branch2b = mx . symbol . Convolution ( name = ' res4b19 _ branch2b ' , data = res4b19_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2b = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2b ' , data = res4b19_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b19_branch2b = bn4b19_branch2b NEW_LINE res4b19_branch2b_relu = mx . symbol . Activation ( name = ' res4b19 _ branch2b _ relu ' , data = scale4b19_branch2b , act_type = ' relu ' ) NEW_LINE res4b19_branch2c = mx . symbol . Convolution ( name = ' res4b19 _ branch2c ' , data = res4b19_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2c = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2c ' , data = res4b19_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b19_branch2c = bn4b19_branch2c NEW_LINE res4b19 = mx . symbol . broadcast_add ( name = ' res4b19' , * [ res4b18_relu , scale4b19_branch2c ] ) NEW_LINE res4b19_relu = mx . symbol . Activation ( name = ' res4b19 _ relu ' , data = res4b19 , act_type = ' relu ' ) NEW_LINE res4b20_branch2a = mx . symbol . Convolution ( name = ' res4b20 _ branch2a ' , data = res4b19_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2a = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2a ' , data = res4b20_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b20_branch2a = bn4b20_branch2a NEW_LINE res4b20_branch2a_relu = mx . symbol . Activation ( name = ' res4b20 _ branch2a _ relu ' , data = scale4b20_branch2a , act_type = ' relu ' ) NEW_LINE res4b20_branch2b = mx . symbol . Convolution ( name = ' res4b20 _ branch2b ' , data = res4b20_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2b = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2b ' , data = res4b20_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b20_branch2b = bn4b20_branch2b NEW_LINE res4b20_branch2b_relu = mx . symbol . Activation ( name = ' res4b20 _ branch2b _ relu ' , data = scale4b20_branch2b , act_type = ' relu ' ) NEW_LINE res4b20_branch2c = mx . symbol . Convolution ( name = ' res4b20 _ branch2c ' , data = res4b20_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2c = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2c ' , data = res4b20_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b20_branch2c = bn4b20_branch2c NEW_LINE res4b20 = mx . symbol . broadcast_add ( name = ' res4b20' , * [ res4b19_relu , scale4b20_branch2c ] ) NEW_LINE res4b20_relu = mx . symbol . Activation ( name = ' res4b20 _ relu ' , data = res4b20 , act_type = ' relu ' ) NEW_LINE res4b21_branch2a = mx . symbol . Convolution ( name = ' res4b21 _ branch2a ' , data = res4b20_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2a = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2a ' , data = res4b21_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b21_branch2a = bn4b21_branch2a NEW_LINE res4b21_branch2a_relu = mx . symbol . Activation ( name = ' res4b21 _ branch2a _ relu ' , data = scale4b21_branch2a , act_type = ' relu ' ) NEW_LINE res4b21_branch2b = mx . symbol . Convolution ( name = ' res4b21 _ branch2b ' , data = res4b21_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2b = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2b ' , data = res4b21_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b21_branch2b = bn4b21_branch2b NEW_LINE res4b21_branch2b_relu = mx . symbol . Activation ( name = ' res4b21 _ branch2b _ relu ' , data = scale4b21_branch2b , act_type = ' relu ' ) NEW_LINE res4b21_branch2c = mx . symbol . Convolution ( name = ' res4b21 _ branch2c ' , data = res4b21_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2c = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2c ' , data = res4b21_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b21_branch2c = bn4b21_branch2c NEW_LINE res4b21 = mx . symbol . broadcast_add ( name = ' res4b21' , * [ res4b20_relu , scale4b21_branch2c ] ) NEW_LINE res4b21_relu = mx . symbol . Activation ( name = ' res4b21 _ relu ' , data = res4b21 , act_type = ' relu ' ) NEW_LINE res4b22_branch2a = mx . symbol . Convolution ( name = ' res4b22 _ branch2a ' , data = res4b21_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b22_branch2a = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2a ' , data = res4b22_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b22_branch2a = bn4b22_branch2a NEW_LINE res4b22_branch2a_relu = mx . symbol . Activation ( name = ' res4b22 _ branch2a _ relu ' , data = scale4b22_branch2a , act_type = ' relu ' ) NEW_LINE res4b22_branch2b = mx . symbol . Convolution ( name = ' res4b22 _ branch2b ' , data = res4b22_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b22_branch2b = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2b ' , data = res4b22_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b22_branch2b = bn4b22_branch2b NEW_LINE res4b22_branch2b_relu = mx . symbol . Activation ( name = ' res4b22 _ branch2b _ relu ' , data = scale4b22_branch2b , act_type = ' relu ' ) NEW_LINE res4b22_branch2c = mx . symbol . Convolution ( name = ' res4b22 _ branch2c ' , data = res4b22_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b22_branch2c = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2c ' , data = res4b22_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b22_branch2c = bn4b22_branch2c NEW_LINE res4b22 = mx . symbol . broadcast_add ( name = ' res4b22' , * [ res4b21_relu , scale4b22_branch2c ] ) NEW_LINE res4b22_relu = mx . symbol . Activation ( name = ' res4b22 _ relu ' , data = res4b22 , act_type = ' relu ' ) NEW_LINE return res4b22_relu NEW_LINE DEDENT\",), (\"def get_resnet_v1_conv5 ( self , conv_feat ) : NEW_LINE INDENT res5a_branch1 = mx . symbol . Convolution ( name = ' res5a _ branch1' , data = conv_feat , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5a_branch1 = mx . symbol . BatchNorm ( name = ' bn5a _ branch1' , data = res5a_branch1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5a_branch1 = bn5a_branch1 NEW_LINE res5a_branch2a = mx . symbol . Convolution ( name = ' res5a _ branch2a ' , data = conv_feat , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5a_branch2a = mx . symbol . BatchNorm ( name = ' bn5a _ branch2a ' , data = res5a_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5a_branch2a = bn5a_branch2a NEW_LINE res5a_branch2a_relu = mx . symbol . Activation ( name = ' res5a _ branch2a _ relu ' , data = scale5a_branch2a , act_type = ' relu ' ) NEW_LINE res5a_branch2b = mx . symbol . Convolution ( name = ' res5a _ branch2b ' , data = res5a_branch2a_relu , num_filter = 512 , pad = ( 2 , 2 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn5a_branch2b = mx . symbol . BatchNorm ( name = ' bn5a _ branch2b ' , data = res5a_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5a_branch2b = bn5a_branch2b NEW_LINE res5a_branch2b_relu = mx . symbol . Activation ( name = ' res5a _ branch2b _ relu ' , data = scale5a_branch2b , act_type = ' relu ' ) NEW_LINE res5a_branch2c = mx . symbol . Convolution ( name = ' res5a _ branch2c ' , data = res5a_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5a_branch2c = mx . symbol . BatchNorm ( name = ' bn5a _ branch2c ' , data = res5a_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5a_branch2c = bn5a_branch2c NEW_LINE res5a = mx . symbol . broadcast_add ( name = ' res5a ' , * [ scale5a_branch1 , scale5a_branch2c ] ) NEW_LINE res5a_relu = mx . symbol . Activation ( name = ' res5a _ relu ' , data = res5a , act_type = ' relu ' ) NEW_LINE res5b_branch2a = mx . symbol . Convolution ( name = ' res5b _ branch2a ' , data = res5a_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5b_branch2a = mx . symbol . BatchNorm ( name = ' bn5b _ branch2a ' , data = res5b_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5b_branch2a = bn5b_branch2a NEW_LINE res5b_branch2a_relu = mx . symbol . Activation ( name = ' res5b _ branch2a _ relu ' , data = scale5b_branch2a , act_type = ' relu ' ) NEW_LINE res5b_branch2b = mx . symbol . Convolution ( name = ' res5b _ branch2b ' , data = res5b_branch2a_relu , num_filter = 512 , pad = ( 2 , 2 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn5b_branch2b = mx . symbol . BatchNorm ( name = ' bn5b _ branch2b ' , data = res5b_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5b_branch2b = bn5b_branch2b NEW_LINE res5b_branch2b_relu = mx . symbol . Activation ( name = ' res5b _ branch2b _ relu ' , data = scale5b_branch2b , act_type = ' relu ' ) NEW_LINE res5b_branch2c = mx . symbol . Convolution ( name = ' res5b _ branch2c ' , data = res5b_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5b_branch2c = mx . symbol . BatchNorm ( name = ' bn5b _ branch2c ' , data = res5b_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5b_branch2c = bn5b_branch2c NEW_LINE res5b = mx . symbol . broadcast_add ( name = ' res5b ' , * [ res5a_relu , scale5b_branch2c ] ) NEW_LINE res5b_relu = mx . symbol . Activation ( name = ' res5b _ relu ' , data = res5b , act_type = ' relu ' ) NEW_LINE res5c_branch2a = mx . symbol . Convolution ( name = ' res5c _ branch2a ' , data = res5b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5c_branch2a = mx . symbol . BatchNorm ( name = ' bn5c _ branch2a ' , data = res5c_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5c_branch2a = bn5c_branch2a NEW_LINE res5c_branch2a_relu = mx . symbol . Activation ( name = ' res5c _ branch2a _ relu ' , data = scale5c_branch2a , act_type = ' relu ' ) NEW_LINE res5c_branch2b = mx . symbol . Convolution ( name = ' res5c _ branch2b ' , data = res5c_branch2a_relu , num_filter = 512 , pad = ( 2 , 2 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn5c_branch2b = mx . symbol . BatchNorm ( name = ' bn5c _ branch2b ' , data = res5c_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5c_branch2b = bn5c_branch2b NEW_LINE res5c_branch2b_relu = mx . symbol . Activation ( name = ' res5c _ branch2b _ relu ' , data = scale5c_branch2b , act_type = ' relu ' ) NEW_LINE res5c_branch2c = mx . symbol . Convolution ( name = ' res5c _ branch2c ' , data = res5c_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5c_branch2c = mx . symbol . BatchNorm ( name = ' bn5c _ branch2c ' , data = res5c_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5c_branch2c = bn5c_branch2c NEW_LINE res5c = mx . symbol . broadcast_add ( name = ' res5c ' , * [ res5b_relu , scale5c_branch2c ] ) NEW_LINE res5c_relu = mx . symbol . Activation ( name = ' res5c _ relu ' , data = res5c , act_type = ' relu ' ) NEW_LINE return res5c_relu NEW_LINE DEDENT\",), ('def get_rpn ( self , conv_feat , num_anchors ) : NEW_LINE INDENT rpn_conv = mx . sym . Convolution ( data = conv_feat , kernel = ( 3 , 3 ) , pad = ( 1 , 1 ) , num_filter = 512 , name = \" rpn _ conv _ 3x3\" ) NEW_LINE rpn_relu = mx . sym . Activation ( data = rpn_conv , act_type = \" relu \" , name = \" rpn _ relu \" ) NEW_LINE rpn_cls_score = mx . sym . Convolution ( data = rpn_relu , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , num_filter = 2 * num_anchors , name = \" rpn _ cls _ score \" ) NEW_LINE rpn_bbox_pred = mx . sym . Convolution ( data = rpn_relu , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , num_filter = 4 * num_anchors , name = \" rpn _ bbox _ pred \" ) NEW_LINE return rpn_cls_score , rpn_bbox_pred NEW_LINE DEDENT',), ('def get_symbol_rpn ( self , cfg , is_train = True ) : NEW_LINE INDENT num_anchors = cfg . network . NUM_ANCHORS NEW_LINE if is_train : NEW_LINE INDENT data = mx . sym . Variable ( name = \" data \" ) NEW_LINE rpn_label = mx . sym . Variable ( name = \\' label \\' ) NEW_LINE rpn_bbox_target = mx . sym . Variable ( name = \\' bbox _ target \\' ) NEW_LINE rpn_bbox_weight = mx . sym . Variable ( name = \\' bbox _ weight \\' ) NEW_LINE DEDENT else : NEW_LINE INDENT data = mx . sym . Variable ( name = \" data \" ) NEW_LINE im_info = mx . sym . Variable ( name = \" im _ info \" ) NEW_LINE DEDENT conv_feat = self . get_resnet_v1_conv4 ( data ) NEW_LINE rpn_cls_score , rpn_bbox_pred = self . get_rpn ( conv_feat , num_anchors ) NEW_LINE if is_train : NEW_LINE INDENT rpn_cls_score_reshape = mx . sym . Reshape ( data = rpn_cls_score , shape = ( 0 , 2 , - 1 , 0 ) , name = \" rpn _ cls _ score _ reshape \" ) NEW_LINE rpn_cls_prob = mx . sym . SoftmaxOutput ( data = rpn_cls_score_reshape , label = rpn_label , multi_output = True , normalization = \\' valid \\' , use_ignore = True , ignore_label = - 1 , name = \" rpn _ cls _ prob \" , grad_scale = 1.0 ) NEW_LINE rpn_bbox_loss_ = rpn_bbox_weight * mx . sym . smooth_l1 ( name = \\' rpn _ bbox _ loss _ \\' , scalar = 3.0 , data = ( rpn_bbox_pred - rpn_bbox_target ) ) NEW_LINE rpn_bbox_loss = mx . sym . MakeLoss ( name = \\' rpn _ bbox _ loss \\' , data = rpn_bbox_loss_ , grad_scale = 1.0 / cfg . TRAIN . RPN_BATCH_SIZE ) NEW_LINE group = mx . symbol . Group ( [ rpn_cls_prob , rpn_bbox_loss ] ) NEW_LINE DEDENT else : NEW_LINE INDENT rpn_cls_score_reshape = mx . sym . Reshape ( data = rpn_cls_score , shape = ( 0 , 2 , - 1 , 0 ) , name = \" rpn _ cls _ score _ reshape \" ) NEW_LINE rpn_cls_prob = mx . sym . SoftmaxActivation ( data = rpn_cls_score_reshape , mode = \" channel \" , name = \" rpn _ cls _ prob \" ) NEW_LINE rpn_cls_prob_reshape = mx . sym . Reshape ( data = rpn_cls_prob , shape = ( 0 , 2 * num_anchors , - 1 , 0 ) , name = \\' rpn _ cls _ prob _ reshape \\' ) NEW_LINE if cfg . TEST . CXX_PROPOSAL : NEW_LINE INDENT rois , score = mx . contrib . sym . Proposal ( cls_prob = rpn_cls_prob_reshape , bbox_pred = rpn_bbox_pred , im_info = im_info , name = \\' rois \\' , output_score = True , feature_stride = cfg . network . RPN_FEAT_STRIDE , scales = tuple ( cfg . network . ANCHOR_SCALES ) , ratios = tuple ( cfg . network . ANCHOR_RATIOS ) , rpn_pre_nms_top_n = cfg . TEST . RPN_PRE_NMS_TOP_N , rpn_post_nms_top_n = cfg . TEST . RPN_POST_NMS_TOP_N , threshold = cfg . TEST . RPN_NMS_THRESH , rpn_min_size = cfg . TEST . RPN_MIN_SIZE ) NEW_LINE DEDENT else : NEW_LINE INDENT rois , score = mx . sym . Custom ( cls_prob = rpn_cls_prob_reshape , bbox_pred = rpn_bbox_pred , im_info = im_info , name = \\' rois \\' , output_score = True , op_type = \\' proposal \\' , feat_stride = cfg . network . RPN_FEAT_STRIDE , scales = tuple ( cfg . network . ANCHOR_SCALES ) , ratios = tuple ( cfg . network . ANCHOR_RATIOS ) , rpn_pre_nms_top_n = cfg . TEST . RPN_PRE_NMS_TOP_N , rpn_post_nms_top_n = cfg . TEST . RPN_POST_NMS_TOP_N , threshold = cfg . TEST . RPN_NMS_THRESH , rpn_min_size = cfg . TEST . RPN_MIN_SIZE ) NEW_LINE group = mx . symbol . Group ( [ rois , score ] ) NEW_LINE DEDENT DEDENT self . sym = group NEW_LINE return group NEW_LINE DEDENT',), ('def get_symbol_rcnn ( self , cfg , is_train = True ) : NEW_LINE INDENT num_classes = cfg . dataset . NUM_CLASSES NEW_LINE num_reg_classes = ( 2 if cfg . CLASS_AGNOSTIC else num_classes ) NEW_LINE if is_train : NEW_LINE INDENT data = mx . symbol . Variable ( name = \" data \" ) NEW_LINE rois = mx . symbol . Variable ( name = \\' rois \\' ) NEW_LINE label = mx . symbol . Variable ( name = \\' label \\' ) NEW_LINE bbox_target = mx . symbol . Variable ( name = \\' bbox _ target \\' ) NEW_LINE bbox_weight = mx . symbol . Variable ( name = \\' bbox _ weight \\' ) NEW_LINE rois = mx . symbol . Reshape ( data = rois , shape = ( - 1 , 5 ) , name = \\' rois _ reshape \\' ) NEW_LINE label = mx . symbol . Reshape ( data = label , shape = ( - 1 , ) , name = \\' label _ reshape \\' ) NEW_LINE bbox_target = mx . symbol . Reshape ( data = bbox_target , shape = ( - 1 , 5 * num_classes ) , name = \\' bbox _ target _ reshape \\' ) NEW_LINE bbox_weight = mx . symbol . Reshape ( data = bbox_weight , shape = ( - 1 , 5 * num_classes ) , name = \\' bbox _ weight _ reshape \\' ) NEW_LINE DEDENT else : NEW_LINE INDENT data = mx . sym . Variable ( name = \" data \" ) NEW_LINE rois = mx . symbol . Variable ( name = \\' rois \\' ) NEW_LINE rois = mx . symbol . Reshape ( data = rois , shape = ( - 1 , 5 ) , name = \\' rois _ reshape \\' ) NEW_LINE DEDENT conv_feat = self . get_resnet_v1_conv4 ( data ) NEW_LINE relu1 = self . get_resnet_v1_conv5 ( conv_feat ) NEW_LINE conv_new_1 = mx . sym . Convolution ( data = relu1 , kernel = ( 1 , 1 ) , num_filter = 256 , name = \" conv _ new _ 1\" ) NEW_LINE conv_new_1_relu = mx . sym . Activation ( data = conv_new_1 , act_type = \\' relu \\' , name = \\' conv _ new _ 1 _ relu \\' ) NEW_LINE roi_pool = mx . symbol . ROIPooling ( name = \\' roi _ pool \\' , data = conv_new_1_relu , rois = rois , pooled_size = ( 7 , 7 ) , spatial_scale = 0.0625 ) NEW_LINE fc_new_1 = mx . symbol . FullyConnected ( name = \\' fc _ new _ 1\\' , data = roi_pool , num_hidden = 1024 ) NEW_LINE fc_new_1_relu = mx . sym . Activation ( data = fc_new_1 , act_type = \\' relu \\' , name = \\' fc _ new _ 1 _ relu \\' ) NEW_LINE fc_new_2 = mx . symbol . FullyConnected ( name = \\' fc _ new _ 2\\' , data = fc_new_1_relu , num_hidden = 1024 ) NEW_LINE fc_new_2_relu = mx . sym . Activation ( data = fc_new_2 , act_type = \\' relu \\' , name = \\' fc _ new _ 2 _ relu \\' ) NEW_LINE cls_score = mx . symbol . FullyConnected ( name = \\' cls _ score \\' , data = fc_new_2_relu , num_hidden = num_classes ) NEW_LINE bbox_pred = mx . symbol . FullyConnected ( name = \\' bbox _ pred \\' , data = fc_new_2_relu , num_hidden = num_reg_classes * 5 ) NEW_LINE if is_train : NEW_LINE INDENT if cfg . TRAIN . ENABLE_OHEM : NEW_LINE INDENT labels_ohem , bbox_weights_ohem = mx . sym . Custom ( op_type = \\' BoxAnnotatorOHEM \\' , num_classes = num_classes , num_reg_classes = num_reg_classes , roi_per_img = cfg . TRAIN . BATCH_ROIS_OHEM , cls_score = cls_score , bbox_pred = bbox_pred , labels = label , bbox_targets = bbox_target , bbox_weights = bbox_weight ) NEW_LINE cls_prob = mx . sym . SoftmaxOutput ( name = \\' cls _ prob \\' , data = cls_score , label = labels_ohem , normalization = \\' valid \\' , use_ignore = True , ignore_label = - 1 , grad_scale = 1.0 ) NEW_LINE bbox_loss_ = bbox_weights_ohem * mx . sym . smooth_l1 ( name = \\' bbox _ loss _ \\' , scalar = 1.0 , data = ( bbox_pred - bbox_target ) ) NEW_LINE bbox_loss = mx . sym . MakeLoss ( name = \\' bbox _ loss \\' , data = bbox_loss_ , grad_scale = 1.0 / cfg . TRAIN . BATCH_ROIS_OHEM ) NEW_LINE DEDENT else : NEW_LINE INDENT cls_prob = mx . sym . SoftmaxOutput ( name = \\' cls _ prob \\' , data = cls_score , label = label , normalization = \\' valid \\' , grad_scale = 1.0 ) NEW_LINE bbox_loss_ = bbox_weight * mx . sym . smooth_l1 ( name = \\' bbox _ loss _ \\' , scalar = 1.0 , data = ( bbox_pred - bbox_target ) ) NEW_LINE bbox_loss = mx . sym . MakeLoss ( name = \\' bbox _ loss \\' , data = bbox_loss_ , grad_scale = 1.0 / cfg . TRAIN . BATCH_ROIS ) NEW_LINE DEDENT cls_prob = mx . sym . Reshape ( data = cls_prob , shape = ( cfg . TRAIN . BATCH_IMAGES , - 1 , num_classes ) , name = \\' cls _ prob _ reshape \\' ) NEW_LINE bbox_loss = mx . sym . Reshape ( data = bbox_loss , shape = ( cfg . TRAIN . BATCH_IMAGES , - 1 , 5 * num_reg_classes ) , name = \\' bbox _ loss _ reshape \\' ) NEW_LINE group = mx . sym . Group ( [ cls_prob , bbox_loss ] ) NEW_LINE DEDENT else : NEW_LINE INDENT cls_prob = mx . sym . SoftmaxActivation ( name = \\' cls _ prob \\' , data = cls_score ) NEW_LINE cls_prob = mx . sym . Reshape ( data = cls_prob , shape = ( cfg . TEST . BATCH_IMAGES , - 1 , num_classes ) , name = \\' cls _ prob _ reshape \\' ) NEW_LINE bbox_pred = mx . sym . Reshape ( data = bbox_pred , shape = ( cfg . TEST . BATCH_IMAGES , - 1 , 5 * num_reg_classes ) , name = \\' bbox _ pred _ reshape \\' ) NEW_LINE group = mx . sym . Group ( [ cls_prob , bbox_pred ] ) NEW_LINE DEDENT self . sym = group NEW_LINE return group NEW_LINE DEDENT',), (\"def init_weight_rcnn ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT arg_params [ ' conv _ new _ 1 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' conv _ new _ 1 _ weight ' ] ) NEW_LINE arg_params [ ' conv _ new _ 1 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' conv _ new _ 1 _ bias ' ] ) NEW_LINE arg_params [ ' fc _ new _ 1 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fc _ new _ 1 _ weight ' ] ) NEW_LINE arg_params [ ' fc _ new _ 1 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fc _ new _ 1 _ bias ' ] ) NEW_LINE arg_params [ ' fc _ new _ 2 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fc _ new _ 2 _ weight ' ] ) NEW_LINE arg_params [ ' fc _ new _ 2 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fc _ new _ 2 _ bias ' ] ) NEW_LINE arg_params [ ' cls _ score _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' cls _ score _ weight ' ] ) NEW_LINE arg_params [ ' cls _ score _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' cls _ score _ bias ' ] ) NEW_LINE arg_params [ ' bbox _ pred _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' bbox _ pred _ weight ' ] ) NEW_LINE arg_params [ ' bbox _ pred _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' bbox _ pred _ bias ' ] ) NEW_LINE DEDENT\",), (\"def init_weight_rpn ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT arg_params [ ' rpn _ conv _ 3x3 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' rpn _ conv _ 3x3 _ weight ' ] ) NEW_LINE arg_params [ ' rpn _ conv _ 3x3 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' rpn _ conv _ 3x3 _ bias ' ] ) NEW_LINE arg_params [ ' rpn _ cls _ score _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' rpn _ cls _ score _ weight ' ] ) NEW_LINE arg_params [ ' rpn _ cls _ score _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' rpn _ cls _ score _ bias ' ] ) NEW_LINE arg_params [ ' rpn _ bbox _ pred _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' rpn _ bbox _ pred _ weight ' ] ) NEW_LINE arg_params [ ' rpn _ bbox _ pred _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' rpn _ bbox _ pred _ bias ' ] ) NEW_LINE DEDENT\",), ('def init_weight ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT self . init_weight_rpn ( cfg , arg_params , aux_params ) NEW_LINE self . init_weight_rcnn ( cfg , arg_params , aux_params ) NEW_LINE DEDENT',), (\"def __init__ ( self ) : NEW_LINE INDENT self . eps = 1e-5 NEW_LINE self . use_global_stats = True NEW_LINE self . workspace = 512 NEW_LINE self . units = ( 3 , 4 , 23 , 3 ) NEW_LINE self . filter_list = [ 256 , 512 , 1024 , 2048 ] NEW_LINE self . shared_param_list = [ ' conv _ new _ 1' , ' conv _ new _ 2' , ' conv _ new _ 3' , ' conv _ new _ 4' ] NEW_LINE self . shared_param_dict = { } NEW_LINE for name in self . shared_param_list : NEW_LINE INDENT self . shared_param_dict [ name + ' _ weight ' ] = mx . sym . Variable ( name + ' _ weight ' ) NEW_LINE self . shared_param_dict [ name + ' _ bias ' ] = mx . sym . Variable ( name + ' _ bias ' ) NEW_LINE DEDENT DEDENT\",), (\"def get_resnet_v1_conv4 ( self , data ) : NEW_LINE INDENT conv1 = mx . symbol . Convolution ( name = ' conv1' , data = data , num_filter = 64 , pad = ( 3 , 3 ) , kernel = ( 7 , 7 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn_conv1 = mx . symbol . BatchNorm ( name = ' bn _ conv1' , data = conv1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale_conv1 = bn_conv1 NEW_LINE conv1_relu = mx . symbol . Activation ( name = ' conv1 _ relu ' , data = scale_conv1 , act_type = ' relu ' ) NEW_LINE pool1 = mx . symbol . Pooling ( name = ' pool1' , data = conv1_relu , pooling_convention = ' full ' , pad = ( 0 , 0 ) , kernel = ( 3 , 3 ) , stride = ( 2 , 2 ) , pool_type = ' max ' ) NEW_LINE res2a_branch1 = mx . symbol . Convolution ( name = ' res2a _ branch1' , data = pool1 , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch1 = mx . symbol . BatchNorm ( name = ' bn2a _ branch1' , data = res2a_branch1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2a_branch1 = bn2a_branch1 NEW_LINE res2a_branch2a = mx . symbol . Convolution ( name = ' res2a _ branch2a ' , data = pool1 , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2a = mx . symbol . BatchNorm ( name = ' bn2a _ branch2a ' , data = res2a_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2a_branch2a = bn2a_branch2a NEW_LINE res2a_branch2a_relu = mx . symbol . Activation ( name = ' res2a _ branch2a _ relu ' , data = scale2a_branch2a , act_type = ' relu ' ) NEW_LINE res2a_branch2b = mx . symbol . Convolution ( name = ' res2a _ branch2b ' , data = res2a_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2b = mx . symbol . BatchNorm ( name = ' bn2a _ branch2b ' , data = res2a_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2a_branch2b = bn2a_branch2b NEW_LINE res2a_branch2b_relu = mx . symbol . Activation ( name = ' res2a _ branch2b _ relu ' , data = scale2a_branch2b , act_type = ' relu ' ) NEW_LINE res2a_branch2c = mx . symbol . Convolution ( name = ' res2a _ branch2c ' , data = res2a_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2c = mx . symbol . BatchNorm ( name = ' bn2a _ branch2c ' , data = res2a_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2a_branch2c = bn2a_branch2c NEW_LINE res2a = mx . symbol . broadcast_add ( name = ' res2a ' , * [ scale2a_branch1 , scale2a_branch2c ] ) NEW_LINE res2a_relu = mx . symbol . Activation ( name = ' res2a _ relu ' , data = res2a , act_type = ' relu ' ) NEW_LINE res2b_branch2a = mx . symbol . Convolution ( name = ' res2b _ branch2a ' , data = res2a_relu , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2a = mx . symbol . BatchNorm ( name = ' bn2b _ branch2a ' , data = res2b_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2b_branch2a = bn2b_branch2a NEW_LINE res2b_branch2a_relu = mx . symbol . Activation ( name = ' res2b _ branch2a _ relu ' , data = scale2b_branch2a , act_type = ' relu ' ) NEW_LINE res2b_branch2b = mx . symbol . Convolution ( name = ' res2b _ branch2b ' , data = res2b_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2b = mx . symbol . BatchNorm ( name = ' bn2b _ branch2b ' , data = res2b_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2b_branch2b = bn2b_branch2b NEW_LINE res2b_branch2b_relu = mx . symbol . Activation ( name = ' res2b _ branch2b _ relu ' , data = scale2b_branch2b , act_type = ' relu ' ) NEW_LINE res2b_branch2c = mx . symbol . Convolution ( name = ' res2b _ branch2c ' , data = res2b_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2c = mx . symbol . BatchNorm ( name = ' bn2b _ branch2c ' , data = res2b_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2b_branch2c = bn2b_branch2c NEW_LINE res2b = mx . symbol . broadcast_add ( name = ' res2b ' , * [ res2a_relu , scale2b_branch2c ] ) NEW_LINE res2b_relu = mx . symbol . Activation ( name = ' res2b _ relu ' , data = res2b , act_type = ' relu ' ) NEW_LINE res2c_branch2a = mx . symbol . Convolution ( name = ' res2c _ branch2a ' , data = res2b_relu , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2a = mx . symbol . BatchNorm ( name = ' bn2c _ branch2a ' , data = res2c_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2c_branch2a = bn2c_branch2a NEW_LINE res2c_branch2a_relu = mx . symbol . Activation ( name = ' res2c _ branch2a _ relu ' , data = scale2c_branch2a , act_type = ' relu ' ) NEW_LINE res2c_branch2b = mx . symbol . Convolution ( name = ' res2c _ branch2b ' , data = res2c_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2b = mx . symbol . BatchNorm ( name = ' bn2c _ branch2b ' , data = res2c_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2c_branch2b = bn2c_branch2b NEW_LINE res2c_branch2b_relu = mx . symbol . Activation ( name = ' res2c _ branch2b _ relu ' , data = scale2c_branch2b , act_type = ' relu ' ) NEW_LINE res2c_branch2c = mx . symbol . Convolution ( name = ' res2c _ branch2c ' , data = res2c_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2c = mx . symbol . BatchNorm ( name = ' bn2c _ branch2c ' , data = res2c_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2c_branch2c = bn2c_branch2c NEW_LINE res2c = mx . symbol . broadcast_add ( name = ' res2c ' , * [ res2b_relu , scale2c_branch2c ] ) NEW_LINE res2c_relu = mx . symbol . Activation ( name = ' res2c _ relu ' , data = res2c , act_type = ' relu ' ) NEW_LINE res3a_branch1 = mx . symbol . Convolution ( name = ' res3a _ branch1' , data = res2c_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn3a_branch1 = mx . symbol . BatchNorm ( name = ' bn3a _ branch1' , data = res3a_branch1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3a_branch1 = bn3a_branch1 NEW_LINE res3a_branch2a = mx . symbol . Convolution ( name = ' res3a _ branch2a ' , data = res2c_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn3a_branch2a = mx . symbol . BatchNorm ( name = ' bn3a _ branch2a ' , data = res3a_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3a_branch2a = bn3a_branch2a NEW_LINE res3a_branch2a_relu = mx . symbol . Activation ( name = ' res3a _ branch2a _ relu ' , data = scale3a_branch2a , act_type = ' relu ' ) NEW_LINE res3a_branch2b = mx . symbol . Convolution ( name = ' res3a _ branch2b ' , data = res3a_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3a_branch2b = mx . symbol . BatchNorm ( name = ' bn3a _ branch2b ' , data = res3a_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3a_branch2b = bn3a_branch2b NEW_LINE res3a_branch2b_relu = mx . symbol . Activation ( name = ' res3a _ branch2b _ relu ' , data = scale3a_branch2b , act_type = ' relu ' ) NEW_LINE res3a_branch2c = mx . symbol . Convolution ( name = ' res3a _ branch2c ' , data = res3a_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3a_branch2c = mx . symbol . BatchNorm ( name = ' bn3a _ branch2c ' , data = res3a_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3a_branch2c = bn3a_branch2c NEW_LINE res3a = mx . symbol . broadcast_add ( name = ' res3a ' , * [ scale3a_branch1 , scale3a_branch2c ] ) NEW_LINE res3a_relu = mx . symbol . Activation ( name = ' res3a _ relu ' , data = res3a , act_type = ' relu ' ) NEW_LINE res3b1_branch2a = mx . symbol . Convolution ( name = ' res3b1 _ branch2a ' , data = res3a_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2a = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2a ' , data = res3b1_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b1_branch2a = bn3b1_branch2a NEW_LINE res3b1_branch2a_relu = mx . symbol . Activation ( name = ' res3b1 _ branch2a _ relu ' , data = scale3b1_branch2a , act_type = ' relu ' ) NEW_LINE res3b1_branch2b = mx . symbol . Convolution ( name = ' res3b1 _ branch2b ' , data = res3b1_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2b = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2b ' , data = res3b1_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b1_branch2b = bn3b1_branch2b NEW_LINE res3b1_branch2b_relu = mx . symbol . Activation ( name = ' res3b1 _ branch2b _ relu ' , data = scale3b1_branch2b , act_type = ' relu ' ) NEW_LINE res3b1_branch2c = mx . symbol . Convolution ( name = ' res3b1 _ branch2c ' , data = res3b1_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2c = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2c ' , data = res3b1_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b1_branch2c = bn3b1_branch2c NEW_LINE res3b1 = mx . symbol . broadcast_add ( name = ' res3b1' , * [ res3a_relu , scale3b1_branch2c ] ) NEW_LINE res3b1_relu = mx . symbol . Activation ( name = ' res3b1 _ relu ' , data = res3b1 , act_type = ' relu ' ) NEW_LINE res3b2_branch2a = mx . symbol . Convolution ( name = ' res3b2 _ branch2a ' , data = res3b1_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2a = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2a ' , data = res3b2_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b2_branch2a = bn3b2_branch2a NEW_LINE res3b2_branch2a_relu = mx . symbol . Activation ( name = ' res3b2 _ branch2a _ relu ' , data = scale3b2_branch2a , act_type = ' relu ' ) NEW_LINE res3b2_branch2b = mx . symbol . Convolution ( name = ' res3b2 _ branch2b ' , data = res3b2_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2b = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2b ' , data = res3b2_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b2_branch2b = bn3b2_branch2b NEW_LINE res3b2_branch2b_relu = mx . symbol . Activation ( name = ' res3b2 _ branch2b _ relu ' , data = scale3b2_branch2b , act_type = ' relu ' ) NEW_LINE res3b2_branch2c = mx . symbol . Convolution ( name = ' res3b2 _ branch2c ' , data = res3b2_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2c = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2c ' , data = res3b2_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b2_branch2c = bn3b2_branch2c NEW_LINE res3b2 = mx . symbol . broadcast_add ( name = ' res3b2' , * [ res3b1_relu , scale3b2_branch2c ] ) NEW_LINE res3b2_relu = mx . symbol . Activation ( name = ' res3b2 _ relu ' , data = res3b2 , act_type = ' relu ' ) NEW_LINE res3b3_branch2a = mx . symbol . Convolution ( name = ' res3b3 _ branch2a ' , data = res3b2_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b3_branch2a = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2a ' , data = res3b3_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b3_branch2a = bn3b3_branch2a NEW_LINE res3b3_branch2a_relu = mx . symbol . Activation ( name = ' res3b3 _ branch2a _ relu ' , data = scale3b3_branch2a , act_type = ' relu ' ) NEW_LINE res3b3_branch2b = mx . symbol . Convolution ( name = ' res3b3 _ branch2b ' , data = res3b3_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b3_branch2b = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2b ' , data = res3b3_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b3_branch2b = bn3b3_branch2b NEW_LINE res3b3_branch2b_relu = mx . symbol . Activation ( name = ' res3b3 _ branch2b _ relu ' , data = scale3b3_branch2b , act_type = ' relu ' ) NEW_LINE res3b3_branch2c = mx . symbol . Convolution ( name = ' res3b3 _ branch2c ' , data = res3b3_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b3_branch2c = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2c ' , data = res3b3_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b3_branch2c = bn3b3_branch2c NEW_LINE res3b3 = mx . symbol . broadcast_add ( name = ' res3b3' , * [ res3b2_relu , scale3b3_branch2c ] ) NEW_LINE res3b3_relu = mx . symbol . Activation ( name = ' res3b3 _ relu ' , data = res3b3 , act_type = ' relu ' ) NEW_LINE res4a_branch1 = mx . symbol . Convolution ( name = ' res4a _ branch1' , data = res3b3_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn4a_branch1 = mx . symbol . BatchNorm ( name = ' bn4a _ branch1' , data = res4a_branch1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4a_branch1 = bn4a_branch1 NEW_LINE res4a_branch2a = mx . symbol . Convolution ( name = ' res4a _ branch2a ' , data = res3b3_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn4a_branch2a = mx . symbol . BatchNorm ( name = ' bn4a _ branch2a ' , data = res4a_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4a_branch2a = bn4a_branch2a NEW_LINE res4a_branch2a_relu = mx . symbol . Activation ( name = ' res4a _ branch2a _ relu ' , data = scale4a_branch2a , act_type = ' relu ' ) NEW_LINE res4a_branch2b = mx . symbol . Convolution ( name = ' res4a _ branch2b ' , data = res4a_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4a_branch2b = mx . symbol . BatchNorm ( name = ' bn4a _ branch2b ' , data = res4a_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4a_branch2b = bn4a_branch2b NEW_LINE res4a_branch2b_relu = mx . symbol . Activation ( name = ' res4a _ branch2b _ relu ' , data = scale4a_branch2b , act_type = ' relu ' ) NEW_LINE res4a_branch2c = mx . symbol . Convolution ( name = ' res4a _ branch2c ' , data = res4a_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4a_branch2c = mx . symbol . BatchNorm ( name = ' bn4a _ branch2c ' , data = res4a_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4a_branch2c = bn4a_branch2c NEW_LINE res4a = mx . symbol . broadcast_add ( name = ' res4a ' , * [ scale4a_branch1 , scale4a_branch2c ] ) NEW_LINE res4a_relu = mx . symbol . Activation ( name = ' res4a _ relu ' , data = res4a , act_type = ' relu ' ) NEW_LINE res4b1_branch2a = mx . symbol . Convolution ( name = ' res4b1 _ branch2a ' , data = res4a_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2a = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2a ' , data = res4b1_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b1_branch2a = bn4b1_branch2a NEW_LINE res4b1_branch2a_relu = mx . symbol . Activation ( name = ' res4b1 _ branch2a _ relu ' , data = scale4b1_branch2a , act_type = ' relu ' ) NEW_LINE res4b1_branch2b = mx . symbol . Convolution ( name = ' res4b1 _ branch2b ' , data = res4b1_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2b = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2b ' , data = res4b1_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b1_branch2b = bn4b1_branch2b NEW_LINE res4b1_branch2b_relu = mx . symbol . Activation ( name = ' res4b1 _ branch2b _ relu ' , data = scale4b1_branch2b , act_type = ' relu ' ) NEW_LINE res4b1_branch2c = mx . symbol . Convolution ( name = ' res4b1 _ branch2c ' , data = res4b1_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2c = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2c ' , data = res4b1_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b1_branch2c = bn4b1_branch2c NEW_LINE res4b1 = mx . symbol . broadcast_add ( name = ' res4b1' , * [ res4a_relu , scale4b1_branch2c ] ) NEW_LINE res4b1_relu = mx . symbol . Activation ( name = ' res4b1 _ relu ' , data = res4b1 , act_type = ' relu ' ) NEW_LINE res4b2_branch2a = mx . symbol . Convolution ( name = ' res4b2 _ branch2a ' , data = res4b1_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2a = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2a ' , data = res4b2_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b2_branch2a = bn4b2_branch2a NEW_LINE res4b2_branch2a_relu = mx . symbol . Activation ( name = ' res4b2 _ branch2a _ relu ' , data = scale4b2_branch2a , act_type = ' relu ' ) NEW_LINE res4b2_branch2b = mx . symbol . Convolution ( name = ' res4b2 _ branch2b ' , data = res4b2_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2b = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2b ' , data = res4b2_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b2_branch2b = bn4b2_branch2b NEW_LINE res4b2_branch2b_relu = mx . symbol . Activation ( name = ' res4b2 _ branch2b _ relu ' , data = scale4b2_branch2b , act_type = ' relu ' ) NEW_LINE res4b2_branch2c = mx . symbol . Convolution ( name = ' res4b2 _ branch2c ' , data = res4b2_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2c = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2c ' , data = res4b2_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b2_branch2c = bn4b2_branch2c NEW_LINE res4b2 = mx . symbol . broadcast_add ( name = ' res4b2' , * [ res4b1_relu , scale4b2_branch2c ] ) NEW_LINE res4b2_relu = mx . symbol . Activation ( name = ' res4b2 _ relu ' , data = res4b2 , act_type = ' relu ' ) NEW_LINE res4b3_branch2a = mx . symbol . Convolution ( name = ' res4b3 _ branch2a ' , data = res4b2_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2a = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2a ' , data = res4b3_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b3_branch2a = bn4b3_branch2a NEW_LINE res4b3_branch2a_relu = mx . symbol . Activation ( name = ' res4b3 _ branch2a _ relu ' , data = scale4b3_branch2a , act_type = ' relu ' ) NEW_LINE res4b3_branch2b = mx . symbol . Convolution ( name = ' res4b3 _ branch2b ' , data = res4b3_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2b = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2b ' , data = res4b3_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b3_branch2b = bn4b3_branch2b NEW_LINE res4b3_branch2b_relu = mx . symbol . Activation ( name = ' res4b3 _ branch2b _ relu ' , data = scale4b3_branch2b , act_type = ' relu ' ) NEW_LINE res4b3_branch2c = mx . symbol . Convolution ( name = ' res4b3 _ branch2c ' , data = res4b3_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2c = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2c ' , data = res4b3_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b3_branch2c = bn4b3_branch2c NEW_LINE res4b3 = mx . symbol . broadcast_add ( name = ' res4b3' , * [ res4b2_relu , scale4b3_branch2c ] ) NEW_LINE res4b3_relu = mx . symbol . Activation ( name = ' res4b3 _ relu ' , data = res4b3 , act_type = ' relu ' ) NEW_LINE res4b4_branch2a = mx . symbol . Convolution ( name = ' res4b4 _ branch2a ' , data = res4b3_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2a = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2a ' , data = res4b4_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b4_branch2a = bn4b4_branch2a NEW_LINE res4b4_branch2a_relu = mx . symbol . Activation ( name = ' res4b4 _ branch2a _ relu ' , data = scale4b4_branch2a , act_type = ' relu ' ) NEW_LINE res4b4_branch2b = mx . symbol . Convolution ( name = ' res4b4 _ branch2b ' , data = res4b4_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2b = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2b ' , data = res4b4_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b4_branch2b = bn4b4_branch2b NEW_LINE res4b4_branch2b_relu = mx . symbol . Activation ( name = ' res4b4 _ branch2b _ relu ' , data = scale4b4_branch2b , act_type = ' relu ' ) NEW_LINE res4b4_branch2c = mx . symbol . Convolution ( name = ' res4b4 _ branch2c ' , data = res4b4_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2c = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2c ' , data = res4b4_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b4_branch2c = bn4b4_branch2c NEW_LINE res4b4 = mx . symbol . broadcast_add ( name = ' res4b4' , * [ res4b3_relu , scale4b4_branch2c ] ) NEW_LINE res4b4_relu = mx . symbol . Activation ( name = ' res4b4 _ relu ' , data = res4b4 , act_type = ' relu ' ) NEW_LINE res4b5_branch2a = mx . symbol . Convolution ( name = ' res4b5 _ branch2a ' , data = res4b4_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2a = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2a ' , data = res4b5_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b5_branch2a = bn4b5_branch2a NEW_LINE res4b5_branch2a_relu = mx . symbol . Activation ( name = ' res4b5 _ branch2a _ relu ' , data = scale4b5_branch2a , act_type = ' relu ' ) NEW_LINE res4b5_branch2b = mx . symbol . Convolution ( name = ' res4b5 _ branch2b ' , data = res4b5_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2b = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2b ' , data = res4b5_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b5_branch2b = bn4b5_branch2b NEW_LINE res4b5_branch2b_relu = mx . symbol . Activation ( name = ' res4b5 _ branch2b _ relu ' , data = scale4b5_branch2b , act_type = ' relu ' ) NEW_LINE res4b5_branch2c = mx . symbol . Convolution ( name = ' res4b5 _ branch2c ' , data = res4b5_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2c = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2c ' , data = res4b5_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b5_branch2c = bn4b5_branch2c NEW_LINE res4b5 = mx . symbol . broadcast_add ( name = ' res4b5' , * [ res4b4_relu , scale4b5_branch2c ] ) NEW_LINE res4b5_relu = mx . symbol . Activation ( name = ' res4b5 _ relu ' , data = res4b5 , act_type = ' relu ' ) NEW_LINE res4b6_branch2a = mx . symbol . Convolution ( name = ' res4b6 _ branch2a ' , data = res4b5_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2a = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2a ' , data = res4b6_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b6_branch2a = bn4b6_branch2a NEW_LINE res4b6_branch2a_relu = mx . symbol . Activation ( name = ' res4b6 _ branch2a _ relu ' , data = scale4b6_branch2a , act_type = ' relu ' ) NEW_LINE res4b6_branch2b = mx . symbol . Convolution ( name = ' res4b6 _ branch2b ' , data = res4b6_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2b = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2b ' , data = res4b6_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b6_branch2b = bn4b6_branch2b NEW_LINE res4b6_branch2b_relu = mx . symbol . Activation ( name = ' res4b6 _ branch2b _ relu ' , data = scale4b6_branch2b , act_type = ' relu ' ) NEW_LINE res4b6_branch2c = mx . symbol . Convolution ( name = ' res4b6 _ branch2c ' , data = res4b6_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2c = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2c ' , data = res4b6_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b6_branch2c = bn4b6_branch2c NEW_LINE res4b6 = mx . symbol . broadcast_add ( name = ' res4b6' , * [ res4b5_relu , scale4b6_branch2c ] ) NEW_LINE res4b6_relu = mx . symbol . Activation ( name = ' res4b6 _ relu ' , data = res4b6 , act_type = ' relu ' ) NEW_LINE res4b7_branch2a = mx . symbol . Convolution ( name = ' res4b7 _ branch2a ' , data = res4b6_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2a = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2a ' , data = res4b7_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b7_branch2a = bn4b7_branch2a NEW_LINE res4b7_branch2a_relu = mx . symbol . Activation ( name = ' res4b7 _ branch2a _ relu ' , data = scale4b7_branch2a , act_type = ' relu ' ) NEW_LINE res4b7_branch2b = mx . symbol . Convolution ( name = ' res4b7 _ branch2b ' , data = res4b7_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2b = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2b ' , data = res4b7_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b7_branch2b = bn4b7_branch2b NEW_LINE res4b7_branch2b_relu = mx . symbol . Activation ( name = ' res4b7 _ branch2b _ relu ' , data = scale4b7_branch2b , act_type = ' relu ' ) NEW_LINE res4b7_branch2c = mx . symbol . Convolution ( name = ' res4b7 _ branch2c ' , data = res4b7_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2c = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2c ' , data = res4b7_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b7_branch2c = bn4b7_branch2c NEW_LINE res4b7 = mx . symbol . broadcast_add ( name = ' res4b7' , * [ res4b6_relu , scale4b7_branch2c ] ) NEW_LINE res4b7_relu = mx . symbol . Activation ( name = ' res4b7 _ relu ' , data = res4b7 , act_type = ' relu ' ) NEW_LINE res4b8_branch2a = mx . symbol . Convolution ( name = ' res4b8 _ branch2a ' , data = res4b7_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2a = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2a ' , data = res4b8_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b8_branch2a = bn4b8_branch2a NEW_LINE res4b8_branch2a_relu = mx . symbol . Activation ( name = ' res4b8 _ branch2a _ relu ' , data = scale4b8_branch2a , act_type = ' relu ' ) NEW_LINE res4b8_branch2b = mx . symbol . Convolution ( name = ' res4b8 _ branch2b ' , data = res4b8_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2b = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2b ' , data = res4b8_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b8_branch2b = bn4b8_branch2b NEW_LINE res4b8_branch2b_relu = mx . symbol . Activation ( name = ' res4b8 _ branch2b _ relu ' , data = scale4b8_branch2b , act_type = ' relu ' ) NEW_LINE res4b8_branch2c = mx . symbol . Convolution ( name = ' res4b8 _ branch2c ' , data = res4b8_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2c = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2c ' , data = res4b8_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b8_branch2c = bn4b8_branch2c NEW_LINE res4b8 = mx . symbol . broadcast_add ( name = ' res4b8' , * [ res4b7_relu , scale4b8_branch2c ] ) NEW_LINE res4b8_relu = mx . symbol . Activation ( name = ' res4b8 _ relu ' , data = res4b8 , act_type = ' relu ' ) NEW_LINE res4b9_branch2a = mx . symbol . Convolution ( name = ' res4b9 _ branch2a ' , data = res4b8_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2a = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2a ' , data = res4b9_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b9_branch2a = bn4b9_branch2a NEW_LINE res4b9_branch2a_relu = mx . symbol . Activation ( name = ' res4b9 _ branch2a _ relu ' , data = scale4b9_branch2a , act_type = ' relu ' ) NEW_LINE res4b9_branch2b = mx . symbol . Convolution ( name = ' res4b9 _ branch2b ' , data = res4b9_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2b = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2b ' , data = res4b9_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b9_branch2b = bn4b9_branch2b NEW_LINE res4b9_branch2b_relu = mx . symbol . Activation ( name = ' res4b9 _ branch2b _ relu ' , data = scale4b9_branch2b , act_type = ' relu ' ) NEW_LINE res4b9_branch2c = mx . symbol . Convolution ( name = ' res4b9 _ branch2c ' , data = res4b9_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2c = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2c ' , data = res4b9_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b9_branch2c = bn4b9_branch2c NEW_LINE res4b9 = mx . symbol . broadcast_add ( name = ' res4b9' , * [ res4b8_relu , scale4b9_branch2c ] ) NEW_LINE res4b9_relu = mx . symbol . Activation ( name = ' res4b9 _ relu ' , data = res4b9 , act_type = ' relu ' ) NEW_LINE res4b10_branch2a = mx . symbol . Convolution ( name = ' res4b10 _ branch2a ' , data = res4b9_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2a = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2a ' , data = res4b10_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b10_branch2a = bn4b10_branch2a NEW_LINE res4b10_branch2a_relu = mx . symbol . Activation ( name = ' res4b10 _ branch2a _ relu ' , data = scale4b10_branch2a , act_type = ' relu ' ) NEW_LINE res4b10_branch2b = mx . symbol . Convolution ( name = ' res4b10 _ branch2b ' , data = res4b10_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2b = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2b ' , data = res4b10_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b10_branch2b = bn4b10_branch2b NEW_LINE res4b10_branch2b_relu = mx . symbol . Activation ( name = ' res4b10 _ branch2b _ relu ' , data = scale4b10_branch2b , act_type = ' relu ' ) NEW_LINE res4b10_branch2c = mx . symbol . Convolution ( name = ' res4b10 _ branch2c ' , data = res4b10_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2c = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2c ' , data = res4b10_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b10_branch2c = bn4b10_branch2c NEW_LINE res4b10 = mx . symbol . broadcast_add ( name = ' res4b10' , * [ res4b9_relu , scale4b10_branch2c ] ) NEW_LINE res4b10_relu = mx . symbol . Activation ( name = ' res4b10 _ relu ' , data = res4b10 , act_type = ' relu ' ) NEW_LINE res4b11_branch2a = mx . symbol . Convolution ( name = ' res4b11 _ branch2a ' , data = res4b10_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2a = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2a ' , data = res4b11_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b11_branch2a = bn4b11_branch2a NEW_LINE res4b11_branch2a_relu = mx . symbol . Activation ( name = ' res4b11 _ branch2a _ relu ' , data = scale4b11_branch2a , act_type = ' relu ' ) NEW_LINE res4b11_branch2b = mx . symbol . Convolution ( name = ' res4b11 _ branch2b ' , data = res4b11_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2b = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2b ' , data = res4b11_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b11_branch2b = bn4b11_branch2b NEW_LINE res4b11_branch2b_relu = mx . symbol . Activation ( name = ' res4b11 _ branch2b _ relu ' , data = scale4b11_branch2b , act_type = ' relu ' ) NEW_LINE res4b11_branch2c = mx . symbol . Convolution ( name = ' res4b11 _ branch2c ' , data = res4b11_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2c = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2c ' , data = res4b11_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b11_branch2c = bn4b11_branch2c NEW_LINE res4b11 = mx . symbol . broadcast_add ( name = ' res4b11' , * [ res4b10_relu , scale4b11_branch2c ] ) NEW_LINE res4b11_relu = mx . symbol . Activation ( name = ' res4b11 _ relu ' , data = res4b11 , act_type = ' relu ' ) NEW_LINE res4b12_branch2a = mx . symbol . Convolution ( name = ' res4b12 _ branch2a ' , data = res4b11_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2a = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2a ' , data = res4b12_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b12_branch2a = bn4b12_branch2a NEW_LINE res4b12_branch2a_relu = mx . symbol . Activation ( name = ' res4b12 _ branch2a _ relu ' , data = scale4b12_branch2a , act_type = ' relu ' ) NEW_LINE res4b12_branch2b = mx . symbol . Convolution ( name = ' res4b12 _ branch2b ' , data = res4b12_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2b = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2b ' , data = res4b12_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b12_branch2b = bn4b12_branch2b NEW_LINE res4b12_branch2b_relu = mx . symbol . Activation ( name = ' res4b12 _ branch2b _ relu ' , data = scale4b12_branch2b , act_type = ' relu ' ) NEW_LINE res4b12_branch2c = mx . symbol . Convolution ( name = ' res4b12 _ branch2c ' , data = res4b12_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2c = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2c ' , data = res4b12_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b12_branch2c = bn4b12_branch2c NEW_LINE res4b12 = mx . symbol . broadcast_add ( name = ' res4b12' , * [ res4b11_relu , scale4b12_branch2c ] ) NEW_LINE res4b12_relu = mx . symbol . Activation ( name = ' res4b12 _ relu ' , data = res4b12 , act_type = ' relu ' ) NEW_LINE res4b13_branch2a = mx . symbol . Convolution ( name = ' res4b13 _ branch2a ' , data = res4b12_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2a = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2a ' , data = res4b13_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b13_branch2a = bn4b13_branch2a NEW_LINE res4b13_branch2a_relu = mx . symbol . Activation ( name = ' res4b13 _ branch2a _ relu ' , data = scale4b13_branch2a , act_type = ' relu ' ) NEW_LINE res4b13_branch2b = mx . symbol . Convolution ( name = ' res4b13 _ branch2b ' , data = res4b13_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2b = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2b ' , data = res4b13_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b13_branch2b = bn4b13_branch2b NEW_LINE res4b13_branch2b_relu = mx . symbol . Activation ( name = ' res4b13 _ branch2b _ relu ' , data = scale4b13_branch2b , act_type = ' relu ' ) NEW_LINE res4b13_branch2c = mx . symbol . Convolution ( name = ' res4b13 _ branch2c ' , data = res4b13_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2c = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2c ' , data = res4b13_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b13_branch2c = bn4b13_branch2c NEW_LINE res4b13 = mx . symbol . broadcast_add ( name = ' res4b13' , * [ res4b12_relu , scale4b13_branch2c ] ) NEW_LINE res4b13_relu = mx . symbol . Activation ( name = ' res4b13 _ relu ' , data = res4b13 , act_type = ' relu ' ) NEW_LINE res4b14_branch2a = mx . symbol . Convolution ( name = ' res4b14 _ branch2a ' , data = res4b13_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2a = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2a ' , data = res4b14_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b14_branch2a = bn4b14_branch2a NEW_LINE res4b14_branch2a_relu = mx . symbol . Activation ( name = ' res4b14 _ branch2a _ relu ' , data = scale4b14_branch2a , act_type = ' relu ' ) NEW_LINE res4b14_branch2b = mx . symbol . Convolution ( name = ' res4b14 _ branch2b ' , data = res4b14_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2b = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2b ' , data = res4b14_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b14_branch2b = bn4b14_branch2b NEW_LINE res4b14_branch2b_relu = mx . symbol . Activation ( name = ' res4b14 _ branch2b _ relu ' , data = scale4b14_branch2b , act_type = ' relu ' ) NEW_LINE res4b14_branch2c = mx . symbol . Convolution ( name = ' res4b14 _ branch2c ' , data = res4b14_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2c = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2c ' , data = res4b14_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b14_branch2c = bn4b14_branch2c NEW_LINE res4b14 = mx . symbol . broadcast_add ( name = ' res4b14' , * [ res4b13_relu , scale4b14_branch2c ] ) NEW_LINE res4b14_relu = mx . symbol . Activation ( name = ' res4b14 _ relu ' , data = res4b14 , act_type = ' relu ' ) NEW_LINE res4b15_branch2a = mx . symbol . Convolution ( name = ' res4b15 _ branch2a ' , data = res4b14_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2a = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2a ' , data = res4b15_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b15_branch2a = bn4b15_branch2a NEW_LINE res4b15_branch2a_relu = mx . symbol . Activation ( name = ' res4b15 _ branch2a _ relu ' , data = scale4b15_branch2a , act_type = ' relu ' ) NEW_LINE res4b15_branch2b = mx . symbol . Convolution ( name = ' res4b15 _ branch2b ' , data = res4b15_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2b = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2b ' , data = res4b15_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b15_branch2b = bn4b15_branch2b NEW_LINE res4b15_branch2b_relu = mx . symbol . Activation ( name = ' res4b15 _ branch2b _ relu ' , data = scale4b15_branch2b , act_type = ' relu ' ) NEW_LINE res4b15_branch2c = mx . symbol . Convolution ( name = ' res4b15 _ branch2c ' , data = res4b15_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2c = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2c ' , data = res4b15_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b15_branch2c = bn4b15_branch2c NEW_LINE res4b15 = mx . symbol . broadcast_add ( name = ' res4b15' , * [ res4b14_relu , scale4b15_branch2c ] ) NEW_LINE res4b15_relu = mx . symbol . Activation ( name = ' res4b15 _ relu ' , data = res4b15 , act_type = ' relu ' ) NEW_LINE res4b16_branch2a = mx . symbol . Convolution ( name = ' res4b16 _ branch2a ' , data = res4b15_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2a = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2a ' , data = res4b16_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b16_branch2a = bn4b16_branch2a NEW_LINE res4b16_branch2a_relu = mx . symbol . Activation ( name = ' res4b16 _ branch2a _ relu ' , data = scale4b16_branch2a , act_type = ' relu ' ) NEW_LINE res4b16_branch2b = mx . symbol . Convolution ( name = ' res4b16 _ branch2b ' , data = res4b16_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2b = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2b ' , data = res4b16_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b16_branch2b = bn4b16_branch2b NEW_LINE res4b16_branch2b_relu = mx . symbol . Activation ( name = ' res4b16 _ branch2b _ relu ' , data = scale4b16_branch2b , act_type = ' relu ' ) NEW_LINE res4b16_branch2c = mx . symbol . Convolution ( name = ' res4b16 _ branch2c ' , data = res4b16_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2c = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2c ' , data = res4b16_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b16_branch2c = bn4b16_branch2c NEW_LINE res4b16 = mx . symbol . broadcast_add ( name = ' res4b16' , * [ res4b15_relu , scale4b16_branch2c ] ) NEW_LINE res4b16_relu = mx . symbol . Activation ( name = ' res4b16 _ relu ' , data = res4b16 , act_type = ' relu ' ) NEW_LINE res4b17_branch2a = mx . symbol . Convolution ( name = ' res4b17 _ branch2a ' , data = res4b16_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2a = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2a ' , data = res4b17_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b17_branch2a = bn4b17_branch2a NEW_LINE res4b17_branch2a_relu = mx . symbol . Activation ( name = ' res4b17 _ branch2a _ relu ' , data = scale4b17_branch2a , act_type = ' relu ' ) NEW_LINE res4b17_branch2b = mx . symbol . Convolution ( name = ' res4b17 _ branch2b ' , data = res4b17_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2b = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2b ' , data = res4b17_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b17_branch2b = bn4b17_branch2b NEW_LINE res4b17_branch2b_relu = mx . symbol . Activation ( name = ' res4b17 _ branch2b _ relu ' , data = scale4b17_branch2b , act_type = ' relu ' ) NEW_LINE res4b17_branch2c = mx . symbol . Convolution ( name = ' res4b17 _ branch2c ' , data = res4b17_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2c = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2c ' , data = res4b17_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b17_branch2c = bn4b17_branch2c NEW_LINE res4b17 = mx . symbol . broadcast_add ( name = ' res4b17' , * [ res4b16_relu , scale4b17_branch2c ] ) NEW_LINE res4b17_relu = mx . symbol . Activation ( name = ' res4b17 _ relu ' , data = res4b17 , act_type = ' relu ' ) NEW_LINE res4b18_branch2a = mx . symbol . Convolution ( name = ' res4b18 _ branch2a ' , data = res4b17_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2a = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2a ' , data = res4b18_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b18_branch2a = bn4b18_branch2a NEW_LINE res4b18_branch2a_relu = mx . symbol . Activation ( name = ' res4b18 _ branch2a _ relu ' , data = scale4b18_branch2a , act_type = ' relu ' ) NEW_LINE res4b18_branch2b = mx . symbol . Convolution ( name = ' res4b18 _ branch2b ' , data = res4b18_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2b = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2b ' , data = res4b18_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b18_branch2b = bn4b18_branch2b NEW_LINE res4b18_branch2b_relu = mx . symbol . Activation ( name = ' res4b18 _ branch2b _ relu ' , data = scale4b18_branch2b , act_type = ' relu ' ) NEW_LINE res4b18_branch2c = mx . symbol . Convolution ( name = ' res4b18 _ branch2c ' , data = res4b18_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2c = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2c ' , data = res4b18_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b18_branch2c = bn4b18_branch2c NEW_LINE res4b18 = mx . symbol . broadcast_add ( name = ' res4b18' , * [ res4b17_relu , scale4b18_branch2c ] ) NEW_LINE res4b18_relu = mx . symbol . Activation ( name = ' res4b18 _ relu ' , data = res4b18 , act_type = ' relu ' ) NEW_LINE res4b19_branch2a = mx . symbol . Convolution ( name = ' res4b19 _ branch2a ' , data = res4b18_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2a = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2a ' , data = res4b19_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b19_branch2a = bn4b19_branch2a NEW_LINE res4b19_branch2a_relu = mx . symbol . Activation ( name = ' res4b19 _ branch2a _ relu ' , data = scale4b19_branch2a , act_type = ' relu ' ) NEW_LINE res4b19_branch2b = mx . symbol . Convolution ( name = ' res4b19 _ branch2b ' , data = res4b19_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2b = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2b ' , data = res4b19_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b19_branch2b = bn4b19_branch2b NEW_LINE res4b19_branch2b_relu = mx . symbol . Activation ( name = ' res4b19 _ branch2b _ relu ' , data = scale4b19_branch2b , act_type = ' relu ' ) NEW_LINE res4b19_branch2c = mx . symbol . Convolution ( name = ' res4b19 _ branch2c ' , data = res4b19_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2c = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2c ' , data = res4b19_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b19_branch2c = bn4b19_branch2c NEW_LINE res4b19 = mx . symbol . broadcast_add ( name = ' res4b19' , * [ res4b18_relu , scale4b19_branch2c ] ) NEW_LINE res4b19_relu = mx . symbol . Activation ( name = ' res4b19 _ relu ' , data = res4b19 , act_type = ' relu ' ) NEW_LINE res4b20_branch2a = mx . symbol . Convolution ( name = ' res4b20 _ branch2a ' , data = res4b19_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2a = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2a ' , data = res4b20_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b20_branch2a = bn4b20_branch2a NEW_LINE res4b20_branch2a_relu = mx . symbol . Activation ( name = ' res4b20 _ branch2a _ relu ' , data = scale4b20_branch2a , act_type = ' relu ' ) NEW_LINE res4b20_branch2b = mx . symbol . Convolution ( name = ' res4b20 _ branch2b ' , data = res4b20_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2b = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2b ' , data = res4b20_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b20_branch2b = bn4b20_branch2b NEW_LINE res4b20_branch2b_relu = mx . symbol . Activation ( name = ' res4b20 _ branch2b _ relu ' , data = scale4b20_branch2b , act_type = ' relu ' ) NEW_LINE res4b20_branch2c = mx . symbol . Convolution ( name = ' res4b20 _ branch2c ' , data = res4b20_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2c = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2c ' , data = res4b20_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b20_branch2c = bn4b20_branch2c NEW_LINE res4b20 = mx . symbol . broadcast_add ( name = ' res4b20' , * [ res4b19_relu , scale4b20_branch2c ] ) NEW_LINE res4b20_relu = mx . symbol . Activation ( name = ' res4b20 _ relu ' , data = res4b20 , act_type = ' relu ' ) NEW_LINE res4b21_branch2a = mx . symbol . Convolution ( name = ' res4b21 _ branch2a ' , data = res4b20_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2a = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2a ' , data = res4b21_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b21_branch2a = bn4b21_branch2a NEW_LINE res4b21_branch2a_relu = mx . symbol . Activation ( name = ' res4b21 _ branch2a _ relu ' , data = scale4b21_branch2a , act_type = ' relu ' ) NEW_LINE res4b21_branch2b = mx . symbol . Convolution ( name = ' res4b21 _ branch2b ' , data = res4b21_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2b = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2b ' , data = res4b21_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b21_branch2b = bn4b21_branch2b NEW_LINE res4b21_branch2b_relu = mx . symbol . Activation ( name = ' res4b21 _ branch2b _ relu ' , data = scale4b21_branch2b , act_type = ' relu ' ) NEW_LINE res4b21_branch2c = mx . symbol . Convolution ( name = ' res4b21 _ branch2c ' , data = res4b21_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2c = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2c ' , data = res4b21_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b21_branch2c = bn4b21_branch2c NEW_LINE res4b21 = mx . symbol . broadcast_add ( name = ' res4b21' , * [ res4b20_relu , scale4b21_branch2c ] ) NEW_LINE res4b21_relu = mx . symbol . Activation ( name = ' res4b21 _ relu ' , data = res4b21 , act_type = ' relu ' ) NEW_LINE res4b22_branch2a = mx . symbol . Convolution ( name = ' res4b22 _ branch2a ' , data = res4b21_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b22_branch2a = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2a ' , data = res4b22_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b22_branch2a = bn4b22_branch2a NEW_LINE res4b22_branch2a_relu = mx . symbol . Activation ( name = ' res4b22 _ branch2a _ relu ' , data = scale4b22_branch2a , act_type = ' relu ' ) NEW_LINE res4b22_branch2b = mx . symbol . Convolution ( name = ' res4b22 _ branch2b ' , data = res4b22_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b22_branch2b = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2b ' , data = res4b22_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b22_branch2b = bn4b22_branch2b NEW_LINE res4b22_branch2b_relu = mx . symbol . Activation ( name = ' res4b22 _ branch2b _ relu ' , data = scale4b22_branch2b , act_type = ' relu ' ) NEW_LINE res4b22_branch2c = mx . symbol . Convolution ( name = ' res4b22 _ branch2c ' , data = res4b22_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b22_branch2c = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2c ' , data = res4b22_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b22_branch2c = bn4b22_branch2c NEW_LINE res4b22 = mx . symbol . broadcast_add ( name = ' res4b22' , * [ res4b21_relu , scale4b22_branch2c ] ) NEW_LINE res4b22_relu = mx . symbol . Activation ( name = ' res4b22 _ relu ' , data = res4b22 , act_type = ' relu ' ) NEW_LINE return res4b22_relu NEW_LINE DEDENT\",), (\"def get_resnet_v1_conv5 ( self , conv_feat ) : NEW_LINE INDENT res5a_branch1 = mx . symbol . Convolution ( name = ' res5a _ branch1' , data = conv_feat , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5a_branch1 = mx . symbol . BatchNorm ( name = ' bn5a _ branch1' , data = res5a_branch1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5a_branch1 = bn5a_branch1 NEW_LINE res5a_branch2a = mx . symbol . Convolution ( name = ' res5a _ branch2a ' , data = conv_feat , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5a_branch2a = mx . symbol . BatchNorm ( name = ' bn5a _ branch2a ' , data = res5a_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5a_branch2a = bn5a_branch2a NEW_LINE res5a_branch2a_relu = mx . symbol . Activation ( name = ' res5a _ branch2a _ relu ' , data = scale5a_branch2a , act_type = ' relu ' ) NEW_LINE res5a_branch2b = mx . symbol . Convolution ( name = ' res5a _ branch2b ' , data = res5a_branch2a_relu , num_filter = 512 , pad = ( 2 , 2 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn5a_branch2b = mx . symbol . BatchNorm ( name = ' bn5a _ branch2b ' , data = res5a_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5a_branch2b = bn5a_branch2b NEW_LINE res5a_branch2b_relu = mx . symbol . Activation ( name = ' res5a _ branch2b _ relu ' , data = scale5a_branch2b , act_type = ' relu ' ) NEW_LINE res5a_branch2c = mx . symbol . Convolution ( name = ' res5a _ branch2c ' , data = res5a_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5a_branch2c = mx . symbol . BatchNorm ( name = ' bn5a _ branch2c ' , data = res5a_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5a_branch2c = bn5a_branch2c NEW_LINE res5a = mx . symbol . broadcast_add ( name = ' res5a ' , * [ scale5a_branch1 , scale5a_branch2c ] ) NEW_LINE res5a_relu = mx . symbol . Activation ( name = ' res5a _ relu ' , data = res5a , act_type = ' relu ' ) NEW_LINE res5b_branch2a = mx . symbol . Convolution ( name = ' res5b _ branch2a ' , data = res5a_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5b_branch2a = mx . symbol . BatchNorm ( name = ' bn5b _ branch2a ' , data = res5b_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5b_branch2a = bn5b_branch2a NEW_LINE res5b_branch2a_relu = mx . symbol . Activation ( name = ' res5b _ branch2a _ relu ' , data = scale5b_branch2a , act_type = ' relu ' ) NEW_LINE res5b_branch2b = mx . symbol . Convolution ( name = ' res5b _ branch2b ' , data = res5b_branch2a_relu , num_filter = 512 , pad = ( 2 , 2 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn5b_branch2b = mx . symbol . BatchNorm ( name = ' bn5b _ branch2b ' , data = res5b_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5b_branch2b = bn5b_branch2b NEW_LINE res5b_branch2b_relu = mx . symbol . Activation ( name = ' res5b _ branch2b _ relu ' , data = scale5b_branch2b , act_type = ' relu ' ) NEW_LINE res5b_branch2c = mx . symbol . Convolution ( name = ' res5b _ branch2c ' , data = res5b_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5b_branch2c = mx . symbol . BatchNorm ( name = ' bn5b _ branch2c ' , data = res5b_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5b_branch2c = bn5b_branch2c NEW_LINE res5b = mx . symbol . broadcast_add ( name = ' res5b ' , * [ res5a_relu , scale5b_branch2c ] ) NEW_LINE res5b_relu = mx . symbol . Activation ( name = ' res5b _ relu ' , data = res5b , act_type = ' relu ' ) NEW_LINE res5c_branch2a = mx . symbol . Convolution ( name = ' res5c _ branch2a ' , data = res5b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5c_branch2a = mx . symbol . BatchNorm ( name = ' bn5c _ branch2a ' , data = res5c_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5c_branch2a = bn5c_branch2a NEW_LINE res5c_branch2a_relu = mx . symbol . Activation ( name = ' res5c _ branch2a _ relu ' , data = scale5c_branch2a , act_type = ' relu ' ) NEW_LINE res5c_branch2b = mx . symbol . Convolution ( name = ' res5c _ branch2b ' , data = res5c_branch2a_relu , num_filter = 512 , pad = ( 2 , 2 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn5c_branch2b = mx . symbol . BatchNorm ( name = ' bn5c _ branch2b ' , data = res5c_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5c_branch2b = bn5c_branch2b NEW_LINE res5c_branch2b_relu = mx . symbol . Activation ( name = ' res5c _ branch2b _ relu ' , data = scale5c_branch2b , act_type = ' relu ' ) NEW_LINE res5c_branch2c = mx . symbol . Convolution ( name = ' res5c _ branch2c ' , data = res5c_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5c_branch2c = mx . symbol . BatchNorm ( name = ' bn5c _ branch2c ' , data = res5c_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5c_branch2c = bn5c_branch2c NEW_LINE res5c = mx . symbol . broadcast_add ( name = ' res5c ' , * [ res5b_relu , scale5c_branch2c ] ) NEW_LINE res5c_relu = mx . symbol . Activation ( name = ' res5c _ relu ' , data = res5c , act_type = ' relu ' ) NEW_LINE return res5c_relu NEW_LINE DEDENT\",), ('def get_light_head ( self , data , mid_num_filter = 256 , suffix = \\' separable \\' ) : NEW_LINE INDENT conv_new_1 = mx . sym . Convolution ( data = data , kernel = ( 15 , 1 ) , pad = ( 7 , 0 ) , num_filter = mid_num_filter , name = \" conv _ new _ 1\" + suffix , weight = self . shared_param_dict [ \\' conv _ new _ 1 _ weight \\' ] , bias = self . shared_param_dict [ \\' conv _ new _ 1 _ bias \\' ] , lr_mult = 3.0 ) NEW_LINE relu_new_1 = mx . sym . Activation ( data = conv_new_1 , act_type = \\' relu \\' , name = \\' relu1\\' + suffix ) NEW_LINE conv_new_2 = mx . sym . Convolution ( data = relu_new_1 , kernel = ( 1 , 15 ) , pad = ( 0 , 7 ) , num_filter = 10 * 7 * 7 , name = \" conv _ new _ 2\" + suffix , weight = self . shared_param_dict [ \\' conv _ new _ 2 _ weight \\' ] , bias = self . shared_param_dict [ \\' conv _ new _ 2 _ bias \\' ] , lr_mult = 3.0 ) NEW_LINE relu_new_2 = mx . sym . Activation ( data = conv_new_2 , act_type = \\' relu \\' , name = \\' relu2\\' + suffix ) NEW_LINE conv_new_3 = mx . sym . Convolution ( data = data , kernel = ( 1 , 15 ) , pad = ( 0 , 7 ) , num_filter = mid_num_filter , name = \" conv _ new _ 3\" + suffix , weight = self . shared_param_dict [ \\' conv _ new _ 3 _ weight \\' ] , bias = self . shared_param_dict [ \\' conv _ new _ 3 _ bias \\' ] , lr_mult = 3.0 ) NEW_LINE relu_new_3 = mx . sym . Activation ( data = conv_new_3 , act_type = \\' relu \\' , name = \\' relu3\\' + suffix ) NEW_LINE conv_new_4 = mx . sym . Convolution ( data = relu_new_3 , kernel = ( 15 , 1 ) , pad = ( 7 , 0 ) , num_filter = 10 * 7 * 7 , name = \" conv _ new _ 4\" + suffix , weight = self . shared_param_dict [ \\' conv _ new _ 4 _ weight \\' ] , bias = self . shared_param_dict [ \\' conv _ new _ 4 _ bias \\' ] , lr_mult = 3.0 ) NEW_LINE relu_new_4 = mx . sym . Activation ( data = conv_new_4 , act_type = \\' relu \\' , name = \\' relu4\\' + suffix ) NEW_LINE light_head = mx . symbol . broadcast_add ( name = \\' light _ head \\' , * [ relu_new_2 , relu_new_4 ] ) NEW_LINE return light_head NEW_LINE DEDENT',), ('def get_rpn ( self , conv_feat , num_anchors ) : NEW_LINE INDENT rpn_conv = mx . sym . Convolution ( data = conv_feat , kernel = ( 3 , 3 ) , pad = ( 1 , 1 ) , num_filter = 512 , name = \" rpn _ conv _ 3x3\" ) NEW_LINE rpn_relu = mx . sym . Activation ( data = rpn_conv , act_type = \" relu \" , name = \" rpn _ relu \" ) NEW_LINE rpn_cls_score = mx . sym . Convolution ( data = rpn_relu , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , num_filter = 2 * num_anchors , name = \" rpn _ cls _ score \" ) NEW_LINE rpn_bbox_pred = mx . sym . Convolution ( data = rpn_relu , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , num_filter = 4 * num_anchors , name = \" rpn _ bbox _ pred \" ) NEW_LINE return rpn_cls_score , rpn_bbox_pred NEW_LINE DEDENT',), ('def get_symbol_rpn ( self , cfg , is_train = True ) : NEW_LINE INDENT num_anchors = cfg . network . NUM_ANCHORS NEW_LINE if is_train : NEW_LINE INDENT data = mx . sym . Variable ( name = \" data \" ) NEW_LINE rpn_label = mx . sym . Variable ( name = \\' label \\' ) NEW_LINE rpn_bbox_target = mx . sym . Variable ( name = \\' bbox _ target \\' ) NEW_LINE rpn_bbox_weight = mx . sym . Variable ( name = \\' bbox _ weight \\' ) NEW_LINE DEDENT else : NEW_LINE INDENT data = mx . sym . Variable ( name = \" data \" ) NEW_LINE im_info = mx . sym . Variable ( name = \" im _ info \" ) NEW_LINE DEDENT conv_feat = self . get_resnet_v1_conv4 ( data ) NEW_LINE rpn_cls_score , rpn_bbox_pred = self . get_rpn ( conv_feat , num_anchors ) NEW_LINE if is_train : NEW_LINE INDENT rpn_cls_score_reshape = mx . sym . Reshape ( data = rpn_cls_score , shape = ( 0 , 2 , - 1 , 0 ) , name = \" rpn _ cls _ score _ reshape \" ) NEW_LINE rpn_cls_prob = mx . sym . SoftmaxOutput ( data = rpn_cls_score_reshape , label = rpn_label , multi_output = True , normalization = \\' valid \\' , use_ignore = True , ignore_label = - 1 , name = \" rpn _ cls _ prob \" , grad_scale = 1.0 ) NEW_LINE rpn_bbox_loss_ = rpn_bbox_weight * mx . sym . smooth_l1 ( name = \\' rpn _ bbox _ loss _ \\' , scalar = 3.0 , data = ( rpn_bbox_pred - rpn_bbox_target ) ) NEW_LINE rpn_bbox_loss = mx . sym . MakeLoss ( name = \\' rpn _ bbox _ loss \\' , data = rpn_bbox_loss_ , grad_scale = 1.0 / cfg . TRAIN . RPN_BATCH_SIZE ) NEW_LINE group = mx . symbol . Group ( [ rpn_cls_prob , rpn_bbox_loss ] ) NEW_LINE DEDENT else : NEW_LINE INDENT rpn_cls_score_reshape = mx . sym . Reshape ( data = rpn_cls_score , shape = ( 0 , 2 , - 1 , 0 ) , name = \" rpn _ cls _ score _ reshape \" ) NEW_LINE rpn_cls_prob = mx . sym . SoftmaxActivation ( data = rpn_cls_score_reshape , mode = \" channel \" , name = \" rpn _ cls _ prob \" ) NEW_LINE rpn_cls_prob_reshape = mx . sym . Reshape ( data = rpn_cls_prob , shape = ( 0 , 2 * num_anchors , - 1 , 0 ) , name = \\' rpn _ cls _ prob _ reshape \\' ) NEW_LINE if cfg . TEST . CXX_PROPOSAL : NEW_LINE INDENT rois , score = mx . contrib . sym . Proposal ( cls_prob = rpn_cls_prob_reshape , bbox_pred = rpn_bbox_pred , im_info = im_info , name = \\' rois \\' , output_score = True , feature_stride = cfg . network . RPN_FEAT_STRIDE , scales = tuple ( cfg . network . ANCHOR_SCALES ) , ratios = tuple ( cfg . network . ANCHOR_RATIOS ) , rpn_pre_nms_top_n = cfg . TEST . RPN_PRE_NMS_TOP_N , rpn_post_nms_top_n = cfg . TEST . RPN_POST_NMS_TOP_N , threshold = cfg . TEST . RPN_NMS_THRESH , rpn_min_size = cfg . TEST . RPN_MIN_SIZE ) NEW_LINE DEDENT else : NEW_LINE INDENT rois , score = mx . sym . Custom ( cls_prob = rpn_cls_prob_reshape , bbox_pred = rpn_bbox_pred , im_info = im_info , name = \\' rois \\' , output_score = True , op_type = \\' proposal \\' , feat_stride = cfg . network . RPN_FEAT_STRIDE , scales = tuple ( cfg . network . ANCHOR_SCALES ) , ratios = tuple ( cfg . network . ANCHOR_RATIOS ) , rpn_pre_nms_top_n = cfg . TEST . RPN_PRE_NMS_TOP_N , rpn_post_nms_top_n = cfg . TEST . RPN_POST_NMS_TOP_N , threshold = cfg . TEST . RPN_NMS_THRESH , rpn_min_size = cfg . TEST . RPN_MIN_SIZE ) NEW_LINE group = mx . symbol . Group ( [ rois , score ] ) NEW_LINE DEDENT DEDENT self . sym = group NEW_LINE return group NEW_LINE DEDENT',), (\"def init_weight_rcnn ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT arg_params [ ' cls _ score _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' cls _ score _ weight ' ] ) NEW_LINE arg_params [ ' cls _ score _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' cls _ score _ bias ' ] ) NEW_LINE arg_params [ ' bbox _ pred _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' bbox _ pred _ weight ' ] ) NEW_LINE arg_params [ ' bbox _ pred _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' bbox _ pred _ bias ' ] ) NEW_LINE arg_params [ ' fc _ new _ 3 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fc _ new _ 3 _ weight ' ] ) NEW_LINE arg_params [ ' fc _ new _ 3 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fc _ new _ 3 _ bias ' ] ) NEW_LINE arg_params [ ' Rroi _ cls _ score _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' Rroi _ cls _ score _ weight ' ] ) NEW_LINE arg_params [ ' Rroi _ cls _ score _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' Rroi _ cls _ score _ bias ' ] ) NEW_LINE arg_params [ ' Rroi _ bbox _ pred _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' Rroi _ bbox _ pred _ weight ' ] ) NEW_LINE arg_params [ ' Rroi _ bbox _ pred _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' Rroi _ bbox _ pred _ bias ' ] ) NEW_LINE DEDENT\",), (\"def init_weight_rpn ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT arg_params [ ' rpn _ conv _ 3x3 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' rpn _ conv _ 3x3 _ weight ' ] ) NEW_LINE arg_params [ ' rpn _ conv _ 3x3 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' rpn _ conv _ 3x3 _ bias ' ] ) NEW_LINE arg_params [ ' rpn _ cls _ score _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' rpn _ cls _ score _ weight ' ] ) NEW_LINE arg_params [ ' rpn _ cls _ score _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' rpn _ cls _ score _ bias ' ] ) NEW_LINE arg_params [ ' rpn _ bbox _ pred _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' rpn _ bbox _ pred _ weight ' ] ) NEW_LINE arg_params [ ' rpn _ bbox _ pred _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' rpn _ bbox _ pred _ bias ' ] ) NEW_LINE DEDENT\",), (\"def init_weight ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT self . init_weight_rpn ( cfg , arg_params , aux_params ) NEW_LINE self . init_weight_rcnn ( cfg , arg_params , aux_params ) NEW_LINE for name in self . shared_param_list : NEW_LINE INDENT arg_params [ name + ' _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ name + ' _ weight ' ] ) NEW_LINE arg_params [ name + ' _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ name + ' _ bias ' ] ) NEW_LINE DEDENT DEDENT\",), ('def __init__ ( self ) : NEW_LINE INDENT self . eps = 1e-5 NEW_LINE self . use_global_stats = True NEW_LINE self . workspace = 512 NEW_LINE self . units = ( 3 , 4 , 23 , 3 ) NEW_LINE self . filter_list = [ 256 , 512 , 1024 , 2048 ] NEW_LINE DEDENT',), (\"def get_resnet_v1_conv4 ( self , data ) : NEW_LINE INDENT conv1 = mx . symbol . Convolution ( name = ' conv1' , data = data , num_filter = 64 , pad = ( 3 , 3 ) , kernel = ( 7 , 7 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn_conv1 = mx . symbol . BatchNorm ( name = ' bn _ conv1' , data = conv1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale_conv1 = bn_conv1 NEW_LINE conv1_relu = mx . symbol . Activation ( name = ' conv1 _ relu ' , data = scale_conv1 , act_type = ' relu ' ) NEW_LINE pool1 = mx . symbol . Pooling ( name = ' pool1' , data = conv1_relu , pooling_convention = ' full ' , pad = ( 0 , 0 ) , kernel = ( 3 , 3 ) , stride = ( 2 , 2 ) , pool_type = ' max ' ) NEW_LINE res2a_branch1 = mx . symbol . Convolution ( name = ' res2a _ branch1' , data = pool1 , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch1 = mx . symbol . BatchNorm ( name = ' bn2a _ branch1' , data = res2a_branch1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2a_branch1 = bn2a_branch1 NEW_LINE res2a_branch2a = mx . symbol . Convolution ( name = ' res2a _ branch2a ' , data = pool1 , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2a = mx . symbol . BatchNorm ( name = ' bn2a _ branch2a ' , data = res2a_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2a_branch2a = bn2a_branch2a NEW_LINE res2a_branch2a_relu = mx . symbol . Activation ( name = ' res2a _ branch2a _ relu ' , data = scale2a_branch2a , act_type = ' relu ' ) NEW_LINE res2a_branch2b = mx . symbol . Convolution ( name = ' res2a _ branch2b ' , data = res2a_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2b = mx . symbol . BatchNorm ( name = ' bn2a _ branch2b ' , data = res2a_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2a_branch2b = bn2a_branch2b NEW_LINE res2a_branch2b_relu = mx . symbol . Activation ( name = ' res2a _ branch2b _ relu ' , data = scale2a_branch2b , act_type = ' relu ' ) NEW_LINE res2a_branch2c = mx . symbol . Convolution ( name = ' res2a _ branch2c ' , data = res2a_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2c = mx . symbol . BatchNorm ( name = ' bn2a _ branch2c ' , data = res2a_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2a_branch2c = bn2a_branch2c NEW_LINE res2a = mx . symbol . broadcast_add ( name = ' res2a ' , * [ scale2a_branch1 , scale2a_branch2c ] ) NEW_LINE res2a_relu = mx . symbol . Activation ( name = ' res2a _ relu ' , data = res2a , act_type = ' relu ' ) NEW_LINE res2b_branch2a = mx . symbol . Convolution ( name = ' res2b _ branch2a ' , data = res2a_relu , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2a = mx . symbol . BatchNorm ( name = ' bn2b _ branch2a ' , data = res2b_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2b_branch2a = bn2b_branch2a NEW_LINE res2b_branch2a_relu = mx . symbol . Activation ( name = ' res2b _ branch2a _ relu ' , data = scale2b_branch2a , act_type = ' relu ' ) NEW_LINE res2b_branch2b = mx . symbol . Convolution ( name = ' res2b _ branch2b ' , data = res2b_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2b = mx . symbol . BatchNorm ( name = ' bn2b _ branch2b ' , data = res2b_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2b_branch2b = bn2b_branch2b NEW_LINE res2b_branch2b_relu = mx . symbol . Activation ( name = ' res2b _ branch2b _ relu ' , data = scale2b_branch2b , act_type = ' relu ' ) NEW_LINE res2b_branch2c = mx . symbol . Convolution ( name = ' res2b _ branch2c ' , data = res2b_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2c = mx . symbol . BatchNorm ( name = ' bn2b _ branch2c ' , data = res2b_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2b_branch2c = bn2b_branch2c NEW_LINE res2b = mx . symbol . broadcast_add ( name = ' res2b ' , * [ res2a_relu , scale2b_branch2c ] ) NEW_LINE res2b_relu = mx . symbol . Activation ( name = ' res2b _ relu ' , data = res2b , act_type = ' relu ' ) NEW_LINE res2c_branch2a = mx . symbol . Convolution ( name = ' res2c _ branch2a ' , data = res2b_relu , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2a = mx . symbol . BatchNorm ( name = ' bn2c _ branch2a ' , data = res2c_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2c_branch2a = bn2c_branch2a NEW_LINE res2c_branch2a_relu = mx . symbol . Activation ( name = ' res2c _ branch2a _ relu ' , data = scale2c_branch2a , act_type = ' relu ' ) NEW_LINE res2c_branch2b = mx . symbol . Convolution ( name = ' res2c _ branch2b ' , data = res2c_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2b = mx . symbol . BatchNorm ( name = ' bn2c _ branch2b ' , data = res2c_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2c_branch2b = bn2c_branch2b NEW_LINE res2c_branch2b_relu = mx . symbol . Activation ( name = ' res2c _ branch2b _ relu ' , data = scale2c_branch2b , act_type = ' relu ' ) NEW_LINE res2c_branch2c = mx . symbol . Convolution ( name = ' res2c _ branch2c ' , data = res2c_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2c = mx . symbol . BatchNorm ( name = ' bn2c _ branch2c ' , data = res2c_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2c_branch2c = bn2c_branch2c NEW_LINE res2c = mx . symbol . broadcast_add ( name = ' res2c ' , * [ res2b_relu , scale2c_branch2c ] ) NEW_LINE res2c_relu = mx . symbol . Activation ( name = ' res2c _ relu ' , data = res2c , act_type = ' relu ' ) NEW_LINE res3a_branch1 = mx . symbol . Convolution ( name = ' res3a _ branch1' , data = res2c_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn3a_branch1 = mx . symbol . BatchNorm ( name = ' bn3a _ branch1' , data = res3a_branch1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3a_branch1 = bn3a_branch1 NEW_LINE res3a_branch2a = mx . symbol . Convolution ( name = ' res3a _ branch2a ' , data = res2c_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn3a_branch2a = mx . symbol . BatchNorm ( name = ' bn3a _ branch2a ' , data = res3a_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3a_branch2a = bn3a_branch2a NEW_LINE res3a_branch2a_relu = mx . symbol . Activation ( name = ' res3a _ branch2a _ relu ' , data = scale3a_branch2a , act_type = ' relu ' ) NEW_LINE res3a_branch2b = mx . symbol . Convolution ( name = ' res3a _ branch2b ' , data = res3a_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3a_branch2b = mx . symbol . BatchNorm ( name = ' bn3a _ branch2b ' , data = res3a_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3a_branch2b = bn3a_branch2b NEW_LINE res3a_branch2b_relu = mx . symbol . Activation ( name = ' res3a _ branch2b _ relu ' , data = scale3a_branch2b , act_type = ' relu ' ) NEW_LINE res3a_branch2c = mx . symbol . Convolution ( name = ' res3a _ branch2c ' , data = res3a_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3a_branch2c = mx . symbol . BatchNorm ( name = ' bn3a _ branch2c ' , data = res3a_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3a_branch2c = bn3a_branch2c NEW_LINE res3a = mx . symbol . broadcast_add ( name = ' res3a ' , * [ scale3a_branch1 , scale3a_branch2c ] ) NEW_LINE res3a_relu = mx . symbol . Activation ( name = ' res3a _ relu ' , data = res3a , act_type = ' relu ' ) NEW_LINE res3b1_branch2a = mx . symbol . Convolution ( name = ' res3b1 _ branch2a ' , data = res3a_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2a = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2a ' , data = res3b1_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b1_branch2a = bn3b1_branch2a NEW_LINE res3b1_branch2a_relu = mx . symbol . Activation ( name = ' res3b1 _ branch2a _ relu ' , data = scale3b1_branch2a , act_type = ' relu ' ) NEW_LINE res3b1_branch2b = mx . symbol . Convolution ( name = ' res3b1 _ branch2b ' , data = res3b1_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2b = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2b ' , data = res3b1_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b1_branch2b = bn3b1_branch2b NEW_LINE res3b1_branch2b_relu = mx . symbol . Activation ( name = ' res3b1 _ branch2b _ relu ' , data = scale3b1_branch2b , act_type = ' relu ' ) NEW_LINE res3b1_branch2c = mx . symbol . Convolution ( name = ' res3b1 _ branch2c ' , data = res3b1_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2c = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2c ' , data = res3b1_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b1_branch2c = bn3b1_branch2c NEW_LINE res3b1 = mx . symbol . broadcast_add ( name = ' res3b1' , * [ res3a_relu , scale3b1_branch2c ] ) NEW_LINE res3b1_relu = mx . symbol . Activation ( name = ' res3b1 _ relu ' , data = res3b1 , act_type = ' relu ' ) NEW_LINE res3b2_branch2a = mx . symbol . Convolution ( name = ' res3b2 _ branch2a ' , data = res3b1_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2a = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2a ' , data = res3b2_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b2_branch2a = bn3b2_branch2a NEW_LINE res3b2_branch2a_relu = mx . symbol . Activation ( name = ' res3b2 _ branch2a _ relu ' , data = scale3b2_branch2a , act_type = ' relu ' ) NEW_LINE res3b2_branch2b = mx . symbol . Convolution ( name = ' res3b2 _ branch2b ' , data = res3b2_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2b = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2b ' , data = res3b2_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b2_branch2b = bn3b2_branch2b NEW_LINE res3b2_branch2b_relu = mx . symbol . Activation ( name = ' res3b2 _ branch2b _ relu ' , data = scale3b2_branch2b , act_type = ' relu ' ) NEW_LINE res3b2_branch2c = mx . symbol . Convolution ( name = ' res3b2 _ branch2c ' , data = res3b2_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2c = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2c ' , data = res3b2_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b2_branch2c = bn3b2_branch2c NEW_LINE res3b2 = mx . symbol . broadcast_add ( name = ' res3b2' , * [ res3b1_relu , scale3b2_branch2c ] ) NEW_LINE res3b2_relu = mx . symbol . Activation ( name = ' res3b2 _ relu ' , data = res3b2 , act_type = ' relu ' ) NEW_LINE res3b3_branch2a = mx . symbol . Convolution ( name = ' res3b3 _ branch2a ' , data = res3b2_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b3_branch2a = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2a ' , data = res3b3_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b3_branch2a = bn3b3_branch2a NEW_LINE res3b3_branch2a_relu = mx . symbol . Activation ( name = ' res3b3 _ branch2a _ relu ' , data = scale3b3_branch2a , act_type = ' relu ' ) NEW_LINE res3b3_branch2b = mx . symbol . Convolution ( name = ' res3b3 _ branch2b ' , data = res3b3_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b3_branch2b = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2b ' , data = res3b3_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b3_branch2b = bn3b3_branch2b NEW_LINE res3b3_branch2b_relu = mx . symbol . Activation ( name = ' res3b3 _ branch2b _ relu ' , data = scale3b3_branch2b , act_type = ' relu ' ) NEW_LINE res3b3_branch2c = mx . symbol . Convolution ( name = ' res3b3 _ branch2c ' , data = res3b3_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b3_branch2c = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2c ' , data = res3b3_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b3_branch2c = bn3b3_branch2c NEW_LINE res3b3 = mx . symbol . broadcast_add ( name = ' res3b3' , * [ res3b2_relu , scale3b3_branch2c ] ) NEW_LINE res3b3_relu = mx . symbol . Activation ( name = ' res3b3 _ relu ' , data = res3b3 , act_type = ' relu ' ) NEW_LINE res4a_branch1 = mx . symbol . Convolution ( name = ' res4a _ branch1' , data = res3b3_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn4a_branch1 = mx . symbol . BatchNorm ( name = ' bn4a _ branch1' , data = res4a_branch1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4a_branch1 = bn4a_branch1 NEW_LINE res4a_branch2a = mx . symbol . Convolution ( name = ' res4a _ branch2a ' , data = res3b3_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn4a_branch2a = mx . symbol . BatchNorm ( name = ' bn4a _ branch2a ' , data = res4a_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4a_branch2a = bn4a_branch2a NEW_LINE res4a_branch2a_relu = mx . symbol . Activation ( name = ' res4a _ branch2a _ relu ' , data = scale4a_branch2a , act_type = ' relu ' ) NEW_LINE res4a_branch2b = mx . symbol . Convolution ( name = ' res4a _ branch2b ' , data = res4a_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4a_branch2b = mx . symbol . BatchNorm ( name = ' bn4a _ branch2b ' , data = res4a_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4a_branch2b = bn4a_branch2b NEW_LINE res4a_branch2b_relu = mx . symbol . Activation ( name = ' res4a _ branch2b _ relu ' , data = scale4a_branch2b , act_type = ' relu ' ) NEW_LINE res4a_branch2c = mx . symbol . Convolution ( name = ' res4a _ branch2c ' , data = res4a_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4a_branch2c = mx . symbol . BatchNorm ( name = ' bn4a _ branch2c ' , data = res4a_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4a_branch2c = bn4a_branch2c NEW_LINE res4a = mx . symbol . broadcast_add ( name = ' res4a ' , * [ scale4a_branch1 , scale4a_branch2c ] ) NEW_LINE res4a_relu = mx . symbol . Activation ( name = ' res4a _ relu ' , data = res4a , act_type = ' relu ' ) NEW_LINE res4b1_branch2a = mx . symbol . Convolution ( name = ' res4b1 _ branch2a ' , data = res4a_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2a = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2a ' , data = res4b1_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b1_branch2a = bn4b1_branch2a NEW_LINE res4b1_branch2a_relu = mx . symbol . Activation ( name = ' res4b1 _ branch2a _ relu ' , data = scale4b1_branch2a , act_type = ' relu ' ) NEW_LINE res4b1_branch2b = mx . symbol . Convolution ( name = ' res4b1 _ branch2b ' , data = res4b1_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2b = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2b ' , data = res4b1_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b1_branch2b = bn4b1_branch2b NEW_LINE res4b1_branch2b_relu = mx . symbol . Activation ( name = ' res4b1 _ branch2b _ relu ' , data = scale4b1_branch2b , act_type = ' relu ' ) NEW_LINE res4b1_branch2c = mx . symbol . Convolution ( name = ' res4b1 _ branch2c ' , data = res4b1_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2c = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2c ' , data = res4b1_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b1_branch2c = bn4b1_branch2c NEW_LINE res4b1 = mx . symbol . broadcast_add ( name = ' res4b1' , * [ res4a_relu , scale4b1_branch2c ] ) NEW_LINE res4b1_relu = mx . symbol . Activation ( name = ' res4b1 _ relu ' , data = res4b1 , act_type = ' relu ' ) NEW_LINE res4b2_branch2a = mx . symbol . Convolution ( name = ' res4b2 _ branch2a ' , data = res4b1_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2a = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2a ' , data = res4b2_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b2_branch2a = bn4b2_branch2a NEW_LINE res4b2_branch2a_relu = mx . symbol . Activation ( name = ' res4b2 _ branch2a _ relu ' , data = scale4b2_branch2a , act_type = ' relu ' ) NEW_LINE res4b2_branch2b = mx . symbol . Convolution ( name = ' res4b2 _ branch2b ' , data = res4b2_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2b = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2b ' , data = res4b2_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b2_branch2b = bn4b2_branch2b NEW_LINE res4b2_branch2b_relu = mx . symbol . Activation ( name = ' res4b2 _ branch2b _ relu ' , data = scale4b2_branch2b , act_type = ' relu ' ) NEW_LINE res4b2_branch2c = mx . symbol . Convolution ( name = ' res4b2 _ branch2c ' , data = res4b2_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2c = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2c ' , data = res4b2_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b2_branch2c = bn4b2_branch2c NEW_LINE res4b2 = mx . symbol . broadcast_add ( name = ' res4b2' , * [ res4b1_relu , scale4b2_branch2c ] ) NEW_LINE res4b2_relu = mx . symbol . Activation ( name = ' res4b2 _ relu ' , data = res4b2 , act_type = ' relu ' ) NEW_LINE res4b3_branch2a = mx . symbol . Convolution ( name = ' res4b3 _ branch2a ' , data = res4b2_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2a = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2a ' , data = res4b3_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b3_branch2a = bn4b3_branch2a NEW_LINE res4b3_branch2a_relu = mx . symbol . Activation ( name = ' res4b3 _ branch2a _ relu ' , data = scale4b3_branch2a , act_type = ' relu ' ) NEW_LINE res4b3_branch2b = mx . symbol . Convolution ( name = ' res4b3 _ branch2b ' , data = res4b3_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2b = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2b ' , data = res4b3_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b3_branch2b = bn4b3_branch2b NEW_LINE res4b3_branch2b_relu = mx . symbol . Activation ( name = ' res4b3 _ branch2b _ relu ' , data = scale4b3_branch2b , act_type = ' relu ' ) NEW_LINE res4b3_branch2c = mx . symbol . Convolution ( name = ' res4b3 _ branch2c ' , data = res4b3_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2c = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2c ' , data = res4b3_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b3_branch2c = bn4b3_branch2c NEW_LINE res4b3 = mx . symbol . broadcast_add ( name = ' res4b3' , * [ res4b2_relu , scale4b3_branch2c ] ) NEW_LINE res4b3_relu = mx . symbol . Activation ( name = ' res4b3 _ relu ' , data = res4b3 , act_type = ' relu ' ) NEW_LINE res4b4_branch2a = mx . symbol . Convolution ( name = ' res4b4 _ branch2a ' , data = res4b3_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2a = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2a ' , data = res4b4_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b4_branch2a = bn4b4_branch2a NEW_LINE res4b4_branch2a_relu = mx . symbol . Activation ( name = ' res4b4 _ branch2a _ relu ' , data = scale4b4_branch2a , act_type = ' relu ' ) NEW_LINE res4b4_branch2b = mx . symbol . Convolution ( name = ' res4b4 _ branch2b ' , data = res4b4_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2b = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2b ' , data = res4b4_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b4_branch2b = bn4b4_branch2b NEW_LINE res4b4_branch2b_relu = mx . symbol . Activation ( name = ' res4b4 _ branch2b _ relu ' , data = scale4b4_branch2b , act_type = ' relu ' ) NEW_LINE res4b4_branch2c = mx . symbol . Convolution ( name = ' res4b4 _ branch2c ' , data = res4b4_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2c = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2c ' , data = res4b4_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b4_branch2c = bn4b4_branch2c NEW_LINE res4b4 = mx . symbol . broadcast_add ( name = ' res4b4' , * [ res4b3_relu , scale4b4_branch2c ] ) NEW_LINE res4b4_relu = mx . symbol . Activation ( name = ' res4b4 _ relu ' , data = res4b4 , act_type = ' relu ' ) NEW_LINE res4b5_branch2a = mx . symbol . Convolution ( name = ' res4b5 _ branch2a ' , data = res4b4_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2a = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2a ' , data = res4b5_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b5_branch2a = bn4b5_branch2a NEW_LINE res4b5_branch2a_relu = mx . symbol . Activation ( name = ' res4b5 _ branch2a _ relu ' , data = scale4b5_branch2a , act_type = ' relu ' ) NEW_LINE res4b5_branch2b = mx . symbol . Convolution ( name = ' res4b5 _ branch2b ' , data = res4b5_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2b = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2b ' , data = res4b5_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b5_branch2b = bn4b5_branch2b NEW_LINE res4b5_branch2b_relu = mx . symbol . Activation ( name = ' res4b5 _ branch2b _ relu ' , data = scale4b5_branch2b , act_type = ' relu ' ) NEW_LINE res4b5_branch2c = mx . symbol . Convolution ( name = ' res4b5 _ branch2c ' , data = res4b5_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2c = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2c ' , data = res4b5_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b5_branch2c = bn4b5_branch2c NEW_LINE res4b5 = mx . symbol . broadcast_add ( name = ' res4b5' , * [ res4b4_relu , scale4b5_branch2c ] ) NEW_LINE res4b5_relu = mx . symbol . Activation ( name = ' res4b5 _ relu ' , data = res4b5 , act_type = ' relu ' ) NEW_LINE res4b6_branch2a = mx . symbol . Convolution ( name = ' res4b6 _ branch2a ' , data = res4b5_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2a = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2a ' , data = res4b6_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b6_branch2a = bn4b6_branch2a NEW_LINE res4b6_branch2a_relu = mx . symbol . Activation ( name = ' res4b6 _ branch2a _ relu ' , data = scale4b6_branch2a , act_type = ' relu ' ) NEW_LINE res4b6_branch2b = mx . symbol . Convolution ( name = ' res4b6 _ branch2b ' , data = res4b6_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2b = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2b ' , data = res4b6_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b6_branch2b = bn4b6_branch2b NEW_LINE res4b6_branch2b_relu = mx . symbol . Activation ( name = ' res4b6 _ branch2b _ relu ' , data = scale4b6_branch2b , act_type = ' relu ' ) NEW_LINE res4b6_branch2c = mx . symbol . Convolution ( name = ' res4b6 _ branch2c ' , data = res4b6_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2c = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2c ' , data = res4b6_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b6_branch2c = bn4b6_branch2c NEW_LINE res4b6 = mx . symbol . broadcast_add ( name = ' res4b6' , * [ res4b5_relu , scale4b6_branch2c ] ) NEW_LINE res4b6_relu = mx . symbol . Activation ( name = ' res4b6 _ relu ' , data = res4b6 , act_type = ' relu ' ) NEW_LINE res4b7_branch2a = mx . symbol . Convolution ( name = ' res4b7 _ branch2a ' , data = res4b6_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2a = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2a ' , data = res4b7_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b7_branch2a = bn4b7_branch2a NEW_LINE res4b7_branch2a_relu = mx . symbol . Activation ( name = ' res4b7 _ branch2a _ relu ' , data = scale4b7_branch2a , act_type = ' relu ' ) NEW_LINE res4b7_branch2b = mx . symbol . Convolution ( name = ' res4b7 _ branch2b ' , data = res4b7_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2b = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2b ' , data = res4b7_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b7_branch2b = bn4b7_branch2b NEW_LINE res4b7_branch2b_relu = mx . symbol . Activation ( name = ' res4b7 _ branch2b _ relu ' , data = scale4b7_branch2b , act_type = ' relu ' ) NEW_LINE res4b7_branch2c = mx . symbol . Convolution ( name = ' res4b7 _ branch2c ' , data = res4b7_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2c = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2c ' , data = res4b7_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b7_branch2c = bn4b7_branch2c NEW_LINE res4b7 = mx . symbol . broadcast_add ( name = ' res4b7' , * [ res4b6_relu , scale4b7_branch2c ] ) NEW_LINE res4b7_relu = mx . symbol . Activation ( name = ' res4b7 _ relu ' , data = res4b7 , act_type = ' relu ' ) NEW_LINE res4b8_branch2a = mx . symbol . Convolution ( name = ' res4b8 _ branch2a ' , data = res4b7_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2a = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2a ' , data = res4b8_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b8_branch2a = bn4b8_branch2a NEW_LINE res4b8_branch2a_relu = mx . symbol . Activation ( name = ' res4b8 _ branch2a _ relu ' , data = scale4b8_branch2a , act_type = ' relu ' ) NEW_LINE res4b8_branch2b = mx . symbol . Convolution ( name = ' res4b8 _ branch2b ' , data = res4b8_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2b = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2b ' , data = res4b8_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b8_branch2b = bn4b8_branch2b NEW_LINE res4b8_branch2b_relu = mx . symbol . Activation ( name = ' res4b8 _ branch2b _ relu ' , data = scale4b8_branch2b , act_type = ' relu ' ) NEW_LINE res4b8_branch2c = mx . symbol . Convolution ( name = ' res4b8 _ branch2c ' , data = res4b8_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2c = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2c ' , data = res4b8_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b8_branch2c = bn4b8_branch2c NEW_LINE res4b8 = mx . symbol . broadcast_add ( name = ' res4b8' , * [ res4b7_relu , scale4b8_branch2c ] ) NEW_LINE res4b8_relu = mx . symbol . Activation ( name = ' res4b8 _ relu ' , data = res4b8 , act_type = ' relu ' ) NEW_LINE res4b9_branch2a = mx . symbol . Convolution ( name = ' res4b9 _ branch2a ' , data = res4b8_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2a = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2a ' , data = res4b9_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b9_branch2a = bn4b9_branch2a NEW_LINE res4b9_branch2a_relu = mx . symbol . Activation ( name = ' res4b9 _ branch2a _ relu ' , data = scale4b9_branch2a , act_type = ' relu ' ) NEW_LINE res4b9_branch2b = mx . symbol . Convolution ( name = ' res4b9 _ branch2b ' , data = res4b9_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2b = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2b ' , data = res4b9_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b9_branch2b = bn4b9_branch2b NEW_LINE res4b9_branch2b_relu = mx . symbol . Activation ( name = ' res4b9 _ branch2b _ relu ' , data = scale4b9_branch2b , act_type = ' relu ' ) NEW_LINE res4b9_branch2c = mx . symbol . Convolution ( name = ' res4b9 _ branch2c ' , data = res4b9_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2c = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2c ' , data = res4b9_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b9_branch2c = bn4b9_branch2c NEW_LINE res4b9 = mx . symbol . broadcast_add ( name = ' res4b9' , * [ res4b8_relu , scale4b9_branch2c ] ) NEW_LINE res4b9_relu = mx . symbol . Activation ( name = ' res4b9 _ relu ' , data = res4b9 , act_type = ' relu ' ) NEW_LINE res4b10_branch2a = mx . symbol . Convolution ( name = ' res4b10 _ branch2a ' , data = res4b9_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2a = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2a ' , data = res4b10_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b10_branch2a = bn4b10_branch2a NEW_LINE res4b10_branch2a_relu = mx . symbol . Activation ( name = ' res4b10 _ branch2a _ relu ' , data = scale4b10_branch2a , act_type = ' relu ' ) NEW_LINE res4b10_branch2b = mx . symbol . Convolution ( name = ' res4b10 _ branch2b ' , data = res4b10_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2b = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2b ' , data = res4b10_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b10_branch2b = bn4b10_branch2b NEW_LINE res4b10_branch2b_relu = mx . symbol . Activation ( name = ' res4b10 _ branch2b _ relu ' , data = scale4b10_branch2b , act_type = ' relu ' ) NEW_LINE res4b10_branch2c = mx . symbol . Convolution ( name = ' res4b10 _ branch2c ' , data = res4b10_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2c = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2c ' , data = res4b10_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b10_branch2c = bn4b10_branch2c NEW_LINE res4b10 = mx . symbol . broadcast_add ( name = ' res4b10' , * [ res4b9_relu , scale4b10_branch2c ] ) NEW_LINE res4b10_relu = mx . symbol . Activation ( name = ' res4b10 _ relu ' , data = res4b10 , act_type = ' relu ' ) NEW_LINE res4b11_branch2a = mx . symbol . Convolution ( name = ' res4b11 _ branch2a ' , data = res4b10_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2a = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2a ' , data = res4b11_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b11_branch2a = bn4b11_branch2a NEW_LINE res4b11_branch2a_relu = mx . symbol . Activation ( name = ' res4b11 _ branch2a _ relu ' , data = scale4b11_branch2a , act_type = ' relu ' ) NEW_LINE res4b11_branch2b = mx . symbol . Convolution ( name = ' res4b11 _ branch2b ' , data = res4b11_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2b = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2b ' , data = res4b11_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b11_branch2b = bn4b11_branch2b NEW_LINE res4b11_branch2b_relu = mx . symbol . Activation ( name = ' res4b11 _ branch2b _ relu ' , data = scale4b11_branch2b , act_type = ' relu ' ) NEW_LINE res4b11_branch2c = mx . symbol . Convolution ( name = ' res4b11 _ branch2c ' , data = res4b11_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2c = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2c ' , data = res4b11_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b11_branch2c = bn4b11_branch2c NEW_LINE res4b11 = mx . symbol . broadcast_add ( name = ' res4b11' , * [ res4b10_relu , scale4b11_branch2c ] ) NEW_LINE res4b11_relu = mx . symbol . Activation ( name = ' res4b11 _ relu ' , data = res4b11 , act_type = ' relu ' ) NEW_LINE res4b12_branch2a = mx . symbol . Convolution ( name = ' res4b12 _ branch2a ' , data = res4b11_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2a = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2a ' , data = res4b12_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b12_branch2a = bn4b12_branch2a NEW_LINE res4b12_branch2a_relu = mx . symbol . Activation ( name = ' res4b12 _ branch2a _ relu ' , data = scale4b12_branch2a , act_type = ' relu ' ) NEW_LINE res4b12_branch2b = mx . symbol . Convolution ( name = ' res4b12 _ branch2b ' , data = res4b12_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2b = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2b ' , data = res4b12_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b12_branch2b = bn4b12_branch2b NEW_LINE res4b12_branch2b_relu = mx . symbol . Activation ( name = ' res4b12 _ branch2b _ relu ' , data = scale4b12_branch2b , act_type = ' relu ' ) NEW_LINE res4b12_branch2c = mx . symbol . Convolution ( name = ' res4b12 _ branch2c ' , data = res4b12_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2c = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2c ' , data = res4b12_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b12_branch2c = bn4b12_branch2c NEW_LINE res4b12 = mx . symbol . broadcast_add ( name = ' res4b12' , * [ res4b11_relu , scale4b12_branch2c ] ) NEW_LINE res4b12_relu = mx . symbol . Activation ( name = ' res4b12 _ relu ' , data = res4b12 , act_type = ' relu ' ) NEW_LINE res4b13_branch2a = mx . symbol . Convolution ( name = ' res4b13 _ branch2a ' , data = res4b12_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2a = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2a ' , data = res4b13_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b13_branch2a = bn4b13_branch2a NEW_LINE res4b13_branch2a_relu = mx . symbol . Activation ( name = ' res4b13 _ branch2a _ relu ' , data = scale4b13_branch2a , act_type = ' relu ' ) NEW_LINE res4b13_branch2b = mx . symbol . Convolution ( name = ' res4b13 _ branch2b ' , data = res4b13_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2b = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2b ' , data = res4b13_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b13_branch2b = bn4b13_branch2b NEW_LINE res4b13_branch2b_relu = mx . symbol . Activation ( name = ' res4b13 _ branch2b _ relu ' , data = scale4b13_branch2b , act_type = ' relu ' ) NEW_LINE res4b13_branch2c = mx . symbol . Convolution ( name = ' res4b13 _ branch2c ' , data = res4b13_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2c = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2c ' , data = res4b13_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b13_branch2c = bn4b13_branch2c NEW_LINE res4b13 = mx . symbol . broadcast_add ( name = ' res4b13' , * [ res4b12_relu , scale4b13_branch2c ] ) NEW_LINE res4b13_relu = mx . symbol . Activation ( name = ' res4b13 _ relu ' , data = res4b13 , act_type = ' relu ' ) NEW_LINE res4b14_branch2a = mx . symbol . Convolution ( name = ' res4b14 _ branch2a ' , data = res4b13_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2a = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2a ' , data = res4b14_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b14_branch2a = bn4b14_branch2a NEW_LINE res4b14_branch2a_relu = mx . symbol . Activation ( name = ' res4b14 _ branch2a _ relu ' , data = scale4b14_branch2a , act_type = ' relu ' ) NEW_LINE res4b14_branch2b = mx . symbol . Convolution ( name = ' res4b14 _ branch2b ' , data = res4b14_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2b = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2b ' , data = res4b14_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b14_branch2b = bn4b14_branch2b NEW_LINE res4b14_branch2b_relu = mx . symbol . Activation ( name = ' res4b14 _ branch2b _ relu ' , data = scale4b14_branch2b , act_type = ' relu ' ) NEW_LINE res4b14_branch2c = mx . symbol . Convolution ( name = ' res4b14 _ branch2c ' , data = res4b14_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2c = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2c ' , data = res4b14_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b14_branch2c = bn4b14_branch2c NEW_LINE res4b14 = mx . symbol . broadcast_add ( name = ' res4b14' , * [ res4b13_relu , scale4b14_branch2c ] ) NEW_LINE res4b14_relu = mx . symbol . Activation ( name = ' res4b14 _ relu ' , data = res4b14 , act_type = ' relu ' ) NEW_LINE res4b15_branch2a = mx . symbol . Convolution ( name = ' res4b15 _ branch2a ' , data = res4b14_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2a = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2a ' , data = res4b15_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b15_branch2a = bn4b15_branch2a NEW_LINE res4b15_branch2a_relu = mx . symbol . Activation ( name = ' res4b15 _ branch2a _ relu ' , data = scale4b15_branch2a , act_type = ' relu ' ) NEW_LINE res4b15_branch2b = mx . symbol . Convolution ( name = ' res4b15 _ branch2b ' , data = res4b15_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2b = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2b ' , data = res4b15_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b15_branch2b = bn4b15_branch2b NEW_LINE res4b15_branch2b_relu = mx . symbol . Activation ( name = ' res4b15 _ branch2b _ relu ' , data = scale4b15_branch2b , act_type = ' relu ' ) NEW_LINE res4b15_branch2c = mx . symbol . Convolution ( name = ' res4b15 _ branch2c ' , data = res4b15_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2c = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2c ' , data = res4b15_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b15_branch2c = bn4b15_branch2c NEW_LINE res4b15 = mx . symbol . broadcast_add ( name = ' res4b15' , * [ res4b14_relu , scale4b15_branch2c ] ) NEW_LINE res4b15_relu = mx . symbol . Activation ( name = ' res4b15 _ relu ' , data = res4b15 , act_type = ' relu ' ) NEW_LINE res4b16_branch2a = mx . symbol . Convolution ( name = ' res4b16 _ branch2a ' , data = res4b15_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2a = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2a ' , data = res4b16_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b16_branch2a = bn4b16_branch2a NEW_LINE res4b16_branch2a_relu = mx . symbol . Activation ( name = ' res4b16 _ branch2a _ relu ' , data = scale4b16_branch2a , act_type = ' relu ' ) NEW_LINE res4b16_branch2b = mx . symbol . Convolution ( name = ' res4b16 _ branch2b ' , data = res4b16_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2b = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2b ' , data = res4b16_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b16_branch2b = bn4b16_branch2b NEW_LINE res4b16_branch2b_relu = mx . symbol . Activation ( name = ' res4b16 _ branch2b _ relu ' , data = scale4b16_branch2b , act_type = ' relu ' ) NEW_LINE res4b16_branch2c = mx . symbol . Convolution ( name = ' res4b16 _ branch2c ' , data = res4b16_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2c = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2c ' , data = res4b16_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b16_branch2c = bn4b16_branch2c NEW_LINE res4b16 = mx . symbol . broadcast_add ( name = ' res4b16' , * [ res4b15_relu , scale4b16_branch2c ] ) NEW_LINE res4b16_relu = mx . symbol . Activation ( name = ' res4b16 _ relu ' , data = res4b16 , act_type = ' relu ' ) NEW_LINE res4b17_branch2a = mx . symbol . Convolution ( name = ' res4b17 _ branch2a ' , data = res4b16_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2a = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2a ' , data = res4b17_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b17_branch2a = bn4b17_branch2a NEW_LINE res4b17_branch2a_relu = mx . symbol . Activation ( name = ' res4b17 _ branch2a _ relu ' , data = scale4b17_branch2a , act_type = ' relu ' ) NEW_LINE res4b17_branch2b = mx . symbol . Convolution ( name = ' res4b17 _ branch2b ' , data = res4b17_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2b = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2b ' , data = res4b17_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b17_branch2b = bn4b17_branch2b NEW_LINE res4b17_branch2b_relu = mx . symbol . Activation ( name = ' res4b17 _ branch2b _ relu ' , data = scale4b17_branch2b , act_type = ' relu ' ) NEW_LINE res4b17_branch2c = mx . symbol . Convolution ( name = ' res4b17 _ branch2c ' , data = res4b17_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2c = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2c ' , data = res4b17_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b17_branch2c = bn4b17_branch2c NEW_LINE res4b17 = mx . symbol . broadcast_add ( name = ' res4b17' , * [ res4b16_relu , scale4b17_branch2c ] ) NEW_LINE res4b17_relu = mx . symbol . Activation ( name = ' res4b17 _ relu ' , data = res4b17 , act_type = ' relu ' ) NEW_LINE res4b18_branch2a = mx . symbol . Convolution ( name = ' res4b18 _ branch2a ' , data = res4b17_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2a = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2a ' , data = res4b18_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b18_branch2a = bn4b18_branch2a NEW_LINE res4b18_branch2a_relu = mx . symbol . Activation ( name = ' res4b18 _ branch2a _ relu ' , data = scale4b18_branch2a , act_type = ' relu ' ) NEW_LINE res4b18_branch2b = mx . symbol . Convolution ( name = ' res4b18 _ branch2b ' , data = res4b18_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2b = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2b ' , data = res4b18_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b18_branch2b = bn4b18_branch2b NEW_LINE res4b18_branch2b_relu = mx . symbol . Activation ( name = ' res4b18 _ branch2b _ relu ' , data = scale4b18_branch2b , act_type = ' relu ' ) NEW_LINE res4b18_branch2c = mx . symbol . Convolution ( name = ' res4b18 _ branch2c ' , data = res4b18_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2c = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2c ' , data = res4b18_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b18_branch2c = bn4b18_branch2c NEW_LINE res4b18 = mx . symbol . broadcast_add ( name = ' res4b18' , * [ res4b17_relu , scale4b18_branch2c ] ) NEW_LINE res4b18_relu = mx . symbol . Activation ( name = ' res4b18 _ relu ' , data = res4b18 , act_type = ' relu ' ) NEW_LINE res4b19_branch2a = mx . symbol . Convolution ( name = ' res4b19 _ branch2a ' , data = res4b18_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2a = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2a ' , data = res4b19_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b19_branch2a = bn4b19_branch2a NEW_LINE res4b19_branch2a_relu = mx . symbol . Activation ( name = ' res4b19 _ branch2a _ relu ' , data = scale4b19_branch2a , act_type = ' relu ' ) NEW_LINE res4b19_branch2b = mx . symbol . Convolution ( name = ' res4b19 _ branch2b ' , data = res4b19_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2b = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2b ' , data = res4b19_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b19_branch2b = bn4b19_branch2b NEW_LINE res4b19_branch2b_relu = mx . symbol . Activation ( name = ' res4b19 _ branch2b _ relu ' , data = scale4b19_branch2b , act_type = ' relu ' ) NEW_LINE res4b19_branch2c = mx . symbol . Convolution ( name = ' res4b19 _ branch2c ' , data = res4b19_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2c = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2c ' , data = res4b19_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b19_branch2c = bn4b19_branch2c NEW_LINE res4b19 = mx . symbol . broadcast_add ( name = ' res4b19' , * [ res4b18_relu , scale4b19_branch2c ] ) NEW_LINE res4b19_relu = mx . symbol . Activation ( name = ' res4b19 _ relu ' , data = res4b19 , act_type = ' relu ' ) NEW_LINE res4b20_branch2a = mx . symbol . Convolution ( name = ' res4b20 _ branch2a ' , data = res4b19_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2a = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2a ' , data = res4b20_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b20_branch2a = bn4b20_branch2a NEW_LINE res4b20_branch2a_relu = mx . symbol . Activation ( name = ' res4b20 _ branch2a _ relu ' , data = scale4b20_branch2a , act_type = ' relu ' ) NEW_LINE res4b20_branch2b = mx . symbol . Convolution ( name = ' res4b20 _ branch2b ' , data = res4b20_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2b = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2b ' , data = res4b20_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b20_branch2b = bn4b20_branch2b NEW_LINE res4b20_branch2b_relu = mx . symbol . Activation ( name = ' res4b20 _ branch2b _ relu ' , data = scale4b20_branch2b , act_type = ' relu ' ) NEW_LINE res4b20_branch2c = mx . symbol . Convolution ( name = ' res4b20 _ branch2c ' , data = res4b20_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2c = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2c ' , data = res4b20_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b20_branch2c = bn4b20_branch2c NEW_LINE res4b20 = mx . symbol . broadcast_add ( name = ' res4b20' , * [ res4b19_relu , scale4b20_branch2c ] ) NEW_LINE res4b20_relu = mx . symbol . Activation ( name = ' res4b20 _ relu ' , data = res4b20 , act_type = ' relu ' ) NEW_LINE res4b21_branch2a = mx . symbol . Convolution ( name = ' res4b21 _ branch2a ' , data = res4b20_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2a = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2a ' , data = res4b21_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b21_branch2a = bn4b21_branch2a NEW_LINE res4b21_branch2a_relu = mx . symbol . Activation ( name = ' res4b21 _ branch2a _ relu ' , data = scale4b21_branch2a , act_type = ' relu ' ) NEW_LINE res4b21_branch2b = mx . symbol . Convolution ( name = ' res4b21 _ branch2b ' , data = res4b21_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2b = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2b ' , data = res4b21_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b21_branch2b = bn4b21_branch2b NEW_LINE res4b21_branch2b_relu = mx . symbol . Activation ( name = ' res4b21 _ branch2b _ relu ' , data = scale4b21_branch2b , act_type = ' relu ' ) NEW_LINE res4b21_branch2c = mx . symbol . Convolution ( name = ' res4b21 _ branch2c ' , data = res4b21_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2c = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2c ' , data = res4b21_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b21_branch2c = bn4b21_branch2c NEW_LINE res4b21 = mx . symbol . broadcast_add ( name = ' res4b21' , * [ res4b20_relu , scale4b21_branch2c ] ) NEW_LINE res4b21_relu = mx . symbol . Activation ( name = ' res4b21 _ relu ' , data = res4b21 , act_type = ' relu ' ) NEW_LINE res4b22_branch2a = mx . symbol . Convolution ( name = ' res4b22 _ branch2a ' , data = res4b21_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b22_branch2a = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2a ' , data = res4b22_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b22_branch2a = bn4b22_branch2a NEW_LINE res4b22_branch2a_relu = mx . symbol . Activation ( name = ' res4b22 _ branch2a _ relu ' , data = scale4b22_branch2a , act_type = ' relu ' ) NEW_LINE res4b22_branch2b = mx . symbol . Convolution ( name = ' res4b22 _ branch2b ' , data = res4b22_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b22_branch2b = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2b ' , data = res4b22_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b22_branch2b = bn4b22_branch2b NEW_LINE res4b22_branch2b_relu = mx . symbol . Activation ( name = ' res4b22 _ branch2b _ relu ' , data = scale4b22_branch2b , act_type = ' relu ' ) NEW_LINE res4b22_branch2c = mx . symbol . Convolution ( name = ' res4b22 _ branch2c ' , data = res4b22_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b22_branch2c = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2c ' , data = res4b22_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b22_branch2c = bn4b22_branch2c NEW_LINE res4b22 = mx . symbol . broadcast_add ( name = ' res4b22' , * [ res4b21_relu , scale4b22_branch2c ] ) NEW_LINE res4b22_relu = mx . symbol . Activation ( name = ' res4b22 _ relu ' , data = res4b22 , act_type = ' relu ' ) NEW_LINE return res4b22_relu NEW_LINE DEDENT\",), (\"def get_resnet_v1_conv5 ( self , conv_feat ) : NEW_LINE INDENT res5a_branch1 = mx . symbol . Convolution ( name = ' res5a _ branch1' , data = conv_feat , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5a_branch1 = mx . symbol . BatchNorm ( name = ' bn5a _ branch1' , data = res5a_branch1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5a_branch1 = bn5a_branch1 NEW_LINE res5a_branch2a = mx . symbol . Convolution ( name = ' res5a _ branch2a ' , data = conv_feat , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5a_branch2a = mx . symbol . BatchNorm ( name = ' bn5a _ branch2a ' , data = res5a_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5a_branch2a = bn5a_branch2a NEW_LINE res5a_branch2a_relu = mx . symbol . Activation ( name = ' res5a _ branch2a _ relu ' , data = scale5a_branch2a , act_type = ' relu ' ) NEW_LINE res5a_branch2b_offset = mx . symbol . Convolution ( name = ' res5a _ branch2b _ offset ' , data = res5a_branch2a_relu , num_filter = 72 , pad = ( 2 , 2 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = ( 2 , 2 ) , cudnn_off = True ) NEW_LINE res5a_branch2b = mx . contrib . symbol . DeformableConvolution ( name = ' res5a _ branch2b ' , data = res5a_branch2a_relu , offset = res5a_branch2b_offset , num_filter = 512 , pad = ( 2 , 2 ) , kernel = ( 3 , 3 ) , num_deformable_group = 4 , stride = ( 1 , 1 ) , dilate = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn5a_branch2b = mx . symbol . BatchNorm ( name = ' bn5a _ branch2b ' , data = res5a_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5a_branch2b = bn5a_branch2b NEW_LINE res5a_branch2b_relu = mx . symbol . Activation ( name = ' res5a _ branch2b _ relu ' , data = scale5a_branch2b , act_type = ' relu ' ) NEW_LINE res5a_branch2c = mx . symbol . Convolution ( name = ' res5a _ branch2c ' , data = res5a_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5a_branch2c = mx . symbol . BatchNorm ( name = ' bn5a _ branch2c ' , data = res5a_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5a_branch2c = bn5a_branch2c NEW_LINE res5a = mx . symbol . broadcast_add ( name = ' res5a ' , * [ scale5a_branch1 , scale5a_branch2c ] ) NEW_LINE res5a_relu = mx . symbol . Activation ( name = ' res5a _ relu ' , data = res5a , act_type = ' relu ' ) NEW_LINE res5b_branch2a = mx . symbol . Convolution ( name = ' res5b _ branch2a ' , data = res5a_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5b_branch2a = mx . symbol . BatchNorm ( name = ' bn5b _ branch2a ' , data = res5b_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5b_branch2a = bn5b_branch2a NEW_LINE res5b_branch2a_relu = mx . symbol . Activation ( name = ' res5b _ branch2a _ relu ' , data = scale5b_branch2a , act_type = ' relu ' ) NEW_LINE res5b_branch2b_offset = mx . symbol . Convolution ( name = ' res5b _ branch2b _ offset ' , data = res5b_branch2a_relu , num_filter = 72 , pad = ( 2 , 2 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = ( 2 , 2 ) , cudnn_off = True ) NEW_LINE res5b_branch2b = mx . contrib . symbol . DeformableConvolution ( name = ' res5b _ branch2b ' , data = res5b_branch2a_relu , offset = res5b_branch2b_offset , num_filter = 512 , pad = ( 2 , 2 ) , kernel = ( 3 , 3 ) , num_deformable_group = 4 , stride = ( 1 , 1 ) , dilate = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn5b_branch2b = mx . symbol . BatchNorm ( name = ' bn5b _ branch2b ' , data = res5b_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5b_branch2b = bn5b_branch2b NEW_LINE res5b_branch2b_relu = mx . symbol . Activation ( name = ' res5b _ branch2b _ relu ' , data = scale5b_branch2b , act_type = ' relu ' ) NEW_LINE res5b_branch2c = mx . symbol . Convolution ( name = ' res5b _ branch2c ' , data = res5b_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5b_branch2c = mx . symbol . BatchNorm ( name = ' bn5b _ branch2c ' , data = res5b_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5b_branch2c = bn5b_branch2c NEW_LINE res5b = mx . symbol . broadcast_add ( name = ' res5b ' , * [ res5a_relu , scale5b_branch2c ] ) NEW_LINE res5b_relu = mx . symbol . Activation ( name = ' res5b _ relu ' , data = res5b , act_type = ' relu ' ) NEW_LINE res5c_branch2a = mx . symbol . Convolution ( name = ' res5c _ branch2a ' , data = res5b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5c_branch2a = mx . symbol . BatchNorm ( name = ' bn5c _ branch2a ' , data = res5c_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5c_branch2a = bn5c_branch2a NEW_LINE res5c_branch2a_relu = mx . symbol . Activation ( name = ' res5c _ branch2a _ relu ' , data = scale5c_branch2a , act_type = ' relu ' ) NEW_LINE res5c_branch2b_offset = mx . symbol . Convolution ( name = ' res5c _ branch2b _ offset ' , data = res5c_branch2a_relu , num_filter = 72 , pad = ( 2 , 2 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = ( 2 , 2 ) , cudnn_off = True ) NEW_LINE res5c_branch2b = mx . contrib . symbol . DeformableConvolution ( name = ' res5c _ branch2b ' , data = res5c_branch2a_relu , offset = res5c_branch2b_offset , num_filter = 512 , pad = ( 2 , 2 ) , kernel = ( 3 , 3 ) , num_deformable_group = 4 , stride = ( 1 , 1 ) , dilate = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn5c_branch2b = mx . symbol . BatchNorm ( name = ' bn5c _ branch2b ' , data = res5c_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5c_branch2b = bn5c_branch2b NEW_LINE res5c_branch2b_relu = mx . symbol . Activation ( name = ' res5c _ branch2b _ relu ' , data = scale5c_branch2b , act_type = ' relu ' ) NEW_LINE res5c_branch2c = mx . symbol . Convolution ( name = ' res5c _ branch2c ' , data = res5c_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5c_branch2c = mx . symbol . BatchNorm ( name = ' bn5c _ branch2c ' , data = res5c_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5c_branch2c = bn5c_branch2c NEW_LINE res5c = mx . symbol . broadcast_add ( name = ' res5c ' , * [ res5b_relu , scale5c_branch2c ] ) NEW_LINE res5c_relu = mx . symbol . Activation ( name = ' res5c _ relu ' , data = res5c , act_type = ' relu ' ) NEW_LINE return res5c_relu NEW_LINE DEDENT\",), ('def get_rpn ( self , conv_feat , num_anchors ) : NEW_LINE INDENT rpn_conv = mx . sym . Convolution ( data = conv_feat , kernel = ( 3 , 3 ) , pad = ( 1 , 1 ) , num_filter = 512 , name = \" rpn _ conv _ 3x3\" ) NEW_LINE rpn_relu = mx . sym . Activation ( data = rpn_conv , act_type = \" relu \" , name = \" rpn _ relu \" ) NEW_LINE rpn_cls_score = mx . sym . Convolution ( data = rpn_relu , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , num_filter = 2 * num_anchors , name = \" rpn _ cls _ score \" ) NEW_LINE rpn_bbox_pred = mx . sym . Convolution ( data = rpn_relu , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , num_filter = 4 * num_anchors , name = \" rpn _ bbox _ pred \" ) NEW_LINE return rpn_cls_score , rpn_bbox_pred NEW_LINE DEDENT',), ('def get_symbol_rpn ( self , cfg , is_train = True ) : NEW_LINE INDENT num_anchors = cfg . network . NUM_ANCHORS NEW_LINE if is_train : NEW_LINE INDENT data = mx . sym . Variable ( name = \" data \" ) NEW_LINE rpn_label = mx . sym . Variable ( name = \\' label \\' ) NEW_LINE rpn_bbox_target = mx . sym . Variable ( name = \\' bbox _ target \\' ) NEW_LINE rpn_bbox_weight = mx . sym . Variable ( name = \\' bbox _ weight \\' ) NEW_LINE DEDENT else : NEW_LINE INDENT data = mx . sym . Variable ( name = \" data \" ) NEW_LINE im_info = mx . sym . Variable ( name = \" im _ info \" ) NEW_LINE DEDENT conv_feat = self . get_resnet_v1_conv4 ( data ) NEW_LINE rpn_cls_score , rpn_bbox_pred = self . get_rpn ( conv_feat , num_anchors ) NEW_LINE if is_train : NEW_LINE INDENT rpn_cls_score_reshape = mx . sym . Reshape ( data = rpn_cls_score , shape = ( 0 , 2 , - 1 , 0 ) , name = \" rpn _ cls _ score _ reshape \" ) NEW_LINE rpn_cls_prob = mx . sym . SoftmaxOutput ( data = rpn_cls_score_reshape , label = rpn_label , multi_output = True , normalization = \\' valid \\' , use_ignore = True , ignore_label = - 1 , name = \" rpn _ cls _ prob \" , grad_scale = 1.0 ) NEW_LINE rpn_bbox_loss_ = rpn_bbox_weight * mx . sym . smooth_l1 ( name = \\' rpn _ bbox _ loss _ \\' , scalar = 3.0 , data = ( rpn_bbox_pred - rpn_bbox_target ) ) NEW_LINE rpn_bbox_loss = mx . sym . MakeLoss ( name = \\' rpn _ bbox _ loss \\' , data = rpn_bbox_loss_ , grad_scale = 1.0 / cfg . TRAIN . RPN_BATCH_SIZE ) NEW_LINE group = mx . symbol . Group ( [ rpn_cls_prob , rpn_bbox_loss ] ) NEW_LINE DEDENT else : NEW_LINE INDENT rpn_cls_score_reshape = mx . sym . Reshape ( data = rpn_cls_score , shape = ( 0 , 2 , - 1 , 0 ) , name = \" rpn _ cls _ score _ reshape \" ) NEW_LINE rpn_cls_prob = mx . sym . SoftmaxActivation ( data = rpn_cls_score_reshape , mode = \" channel \" , name = \" rpn _ cls _ prob \" ) NEW_LINE rpn_cls_prob_reshape = mx . sym . Reshape ( data = rpn_cls_prob , shape = ( 0 , 2 * num_anchors , - 1 , 0 ) , name = \\' rpn _ cls _ prob _ reshape \\' ) NEW_LINE if cfg . TEST . CXX_PROPOSAL : NEW_LINE INDENT rois , score = mx . contrib . sym . Proposal ( cls_prob = rpn_cls_prob_reshape , bbox_pred = rpn_bbox_pred , im_info = im_info , name = \\' rois \\' , output_score = True , feature_stride = cfg . network . RPN_FEAT_STRIDE , scales = tuple ( cfg . network . ANCHOR_SCALES ) , ratios = tuple ( cfg . network . ANCHOR_RATIOS ) , rpn_pre_nms_top_n = cfg . TEST . RPN_PRE_NMS_TOP_N , rpn_post_nms_top_n = cfg . TEST . RPN_POST_NMS_TOP_N , threshold = cfg . TEST . RPN_NMS_THRESH , rpn_min_size = cfg . TEST . RPN_MIN_SIZE ) NEW_LINE DEDENT else : NEW_LINE INDENT rois , score = mx . sym . Custom ( cls_prob = rpn_cls_prob_reshape , bbox_pred = rpn_bbox_pred , im_info = im_info , name = \\' rois \\' , output_score = True , op_type = \\' proposal \\' , feat_stride = cfg . network . RPN_FEAT_STRIDE , scales = tuple ( cfg . network . ANCHOR_SCALES ) , ratios = tuple ( cfg . network . ANCHOR_RATIOS ) , rpn_pre_nms_top_n = cfg . TEST . RPN_PRE_NMS_TOP_N , rpn_post_nms_top_n = cfg . TEST . RPN_POST_NMS_TOP_N , threshold = cfg . TEST . RPN_NMS_THRESH , rpn_min_size = cfg . TEST . RPN_MIN_SIZE ) NEW_LINE group = mx . symbol . Group ( [ rois , score ] ) NEW_LINE DEDENT DEDENT self . sym = group NEW_LINE return group NEW_LINE DEDENT',), ('def get_symbol_rcnn ( self , cfg , is_train = True ) : NEW_LINE INDENT num_classes = cfg . dataset . NUM_CLASSES NEW_LINE num_reg_classes = ( 2 if cfg . CLASS_AGNOSTIC else num_classes ) NEW_LINE if is_train : NEW_LINE INDENT data = mx . symbol . Variable ( name = \" data \" ) NEW_LINE rois = mx . symbol . Variable ( name = \\' rois \\' ) NEW_LINE label = mx . symbol . Variable ( name = \\' label \\' ) NEW_LINE bbox_target = mx . symbol . Variable ( name = \\' bbox _ target \\' ) NEW_LINE bbox_weight = mx . symbol . Variable ( name = \\' bbox _ weight \\' ) NEW_LINE rois = mx . symbol . Reshape ( data = rois , shape = ( - 1 , 5 ) , name = \\' rois _ reshape \\' ) NEW_LINE label = mx . symbol . Reshape ( data = label , shape = ( - 1 , ) , name = \\' label _ reshape \\' ) NEW_LINE bbox_target = mx . symbol . Reshape ( data = bbox_target , shape = ( - 1 , 4 * num_classes ) , name = \\' bbox _ target _ reshape \\' ) NEW_LINE bbox_weight = mx . symbol . Reshape ( data = bbox_weight , shape = ( - 1 , 4 * num_classes ) , name = \\' bbox _ weight _ reshape \\' ) NEW_LINE DEDENT else : NEW_LINE INDENT data = mx . sym . Variable ( name = \" data \" ) NEW_LINE rois = mx . symbol . Variable ( name = \\' rois \\' ) NEW_LINE rois = mx . symbol . Reshape ( data = rois , shape = ( - 1 , 5 ) , name = \\' rois _ reshape \\' ) NEW_LINE DEDENT conv_feat = self . get_resnet_v1_conv4 ( data ) NEW_LINE relu1 = self . get_resnet_v1_conv5 ( conv_feat ) NEW_LINE conv_new_1 = mx . sym . Convolution ( data = relu1 , kernel = ( 1 , 1 ) , num_filter = 256 , name = \" conv _ new _ 1\" ) NEW_LINE conv_new_1_relu = mx . sym . Activation ( data = conv_new_1 , act_type = \\' relu \\' , name = \\' conv _ new _ 1 _ relu \\' ) NEW_LINE offset_t = mx . contrib . sym . DeformablePSROIPooling ( name = \\' offset _ t \\' , data = conv_new_1_relu , rois = rois , group_size = 1 , pooled_size = 7 , sample_per_part = 4 , no_trans = True , part_size = 7 , output_dim = 256 , spatial_scale = 0.0625 ) NEW_LINE offset = mx . sym . FullyConnected ( name = \\' offset \\' , data = offset_t , num_hidden = 7 * 7 * 2 , lr_mult = 0.01 ) NEW_LINE offset_reshape = mx . sym . Reshape ( data = offset , shape = ( - 1 , 2 , 7 , 7 ) , name = \" offset _ reshape \" ) NEW_LINE deformable_roi_pool = mx . contrib . sym . DeformablePSROIPooling ( name = \\' deformable _ roi _ pool \\' , data = conv_new_1_relu , rois = rois , trans = offset_reshape , group_size = 1 , pooled_size = 7 , sample_per_part = 4 , no_trans = False , part_size = 7 , output_dim = 256 , spatial_scale = 0.0625 , trans_std = 0.1 ) NEW_LINE fc_new_1 = mx . sym . FullyConnected ( name = \\' fc _ new _ 1\\' , data = deformable_roi_pool , num_hidden = 1024 ) NEW_LINE fc_new_1_relu = mx . sym . Activation ( data = fc_new_1 , act_type = \\' relu \\' , name = \\' fc _ new _ 1 _ relu \\' ) NEW_LINE fc_new_2 = mx . sym . FullyConnected ( name = \\' fc _ new _ 2\\' , data = fc_new_1_relu , num_hidden = 1024 ) NEW_LINE fc_new_2_relu = mx . sym . Activation ( data = fc_new_2 , act_type = \\' relu \\' , name = \\' fc _ new _ 2 _ relu \\' ) NEW_LINE cls_score = mx . sym . FullyConnected ( name = \\' cls _ score \\' , data = fc_new_2_relu , num_hidden = num_classes ) NEW_LINE bbox_pred = mx . sym . FullyConnected ( name = \\' bbox _ pred \\' , data = fc_new_2_relu , num_hidden = num_reg_classes * 4 ) NEW_LINE if is_train : NEW_LINE INDENT if cfg . TRAIN . ENABLE_OHEM : NEW_LINE INDENT labels_ohem , bbox_weights_ohem = mx . sym . Custom ( op_type = \\' BoxAnnotatorOHEM \\' , num_classes = num_classes , num_reg_classes = num_reg_classes , roi_per_img = cfg . TRAIN . BATCH_ROIS_OHEM , cls_score = cls_score , bbox_pred = bbox_pred , labels = label , bbox_targets = bbox_target , bbox_weights = bbox_weight ) NEW_LINE cls_prob = mx . sym . SoftmaxOutput ( name = \\' cls _ prob \\' , data = cls_score , label = labels_ohem , normalization = \\' valid \\' , use_ignore = True , ignore_label = - 1 , grad_scale = 1.0 ) NEW_LINE bbox_loss_ = bbox_weights_ohem * mx . sym . smooth_l1 ( name = \\' bbox _ loss _ \\' , scalar = 1.0 , data = ( bbox_pred - bbox_target ) ) NEW_LINE bbox_loss = mx . sym . MakeLoss ( name = \\' bbox _ loss \\' , data = bbox_loss_ , grad_scale = 1.0 / cfg . TRAIN . BATCH_ROIS_OHEM ) NEW_LINE DEDENT else : NEW_LINE INDENT cls_prob = mx . sym . SoftmaxOutput ( name = \\' cls _ prob \\' , data = cls_score , label = label , normalization = \\' valid \\' , grad_scale = 1.0 ) NEW_LINE bbox_loss_ = bbox_weight * mx . sym . smooth_l1 ( name = \\' bbox _ loss _ \\' , scalar = 1.0 , data = ( bbox_pred - bbox_target ) ) NEW_LINE bbox_loss = mx . sym . MakeLoss ( name = \\' bbox _ loss \\' , data = bbox_loss_ , grad_scale = 1.0 / cfg . TRAIN . BATCH_ROIS ) NEW_LINE DEDENT cls_prob = mx . sym . Reshape ( data = cls_prob , shape = ( cfg . TRAIN . BATCH_IMAGES , - 1 , num_classes ) , name = \\' cls _ prob _ reshape \\' ) NEW_LINE bbox_loss = mx . sym . Reshape ( data = bbox_loss , shape = ( cfg . TRAIN . BATCH_IMAGES , - 1 , 4 * num_reg_classes ) , name = \\' bbox _ loss _ reshape \\' ) NEW_LINE group = mx . sym . Group ( [ cls_prob , bbox_loss ] ) NEW_LINE DEDENT else : NEW_LINE INDENT cls_prob = mx . sym . SoftmaxActivation ( name = \\' cls _ prob \\' , data = cls_score ) NEW_LINE cls_prob = mx . sym . Reshape ( data = cls_prob , shape = ( cfg . TEST . BATCH_IMAGES , - 1 , num_classes ) , name = \\' cls _ prob _ reshape \\' ) NEW_LINE bbox_pred = mx . sym . Reshape ( data = bbox_pred , shape = ( cfg . TEST . BATCH_IMAGES , - 1 , 4 * num_reg_classes ) , name = \\' bbox _ pred _ reshape \\' ) NEW_LINE group = mx . sym . Group ( [ cls_prob , bbox_pred ] ) NEW_LINE DEDENT self . sym = group NEW_LINE return group NEW_LINE DEDENT',), (\"def init_weight ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT arg_params [ ' rpn _ conv _ 3x3 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' rpn _ conv _ 3x3 _ weight ' ] ) NEW_LINE arg_params [ ' rpn _ conv _ 3x3 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' rpn _ conv _ 3x3 _ bias ' ] ) NEW_LINE arg_params [ ' rpn _ cls _ score _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' rpn _ cls _ score _ weight ' ] ) NEW_LINE arg_params [ ' rpn _ cls _ score _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' rpn _ cls _ score _ bias ' ] ) NEW_LINE arg_params [ ' rpn _ bbox _ pred _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' rpn _ bbox _ pred _ weight ' ] ) NEW_LINE arg_params [ ' rpn _ bbox _ pred _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' rpn _ bbox _ pred _ bias ' ] ) NEW_LINE arg_params [ ' res5a _ branch2b _ offset _ weight ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' res5a _ branch2b _ offset _ weight ' ] ) NEW_LINE arg_params [ ' res5a _ branch2b _ offset _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' res5a _ branch2b _ offset _ bias ' ] ) NEW_LINE arg_params [ ' res5b _ branch2b _ offset _ weight ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' res5b _ branch2b _ offset _ weight ' ] ) NEW_LINE arg_params [ ' res5b _ branch2b _ offset _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' res5b _ branch2b _ offset _ bias ' ] ) NEW_LINE arg_params [ ' res5c _ branch2b _ offset _ weight ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' res5c _ branch2b _ offset _ weight ' ] ) NEW_LINE arg_params [ ' res5c _ branch2b _ offset _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' res5c _ branch2b _ offset _ bias ' ] ) NEW_LINE arg_params [ ' conv _ new _ 1 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' conv _ new _ 1 _ weight ' ] ) NEW_LINE arg_params [ ' conv _ new _ 1 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' conv _ new _ 1 _ bias ' ] ) NEW_LINE arg_params [ ' offset _ weight ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' offset _ weight ' ] ) NEW_LINE arg_params [ ' offset _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' offset _ bias ' ] ) NEW_LINE arg_params [ ' fc _ new _ 1 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fc _ new _ 1 _ weight ' ] ) NEW_LINE arg_params [ ' fc _ new _ 1 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fc _ new _ 1 _ bias ' ] ) NEW_LINE arg_params [ ' fc _ new _ 2 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fc _ new _ 2 _ weight ' ] ) NEW_LINE arg_params [ ' fc _ new _ 2 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fc _ new _ 2 _ bias ' ] ) NEW_LINE arg_params [ ' cls _ score _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' cls _ score _ weight ' ] ) NEW_LINE arg_params [ ' cls _ score _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' cls _ score _ bias ' ] ) NEW_LINE arg_params [ ' bbox _ pred _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' bbox _ pred _ weight ' ] ) NEW_LINE arg_params [ ' bbox _ pred _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' bbox _ pred _ bias ' ] ) NEW_LINE DEDENT\",), (\"def init_weight_rpn ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT arg_params [ ' rpn _ conv _ 3x3 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' rpn _ conv _ 3x3 _ weight ' ] ) NEW_LINE arg_params [ ' rpn _ conv _ 3x3 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' rpn _ conv _ 3x3 _ bias ' ] ) NEW_LINE arg_params [ ' rpn _ cls _ score _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' rpn _ cls _ score _ weight ' ] ) NEW_LINE arg_params [ ' rpn _ cls _ score _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' rpn _ cls _ score _ bias ' ] ) NEW_LINE arg_params [ ' rpn _ bbox _ pred _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' rpn _ bbox _ pred _ weight ' ] ) NEW_LINE arg_params [ ' rpn _ bbox _ pred _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' rpn _ bbox _ pred _ bias ' ] ) NEW_LINE DEDENT\",), (\"def init_weight_rcnn ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT arg_params [ ' res5a _ branch2b _ offset _ weight ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' res5a _ branch2b _ offset _ weight ' ] ) NEW_LINE arg_params [ ' res5a _ branch2b _ offset _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' res5a _ branch2b _ offset _ bias ' ] ) NEW_LINE arg_params [ ' res5b _ branch2b _ offset _ weight ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' res5b _ branch2b _ offset _ weight ' ] ) NEW_LINE arg_params [ ' res5b _ branch2b _ offset _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' res5b _ branch2b _ offset _ bias ' ] ) NEW_LINE arg_params [ ' res5c _ branch2b _ offset _ weight ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' res5c _ branch2b _ offset _ weight ' ] ) NEW_LINE arg_params [ ' res5c _ branch2b _ offset _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' res5c _ branch2b _ offset _ bias ' ] ) NEW_LINE arg_params [ ' conv _ new _ 1 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' conv _ new _ 1 _ weight ' ] ) NEW_LINE arg_params [ ' conv _ new _ 1 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' conv _ new _ 1 _ weight ' ] ) NEW_LINE arg_params [ ' conv _ new _ 1 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' conv _ new _ 1 _ bias ' ] ) NEW_LINE arg_params [ ' offset _ weight ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' offset _ weight ' ] ) NEW_LINE arg_params [ ' offset _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' offset _ bias ' ] ) NEW_LINE arg_params [ ' fc _ new _ 1 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fc _ new _ 1 _ weight ' ] ) NEW_LINE arg_params [ ' fc _ new _ 1 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fc _ new _ 1 _ bias ' ] ) NEW_LINE arg_params [ ' fc _ new _ 2 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fc _ new _ 2 _ weight ' ] ) NEW_LINE arg_params [ ' fc _ new _ 2 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fc _ new _ 2 _ bias ' ] ) NEW_LINE arg_params [ ' cls _ score _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' cls _ score _ weight ' ] ) NEW_LINE arg_params [ ' cls _ score _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' cls _ score _ bias ' ] ) NEW_LINE arg_params [ ' bbox _ pred _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' bbox _ pred _ weight ' ] ) NEW_LINE arg_params [ ' bbox _ pred _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' bbox _ pred _ bias ' ] ) NEW_LINE DEDENT\",), (\"def __init__ ( self ) : NEW_LINE INDENT self . eps = 1e-5 NEW_LINE self . use_global_stats = True NEW_LINE self . workspace = 512 NEW_LINE self . units = ( 3 , 4 , 23 , 3 ) NEW_LINE self . filter_list = [ 256 , 512 , 1024 , 2048 ] NEW_LINE self . shared_param_list = [ ' conv _ new _ 1' , ' conv _ new _ 2' , ' conv _ new _ 3' , ' conv _ new _ 4' ] NEW_LINE self . shared_param_dict = { } NEW_LINE for name in self . shared_param_list : NEW_LINE INDENT self . shared_param_dict [ name + ' _ weight ' ] = mx . sym . Variable ( name + ' _ weight ' ) NEW_LINE self . shared_param_dict [ name + ' _ bias ' ] = mx . sym . Variable ( name + ' _ bias ' ) NEW_LINE DEDENT DEDENT\",), (\"def get_resnet_v1_conv4 ( self , data ) : NEW_LINE INDENT conv1 = mx . symbol . Convolution ( name = ' conv1' , data = data , num_filter = 64 , pad = ( 3 , 3 ) , kernel = ( 7 , 7 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn_conv1 = mx . symbol . BatchNorm ( name = ' bn _ conv1' , data = conv1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale_conv1 = bn_conv1 NEW_LINE conv1_relu = mx . symbol . Activation ( name = ' conv1 _ relu ' , data = scale_conv1 , act_type = ' relu ' ) NEW_LINE pool1 = mx . symbol . Pooling ( name = ' pool1' , data = conv1_relu , pooling_convention = ' full ' , pad = ( 0 , 0 ) , kernel = ( 3 , 3 ) , stride = ( 2 , 2 ) , pool_type = ' max ' ) NEW_LINE res2a_branch1 = mx . symbol . Convolution ( name = ' res2a _ branch1' , data = pool1 , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch1 = mx . symbol . BatchNorm ( name = ' bn2a _ branch1' , data = res2a_branch1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2a_branch1 = bn2a_branch1 NEW_LINE res2a_branch2a = mx . symbol . Convolution ( name = ' res2a _ branch2a ' , data = pool1 , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2a = mx . symbol . BatchNorm ( name = ' bn2a _ branch2a ' , data = res2a_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2a_branch2a = bn2a_branch2a NEW_LINE res2a_branch2a_relu = mx . symbol . Activation ( name = ' res2a _ branch2a _ relu ' , data = scale2a_branch2a , act_type = ' relu ' ) NEW_LINE res2a_branch2b = mx . symbol . Convolution ( name = ' res2a _ branch2b ' , data = res2a_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2b = mx . symbol . BatchNorm ( name = ' bn2a _ branch2b ' , data = res2a_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2a_branch2b = bn2a_branch2b NEW_LINE res2a_branch2b_relu = mx . symbol . Activation ( name = ' res2a _ branch2b _ relu ' , data = scale2a_branch2b , act_type = ' relu ' ) NEW_LINE res2a_branch2c = mx . symbol . Convolution ( name = ' res2a _ branch2c ' , data = res2a_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2c = mx . symbol . BatchNorm ( name = ' bn2a _ branch2c ' , data = res2a_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2a_branch2c = bn2a_branch2c NEW_LINE res2a = mx . symbol . broadcast_add ( name = ' res2a ' , * [ scale2a_branch1 , scale2a_branch2c ] ) NEW_LINE res2a_relu = mx . symbol . Activation ( name = ' res2a _ relu ' , data = res2a , act_type = ' relu ' ) NEW_LINE res2b_branch2a = mx . symbol . Convolution ( name = ' res2b _ branch2a ' , data = res2a_relu , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2a = mx . symbol . BatchNorm ( name = ' bn2b _ branch2a ' , data = res2b_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2b_branch2a = bn2b_branch2a NEW_LINE res2b_branch2a_relu = mx . symbol . Activation ( name = ' res2b _ branch2a _ relu ' , data = scale2b_branch2a , act_type = ' relu ' ) NEW_LINE res2b_branch2b = mx . symbol . Convolution ( name = ' res2b _ branch2b ' , data = res2b_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2b = mx . symbol . BatchNorm ( name = ' bn2b _ branch2b ' , data = res2b_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2b_branch2b = bn2b_branch2b NEW_LINE res2b_branch2b_relu = mx . symbol . Activation ( name = ' res2b _ branch2b _ relu ' , data = scale2b_branch2b , act_type = ' relu ' ) NEW_LINE res2b_branch2c = mx . symbol . Convolution ( name = ' res2b _ branch2c ' , data = res2b_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2c = mx . symbol . BatchNorm ( name = ' bn2b _ branch2c ' , data = res2b_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2b_branch2c = bn2b_branch2c NEW_LINE res2b = mx . symbol . broadcast_add ( name = ' res2b ' , * [ res2a_relu , scale2b_branch2c ] ) NEW_LINE res2b_relu = mx . symbol . Activation ( name = ' res2b _ relu ' , data = res2b , act_type = ' relu ' ) NEW_LINE res2c_branch2a = mx . symbol . Convolution ( name = ' res2c _ branch2a ' , data = res2b_relu , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2a = mx . symbol . BatchNorm ( name = ' bn2c _ branch2a ' , data = res2c_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2c_branch2a = bn2c_branch2a NEW_LINE res2c_branch2a_relu = mx . symbol . Activation ( name = ' res2c _ branch2a _ relu ' , data = scale2c_branch2a , act_type = ' relu ' ) NEW_LINE res2c_branch2b = mx . symbol . Convolution ( name = ' res2c _ branch2b ' , data = res2c_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2b = mx . symbol . BatchNorm ( name = ' bn2c _ branch2b ' , data = res2c_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2c_branch2b = bn2c_branch2b NEW_LINE res2c_branch2b_relu = mx . symbol . Activation ( name = ' res2c _ branch2b _ relu ' , data = scale2c_branch2b , act_type = ' relu ' ) NEW_LINE res2c_branch2c = mx . symbol . Convolution ( name = ' res2c _ branch2c ' , data = res2c_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2c = mx . symbol . BatchNorm ( name = ' bn2c _ branch2c ' , data = res2c_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2c_branch2c = bn2c_branch2c NEW_LINE res2c = mx . symbol . broadcast_add ( name = ' res2c ' , * [ res2b_relu , scale2c_branch2c ] ) NEW_LINE res2c_relu = mx . symbol . Activation ( name = ' res2c _ relu ' , data = res2c , act_type = ' relu ' ) NEW_LINE res3a_branch1 = mx . symbol . Convolution ( name = ' res3a _ branch1' , data = res2c_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn3a_branch1 = mx . symbol . BatchNorm ( name = ' bn3a _ branch1' , data = res3a_branch1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3a_branch1 = bn3a_branch1 NEW_LINE res3a_branch2a = mx . symbol . Convolution ( name = ' res3a _ branch2a ' , data = res2c_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn3a_branch2a = mx . symbol . BatchNorm ( name = ' bn3a _ branch2a ' , data = res3a_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3a_branch2a = bn3a_branch2a NEW_LINE res3a_branch2a_relu = mx . symbol . Activation ( name = ' res3a _ branch2a _ relu ' , data = scale3a_branch2a , act_type = ' relu ' ) NEW_LINE res3a_branch2b = mx . symbol . Convolution ( name = ' res3a _ branch2b ' , data = res3a_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3a_branch2b = mx . symbol . BatchNorm ( name = ' bn3a _ branch2b ' , data = res3a_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3a_branch2b = bn3a_branch2b NEW_LINE res3a_branch2b_relu = mx . symbol . Activation ( name = ' res3a _ branch2b _ relu ' , data = scale3a_branch2b , act_type = ' relu ' ) NEW_LINE res3a_branch2c = mx . symbol . Convolution ( name = ' res3a _ branch2c ' , data = res3a_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3a_branch2c = mx . symbol . BatchNorm ( name = ' bn3a _ branch2c ' , data = res3a_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3a_branch2c = bn3a_branch2c NEW_LINE res3a = mx . symbol . broadcast_add ( name = ' res3a ' , * [ scale3a_branch1 , scale3a_branch2c ] ) NEW_LINE res3a_relu = mx . symbol . Activation ( name = ' res3a _ relu ' , data = res3a , act_type = ' relu ' ) NEW_LINE res3b1_branch2a = mx . symbol . Convolution ( name = ' res3b1 _ branch2a ' , data = res3a_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2a = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2a ' , data = res3b1_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b1_branch2a = bn3b1_branch2a NEW_LINE res3b1_branch2a_relu = mx . symbol . Activation ( name = ' res3b1 _ branch2a _ relu ' , data = scale3b1_branch2a , act_type = ' relu ' ) NEW_LINE res3b1_branch2b = mx . symbol . Convolution ( name = ' res3b1 _ branch2b ' , data = res3b1_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2b = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2b ' , data = res3b1_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b1_branch2b = bn3b1_branch2b NEW_LINE res3b1_branch2b_relu = mx . symbol . Activation ( name = ' res3b1 _ branch2b _ relu ' , data = scale3b1_branch2b , act_type = ' relu ' ) NEW_LINE res3b1_branch2c = mx . symbol . Convolution ( name = ' res3b1 _ branch2c ' , data = res3b1_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2c = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2c ' , data = res3b1_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b1_branch2c = bn3b1_branch2c NEW_LINE res3b1 = mx . symbol . broadcast_add ( name = ' res3b1' , * [ res3a_relu , scale3b1_branch2c ] ) NEW_LINE res3b1_relu = mx . symbol . Activation ( name = ' res3b1 _ relu ' , data = res3b1 , act_type = ' relu ' ) NEW_LINE res3b2_branch2a = mx . symbol . Convolution ( name = ' res3b2 _ branch2a ' , data = res3b1_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2a = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2a ' , data = res3b2_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b2_branch2a = bn3b2_branch2a NEW_LINE res3b2_branch2a_relu = mx . symbol . Activation ( name = ' res3b2 _ branch2a _ relu ' , data = scale3b2_branch2a , act_type = ' relu ' ) NEW_LINE res3b2_branch2b = mx . symbol . Convolution ( name = ' res3b2 _ branch2b ' , data = res3b2_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2b = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2b ' , data = res3b2_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b2_branch2b = bn3b2_branch2b NEW_LINE res3b2_branch2b_relu = mx . symbol . Activation ( name = ' res3b2 _ branch2b _ relu ' , data = scale3b2_branch2b , act_type = ' relu ' ) NEW_LINE res3b2_branch2c = mx . symbol . Convolution ( name = ' res3b2 _ branch2c ' , data = res3b2_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2c = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2c ' , data = res3b2_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b2_branch2c = bn3b2_branch2c NEW_LINE res3b2 = mx . symbol . broadcast_add ( name = ' res3b2' , * [ res3b1_relu , scale3b2_branch2c ] ) NEW_LINE res3b2_relu = mx . symbol . Activation ( name = ' res3b2 _ relu ' , data = res3b2 , act_type = ' relu ' ) NEW_LINE res3b3_branch2a = mx . symbol . Convolution ( name = ' res3b3 _ branch2a ' , data = res3b2_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b3_branch2a = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2a ' , data = res3b3_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b3_branch2a = bn3b3_branch2a NEW_LINE res3b3_branch2a_relu = mx . symbol . Activation ( name = ' res3b3 _ branch2a _ relu ' , data = scale3b3_branch2a , act_type = ' relu ' ) NEW_LINE res3b3_branch2b = mx . symbol . Convolution ( name = ' res3b3 _ branch2b ' , data = res3b3_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b3_branch2b = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2b ' , data = res3b3_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b3_branch2b = bn3b3_branch2b NEW_LINE res3b3_branch2b_relu = mx . symbol . Activation ( name = ' res3b3 _ branch2b _ relu ' , data = scale3b3_branch2b , act_type = ' relu ' ) NEW_LINE res3b3_branch2c = mx . symbol . Convolution ( name = ' res3b3 _ branch2c ' , data = res3b3_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b3_branch2c = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2c ' , data = res3b3_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b3_branch2c = bn3b3_branch2c NEW_LINE res3b3 = mx . symbol . broadcast_add ( name = ' res3b3' , * [ res3b2_relu , scale3b3_branch2c ] ) NEW_LINE res3b3_relu = mx . symbol . Activation ( name = ' res3b3 _ relu ' , data = res3b3 , act_type = ' relu ' ) NEW_LINE res4a_branch1 = mx . symbol . Convolution ( name = ' res4a _ branch1' , data = res3b3_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn4a_branch1 = mx . symbol . BatchNorm ( name = ' bn4a _ branch1' , data = res4a_branch1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4a_branch1 = bn4a_branch1 NEW_LINE res4a_branch2a = mx . symbol . Convolution ( name = ' res4a _ branch2a ' , data = res3b3_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn4a_branch2a = mx . symbol . BatchNorm ( name = ' bn4a _ branch2a ' , data = res4a_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4a_branch2a = bn4a_branch2a NEW_LINE res4a_branch2a_relu = mx . symbol . Activation ( name = ' res4a _ branch2a _ relu ' , data = scale4a_branch2a , act_type = ' relu ' ) NEW_LINE res4a_branch2b = mx . symbol . Convolution ( name = ' res4a _ branch2b ' , data = res4a_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4a_branch2b = mx . symbol . BatchNorm ( name = ' bn4a _ branch2b ' , data = res4a_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4a_branch2b = bn4a_branch2b NEW_LINE res4a_branch2b_relu = mx . symbol . Activation ( name = ' res4a _ branch2b _ relu ' , data = scale4a_branch2b , act_type = ' relu ' ) NEW_LINE res4a_branch2c = mx . symbol . Convolution ( name = ' res4a _ branch2c ' , data = res4a_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4a_branch2c = mx . symbol . BatchNorm ( name = ' bn4a _ branch2c ' , data = res4a_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4a_branch2c = bn4a_branch2c NEW_LINE res4a = mx . symbol . broadcast_add ( name = ' res4a ' , * [ scale4a_branch1 , scale4a_branch2c ] ) NEW_LINE res4a_relu = mx . symbol . Activation ( name = ' res4a _ relu ' , data = res4a , act_type = ' relu ' ) NEW_LINE res4b1_branch2a = mx . symbol . Convolution ( name = ' res4b1 _ branch2a ' , data = res4a_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2a = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2a ' , data = res4b1_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b1_branch2a = bn4b1_branch2a NEW_LINE res4b1_branch2a_relu = mx . symbol . Activation ( name = ' res4b1 _ branch2a _ relu ' , data = scale4b1_branch2a , act_type = ' relu ' ) NEW_LINE res4b1_branch2b = mx . symbol . Convolution ( name = ' res4b1 _ branch2b ' , data = res4b1_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2b = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2b ' , data = res4b1_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b1_branch2b = bn4b1_branch2b NEW_LINE res4b1_branch2b_relu = mx . symbol . Activation ( name = ' res4b1 _ branch2b _ relu ' , data = scale4b1_branch2b , act_type = ' relu ' ) NEW_LINE res4b1_branch2c = mx . symbol . Convolution ( name = ' res4b1 _ branch2c ' , data = res4b1_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2c = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2c ' , data = res4b1_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b1_branch2c = bn4b1_branch2c NEW_LINE res4b1 = mx . symbol . broadcast_add ( name = ' res4b1' , * [ res4a_relu , scale4b1_branch2c ] ) NEW_LINE res4b1_relu = mx . symbol . Activation ( name = ' res4b1 _ relu ' , data = res4b1 , act_type = ' relu ' ) NEW_LINE res4b2_branch2a = mx . symbol . Convolution ( name = ' res4b2 _ branch2a ' , data = res4b1_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2a = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2a ' , data = res4b2_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b2_branch2a = bn4b2_branch2a NEW_LINE res4b2_branch2a_relu = mx . symbol . Activation ( name = ' res4b2 _ branch2a _ relu ' , data = scale4b2_branch2a , act_type = ' relu ' ) NEW_LINE res4b2_branch2b = mx . symbol . Convolution ( name = ' res4b2 _ branch2b ' , data = res4b2_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2b = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2b ' , data = res4b2_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b2_branch2b = bn4b2_branch2b NEW_LINE res4b2_branch2b_relu = mx . symbol . Activation ( name = ' res4b2 _ branch2b _ relu ' , data = scale4b2_branch2b , act_type = ' relu ' ) NEW_LINE res4b2_branch2c = mx . symbol . Convolution ( name = ' res4b2 _ branch2c ' , data = res4b2_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2c = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2c ' , data = res4b2_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b2_branch2c = bn4b2_branch2c NEW_LINE res4b2 = mx . symbol . broadcast_add ( name = ' res4b2' , * [ res4b1_relu , scale4b2_branch2c ] ) NEW_LINE res4b2_relu = mx . symbol . Activation ( name = ' res4b2 _ relu ' , data = res4b2 , act_type = ' relu ' ) NEW_LINE res4b3_branch2a = mx . symbol . Convolution ( name = ' res4b3 _ branch2a ' , data = res4b2_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2a = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2a ' , data = res4b3_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b3_branch2a = bn4b3_branch2a NEW_LINE res4b3_branch2a_relu = mx . symbol . Activation ( name = ' res4b3 _ branch2a _ relu ' , data = scale4b3_branch2a , act_type = ' relu ' ) NEW_LINE res4b3_branch2b = mx . symbol . Convolution ( name = ' res4b3 _ branch2b ' , data = res4b3_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2b = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2b ' , data = res4b3_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b3_branch2b = bn4b3_branch2b NEW_LINE res4b3_branch2b_relu = mx . symbol . Activation ( name = ' res4b3 _ branch2b _ relu ' , data = scale4b3_branch2b , act_type = ' relu ' ) NEW_LINE res4b3_branch2c = mx . symbol . Convolution ( name = ' res4b3 _ branch2c ' , data = res4b3_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2c = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2c ' , data = res4b3_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b3_branch2c = bn4b3_branch2c NEW_LINE res4b3 = mx . symbol . broadcast_add ( name = ' res4b3' , * [ res4b2_relu , scale4b3_branch2c ] ) NEW_LINE res4b3_relu = mx . symbol . Activation ( name = ' res4b3 _ relu ' , data = res4b3 , act_type = ' relu ' ) NEW_LINE res4b4_branch2a = mx . symbol . Convolution ( name = ' res4b4 _ branch2a ' , data = res4b3_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2a = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2a ' , data = res4b4_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b4_branch2a = bn4b4_branch2a NEW_LINE res4b4_branch2a_relu = mx . symbol . Activation ( name = ' res4b4 _ branch2a _ relu ' , data = scale4b4_branch2a , act_type = ' relu ' ) NEW_LINE res4b4_branch2b = mx . symbol . Convolution ( name = ' res4b4 _ branch2b ' , data = res4b4_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2b = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2b ' , data = res4b4_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b4_branch2b = bn4b4_branch2b NEW_LINE res4b4_branch2b_relu = mx . symbol . Activation ( name = ' res4b4 _ branch2b _ relu ' , data = scale4b4_branch2b , act_type = ' relu ' ) NEW_LINE res4b4_branch2c = mx . symbol . Convolution ( name = ' res4b4 _ branch2c ' , data = res4b4_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2c = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2c ' , data = res4b4_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b4_branch2c = bn4b4_branch2c NEW_LINE res4b4 = mx . symbol . broadcast_add ( name = ' res4b4' , * [ res4b3_relu , scale4b4_branch2c ] ) NEW_LINE res4b4_relu = mx . symbol . Activation ( name = ' res4b4 _ relu ' , data = res4b4 , act_type = ' relu ' ) NEW_LINE res4b5_branch2a = mx . symbol . Convolution ( name = ' res4b5 _ branch2a ' , data = res4b4_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2a = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2a ' , data = res4b5_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b5_branch2a = bn4b5_branch2a NEW_LINE res4b5_branch2a_relu = mx . symbol . Activation ( name = ' res4b5 _ branch2a _ relu ' , data = scale4b5_branch2a , act_type = ' relu ' ) NEW_LINE res4b5_branch2b = mx . symbol . Convolution ( name = ' res4b5 _ branch2b ' , data = res4b5_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2b = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2b ' , data = res4b5_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b5_branch2b = bn4b5_branch2b NEW_LINE res4b5_branch2b_relu = mx . symbol . Activation ( name = ' res4b5 _ branch2b _ relu ' , data = scale4b5_branch2b , act_type = ' relu ' ) NEW_LINE res4b5_branch2c = mx . symbol . Convolution ( name = ' res4b5 _ branch2c ' , data = res4b5_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2c = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2c ' , data = res4b5_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b5_branch2c = bn4b5_branch2c NEW_LINE res4b5 = mx . symbol . broadcast_add ( name = ' res4b5' , * [ res4b4_relu , scale4b5_branch2c ] ) NEW_LINE res4b5_relu = mx . symbol . Activation ( name = ' res4b5 _ relu ' , data = res4b5 , act_type = ' relu ' ) NEW_LINE res4b6_branch2a = mx . symbol . Convolution ( name = ' res4b6 _ branch2a ' , data = res4b5_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2a = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2a ' , data = res4b6_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b6_branch2a = bn4b6_branch2a NEW_LINE res4b6_branch2a_relu = mx . symbol . Activation ( name = ' res4b6 _ branch2a _ relu ' , data = scale4b6_branch2a , act_type = ' relu ' ) NEW_LINE res4b6_branch2b = mx . symbol . Convolution ( name = ' res4b6 _ branch2b ' , data = res4b6_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2b = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2b ' , data = res4b6_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b6_branch2b = bn4b6_branch2b NEW_LINE res4b6_branch2b_relu = mx . symbol . Activation ( name = ' res4b6 _ branch2b _ relu ' , data = scale4b6_branch2b , act_type = ' relu ' ) NEW_LINE res4b6_branch2c = mx . symbol . Convolution ( name = ' res4b6 _ branch2c ' , data = res4b6_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2c = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2c ' , data = res4b6_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b6_branch2c = bn4b6_branch2c NEW_LINE res4b6 = mx . symbol . broadcast_add ( name = ' res4b6' , * [ res4b5_relu , scale4b6_branch2c ] ) NEW_LINE res4b6_relu = mx . symbol . Activation ( name = ' res4b6 _ relu ' , data = res4b6 , act_type = ' relu ' ) NEW_LINE res4b7_branch2a = mx . symbol . Convolution ( name = ' res4b7 _ branch2a ' , data = res4b6_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2a = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2a ' , data = res4b7_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b7_branch2a = bn4b7_branch2a NEW_LINE res4b7_branch2a_relu = mx . symbol . Activation ( name = ' res4b7 _ branch2a _ relu ' , data = scale4b7_branch2a , act_type = ' relu ' ) NEW_LINE res4b7_branch2b = mx . symbol . Convolution ( name = ' res4b7 _ branch2b ' , data = res4b7_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2b = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2b ' , data = res4b7_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b7_branch2b = bn4b7_branch2b NEW_LINE res4b7_branch2b_relu = mx . symbol . Activation ( name = ' res4b7 _ branch2b _ relu ' , data = scale4b7_branch2b , act_type = ' relu ' ) NEW_LINE res4b7_branch2c = mx . symbol . Convolution ( name = ' res4b7 _ branch2c ' , data = res4b7_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2c = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2c ' , data = res4b7_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b7_branch2c = bn4b7_branch2c NEW_LINE res4b7 = mx . symbol . broadcast_add ( name = ' res4b7' , * [ res4b6_relu , scale4b7_branch2c ] ) NEW_LINE res4b7_relu = mx . symbol . Activation ( name = ' res4b7 _ relu ' , data = res4b7 , act_type = ' relu ' ) NEW_LINE res4b8_branch2a = mx . symbol . Convolution ( name = ' res4b8 _ branch2a ' , data = res4b7_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2a = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2a ' , data = res4b8_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b8_branch2a = bn4b8_branch2a NEW_LINE res4b8_branch2a_relu = mx . symbol . Activation ( name = ' res4b8 _ branch2a _ relu ' , data = scale4b8_branch2a , act_type = ' relu ' ) NEW_LINE res4b8_branch2b = mx . symbol . Convolution ( name = ' res4b8 _ branch2b ' , data = res4b8_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2b = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2b ' , data = res4b8_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b8_branch2b = bn4b8_branch2b NEW_LINE res4b8_branch2b_relu = mx . symbol . Activation ( name = ' res4b8 _ branch2b _ relu ' , data = scale4b8_branch2b , act_type = ' relu ' ) NEW_LINE res4b8_branch2c = mx . symbol . Convolution ( name = ' res4b8 _ branch2c ' , data = res4b8_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2c = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2c ' , data = res4b8_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b8_branch2c = bn4b8_branch2c NEW_LINE res4b8 = mx . symbol . broadcast_add ( name = ' res4b8' , * [ res4b7_relu , scale4b8_branch2c ] ) NEW_LINE res4b8_relu = mx . symbol . Activation ( name = ' res4b8 _ relu ' , data = res4b8 , act_type = ' relu ' ) NEW_LINE res4b9_branch2a = mx . symbol . Convolution ( name = ' res4b9 _ branch2a ' , data = res4b8_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2a = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2a ' , data = res4b9_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b9_branch2a = bn4b9_branch2a NEW_LINE res4b9_branch2a_relu = mx . symbol . Activation ( name = ' res4b9 _ branch2a _ relu ' , data = scale4b9_branch2a , act_type = ' relu ' ) NEW_LINE res4b9_branch2b = mx . symbol . Convolution ( name = ' res4b9 _ branch2b ' , data = res4b9_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2b = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2b ' , data = res4b9_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b9_branch2b = bn4b9_branch2b NEW_LINE res4b9_branch2b_relu = mx . symbol . Activation ( name = ' res4b9 _ branch2b _ relu ' , data = scale4b9_branch2b , act_type = ' relu ' ) NEW_LINE res4b9_branch2c = mx . symbol . Convolution ( name = ' res4b9 _ branch2c ' , data = res4b9_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2c = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2c ' , data = res4b9_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b9_branch2c = bn4b9_branch2c NEW_LINE res4b9 = mx . symbol . broadcast_add ( name = ' res4b9' , * [ res4b8_relu , scale4b9_branch2c ] ) NEW_LINE res4b9_relu = mx . symbol . Activation ( name = ' res4b9 _ relu ' , data = res4b9 , act_type = ' relu ' ) NEW_LINE res4b10_branch2a = mx . symbol . Convolution ( name = ' res4b10 _ branch2a ' , data = res4b9_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2a = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2a ' , data = res4b10_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b10_branch2a = bn4b10_branch2a NEW_LINE res4b10_branch2a_relu = mx . symbol . Activation ( name = ' res4b10 _ branch2a _ relu ' , data = scale4b10_branch2a , act_type = ' relu ' ) NEW_LINE res4b10_branch2b = mx . symbol . Convolution ( name = ' res4b10 _ branch2b ' , data = res4b10_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2b = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2b ' , data = res4b10_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b10_branch2b = bn4b10_branch2b NEW_LINE res4b10_branch2b_relu = mx . symbol . Activation ( name = ' res4b10 _ branch2b _ relu ' , data = scale4b10_branch2b , act_type = ' relu ' ) NEW_LINE res4b10_branch2c = mx . symbol . Convolution ( name = ' res4b10 _ branch2c ' , data = res4b10_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2c = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2c ' , data = res4b10_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b10_branch2c = bn4b10_branch2c NEW_LINE res4b10 = mx . symbol . broadcast_add ( name = ' res4b10' , * [ res4b9_relu , scale4b10_branch2c ] ) NEW_LINE res4b10_relu = mx . symbol . Activation ( name = ' res4b10 _ relu ' , data = res4b10 , act_type = ' relu ' ) NEW_LINE res4b11_branch2a = mx . symbol . Convolution ( name = ' res4b11 _ branch2a ' , data = res4b10_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2a = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2a ' , data = res4b11_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b11_branch2a = bn4b11_branch2a NEW_LINE res4b11_branch2a_relu = mx . symbol . Activation ( name = ' res4b11 _ branch2a _ relu ' , data = scale4b11_branch2a , act_type = ' relu ' ) NEW_LINE res4b11_branch2b = mx . symbol . Convolution ( name = ' res4b11 _ branch2b ' , data = res4b11_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2b = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2b ' , data = res4b11_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b11_branch2b = bn4b11_branch2b NEW_LINE res4b11_branch2b_relu = mx . symbol . Activation ( name = ' res4b11 _ branch2b _ relu ' , data = scale4b11_branch2b , act_type = ' relu ' ) NEW_LINE res4b11_branch2c = mx . symbol . Convolution ( name = ' res4b11 _ branch2c ' , data = res4b11_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2c = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2c ' , data = res4b11_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b11_branch2c = bn4b11_branch2c NEW_LINE res4b11 = mx . symbol . broadcast_add ( name = ' res4b11' , * [ res4b10_relu , scale4b11_branch2c ] ) NEW_LINE res4b11_relu = mx . symbol . Activation ( name = ' res4b11 _ relu ' , data = res4b11 , act_type = ' relu ' ) NEW_LINE res4b12_branch2a = mx . symbol . Convolution ( name = ' res4b12 _ branch2a ' , data = res4b11_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2a = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2a ' , data = res4b12_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b12_branch2a = bn4b12_branch2a NEW_LINE res4b12_branch2a_relu = mx . symbol . Activation ( name = ' res4b12 _ branch2a _ relu ' , data = scale4b12_branch2a , act_type = ' relu ' ) NEW_LINE res4b12_branch2b = mx . symbol . Convolution ( name = ' res4b12 _ branch2b ' , data = res4b12_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2b = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2b ' , data = res4b12_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b12_branch2b = bn4b12_branch2b NEW_LINE res4b12_branch2b_relu = mx . symbol . Activation ( name = ' res4b12 _ branch2b _ relu ' , data = scale4b12_branch2b , act_type = ' relu ' ) NEW_LINE res4b12_branch2c = mx . symbol . Convolution ( name = ' res4b12 _ branch2c ' , data = res4b12_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2c = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2c ' , data = res4b12_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b12_branch2c = bn4b12_branch2c NEW_LINE res4b12 = mx . symbol . broadcast_add ( name = ' res4b12' , * [ res4b11_relu , scale4b12_branch2c ] ) NEW_LINE res4b12_relu = mx . symbol . Activation ( name = ' res4b12 _ relu ' , data = res4b12 , act_type = ' relu ' ) NEW_LINE res4b13_branch2a = mx . symbol . Convolution ( name = ' res4b13 _ branch2a ' , data = res4b12_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2a = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2a ' , data = res4b13_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b13_branch2a = bn4b13_branch2a NEW_LINE res4b13_branch2a_relu = mx . symbol . Activation ( name = ' res4b13 _ branch2a _ relu ' , data = scale4b13_branch2a , act_type = ' relu ' ) NEW_LINE res4b13_branch2b = mx . symbol . Convolution ( name = ' res4b13 _ branch2b ' , data = res4b13_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2b = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2b ' , data = res4b13_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b13_branch2b = bn4b13_branch2b NEW_LINE res4b13_branch2b_relu = mx . symbol . Activation ( name = ' res4b13 _ branch2b _ relu ' , data = scale4b13_branch2b , act_type = ' relu ' ) NEW_LINE res4b13_branch2c = mx . symbol . Convolution ( name = ' res4b13 _ branch2c ' , data = res4b13_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2c = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2c ' , data = res4b13_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b13_branch2c = bn4b13_branch2c NEW_LINE res4b13 = mx . symbol . broadcast_add ( name = ' res4b13' , * [ res4b12_relu , scale4b13_branch2c ] ) NEW_LINE res4b13_relu = mx . symbol . Activation ( name = ' res4b13 _ relu ' , data = res4b13 , act_type = ' relu ' ) NEW_LINE res4b14_branch2a = mx . symbol . Convolution ( name = ' res4b14 _ branch2a ' , data = res4b13_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2a = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2a ' , data = res4b14_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b14_branch2a = bn4b14_branch2a NEW_LINE res4b14_branch2a_relu = mx . symbol . Activation ( name = ' res4b14 _ branch2a _ relu ' , data = scale4b14_branch2a , act_type = ' relu ' ) NEW_LINE res4b14_branch2b = mx . symbol . Convolution ( name = ' res4b14 _ branch2b ' , data = res4b14_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2b = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2b ' , data = res4b14_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b14_branch2b = bn4b14_branch2b NEW_LINE res4b14_branch2b_relu = mx . symbol . Activation ( name = ' res4b14 _ branch2b _ relu ' , data = scale4b14_branch2b , act_type = ' relu ' ) NEW_LINE res4b14_branch2c = mx . symbol . Convolution ( name = ' res4b14 _ branch2c ' , data = res4b14_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2c = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2c ' , data = res4b14_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b14_branch2c = bn4b14_branch2c NEW_LINE res4b14 = mx . symbol . broadcast_add ( name = ' res4b14' , * [ res4b13_relu , scale4b14_branch2c ] ) NEW_LINE res4b14_relu = mx . symbol . Activation ( name = ' res4b14 _ relu ' , data = res4b14 , act_type = ' relu ' ) NEW_LINE res4b15_branch2a = mx . symbol . Convolution ( name = ' res4b15 _ branch2a ' , data = res4b14_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2a = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2a ' , data = res4b15_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b15_branch2a = bn4b15_branch2a NEW_LINE res4b15_branch2a_relu = mx . symbol . Activation ( name = ' res4b15 _ branch2a _ relu ' , data = scale4b15_branch2a , act_type = ' relu ' ) NEW_LINE res4b15_branch2b = mx . symbol . Convolution ( name = ' res4b15 _ branch2b ' , data = res4b15_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2b = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2b ' , data = res4b15_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b15_branch2b = bn4b15_branch2b NEW_LINE res4b15_branch2b_relu = mx . symbol . Activation ( name = ' res4b15 _ branch2b _ relu ' , data = scale4b15_branch2b , act_type = ' relu ' ) NEW_LINE res4b15_branch2c = mx . symbol . Convolution ( name = ' res4b15 _ branch2c ' , data = res4b15_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2c = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2c ' , data = res4b15_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b15_branch2c = bn4b15_branch2c NEW_LINE res4b15 = mx . symbol . broadcast_add ( name = ' res4b15' , * [ res4b14_relu , scale4b15_branch2c ] ) NEW_LINE res4b15_relu = mx . symbol . Activation ( name = ' res4b15 _ relu ' , data = res4b15 , act_type = ' relu ' ) NEW_LINE res4b16_branch2a = mx . symbol . Convolution ( name = ' res4b16 _ branch2a ' , data = res4b15_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2a = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2a ' , data = res4b16_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b16_branch2a = bn4b16_branch2a NEW_LINE res4b16_branch2a_relu = mx . symbol . Activation ( name = ' res4b16 _ branch2a _ relu ' , data = scale4b16_branch2a , act_type = ' relu ' ) NEW_LINE res4b16_branch2b = mx . symbol . Convolution ( name = ' res4b16 _ branch2b ' , data = res4b16_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2b = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2b ' , data = res4b16_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b16_branch2b = bn4b16_branch2b NEW_LINE res4b16_branch2b_relu = mx . symbol . Activation ( name = ' res4b16 _ branch2b _ relu ' , data = scale4b16_branch2b , act_type = ' relu ' ) NEW_LINE res4b16_branch2c = mx . symbol . Convolution ( name = ' res4b16 _ branch2c ' , data = res4b16_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2c = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2c ' , data = res4b16_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b16_branch2c = bn4b16_branch2c NEW_LINE res4b16 = mx . symbol . broadcast_add ( name = ' res4b16' , * [ res4b15_relu , scale4b16_branch2c ] ) NEW_LINE res4b16_relu = mx . symbol . Activation ( name = ' res4b16 _ relu ' , data = res4b16 , act_type = ' relu ' ) NEW_LINE res4b17_branch2a = mx . symbol . Convolution ( name = ' res4b17 _ branch2a ' , data = res4b16_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2a = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2a ' , data = res4b17_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b17_branch2a = bn4b17_branch2a NEW_LINE res4b17_branch2a_relu = mx . symbol . Activation ( name = ' res4b17 _ branch2a _ relu ' , data = scale4b17_branch2a , act_type = ' relu ' ) NEW_LINE res4b17_branch2b = mx . symbol . Convolution ( name = ' res4b17 _ branch2b ' , data = res4b17_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2b = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2b ' , data = res4b17_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b17_branch2b = bn4b17_branch2b NEW_LINE res4b17_branch2b_relu = mx . symbol . Activation ( name = ' res4b17 _ branch2b _ relu ' , data = scale4b17_branch2b , act_type = ' relu ' ) NEW_LINE res4b17_branch2c = mx . symbol . Convolution ( name = ' res4b17 _ branch2c ' , data = res4b17_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2c = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2c ' , data = res4b17_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b17_branch2c = bn4b17_branch2c NEW_LINE res4b17 = mx . symbol . broadcast_add ( name = ' res4b17' , * [ res4b16_relu , scale4b17_branch2c ] ) NEW_LINE res4b17_relu = mx . symbol . Activation ( name = ' res4b17 _ relu ' , data = res4b17 , act_type = ' relu ' ) NEW_LINE res4b18_branch2a = mx . symbol . Convolution ( name = ' res4b18 _ branch2a ' , data = res4b17_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2a = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2a ' , data = res4b18_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b18_branch2a = bn4b18_branch2a NEW_LINE res4b18_branch2a_relu = mx . symbol . Activation ( name = ' res4b18 _ branch2a _ relu ' , data = scale4b18_branch2a , act_type = ' relu ' ) NEW_LINE res4b18_branch2b = mx . symbol . Convolution ( name = ' res4b18 _ branch2b ' , data = res4b18_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2b = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2b ' , data = res4b18_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b18_branch2b = bn4b18_branch2b NEW_LINE res4b18_branch2b_relu = mx . symbol . Activation ( name = ' res4b18 _ branch2b _ relu ' , data = scale4b18_branch2b , act_type = ' relu ' ) NEW_LINE res4b18_branch2c = mx . symbol . Convolution ( name = ' res4b18 _ branch2c ' , data = res4b18_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2c = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2c ' , data = res4b18_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b18_branch2c = bn4b18_branch2c NEW_LINE res4b18 = mx . symbol . broadcast_add ( name = ' res4b18' , * [ res4b17_relu , scale4b18_branch2c ] ) NEW_LINE res4b18_relu = mx . symbol . Activation ( name = ' res4b18 _ relu ' , data = res4b18 , act_type = ' relu ' ) NEW_LINE res4b19_branch2a = mx . symbol . Convolution ( name = ' res4b19 _ branch2a ' , data = res4b18_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2a = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2a ' , data = res4b19_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b19_branch2a = bn4b19_branch2a NEW_LINE res4b19_branch2a_relu = mx . symbol . Activation ( name = ' res4b19 _ branch2a _ relu ' , data = scale4b19_branch2a , act_type = ' relu ' ) NEW_LINE res4b19_branch2b = mx . symbol . Convolution ( name = ' res4b19 _ branch2b ' , data = res4b19_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2b = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2b ' , data = res4b19_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b19_branch2b = bn4b19_branch2b NEW_LINE res4b19_branch2b_relu = mx . symbol . Activation ( name = ' res4b19 _ branch2b _ relu ' , data = scale4b19_branch2b , act_type = ' relu ' ) NEW_LINE res4b19_branch2c = mx . symbol . Convolution ( name = ' res4b19 _ branch2c ' , data = res4b19_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2c = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2c ' , data = res4b19_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b19_branch2c = bn4b19_branch2c NEW_LINE res4b19 = mx . symbol . broadcast_add ( name = ' res4b19' , * [ res4b18_relu , scale4b19_branch2c ] ) NEW_LINE res4b19_relu = mx . symbol . Activation ( name = ' res4b19 _ relu ' , data = res4b19 , act_type = ' relu ' ) NEW_LINE res4b20_branch2a = mx . symbol . Convolution ( name = ' res4b20 _ branch2a ' , data = res4b19_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2a = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2a ' , data = res4b20_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b20_branch2a = bn4b20_branch2a NEW_LINE res4b20_branch2a_relu = mx . symbol . Activation ( name = ' res4b20 _ branch2a _ relu ' , data = scale4b20_branch2a , act_type = ' relu ' ) NEW_LINE res4b20_branch2b = mx . symbol . Convolution ( name = ' res4b20 _ branch2b ' , data = res4b20_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2b = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2b ' , data = res4b20_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b20_branch2b = bn4b20_branch2b NEW_LINE res4b20_branch2b_relu = mx . symbol . Activation ( name = ' res4b20 _ branch2b _ relu ' , data = scale4b20_branch2b , act_type = ' relu ' ) NEW_LINE res4b20_branch2c = mx . symbol . Convolution ( name = ' res4b20 _ branch2c ' , data = res4b20_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2c = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2c ' , data = res4b20_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b20_branch2c = bn4b20_branch2c NEW_LINE res4b20 = mx . symbol . broadcast_add ( name = ' res4b20' , * [ res4b19_relu , scale4b20_branch2c ] ) NEW_LINE res4b20_relu = mx . symbol . Activation ( name = ' res4b20 _ relu ' , data = res4b20 , act_type = ' relu ' ) NEW_LINE res4b21_branch2a = mx . symbol . Convolution ( name = ' res4b21 _ branch2a ' , data = res4b20_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2a = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2a ' , data = res4b21_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b21_branch2a = bn4b21_branch2a NEW_LINE res4b21_branch2a_relu = mx . symbol . Activation ( name = ' res4b21 _ branch2a _ relu ' , data = scale4b21_branch2a , act_type = ' relu ' ) NEW_LINE res4b21_branch2b = mx . symbol . Convolution ( name = ' res4b21 _ branch2b ' , data = res4b21_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2b = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2b ' , data = res4b21_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b21_branch2b = bn4b21_branch2b NEW_LINE res4b21_branch2b_relu = mx . symbol . Activation ( name = ' res4b21 _ branch2b _ relu ' , data = scale4b21_branch2b , act_type = ' relu ' ) NEW_LINE res4b21_branch2c = mx . symbol . Convolution ( name = ' res4b21 _ branch2c ' , data = res4b21_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2c = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2c ' , data = res4b21_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b21_branch2c = bn4b21_branch2c NEW_LINE res4b21 = mx . symbol . broadcast_add ( name = ' res4b21' , * [ res4b20_relu , scale4b21_branch2c ] ) NEW_LINE res4b21_relu = mx . symbol . Activation ( name = ' res4b21 _ relu ' , data = res4b21 , act_type = ' relu ' ) NEW_LINE res4b22_branch2a = mx . symbol . Convolution ( name = ' res4b22 _ branch2a ' , data = res4b21_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b22_branch2a = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2a ' , data = res4b22_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b22_branch2a = bn4b22_branch2a NEW_LINE res4b22_branch2a_relu = mx . symbol . Activation ( name = ' res4b22 _ branch2a _ relu ' , data = scale4b22_branch2a , act_type = ' relu ' ) NEW_LINE res4b22_branch2b = mx . symbol . Convolution ( name = ' res4b22 _ branch2b ' , data = res4b22_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b22_branch2b = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2b ' , data = res4b22_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b22_branch2b = bn4b22_branch2b NEW_LINE res4b22_branch2b_relu = mx . symbol . Activation ( name = ' res4b22 _ branch2b _ relu ' , data = scale4b22_branch2b , act_type = ' relu ' ) NEW_LINE res4b22_branch2c = mx . symbol . Convolution ( name = ' res4b22 _ branch2c ' , data = res4b22_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b22_branch2c = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2c ' , data = res4b22_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b22_branch2c = bn4b22_branch2c NEW_LINE res4b22 = mx . symbol . broadcast_add ( name = ' res4b22' , * [ res4b21_relu , scale4b22_branch2c ] ) NEW_LINE res4b22_relu = mx . symbol . Activation ( name = ' res4b22 _ relu ' , data = res4b22 , act_type = ' relu ' ) NEW_LINE return res4b22_relu NEW_LINE DEDENT\",), (\"def get_resnet_v1_conv5 ( self , conv_feat ) : NEW_LINE INDENT res5a_branch1 = mx . symbol . Convolution ( name = ' res5a _ branch1' , data = conv_feat , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5a_branch1 = mx . symbol . BatchNorm ( name = ' bn5a _ branch1' , data = res5a_branch1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5a_branch1 = bn5a_branch1 NEW_LINE res5a_branch2a = mx . symbol . Convolution ( name = ' res5a _ branch2a ' , data = conv_feat , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5a_branch2a = mx . symbol . BatchNorm ( name = ' bn5a _ branch2a ' , data = res5a_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5a_branch2a = bn5a_branch2a NEW_LINE res5a_branch2a_relu = mx . symbol . Activation ( name = ' res5a _ branch2a _ relu ' , data = scale5a_branch2a , act_type = ' relu ' ) NEW_LINE res5a_branch2b = mx . symbol . Convolution ( name = ' res5a _ branch2b ' , data = res5a_branch2a_relu , num_filter = 512 , pad = ( 2 , 2 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn5a_branch2b = mx . symbol . BatchNorm ( name = ' bn5a _ branch2b ' , data = res5a_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5a_branch2b = bn5a_branch2b NEW_LINE res5a_branch2b_relu = mx . symbol . Activation ( name = ' res5a _ branch2b _ relu ' , data = scale5a_branch2b , act_type = ' relu ' ) NEW_LINE res5a_branch2c = mx . symbol . Convolution ( name = ' res5a _ branch2c ' , data = res5a_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5a_branch2c = mx . symbol . BatchNorm ( name = ' bn5a _ branch2c ' , data = res5a_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5a_branch2c = bn5a_branch2c NEW_LINE res5a = mx . symbol . broadcast_add ( name = ' res5a ' , * [ scale5a_branch1 , scale5a_branch2c ] ) NEW_LINE res5a_relu = mx . symbol . Activation ( name = ' res5a _ relu ' , data = res5a , act_type = ' relu ' ) NEW_LINE res5b_branch2a = mx . symbol . Convolution ( name = ' res5b _ branch2a ' , data = res5a_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5b_branch2a = mx . symbol . BatchNorm ( name = ' bn5b _ branch2a ' , data = res5b_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5b_branch2a = bn5b_branch2a NEW_LINE res5b_branch2a_relu = mx . symbol . Activation ( name = ' res5b _ branch2a _ relu ' , data = scale5b_branch2a , act_type = ' relu ' ) NEW_LINE res5b_branch2b = mx . symbol . Convolution ( name = ' res5b _ branch2b ' , data = res5b_branch2a_relu , num_filter = 512 , pad = ( 2 , 2 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn5b_branch2b = mx . symbol . BatchNorm ( name = ' bn5b _ branch2b ' , data = res5b_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5b_branch2b = bn5b_branch2b NEW_LINE res5b_branch2b_relu = mx . symbol . Activation ( name = ' res5b _ branch2b _ relu ' , data = scale5b_branch2b , act_type = ' relu ' ) NEW_LINE res5b_branch2c = mx . symbol . Convolution ( name = ' res5b _ branch2c ' , data = res5b_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5b_branch2c = mx . symbol . BatchNorm ( name = ' bn5b _ branch2c ' , data = res5b_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5b_branch2c = bn5b_branch2c NEW_LINE res5b = mx . symbol . broadcast_add ( name = ' res5b ' , * [ res5a_relu , scale5b_branch2c ] ) NEW_LINE res5b_relu = mx . symbol . Activation ( name = ' res5b _ relu ' , data = res5b , act_type = ' relu ' ) NEW_LINE res5c_branch2a = mx . symbol . Convolution ( name = ' res5c _ branch2a ' , data = res5b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5c_branch2a = mx . symbol . BatchNorm ( name = ' bn5c _ branch2a ' , data = res5c_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5c_branch2a = bn5c_branch2a NEW_LINE res5c_branch2a_relu = mx . symbol . Activation ( name = ' res5c _ branch2a _ relu ' , data = scale5c_branch2a , act_type = ' relu ' ) NEW_LINE res5c_branch2b = mx . symbol . Convolution ( name = ' res5c _ branch2b ' , data = res5c_branch2a_relu , num_filter = 512 , pad = ( 2 , 2 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn5c_branch2b = mx . symbol . BatchNorm ( name = ' bn5c _ branch2b ' , data = res5c_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5c_branch2b = bn5c_branch2b NEW_LINE res5c_branch2b_relu = mx . symbol . Activation ( name = ' res5c _ branch2b _ relu ' , data = scale5c_branch2b , act_type = ' relu ' ) NEW_LINE res5c_branch2c = mx . symbol . Convolution ( name = ' res5c _ branch2c ' , data = res5c_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5c_branch2c = mx . symbol . BatchNorm ( name = ' bn5c _ branch2c ' , data = res5c_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5c_branch2c = bn5c_branch2c NEW_LINE res5c = mx . symbol . broadcast_add ( name = ' res5c ' , * [ res5b_relu , scale5c_branch2c ] ) NEW_LINE res5c_relu = mx . symbol . Activation ( name = ' res5c _ relu ' , data = res5c , act_type = ' relu ' ) NEW_LINE return res5c_relu NEW_LINE DEDENT\",), ('def get_light_head ( self , data , mid_num_filter = 256 , suffix = \\' separable \\' ) : NEW_LINE INDENT conv_new_1 = mx . sym . Convolution ( data = data , kernel = ( 15 , 1 ) , pad = ( 7 , 0 ) , num_filter = mid_num_filter , name = \" conv _ new _ 1\" + suffix , weight = self . shared_param_dict [ \\' conv _ new _ 1 _ weight \\' ] , bias = self . shared_param_dict [ \\' conv _ new _ 1 _ bias \\' ] , lr_mult = 3.0 ) NEW_LINE relu_new_1 = mx . sym . Activation ( data = conv_new_1 , act_type = \\' relu \\' , name = \\' relu1\\' + suffix ) NEW_LINE conv_new_2 = mx . sym . Convolution ( data = relu_new_1 , kernel = ( 1 , 15 ) , pad = ( 0 , 7 ) , num_filter = 10 * 7 * 7 , name = \" conv _ new _ 2\" + suffix , weight = self . shared_param_dict [ \\' conv _ new _ 2 _ weight \\' ] , bias = self . shared_param_dict [ \\' conv _ new _ 2 _ bias \\' ] , lr_mult = 3.0 ) NEW_LINE relu_new_2 = mx . sym . Activation ( data = conv_new_2 , act_type = \\' relu \\' , name = \\' relu2\\' + suffix ) NEW_LINE conv_new_3 = mx . sym . Convolution ( data = data , kernel = ( 1 , 15 ) , pad = ( 0 , 7 ) , num_filter = mid_num_filter , name = \" conv _ new _ 3\" + suffix , weight = self . shared_param_dict [ \\' conv _ new _ 3 _ weight \\' ] , bias = self . shared_param_dict [ \\' conv _ new _ 3 _ bias \\' ] , lr_mult = 3.0 ) NEW_LINE relu_new_3 = mx . sym . Activation ( data = conv_new_3 , act_type = \\' relu \\' , name = \\' relu3\\' + suffix ) NEW_LINE conv_new_4 = mx . sym . Convolution ( data = relu_new_3 , kernel = ( 15 , 1 ) , pad = ( 7 , 0 ) , num_filter = 10 * 7 * 7 , name = \" conv _ new _ 4\" + suffix , weight = self . shared_param_dict [ \\' conv _ new _ 4 _ weight \\' ] , bias = self . shared_param_dict [ \\' conv _ new _ 4 _ bias \\' ] , lr_mult = 3.0 ) NEW_LINE relu_new_4 = mx . sym . Activation ( data = conv_new_4 , act_type = \\' relu \\' , name = \\' relu4\\' + suffix ) NEW_LINE light_head = mx . symbol . broadcast_add ( name = \\' light _ head \\' , * [ relu_new_2 , relu_new_4 ] ) NEW_LINE return light_head NEW_LINE DEDENT',), ('def get_rpn ( self , conv_feat , num_anchors ) : NEW_LINE INDENT rpn_conv = mx . sym . Convolution ( data = conv_feat , kernel = ( 3 , 3 ) , pad = ( 1 , 1 ) , num_filter = 512 , name = \" rpn _ conv _ 3x3\" ) NEW_LINE rpn_relu = mx . sym . Activation ( data = rpn_conv , act_type = \" relu \" , name = \" rpn _ relu \" ) NEW_LINE rpn_cls_score = mx . sym . Convolution ( data = rpn_relu , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , num_filter = 2 * num_anchors , name = \" rpn _ cls _ score \" ) NEW_LINE rpn_bbox_pred = mx . sym . Convolution ( data = rpn_relu , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , num_filter = 4 * num_anchors , name = \" rpn _ bbox _ pred \" ) NEW_LINE return rpn_cls_score , rpn_bbox_pred NEW_LINE DEDENT',), ('def get_symbol_rpn ( self , cfg , is_train = True ) : NEW_LINE INDENT num_anchors = cfg . network . NUM_ANCHORS NEW_LINE if is_train : NEW_LINE INDENT data = mx . sym . Variable ( name = \" data \" ) NEW_LINE rpn_label = mx . sym . Variable ( name = \\' label \\' ) NEW_LINE rpn_bbox_target = mx . sym . Variable ( name = \\' bbox _ target \\' ) NEW_LINE rpn_bbox_weight = mx . sym . Variable ( name = \\' bbox _ weight \\' ) NEW_LINE DEDENT else : NEW_LINE INDENT data = mx . sym . Variable ( name = \" data \" ) NEW_LINE im_info = mx . sym . Variable ( name = \" im _ info \" ) NEW_LINE DEDENT conv_feat = self . get_resnet_v1_conv4 ( data ) NEW_LINE rpn_cls_score , rpn_bbox_pred = self . get_rpn ( conv_feat , num_anchors ) NEW_LINE if is_train : NEW_LINE INDENT rpn_cls_score_reshape = mx . sym . Reshape ( data = rpn_cls_score , shape = ( 0 , 2 , - 1 , 0 ) , name = \" rpn _ cls _ score _ reshape \" ) NEW_LINE rpn_cls_prob = mx . sym . SoftmaxOutput ( data = rpn_cls_score_reshape , label = rpn_label , multi_output = True , normalization = \\' valid \\' , use_ignore = True , ignore_label = - 1 , name = \" rpn _ cls _ prob \" , grad_scale = 1.0 ) NEW_LINE rpn_bbox_loss_ = rpn_bbox_weight * mx . sym . smooth_l1 ( name = \\' rpn _ bbox _ loss _ \\' , scalar = 3.0 , data = ( rpn_bbox_pred - rpn_bbox_target ) ) NEW_LINE rpn_bbox_loss = mx . sym . MakeLoss ( name = \\' rpn _ bbox _ loss \\' , data = rpn_bbox_loss_ , grad_scale = 1.0 / cfg . TRAIN . RPN_BATCH_SIZE ) NEW_LINE group = mx . symbol . Group ( [ rpn_cls_prob , rpn_bbox_loss ] ) NEW_LINE DEDENT else : NEW_LINE INDENT rpn_cls_score_reshape = mx . sym . Reshape ( data = rpn_cls_score , shape = ( 0 , 2 , - 1 , 0 ) , name = \" rpn _ cls _ score _ reshape \" ) NEW_LINE rpn_cls_prob = mx . sym . SoftmaxActivation ( data = rpn_cls_score_reshape , mode = \" channel \" , name = \" rpn _ cls _ prob \" ) NEW_LINE rpn_cls_prob_reshape = mx . sym . Reshape ( data = rpn_cls_prob , shape = ( 0 , 2 * num_anchors , - 1 , 0 ) , name = \\' rpn _ cls _ prob _ reshape \\' ) NEW_LINE if cfg . TEST . CXX_PROPOSAL : NEW_LINE INDENT rois , score = mx . contrib . sym . Proposal ( cls_prob = rpn_cls_prob_reshape , bbox_pred = rpn_bbox_pred , im_info = im_info , name = \\' rois \\' , output_score = True , feature_stride = cfg . network . RPN_FEAT_STRIDE , scales = tuple ( cfg . network . ANCHOR_SCALES ) , ratios = tuple ( cfg . network . ANCHOR_RATIOS ) , rpn_pre_nms_top_n = cfg . TEST . RPN_PRE_NMS_TOP_N , rpn_post_nms_top_n = cfg . TEST . RPN_POST_NMS_TOP_N , threshold = cfg . TEST . RPN_NMS_THRESH , rpn_min_size = cfg . TEST . RPN_MIN_SIZE ) NEW_LINE DEDENT else : NEW_LINE INDENT rois , score = mx . sym . Custom ( cls_prob = rpn_cls_prob_reshape , bbox_pred = rpn_bbox_pred , im_info = im_info , name = \\' rois \\' , output_score = True , op_type = \\' proposal \\' , feat_stride = cfg . network . RPN_FEAT_STRIDE , scales = tuple ( cfg . network . ANCHOR_SCALES ) , ratios = tuple ( cfg . network . ANCHOR_RATIOS ) , rpn_pre_nms_top_n = cfg . TEST . RPN_PRE_NMS_TOP_N , rpn_post_nms_top_n = cfg . TEST . RPN_POST_NMS_TOP_N , threshold = cfg . TEST . RPN_NMS_THRESH , rpn_min_size = cfg . TEST . RPN_MIN_SIZE ) NEW_LINE group = mx . symbol . Group ( [ rois , score ] ) NEW_LINE DEDENT DEDENT self . sym = group NEW_LINE return group NEW_LINE DEDENT',), ('def get_symbol_rcnn ( self , cfg , is_train = True ) : NEW_LINE INDENT num_classes = cfg . dataset . NUM_CLASSES NEW_LINE num_reg_classes = ( 2 if cfg . CLASS_AGNOSTIC else num_classes ) NEW_LINE if is_train : NEW_LINE INDENT data = mx . symbol . Variable ( name = \" data \" ) NEW_LINE rois = mx . symbol . Variable ( name = \\' rois \\' ) NEW_LINE label = mx . symbol . Variable ( name = \\' label \\' ) NEW_LINE bbox_target = mx . symbol . Variable ( name = \\' bbox _ target \\' ) NEW_LINE bbox_weight = mx . symbol . Variable ( name = \\' bbox _ weight \\' ) NEW_LINE rois = mx . symbol . Reshape ( data = rois , shape = ( - 1 , 5 ) , name = \\' rois _ reshape \\' ) NEW_LINE label = mx . symbol . Reshape ( data = label , shape = ( - 1 , ) , name = \\' label _ reshape \\' ) NEW_LINE bbox_target = mx . symbol . Reshape ( data = bbox_target , shape = ( - 1 , 5 * num_classes ) , name = \\' bbox _ target _ reshape \\' ) NEW_LINE bbox_weight = mx . symbol . Reshape ( data = bbox_weight , shape = ( - 1 , 5 * num_classes ) , name = \\' bbox _ weight _ reshape \\' ) NEW_LINE DEDENT else : NEW_LINE INDENT data = mx . sym . Variable ( name = \" data \" ) NEW_LINE rois = mx . symbol . Variable ( name = \\' rois \\' ) NEW_LINE rois = mx . symbol . Reshape ( data = rois , shape = ( - 1 , 5 ) , name = \\' rois _ reshape \\' ) NEW_LINE DEDENT conv_feat = self . get_resnet_v1_conv4 ( data ) NEW_LINE relu1 = self . get_resnet_v1_conv5 ( conv_feat ) NEW_LINE conv_thin_feat = self . get_light_head ( data = relu1 , mid_num_filter = 256 ) NEW_LINE roi_pool = mx . contrib . sym . PSROIPooling ( name = \\' psroipooling \\' , data = conv_thin_feat , rois = rois , group_size = 7 , pooled_size = 7 , output_dim = 10 , spatial_scale = 0.0625 ) NEW_LINE fc_new_1 = mx . symbol . FullyConnected ( name = \\' fc _ new _ 1\\' , data = roi_pool , num_hidden = 1024 ) NEW_LINE fc_new_1_relu = mx . sym . Activation ( data = fc_new_1 , act_type = \\' relu \\' , name = \\' fc _ new _ 1 _ relu \\' ) NEW_LINE cls_score = mx . symbol . FullyConnected ( name = \\' cls _ score \\' , data = fc_new_1_relu , num_hidden = num_classes ) NEW_LINE bbox_pred = mx . symbol . FullyConnected ( name = \\' bbox _ pred \\' , data = fc_new_1_relu , num_hidden = num_reg_classes * 5 ) NEW_LINE if is_train : NEW_LINE INDENT if cfg . TRAIN . ENABLE_OHEM : NEW_LINE INDENT labels_ohem , bbox_weights_ohem = mx . sym . Custom ( op_type = \\' BoxAnnotatorOHEM \\' , num_classes = num_classes , num_reg_classes = num_reg_classes , roi_per_img = cfg . TRAIN . BATCH_ROIS_OHEM , cls_score = cls_score , bbox_pred = bbox_pred , labels = label , bbox_targets = bbox_target , bbox_weights = bbox_weight ) NEW_LINE cls_prob = mx . sym . SoftmaxOutput ( name = \\' cls _ prob \\' , data = cls_score , label = labels_ohem , normalization = \\' valid \\' , use_ignore = True , ignore_label = - 1 , grad_scale = 1.0 ) NEW_LINE bbox_loss_ = bbox_weights_ohem * mx . sym . smooth_l1 ( name = \\' bbox _ loss _ \\' , scalar = 1.0 , data = ( bbox_pred - bbox_target ) ) NEW_LINE bbox_loss = mx . sym . MakeLoss ( name = \\' bbox _ loss \\' , data = bbox_loss_ , grad_scale = 1.0 / cfg . TRAIN . BATCH_ROIS_OHEM ) NEW_LINE DEDENT else : NEW_LINE INDENT cls_prob = mx . sym . SoftmaxOutput ( name = \\' cls _ prob \\' , data = cls_score , label = label , normalization = \\' valid \\' , grad_scale = 1.0 ) NEW_LINE bbox_loss_ = bbox_weight * mx . sym . smooth_l1 ( name = \\' bbox _ loss _ \\' , scalar = 1.0 , data = ( bbox_pred - bbox_target ) ) NEW_LINE bbox_loss = mx . sym . MakeLoss ( name = \\' bbox _ loss \\' , data = bbox_loss_ , grad_scale = 1.0 / cfg . TRAIN . BATCH_ROIS ) NEW_LINE DEDENT cls_prob = mx . sym . Reshape ( data = cls_prob , shape = ( cfg . TRAIN . BATCH_IMAGES , - 1 , num_classes ) , name = \\' cls _ prob _ reshape \\' ) NEW_LINE bbox_loss = mx . sym . Reshape ( data = bbox_loss , shape = ( cfg . TRAIN . BATCH_IMAGES , - 1 , 5 * num_reg_classes ) , name = \\' bbox _ loss _ reshape \\' ) NEW_LINE group = mx . sym . Group ( [ cls_prob , bbox_loss ] ) NEW_LINE DEDENT else : NEW_LINE INDENT cls_prob = mx . sym . SoftmaxActivation ( name = \\' cls _ prob \\' , data = cls_score ) NEW_LINE cls_prob = mx . sym . Reshape ( data = cls_prob , shape = ( cfg . TEST . BATCH_IMAGES , - 1 , num_classes ) , name = \\' cls _ prob _ reshape \\' ) NEW_LINE bbox_pred = mx . sym . Reshape ( data = bbox_pred , shape = ( cfg . TEST . BATCH_IMAGES , - 1 , 5 * num_reg_classes ) , name = \\' bbox _ pred _ reshape \\' ) NEW_LINE group = mx . sym . Group ( [ cls_prob , bbox_pred ] ) NEW_LINE DEDENT self . sym = group NEW_LINE return group NEW_LINE DEDENT',), (\"def init_weight_rcnn ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT arg_params [ ' fc _ new _ 1 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fc _ new _ 1 _ weight ' ] ) NEW_LINE arg_params [ ' fc _ new _ 1 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fc _ new _ 1 _ bias ' ] ) NEW_LINE arg_params [ ' cls _ score _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' cls _ score _ weight ' ] ) NEW_LINE arg_params [ ' cls _ score _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' cls _ score _ bias ' ] ) NEW_LINE arg_params [ ' bbox _ pred _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' bbox _ pred _ weight ' ] ) NEW_LINE arg_params [ ' bbox _ pred _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' bbox _ pred _ bias ' ] ) NEW_LINE DEDENT\",), (\"def init_weight_rpn ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT arg_params [ ' rpn _ conv _ 3x3 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' rpn _ conv _ 3x3 _ weight ' ] ) NEW_LINE arg_params [ ' rpn _ conv _ 3x3 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' rpn _ conv _ 3x3 _ bias ' ] ) NEW_LINE arg_params [ ' rpn _ cls _ score _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' rpn _ cls _ score _ weight ' ] ) NEW_LINE arg_params [ ' rpn _ cls _ score _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' rpn _ cls _ score _ bias ' ] ) NEW_LINE arg_params [ ' rpn _ bbox _ pred _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' rpn _ bbox _ pred _ weight ' ] ) NEW_LINE arg_params [ ' rpn _ bbox _ pred _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' rpn _ bbox _ pred _ bias ' ] ) NEW_LINE DEDENT\",), (\"def init_weight ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT self . init_weight_rpn ( cfg , arg_params , aux_params ) NEW_LINE self . init_weight_rcnn ( cfg , arg_params , aux_params ) NEW_LINE for name in self . shared_param_list : NEW_LINE INDENT arg_params [ name + ' _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ name + ' _ weight ' ] ) NEW_LINE arg_params [ name + ' _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ name + ' _ bias ' ] ) NEW_LINE DEDENT DEDENT\",), ('def __init__ ( self ) : NEW_LINE INDENT self . eps = 1e-5 NEW_LINE self . use_global_stats = True NEW_LINE self . workspace = 512 NEW_LINE self . units = ( 3 , 4 , 23 , 3 ) NEW_LINE self . filter_list = [ 256 , 512 , 1024 , 2048 ] NEW_LINE DEDENT',), (\"def get_resnet_v1_conv4 ( self , data ) : NEW_LINE INDENT conv1 = mx . symbol . Convolution ( name = ' conv1' , data = data , num_filter = 64 , pad = ( 3 , 3 ) , kernel = ( 7 , 7 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn_conv1 = mx . symbol . BatchNorm ( name = ' bn _ conv1' , data = conv1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale_conv1 = bn_conv1 NEW_LINE conv1_relu = mx . symbol . Activation ( name = ' conv1 _ relu ' , data = scale_conv1 , act_type = ' relu ' ) NEW_LINE pool1 = mx . symbol . Pooling ( name = ' pool1' , data = conv1_relu , pooling_convention = ' full ' , pad = ( 0 , 0 ) , kernel = ( 3 , 3 ) , stride = ( 2 , 2 ) , pool_type = ' max ' ) NEW_LINE res2a_branch1 = mx . symbol . Convolution ( name = ' res2a _ branch1' , data = pool1 , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch1 = mx . symbol . BatchNorm ( name = ' bn2a _ branch1' , data = res2a_branch1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2a_branch1 = bn2a_branch1 NEW_LINE res2a_branch2a = mx . symbol . Convolution ( name = ' res2a _ branch2a ' , data = pool1 , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2a = mx . symbol . BatchNorm ( name = ' bn2a _ branch2a ' , data = res2a_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2a_branch2a = bn2a_branch2a NEW_LINE res2a_branch2a_relu = mx . symbol . Activation ( name = ' res2a _ branch2a _ relu ' , data = scale2a_branch2a , act_type = ' relu ' ) NEW_LINE res2a_branch2b = mx . symbol . Convolution ( name = ' res2a _ branch2b ' , data = res2a_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2b = mx . symbol . BatchNorm ( name = ' bn2a _ branch2b ' , data = res2a_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2a_branch2b = bn2a_branch2b NEW_LINE res2a_branch2b_relu = mx . symbol . Activation ( name = ' res2a _ branch2b _ relu ' , data = scale2a_branch2b , act_type = ' relu ' ) NEW_LINE res2a_branch2c = mx . symbol . Convolution ( name = ' res2a _ branch2c ' , data = res2a_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2c = mx . symbol . BatchNorm ( name = ' bn2a _ branch2c ' , data = res2a_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2a_branch2c = bn2a_branch2c NEW_LINE res2a = mx . symbol . broadcast_add ( name = ' res2a ' , * [ scale2a_branch1 , scale2a_branch2c ] ) NEW_LINE res2a_relu = mx . symbol . Activation ( name = ' res2a _ relu ' , data = res2a , act_type = ' relu ' ) NEW_LINE res2b_branch2a = mx . symbol . Convolution ( name = ' res2b _ branch2a ' , data = res2a_relu , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2a = mx . symbol . BatchNorm ( name = ' bn2b _ branch2a ' , data = res2b_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2b_branch2a = bn2b_branch2a NEW_LINE res2b_branch2a_relu = mx . symbol . Activation ( name = ' res2b _ branch2a _ relu ' , data = scale2b_branch2a , act_type = ' relu ' ) NEW_LINE res2b_branch2b = mx . symbol . Convolution ( name = ' res2b _ branch2b ' , data = res2b_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2b = mx . symbol . BatchNorm ( name = ' bn2b _ branch2b ' , data = res2b_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2b_branch2b = bn2b_branch2b NEW_LINE res2b_branch2b_relu = mx . symbol . Activation ( name = ' res2b _ branch2b _ relu ' , data = scale2b_branch2b , act_type = ' relu ' ) NEW_LINE res2b_branch2c = mx . symbol . Convolution ( name = ' res2b _ branch2c ' , data = res2b_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2c = mx . symbol . BatchNorm ( name = ' bn2b _ branch2c ' , data = res2b_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2b_branch2c = bn2b_branch2c NEW_LINE res2b = mx . symbol . broadcast_add ( name = ' res2b ' , * [ res2a_relu , scale2b_branch2c ] ) NEW_LINE res2b_relu = mx . symbol . Activation ( name = ' res2b _ relu ' , data = res2b , act_type = ' relu ' ) NEW_LINE res2c_branch2a = mx . symbol . Convolution ( name = ' res2c _ branch2a ' , data = res2b_relu , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2a = mx . symbol . BatchNorm ( name = ' bn2c _ branch2a ' , data = res2c_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2c_branch2a = bn2c_branch2a NEW_LINE res2c_branch2a_relu = mx . symbol . Activation ( name = ' res2c _ branch2a _ relu ' , data = scale2c_branch2a , act_type = ' relu ' ) NEW_LINE res2c_branch2b = mx . symbol . Convolution ( name = ' res2c _ branch2b ' , data = res2c_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2b = mx . symbol . BatchNorm ( name = ' bn2c _ branch2b ' , data = res2c_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2c_branch2b = bn2c_branch2b NEW_LINE res2c_branch2b_relu = mx . symbol . Activation ( name = ' res2c _ branch2b _ relu ' , data = scale2c_branch2b , act_type = ' relu ' ) NEW_LINE res2c_branch2c = mx . symbol . Convolution ( name = ' res2c _ branch2c ' , data = res2c_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2c = mx . symbol . BatchNorm ( name = ' bn2c _ branch2c ' , data = res2c_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2c_branch2c = bn2c_branch2c NEW_LINE res2c = mx . symbol . broadcast_add ( name = ' res2c ' , * [ res2b_relu , scale2c_branch2c ] ) NEW_LINE res2c_relu = mx . symbol . Activation ( name = ' res2c _ relu ' , data = res2c , act_type = ' relu ' ) NEW_LINE res3a_branch1 = mx . symbol . Convolution ( name = ' res3a _ branch1' , data = res2c_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn3a_branch1 = mx . symbol . BatchNorm ( name = ' bn3a _ branch1' , data = res3a_branch1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3a_branch1 = bn3a_branch1 NEW_LINE res3a_branch2a = mx . symbol . Convolution ( name = ' res3a _ branch2a ' , data = res2c_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn3a_branch2a = mx . symbol . BatchNorm ( name = ' bn3a _ branch2a ' , data = res3a_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3a_branch2a = bn3a_branch2a NEW_LINE res3a_branch2a_relu = mx . symbol . Activation ( name = ' res3a _ branch2a _ relu ' , data = scale3a_branch2a , act_type = ' relu ' ) NEW_LINE res3a_branch2b = mx . symbol . Convolution ( name = ' res3a _ branch2b ' , data = res3a_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3a_branch2b = mx . symbol . BatchNorm ( name = ' bn3a _ branch2b ' , data = res3a_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3a_branch2b = bn3a_branch2b NEW_LINE res3a_branch2b_relu = mx . symbol . Activation ( name = ' res3a _ branch2b _ relu ' , data = scale3a_branch2b , act_type = ' relu ' ) NEW_LINE res3a_branch2c = mx . symbol . Convolution ( name = ' res3a _ branch2c ' , data = res3a_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3a_branch2c = mx . symbol . BatchNorm ( name = ' bn3a _ branch2c ' , data = res3a_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3a_branch2c = bn3a_branch2c NEW_LINE res3a = mx . symbol . broadcast_add ( name = ' res3a ' , * [ scale3a_branch1 , scale3a_branch2c ] ) NEW_LINE res3a_relu = mx . symbol . Activation ( name = ' res3a _ relu ' , data = res3a , act_type = ' relu ' ) NEW_LINE res3b1_branch2a = mx . symbol . Convolution ( name = ' res3b1 _ branch2a ' , data = res3a_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2a = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2a ' , data = res3b1_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b1_branch2a = bn3b1_branch2a NEW_LINE res3b1_branch2a_relu = mx . symbol . Activation ( name = ' res3b1 _ branch2a _ relu ' , data = scale3b1_branch2a , act_type = ' relu ' ) NEW_LINE res3b1_branch2b = mx . symbol . Convolution ( name = ' res3b1 _ branch2b ' , data = res3b1_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2b = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2b ' , data = res3b1_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b1_branch2b = bn3b1_branch2b NEW_LINE res3b1_branch2b_relu = mx . symbol . Activation ( name = ' res3b1 _ branch2b _ relu ' , data = scale3b1_branch2b , act_type = ' relu ' ) NEW_LINE res3b1_branch2c = mx . symbol . Convolution ( name = ' res3b1 _ branch2c ' , data = res3b1_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2c = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2c ' , data = res3b1_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b1_branch2c = bn3b1_branch2c NEW_LINE res3b1 = mx . symbol . broadcast_add ( name = ' res3b1' , * [ res3a_relu , scale3b1_branch2c ] ) NEW_LINE res3b1_relu = mx . symbol . Activation ( name = ' res3b1 _ relu ' , data = res3b1 , act_type = ' relu ' ) NEW_LINE res3b2_branch2a = mx . symbol . Convolution ( name = ' res3b2 _ branch2a ' , data = res3b1_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2a = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2a ' , data = res3b2_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b2_branch2a = bn3b2_branch2a NEW_LINE res3b2_branch2a_relu = mx . symbol . Activation ( name = ' res3b2 _ branch2a _ relu ' , data = scale3b2_branch2a , act_type = ' relu ' ) NEW_LINE res3b2_branch2b = mx . symbol . Convolution ( name = ' res3b2 _ branch2b ' , data = res3b2_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2b = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2b ' , data = res3b2_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b2_branch2b = bn3b2_branch2b NEW_LINE res3b2_branch2b_relu = mx . symbol . Activation ( name = ' res3b2 _ branch2b _ relu ' , data = scale3b2_branch2b , act_type = ' relu ' ) NEW_LINE res3b2_branch2c = mx . symbol . Convolution ( name = ' res3b2 _ branch2c ' , data = res3b2_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2c = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2c ' , data = res3b2_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b2_branch2c = bn3b2_branch2c NEW_LINE res3b2 = mx . symbol . broadcast_add ( name = ' res3b2' , * [ res3b1_relu , scale3b2_branch2c ] ) NEW_LINE res3b2_relu = mx . symbol . Activation ( name = ' res3b2 _ relu ' , data = res3b2 , act_type = ' relu ' ) NEW_LINE res3b3_branch2a = mx . symbol . Convolution ( name = ' res3b3 _ branch2a ' , data = res3b2_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b3_branch2a = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2a ' , data = res3b3_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b3_branch2a = bn3b3_branch2a NEW_LINE res3b3_branch2a_relu = mx . symbol . Activation ( name = ' res3b3 _ branch2a _ relu ' , data = scale3b3_branch2a , act_type = ' relu ' ) NEW_LINE res3b3_branch2b = mx . symbol . Convolution ( name = ' res3b3 _ branch2b ' , data = res3b3_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b3_branch2b = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2b ' , data = res3b3_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b3_branch2b = bn3b3_branch2b NEW_LINE res3b3_branch2b_relu = mx . symbol . Activation ( name = ' res3b3 _ branch2b _ relu ' , data = scale3b3_branch2b , act_type = ' relu ' ) NEW_LINE res3b3_branch2c = mx . symbol . Convolution ( name = ' res3b3 _ branch2c ' , data = res3b3_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b3_branch2c = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2c ' , data = res3b3_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b3_branch2c = bn3b3_branch2c NEW_LINE res3b3 = mx . symbol . broadcast_add ( name = ' res3b3' , * [ res3b2_relu , scale3b3_branch2c ] ) NEW_LINE res3b3_relu = mx . symbol . Activation ( name = ' res3b3 _ relu ' , data = res3b3 , act_type = ' relu ' ) NEW_LINE res4a_branch1 = mx . symbol . Convolution ( name = ' res4a _ branch1' , data = res3b3_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn4a_branch1 = mx . symbol . BatchNorm ( name = ' bn4a _ branch1' , data = res4a_branch1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4a_branch1 = bn4a_branch1 NEW_LINE res4a_branch2a = mx . symbol . Convolution ( name = ' res4a _ branch2a ' , data = res3b3_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn4a_branch2a = mx . symbol . BatchNorm ( name = ' bn4a _ branch2a ' , data = res4a_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4a_branch2a = bn4a_branch2a NEW_LINE res4a_branch2a_relu = mx . symbol . Activation ( name = ' res4a _ branch2a _ relu ' , data = scale4a_branch2a , act_type = ' relu ' ) NEW_LINE res4a_branch2b = mx . symbol . Convolution ( name = ' res4a _ branch2b ' , data = res4a_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4a_branch2b = mx . symbol . BatchNorm ( name = ' bn4a _ branch2b ' , data = res4a_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4a_branch2b = bn4a_branch2b NEW_LINE res4a_branch2b_relu = mx . symbol . Activation ( name = ' res4a _ branch2b _ relu ' , data = scale4a_branch2b , act_type = ' relu ' ) NEW_LINE res4a_branch2c = mx . symbol . Convolution ( name = ' res4a _ branch2c ' , data = res4a_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4a_branch2c = mx . symbol . BatchNorm ( name = ' bn4a _ branch2c ' , data = res4a_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4a_branch2c = bn4a_branch2c NEW_LINE res4a = mx . symbol . broadcast_add ( name = ' res4a ' , * [ scale4a_branch1 , scale4a_branch2c ] ) NEW_LINE res4a_relu = mx . symbol . Activation ( name = ' res4a _ relu ' , data = res4a , act_type = ' relu ' ) NEW_LINE res4b1_branch2a = mx . symbol . Convolution ( name = ' res4b1 _ branch2a ' , data = res4a_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2a = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2a ' , data = res4b1_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b1_branch2a = bn4b1_branch2a NEW_LINE res4b1_branch2a_relu = mx . symbol . Activation ( name = ' res4b1 _ branch2a _ relu ' , data = scale4b1_branch2a , act_type = ' relu ' ) NEW_LINE res4b1_branch2b = mx . symbol . Convolution ( name = ' res4b1 _ branch2b ' , data = res4b1_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2b = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2b ' , data = res4b1_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b1_branch2b = bn4b1_branch2b NEW_LINE res4b1_branch2b_relu = mx . symbol . Activation ( name = ' res4b1 _ branch2b _ relu ' , data = scale4b1_branch2b , act_type = ' relu ' ) NEW_LINE res4b1_branch2c = mx . symbol . Convolution ( name = ' res4b1 _ branch2c ' , data = res4b1_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2c = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2c ' , data = res4b1_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b1_branch2c = bn4b1_branch2c NEW_LINE res4b1 = mx . symbol . broadcast_add ( name = ' res4b1' , * [ res4a_relu , scale4b1_branch2c ] ) NEW_LINE res4b1_relu = mx . symbol . Activation ( name = ' res4b1 _ relu ' , data = res4b1 , act_type = ' relu ' ) NEW_LINE res4b2_branch2a = mx . symbol . Convolution ( name = ' res4b2 _ branch2a ' , data = res4b1_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2a = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2a ' , data = res4b2_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b2_branch2a = bn4b2_branch2a NEW_LINE res4b2_branch2a_relu = mx . symbol . Activation ( name = ' res4b2 _ branch2a _ relu ' , data = scale4b2_branch2a , act_type = ' relu ' ) NEW_LINE res4b2_branch2b = mx . symbol . Convolution ( name = ' res4b2 _ branch2b ' , data = res4b2_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2b = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2b ' , data = res4b2_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b2_branch2b = bn4b2_branch2b NEW_LINE res4b2_branch2b_relu = mx . symbol . Activation ( name = ' res4b2 _ branch2b _ relu ' , data = scale4b2_branch2b , act_type = ' relu ' ) NEW_LINE res4b2_branch2c = mx . symbol . Convolution ( name = ' res4b2 _ branch2c ' , data = res4b2_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2c = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2c ' , data = res4b2_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b2_branch2c = bn4b2_branch2c NEW_LINE res4b2 = mx . symbol . broadcast_add ( name = ' res4b2' , * [ res4b1_relu , scale4b2_branch2c ] ) NEW_LINE res4b2_relu = mx . symbol . Activation ( name = ' res4b2 _ relu ' , data = res4b2 , act_type = ' relu ' ) NEW_LINE res4b3_branch2a = mx . symbol . Convolution ( name = ' res4b3 _ branch2a ' , data = res4b2_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2a = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2a ' , data = res4b3_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b3_branch2a = bn4b3_branch2a NEW_LINE res4b3_branch2a_relu = mx . symbol . Activation ( name = ' res4b3 _ branch2a _ relu ' , data = scale4b3_branch2a , act_type = ' relu ' ) NEW_LINE res4b3_branch2b = mx . symbol . Convolution ( name = ' res4b3 _ branch2b ' , data = res4b3_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2b = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2b ' , data = res4b3_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b3_branch2b = bn4b3_branch2b NEW_LINE res4b3_branch2b_relu = mx . symbol . Activation ( name = ' res4b3 _ branch2b _ relu ' , data = scale4b3_branch2b , act_type = ' relu ' ) NEW_LINE res4b3_branch2c = mx . symbol . Convolution ( name = ' res4b3 _ branch2c ' , data = res4b3_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2c = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2c ' , data = res4b3_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b3_branch2c = bn4b3_branch2c NEW_LINE res4b3 = mx . symbol . broadcast_add ( name = ' res4b3' , * [ res4b2_relu , scale4b3_branch2c ] ) NEW_LINE res4b3_relu = mx . symbol . Activation ( name = ' res4b3 _ relu ' , data = res4b3 , act_type = ' relu ' ) NEW_LINE res4b4_branch2a = mx . symbol . Convolution ( name = ' res4b4 _ branch2a ' , data = res4b3_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2a = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2a ' , data = res4b4_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b4_branch2a = bn4b4_branch2a NEW_LINE res4b4_branch2a_relu = mx . symbol . Activation ( name = ' res4b4 _ branch2a _ relu ' , data = scale4b4_branch2a , act_type = ' relu ' ) NEW_LINE res4b4_branch2b = mx . symbol . Convolution ( name = ' res4b4 _ branch2b ' , data = res4b4_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2b = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2b ' , data = res4b4_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b4_branch2b = bn4b4_branch2b NEW_LINE res4b4_branch2b_relu = mx . symbol . Activation ( name = ' res4b4 _ branch2b _ relu ' , data = scale4b4_branch2b , act_type = ' relu ' ) NEW_LINE res4b4_branch2c = mx . symbol . Convolution ( name = ' res4b4 _ branch2c ' , data = res4b4_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2c = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2c ' , data = res4b4_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b4_branch2c = bn4b4_branch2c NEW_LINE res4b4 = mx . symbol . broadcast_add ( name = ' res4b4' , * [ res4b3_relu , scale4b4_branch2c ] ) NEW_LINE res4b4_relu = mx . symbol . Activation ( name = ' res4b4 _ relu ' , data = res4b4 , act_type = ' relu ' ) NEW_LINE res4b5_branch2a = mx . symbol . Convolution ( name = ' res4b5 _ branch2a ' , data = res4b4_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2a = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2a ' , data = res4b5_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b5_branch2a = bn4b5_branch2a NEW_LINE res4b5_branch2a_relu = mx . symbol . Activation ( name = ' res4b5 _ branch2a _ relu ' , data = scale4b5_branch2a , act_type = ' relu ' ) NEW_LINE res4b5_branch2b = mx . symbol . Convolution ( name = ' res4b5 _ branch2b ' , data = res4b5_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2b = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2b ' , data = res4b5_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b5_branch2b = bn4b5_branch2b NEW_LINE res4b5_branch2b_relu = mx . symbol . Activation ( name = ' res4b5 _ branch2b _ relu ' , data = scale4b5_branch2b , act_type = ' relu ' ) NEW_LINE res4b5_branch2c = mx . symbol . Convolution ( name = ' res4b5 _ branch2c ' , data = res4b5_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2c = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2c ' , data = res4b5_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b5_branch2c = bn4b5_branch2c NEW_LINE res4b5 = mx . symbol . broadcast_add ( name = ' res4b5' , * [ res4b4_relu , scale4b5_branch2c ] ) NEW_LINE res4b5_relu = mx . symbol . Activation ( name = ' res4b5 _ relu ' , data = res4b5 , act_type = ' relu ' ) NEW_LINE res4b6_branch2a = mx . symbol . Convolution ( name = ' res4b6 _ branch2a ' , data = res4b5_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2a = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2a ' , data = res4b6_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b6_branch2a = bn4b6_branch2a NEW_LINE res4b6_branch2a_relu = mx . symbol . Activation ( name = ' res4b6 _ branch2a _ relu ' , data = scale4b6_branch2a , act_type = ' relu ' ) NEW_LINE res4b6_branch2b = mx . symbol . Convolution ( name = ' res4b6 _ branch2b ' , data = res4b6_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2b = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2b ' , data = res4b6_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b6_branch2b = bn4b6_branch2b NEW_LINE res4b6_branch2b_relu = mx . symbol . Activation ( name = ' res4b6 _ branch2b _ relu ' , data = scale4b6_branch2b , act_type = ' relu ' ) NEW_LINE res4b6_branch2c = mx . symbol . Convolution ( name = ' res4b6 _ branch2c ' , data = res4b6_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2c = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2c ' , data = res4b6_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b6_branch2c = bn4b6_branch2c NEW_LINE res4b6 = mx . symbol . broadcast_add ( name = ' res4b6' , * [ res4b5_relu , scale4b6_branch2c ] ) NEW_LINE res4b6_relu = mx . symbol . Activation ( name = ' res4b6 _ relu ' , data = res4b6 , act_type = ' relu ' ) NEW_LINE res4b7_branch2a = mx . symbol . Convolution ( name = ' res4b7 _ branch2a ' , data = res4b6_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2a = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2a ' , data = res4b7_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b7_branch2a = bn4b7_branch2a NEW_LINE res4b7_branch2a_relu = mx . symbol . Activation ( name = ' res4b7 _ branch2a _ relu ' , data = scale4b7_branch2a , act_type = ' relu ' ) NEW_LINE res4b7_branch2b = mx . symbol . Convolution ( name = ' res4b7 _ branch2b ' , data = res4b7_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2b = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2b ' , data = res4b7_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b7_branch2b = bn4b7_branch2b NEW_LINE res4b7_branch2b_relu = mx . symbol . Activation ( name = ' res4b7 _ branch2b _ relu ' , data = scale4b7_branch2b , act_type = ' relu ' ) NEW_LINE res4b7_branch2c = mx . symbol . Convolution ( name = ' res4b7 _ branch2c ' , data = res4b7_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2c = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2c ' , data = res4b7_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b7_branch2c = bn4b7_branch2c NEW_LINE res4b7 = mx . symbol . broadcast_add ( name = ' res4b7' , * [ res4b6_relu , scale4b7_branch2c ] ) NEW_LINE res4b7_relu = mx . symbol . Activation ( name = ' res4b7 _ relu ' , data = res4b7 , act_type = ' relu ' ) NEW_LINE res4b8_branch2a = mx . symbol . Convolution ( name = ' res4b8 _ branch2a ' , data = res4b7_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2a = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2a ' , data = res4b8_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b8_branch2a = bn4b8_branch2a NEW_LINE res4b8_branch2a_relu = mx . symbol . Activation ( name = ' res4b8 _ branch2a _ relu ' , data = scale4b8_branch2a , act_type = ' relu ' ) NEW_LINE res4b8_branch2b = mx . symbol . Convolution ( name = ' res4b8 _ branch2b ' , data = res4b8_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2b = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2b ' , data = res4b8_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b8_branch2b = bn4b8_branch2b NEW_LINE res4b8_branch2b_relu = mx . symbol . Activation ( name = ' res4b8 _ branch2b _ relu ' , data = scale4b8_branch2b , act_type = ' relu ' ) NEW_LINE res4b8_branch2c = mx . symbol . Convolution ( name = ' res4b8 _ branch2c ' , data = res4b8_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2c = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2c ' , data = res4b8_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b8_branch2c = bn4b8_branch2c NEW_LINE res4b8 = mx . symbol . broadcast_add ( name = ' res4b8' , * [ res4b7_relu , scale4b8_branch2c ] ) NEW_LINE res4b8_relu = mx . symbol . Activation ( name = ' res4b8 _ relu ' , data = res4b8 , act_type = ' relu ' ) NEW_LINE res4b9_branch2a = mx . symbol . Convolution ( name = ' res4b9 _ branch2a ' , data = res4b8_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2a = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2a ' , data = res4b9_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b9_branch2a = bn4b9_branch2a NEW_LINE res4b9_branch2a_relu = mx . symbol . Activation ( name = ' res4b9 _ branch2a _ relu ' , data = scale4b9_branch2a , act_type = ' relu ' ) NEW_LINE res4b9_branch2b = mx . symbol . Convolution ( name = ' res4b9 _ branch2b ' , data = res4b9_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2b = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2b ' , data = res4b9_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b9_branch2b = bn4b9_branch2b NEW_LINE res4b9_branch2b_relu = mx . symbol . Activation ( name = ' res4b9 _ branch2b _ relu ' , data = scale4b9_branch2b , act_type = ' relu ' ) NEW_LINE res4b9_branch2c = mx . symbol . Convolution ( name = ' res4b9 _ branch2c ' , data = res4b9_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2c = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2c ' , data = res4b9_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b9_branch2c = bn4b9_branch2c NEW_LINE res4b9 = mx . symbol . broadcast_add ( name = ' res4b9' , * [ res4b8_relu , scale4b9_branch2c ] ) NEW_LINE res4b9_relu = mx . symbol . Activation ( name = ' res4b9 _ relu ' , data = res4b9 , act_type = ' relu ' ) NEW_LINE res4b10_branch2a = mx . symbol . Convolution ( name = ' res4b10 _ branch2a ' , data = res4b9_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2a = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2a ' , data = res4b10_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b10_branch2a = bn4b10_branch2a NEW_LINE res4b10_branch2a_relu = mx . symbol . Activation ( name = ' res4b10 _ branch2a _ relu ' , data = scale4b10_branch2a , act_type = ' relu ' ) NEW_LINE res4b10_branch2b = mx . symbol . Convolution ( name = ' res4b10 _ branch2b ' , data = res4b10_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2b = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2b ' , data = res4b10_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b10_branch2b = bn4b10_branch2b NEW_LINE res4b10_branch2b_relu = mx . symbol . Activation ( name = ' res4b10 _ branch2b _ relu ' , data = scale4b10_branch2b , act_type = ' relu ' ) NEW_LINE res4b10_branch2c = mx . symbol . Convolution ( name = ' res4b10 _ branch2c ' , data = res4b10_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2c = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2c ' , data = res4b10_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b10_branch2c = bn4b10_branch2c NEW_LINE res4b10 = mx . symbol . broadcast_add ( name = ' res4b10' , * [ res4b9_relu , scale4b10_branch2c ] ) NEW_LINE res4b10_relu = mx . symbol . Activation ( name = ' res4b10 _ relu ' , data = res4b10 , act_type = ' relu ' ) NEW_LINE res4b11_branch2a = mx . symbol . Convolution ( name = ' res4b11 _ branch2a ' , data = res4b10_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2a = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2a ' , data = res4b11_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b11_branch2a = bn4b11_branch2a NEW_LINE res4b11_branch2a_relu = mx . symbol . Activation ( name = ' res4b11 _ branch2a _ relu ' , data = scale4b11_branch2a , act_type = ' relu ' ) NEW_LINE res4b11_branch2b = mx . symbol . Convolution ( name = ' res4b11 _ branch2b ' , data = res4b11_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2b = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2b ' , data = res4b11_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b11_branch2b = bn4b11_branch2b NEW_LINE res4b11_branch2b_relu = mx . symbol . Activation ( name = ' res4b11 _ branch2b _ relu ' , data = scale4b11_branch2b , act_type = ' relu ' ) NEW_LINE res4b11_branch2c = mx . symbol . Convolution ( name = ' res4b11 _ branch2c ' , data = res4b11_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2c = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2c ' , data = res4b11_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b11_branch2c = bn4b11_branch2c NEW_LINE res4b11 = mx . symbol . broadcast_add ( name = ' res4b11' , * [ res4b10_relu , scale4b11_branch2c ] ) NEW_LINE res4b11_relu = mx . symbol . Activation ( name = ' res4b11 _ relu ' , data = res4b11 , act_type = ' relu ' ) NEW_LINE res4b12_branch2a = mx . symbol . Convolution ( name = ' res4b12 _ branch2a ' , data = res4b11_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2a = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2a ' , data = res4b12_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b12_branch2a = bn4b12_branch2a NEW_LINE res4b12_branch2a_relu = mx . symbol . Activation ( name = ' res4b12 _ branch2a _ relu ' , data = scale4b12_branch2a , act_type = ' relu ' ) NEW_LINE res4b12_branch2b = mx . symbol . Convolution ( name = ' res4b12 _ branch2b ' , data = res4b12_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2b = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2b ' , data = res4b12_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b12_branch2b = bn4b12_branch2b NEW_LINE res4b12_branch2b_relu = mx . symbol . Activation ( name = ' res4b12 _ branch2b _ relu ' , data = scale4b12_branch2b , act_type = ' relu ' ) NEW_LINE res4b12_branch2c = mx . symbol . Convolution ( name = ' res4b12 _ branch2c ' , data = res4b12_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2c = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2c ' , data = res4b12_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b12_branch2c = bn4b12_branch2c NEW_LINE res4b12 = mx . symbol . broadcast_add ( name = ' res4b12' , * [ res4b11_relu , scale4b12_branch2c ] ) NEW_LINE res4b12_relu = mx . symbol . Activation ( name = ' res4b12 _ relu ' , data = res4b12 , act_type = ' relu ' ) NEW_LINE res4b13_branch2a = mx . symbol . Convolution ( name = ' res4b13 _ branch2a ' , data = res4b12_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2a = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2a ' , data = res4b13_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b13_branch2a = bn4b13_branch2a NEW_LINE res4b13_branch2a_relu = mx . symbol . Activation ( name = ' res4b13 _ branch2a _ relu ' , data = scale4b13_branch2a , act_type = ' relu ' ) NEW_LINE res4b13_branch2b = mx . symbol . Convolution ( name = ' res4b13 _ branch2b ' , data = res4b13_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2b = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2b ' , data = res4b13_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b13_branch2b = bn4b13_branch2b NEW_LINE res4b13_branch2b_relu = mx . symbol . Activation ( name = ' res4b13 _ branch2b _ relu ' , data = scale4b13_branch2b , act_type = ' relu ' ) NEW_LINE res4b13_branch2c = mx . symbol . Convolution ( name = ' res4b13 _ branch2c ' , data = res4b13_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2c = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2c ' , data = res4b13_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b13_branch2c = bn4b13_branch2c NEW_LINE res4b13 = mx . symbol . broadcast_add ( name = ' res4b13' , * [ res4b12_relu , scale4b13_branch2c ] ) NEW_LINE res4b13_relu = mx . symbol . Activation ( name = ' res4b13 _ relu ' , data = res4b13 , act_type = ' relu ' ) NEW_LINE res4b14_branch2a = mx . symbol . Convolution ( name = ' res4b14 _ branch2a ' , data = res4b13_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2a = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2a ' , data = res4b14_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b14_branch2a = bn4b14_branch2a NEW_LINE res4b14_branch2a_relu = mx . symbol . Activation ( name = ' res4b14 _ branch2a _ relu ' , data = scale4b14_branch2a , act_type = ' relu ' ) NEW_LINE res4b14_branch2b = mx . symbol . Convolution ( name = ' res4b14 _ branch2b ' , data = res4b14_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2b = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2b ' , data = res4b14_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b14_branch2b = bn4b14_branch2b NEW_LINE res4b14_branch2b_relu = mx . symbol . Activation ( name = ' res4b14 _ branch2b _ relu ' , data = scale4b14_branch2b , act_type = ' relu ' ) NEW_LINE res4b14_branch2c = mx . symbol . Convolution ( name = ' res4b14 _ branch2c ' , data = res4b14_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2c = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2c ' , data = res4b14_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b14_branch2c = bn4b14_branch2c NEW_LINE res4b14 = mx . symbol . broadcast_add ( name = ' res4b14' , * [ res4b13_relu , scale4b14_branch2c ] ) NEW_LINE res4b14_relu = mx . symbol . Activation ( name = ' res4b14 _ relu ' , data = res4b14 , act_type = ' relu ' ) NEW_LINE res4b15_branch2a = mx . symbol . Convolution ( name = ' res4b15 _ branch2a ' , data = res4b14_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2a = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2a ' , data = res4b15_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b15_branch2a = bn4b15_branch2a NEW_LINE res4b15_branch2a_relu = mx . symbol . Activation ( name = ' res4b15 _ branch2a _ relu ' , data = scale4b15_branch2a , act_type = ' relu ' ) NEW_LINE res4b15_branch2b = mx . symbol . Convolution ( name = ' res4b15 _ branch2b ' , data = res4b15_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2b = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2b ' , data = res4b15_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b15_branch2b = bn4b15_branch2b NEW_LINE res4b15_branch2b_relu = mx . symbol . Activation ( name = ' res4b15 _ branch2b _ relu ' , data = scale4b15_branch2b , act_type = ' relu ' ) NEW_LINE res4b15_branch2c = mx . symbol . Convolution ( name = ' res4b15 _ branch2c ' , data = res4b15_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2c = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2c ' , data = res4b15_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b15_branch2c = bn4b15_branch2c NEW_LINE res4b15 = mx . symbol . broadcast_add ( name = ' res4b15' , * [ res4b14_relu , scale4b15_branch2c ] ) NEW_LINE res4b15_relu = mx . symbol . Activation ( name = ' res4b15 _ relu ' , data = res4b15 , act_type = ' relu ' ) NEW_LINE res4b16_branch2a = mx . symbol . Convolution ( name = ' res4b16 _ branch2a ' , data = res4b15_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2a = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2a ' , data = res4b16_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b16_branch2a = bn4b16_branch2a NEW_LINE res4b16_branch2a_relu = mx . symbol . Activation ( name = ' res4b16 _ branch2a _ relu ' , data = scale4b16_branch2a , act_type = ' relu ' ) NEW_LINE res4b16_branch2b = mx . symbol . Convolution ( name = ' res4b16 _ branch2b ' , data = res4b16_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2b = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2b ' , data = res4b16_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b16_branch2b = bn4b16_branch2b NEW_LINE res4b16_branch2b_relu = mx . symbol . Activation ( name = ' res4b16 _ branch2b _ relu ' , data = scale4b16_branch2b , act_type = ' relu ' ) NEW_LINE res4b16_branch2c = mx . symbol . Convolution ( name = ' res4b16 _ branch2c ' , data = res4b16_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2c = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2c ' , data = res4b16_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b16_branch2c = bn4b16_branch2c NEW_LINE res4b16 = mx . symbol . broadcast_add ( name = ' res4b16' , * [ res4b15_relu , scale4b16_branch2c ] ) NEW_LINE res4b16_relu = mx . symbol . Activation ( name = ' res4b16 _ relu ' , data = res4b16 , act_type = ' relu ' ) NEW_LINE res4b17_branch2a = mx . symbol . Convolution ( name = ' res4b17 _ branch2a ' , data = res4b16_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2a = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2a ' , data = res4b17_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b17_branch2a = bn4b17_branch2a NEW_LINE res4b17_branch2a_relu = mx . symbol . Activation ( name = ' res4b17 _ branch2a _ relu ' , data = scale4b17_branch2a , act_type = ' relu ' ) NEW_LINE res4b17_branch2b = mx . symbol . Convolution ( name = ' res4b17 _ branch2b ' , data = res4b17_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2b = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2b ' , data = res4b17_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b17_branch2b = bn4b17_branch2b NEW_LINE res4b17_branch2b_relu = mx . symbol . Activation ( name = ' res4b17 _ branch2b _ relu ' , data = scale4b17_branch2b , act_type = ' relu ' ) NEW_LINE res4b17_branch2c = mx . symbol . Convolution ( name = ' res4b17 _ branch2c ' , data = res4b17_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2c = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2c ' , data = res4b17_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b17_branch2c = bn4b17_branch2c NEW_LINE res4b17 = mx . symbol . broadcast_add ( name = ' res4b17' , * [ res4b16_relu , scale4b17_branch2c ] ) NEW_LINE res4b17_relu = mx . symbol . Activation ( name = ' res4b17 _ relu ' , data = res4b17 , act_type = ' relu ' ) NEW_LINE res4b18_branch2a = mx . symbol . Convolution ( name = ' res4b18 _ branch2a ' , data = res4b17_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2a = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2a ' , data = res4b18_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b18_branch2a = bn4b18_branch2a NEW_LINE res4b18_branch2a_relu = mx . symbol . Activation ( name = ' res4b18 _ branch2a _ relu ' , data = scale4b18_branch2a , act_type = ' relu ' ) NEW_LINE res4b18_branch2b = mx . symbol . Convolution ( name = ' res4b18 _ branch2b ' , data = res4b18_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2b = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2b ' , data = res4b18_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b18_branch2b = bn4b18_branch2b NEW_LINE res4b18_branch2b_relu = mx . symbol . Activation ( name = ' res4b18 _ branch2b _ relu ' , data = scale4b18_branch2b , act_type = ' relu ' ) NEW_LINE res4b18_branch2c = mx . symbol . Convolution ( name = ' res4b18 _ branch2c ' , data = res4b18_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2c = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2c ' , data = res4b18_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b18_branch2c = bn4b18_branch2c NEW_LINE res4b18 = mx . symbol . broadcast_add ( name = ' res4b18' , * [ res4b17_relu , scale4b18_branch2c ] ) NEW_LINE res4b18_relu = mx . symbol . Activation ( name = ' res4b18 _ relu ' , data = res4b18 , act_type = ' relu ' ) NEW_LINE res4b19_branch2a = mx . symbol . Convolution ( name = ' res4b19 _ branch2a ' , data = res4b18_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2a = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2a ' , data = res4b19_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b19_branch2a = bn4b19_branch2a NEW_LINE res4b19_branch2a_relu = mx . symbol . Activation ( name = ' res4b19 _ branch2a _ relu ' , data = scale4b19_branch2a , act_type = ' relu ' ) NEW_LINE res4b19_branch2b = mx . symbol . Convolution ( name = ' res4b19 _ branch2b ' , data = res4b19_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2b = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2b ' , data = res4b19_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b19_branch2b = bn4b19_branch2b NEW_LINE res4b19_branch2b_relu = mx . symbol . Activation ( name = ' res4b19 _ branch2b _ relu ' , data = scale4b19_branch2b , act_type = ' relu ' ) NEW_LINE res4b19_branch2c = mx . symbol . Convolution ( name = ' res4b19 _ branch2c ' , data = res4b19_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2c = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2c ' , data = res4b19_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b19_branch2c = bn4b19_branch2c NEW_LINE res4b19 = mx . symbol . broadcast_add ( name = ' res4b19' , * [ res4b18_relu , scale4b19_branch2c ] ) NEW_LINE res4b19_relu = mx . symbol . Activation ( name = ' res4b19 _ relu ' , data = res4b19 , act_type = ' relu ' ) NEW_LINE res4b20_branch2a = mx . symbol . Convolution ( name = ' res4b20 _ branch2a ' , data = res4b19_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2a = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2a ' , data = res4b20_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b20_branch2a = bn4b20_branch2a NEW_LINE res4b20_branch2a_relu = mx . symbol . Activation ( name = ' res4b20 _ branch2a _ relu ' , data = scale4b20_branch2a , act_type = ' relu ' ) NEW_LINE res4b20_branch2b = mx . symbol . Convolution ( name = ' res4b20 _ branch2b ' , data = res4b20_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2b = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2b ' , data = res4b20_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b20_branch2b = bn4b20_branch2b NEW_LINE res4b20_branch2b_relu = mx . symbol . Activation ( name = ' res4b20 _ branch2b _ relu ' , data = scale4b20_branch2b , act_type = ' relu ' ) NEW_LINE res4b20_branch2c = mx . symbol . Convolution ( name = ' res4b20 _ branch2c ' , data = res4b20_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2c = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2c ' , data = res4b20_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b20_branch2c = bn4b20_branch2c NEW_LINE res4b20 = mx . symbol . broadcast_add ( name = ' res4b20' , * [ res4b19_relu , scale4b20_branch2c ] ) NEW_LINE res4b20_relu = mx . symbol . Activation ( name = ' res4b20 _ relu ' , data = res4b20 , act_type = ' relu ' ) NEW_LINE res4b21_branch2a = mx . symbol . Convolution ( name = ' res4b21 _ branch2a ' , data = res4b20_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2a = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2a ' , data = res4b21_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b21_branch2a = bn4b21_branch2a NEW_LINE res4b21_branch2a_relu = mx . symbol . Activation ( name = ' res4b21 _ branch2a _ relu ' , data = scale4b21_branch2a , act_type = ' relu ' ) NEW_LINE res4b21_branch2b = mx . symbol . Convolution ( name = ' res4b21 _ branch2b ' , data = res4b21_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2b = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2b ' , data = res4b21_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b21_branch2b = bn4b21_branch2b NEW_LINE res4b21_branch2b_relu = mx . symbol . Activation ( name = ' res4b21 _ branch2b _ relu ' , data = scale4b21_branch2b , act_type = ' relu ' ) NEW_LINE res4b21_branch2c = mx . symbol . Convolution ( name = ' res4b21 _ branch2c ' , data = res4b21_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2c = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2c ' , data = res4b21_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b21_branch2c = bn4b21_branch2c NEW_LINE res4b21 = mx . symbol . broadcast_add ( name = ' res4b21' , * [ res4b20_relu , scale4b21_branch2c ] ) NEW_LINE res4b21_relu = mx . symbol . Activation ( name = ' res4b21 _ relu ' , data = res4b21 , act_type = ' relu ' ) NEW_LINE res4b22_branch2a = mx . symbol . Convolution ( name = ' res4b22 _ branch2a ' , data = res4b21_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b22_branch2a = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2a ' , data = res4b22_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b22_branch2a = bn4b22_branch2a NEW_LINE res4b22_branch2a_relu = mx . symbol . Activation ( name = ' res4b22 _ branch2a _ relu ' , data = scale4b22_branch2a , act_type = ' relu ' ) NEW_LINE res4b22_branch2b = mx . symbol . Convolution ( name = ' res4b22 _ branch2b ' , data = res4b22_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b22_branch2b = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2b ' , data = res4b22_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b22_branch2b = bn4b22_branch2b NEW_LINE res4b22_branch2b_relu = mx . symbol . Activation ( name = ' res4b22 _ branch2b _ relu ' , data = scale4b22_branch2b , act_type = ' relu ' ) NEW_LINE res4b22_branch2c = mx . symbol . Convolution ( name = ' res4b22 _ branch2c ' , data = res4b22_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b22_branch2c = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2c ' , data = res4b22_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b22_branch2c = bn4b22_branch2c NEW_LINE res4b22 = mx . symbol . broadcast_add ( name = ' res4b22' , * [ res4b21_relu , scale4b22_branch2c ] ) NEW_LINE res4b22_relu = mx . symbol . Activation ( name = ' res4b22 _ relu ' , data = res4b22 , act_type = ' relu ' ) NEW_LINE return res4b22_relu NEW_LINE DEDENT\",), (\"def get_resnet_v1_conv5 ( self , conv_feat ) : NEW_LINE INDENT res5a_branch1 = mx . symbol . Convolution ( name = ' res5a _ branch1' , data = conv_feat , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5a_branch1 = mx . symbol . BatchNorm ( name = ' bn5a _ branch1' , data = res5a_branch1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5a_branch1 = bn5a_branch1 NEW_LINE res5a_branch2a = mx . symbol . Convolution ( name = ' res5a _ branch2a ' , data = conv_feat , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5a_branch2a = mx . symbol . BatchNorm ( name = ' bn5a _ branch2a ' , data = res5a_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5a_branch2a = bn5a_branch2a NEW_LINE res5a_branch2a_relu = mx . symbol . Activation ( name = ' res5a _ branch2a _ relu ' , data = scale5a_branch2a , act_type = ' relu ' ) NEW_LINE res5a_branch2b = mx . symbol . Convolution ( name = ' res5a _ branch2b ' , data = res5a_branch2a_relu , num_filter = 512 , pad = ( 2 , 2 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn5a_branch2b = mx . symbol . BatchNorm ( name = ' bn5a _ branch2b ' , data = res5a_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5a_branch2b = bn5a_branch2b NEW_LINE res5a_branch2b_relu = mx . symbol . Activation ( name = ' res5a _ branch2b _ relu ' , data = scale5a_branch2b , act_type = ' relu ' ) NEW_LINE res5a_branch2c = mx . symbol . Convolution ( name = ' res5a _ branch2c ' , data = res5a_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5a_branch2c = mx . symbol . BatchNorm ( name = ' bn5a _ branch2c ' , data = res5a_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5a_branch2c = bn5a_branch2c NEW_LINE res5a = mx . symbol . broadcast_add ( name = ' res5a ' , * [ scale5a_branch1 , scale5a_branch2c ] ) NEW_LINE res5a_relu = mx . symbol . Activation ( name = ' res5a _ relu ' , data = res5a , act_type = ' relu ' ) NEW_LINE res5b_branch2a = mx . symbol . Convolution ( name = ' res5b _ branch2a ' , data = res5a_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5b_branch2a = mx . symbol . BatchNorm ( name = ' bn5b _ branch2a ' , data = res5b_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5b_branch2a = bn5b_branch2a NEW_LINE res5b_branch2a_relu = mx . symbol . Activation ( name = ' res5b _ branch2a _ relu ' , data = scale5b_branch2a , act_type = ' relu ' ) NEW_LINE res5b_branch2b = mx . symbol . Convolution ( name = ' res5b _ branch2b ' , data = res5b_branch2a_relu , num_filter = 512 , pad = ( 2 , 2 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn5b_branch2b = mx . symbol . BatchNorm ( name = ' bn5b _ branch2b ' , data = res5b_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5b_branch2b = bn5b_branch2b NEW_LINE res5b_branch2b_relu = mx . symbol . Activation ( name = ' res5b _ branch2b _ relu ' , data = scale5b_branch2b , act_type = ' relu ' ) NEW_LINE res5b_branch2c = mx . symbol . Convolution ( name = ' res5b _ branch2c ' , data = res5b_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5b_branch2c = mx . symbol . BatchNorm ( name = ' bn5b _ branch2c ' , data = res5b_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5b_branch2c = bn5b_branch2c NEW_LINE res5b = mx . symbol . broadcast_add ( name = ' res5b ' , * [ res5a_relu , scale5b_branch2c ] ) NEW_LINE res5b_relu = mx . symbol . Activation ( name = ' res5b _ relu ' , data = res5b , act_type = ' relu ' ) NEW_LINE res5c_branch2a = mx . symbol . Convolution ( name = ' res5c _ branch2a ' , data = res5b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5c_branch2a = mx . symbol . BatchNorm ( name = ' bn5c _ branch2a ' , data = res5c_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5c_branch2a = bn5c_branch2a NEW_LINE res5c_branch2a_relu = mx . symbol . Activation ( name = ' res5c _ branch2a _ relu ' , data = scale5c_branch2a , act_type = ' relu ' ) NEW_LINE res5c_branch2b = mx . symbol . Convolution ( name = ' res5c _ branch2b ' , data = res5c_branch2a_relu , num_filter = 512 , pad = ( 2 , 2 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn5c_branch2b = mx . symbol . BatchNorm ( name = ' bn5c _ branch2b ' , data = res5c_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5c_branch2b = bn5c_branch2b NEW_LINE res5c_branch2b_relu = mx . symbol . Activation ( name = ' res5c _ branch2b _ relu ' , data = scale5c_branch2b , act_type = ' relu ' ) NEW_LINE res5c_branch2c = mx . symbol . Convolution ( name = ' res5c _ branch2c ' , data = res5c_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5c_branch2c = mx . symbol . BatchNorm ( name = ' bn5c _ branch2c ' , data = res5c_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5c_branch2c = bn5c_branch2c NEW_LINE res5c = mx . symbol . broadcast_add ( name = ' res5c ' , * [ res5b_relu , scale5c_branch2c ] ) NEW_LINE res5c_relu = mx . symbol . Activation ( name = ' res5c _ relu ' , data = res5c , act_type = ' relu ' ) NEW_LINE return res5c_relu NEW_LINE DEDENT\",), ('def get_rpn ( self , conv_feat , num_anchors ) : NEW_LINE INDENT rpn_conv = mx . sym . Convolution ( data = conv_feat , kernel = ( 3 , 3 ) , pad = ( 1 , 1 ) , num_filter = 512 , name = \" rpn _ conv _ 3x3\" ) NEW_LINE rpn_relu = mx . sym . Activation ( data = rpn_conv , act_type = \" relu \" , name = \" rpn _ relu \" ) NEW_LINE rpn_cls_score = mx . sym . Convolution ( data = rpn_relu , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , num_filter = 2 * num_anchors , name = \" rpn _ cls _ score \" ) NEW_LINE rpn_bbox_pred = mx . sym . Convolution ( data = rpn_relu , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , num_filter = 4 * num_anchors , name = \" rpn _ bbox _ pred \" ) NEW_LINE return rpn_cls_score , rpn_bbox_pred NEW_LINE DEDENT',), ('def get_symbol_rpn ( self , cfg , is_train = True ) : NEW_LINE INDENT num_anchors = cfg . network . NUM_ANCHORS NEW_LINE if is_train : NEW_LINE INDENT data = mx . sym . Variable ( name = \" data \" ) NEW_LINE rpn_label = mx . sym . Variable ( name = \\' label \\' ) NEW_LINE rpn_bbox_target = mx . sym . Variable ( name = \\' bbox _ target \\' ) NEW_LINE rpn_bbox_weight = mx . sym . Variable ( name = \\' bbox _ weight \\' ) NEW_LINE DEDENT else : NEW_LINE INDENT data = mx . sym . Variable ( name = \" data \" ) NEW_LINE im_info = mx . sym . Variable ( name = \" im _ info \" ) NEW_LINE DEDENT conv_feat = self . get_resnet_v1_conv4 ( data ) NEW_LINE rpn_cls_score , rpn_bbox_pred = self . get_rpn ( conv_feat , num_anchors ) NEW_LINE if is_train : NEW_LINE INDENT rpn_cls_score_reshape = mx . sym . Reshape ( data = rpn_cls_score , shape = ( 0 , 2 , - 1 , 0 ) , name = \" rpn _ cls _ score _ reshape \" ) NEW_LINE rpn_cls_prob = mx . sym . SoftmaxOutput ( data = rpn_cls_score_reshape , label = rpn_label , multi_output = True , normalization = \\' valid \\' , use_ignore = True , ignore_label = - 1 , name = \" rpn _ cls _ prob \" , grad_scale = 1.0 ) NEW_LINE rpn_bbox_loss_ = rpn_bbox_weight * mx . sym . smooth_l1 ( name = \\' rpn _ bbox _ loss _ \\' , scalar = 3.0 , data = ( rpn_bbox_pred - rpn_bbox_target ) ) NEW_LINE rpn_bbox_loss = mx . sym . MakeLoss ( name = \\' rpn _ bbox _ loss \\' , data = rpn_bbox_loss_ , grad_scale = 1.0 / cfg . TRAIN . RPN_BATCH_SIZE ) NEW_LINE group = mx . symbol . Group ( [ rpn_cls_prob , rpn_bbox_loss ] ) NEW_LINE DEDENT else : NEW_LINE INDENT rpn_cls_score_reshape = mx . sym . Reshape ( data = rpn_cls_score , shape = ( 0 , 2 , - 1 , 0 ) , name = \" rpn _ cls _ score _ reshape \" ) NEW_LINE rpn_cls_prob = mx . sym . SoftmaxActivation ( data = rpn_cls_score_reshape , mode = \" channel \" , name = \" rpn _ cls _ prob \" ) NEW_LINE rpn_cls_prob_reshape = mx . sym . Reshape ( data = rpn_cls_prob , shape = ( 0 , 2 * num_anchors , - 1 , 0 ) , name = \\' rpn _ cls _ prob _ reshape \\' ) NEW_LINE if cfg . TEST . CXX_PROPOSAL : NEW_LINE INDENT rois , score = mx . contrib . sym . Proposal ( cls_prob = rpn_cls_prob_reshape , bbox_pred = rpn_bbox_pred , im_info = im_info , name = \\' rois \\' , output_score = True , feature_stride = cfg . network . RPN_FEAT_STRIDE , scales = tuple ( cfg . network . ANCHOR_SCALES ) , ratios = tuple ( cfg . network . ANCHOR_RATIOS ) , rpn_pre_nms_top_n = cfg . TEST . RPN_PRE_NMS_TOP_N , rpn_post_nms_top_n = cfg . TEST . RPN_POST_NMS_TOP_N , threshold = cfg . TEST . RPN_NMS_THRESH , rpn_min_size = cfg . TEST . RPN_MIN_SIZE ) NEW_LINE DEDENT else : NEW_LINE INDENT rois , score = mx . sym . Custom ( cls_prob = rpn_cls_prob_reshape , bbox_pred = rpn_bbox_pred , im_info = im_info , name = \\' rois \\' , output_score = True , op_type = \\' proposal \\' , feat_stride = cfg . network . RPN_FEAT_STRIDE , scales = tuple ( cfg . network . ANCHOR_SCALES ) , ratios = tuple ( cfg . network . ANCHOR_RATIOS ) , rpn_pre_nms_top_n = cfg . TEST . RPN_PRE_NMS_TOP_N , rpn_post_nms_top_n = cfg . TEST . RPN_POST_NMS_TOP_N , threshold = cfg . TEST . RPN_NMS_THRESH , rpn_min_size = cfg . TEST . RPN_MIN_SIZE ) NEW_LINE group = mx . symbol . Group ( [ rois , score ] ) NEW_LINE DEDENT DEDENT self . sym = group NEW_LINE return group NEW_LINE DEDENT',), ('def get_symbol_rcnn ( self , cfg , is_train = True ) : NEW_LINE INDENT num_classes = cfg . dataset . NUM_CLASSES NEW_LINE num_reg_classes = ( 2 if cfg . CLASS_AGNOSTIC else num_classes ) NEW_LINE if is_train : NEW_LINE INDENT data = mx . symbol . Variable ( name = \" data \" ) NEW_LINE rois = mx . symbol . Variable ( name = \\' rois \\' ) NEW_LINE label = mx . symbol . Variable ( name = \\' label \\' ) NEW_LINE bbox_target = mx . symbol . Variable ( name = \\' bbox _ target \\' ) NEW_LINE bbox_weight = mx . symbol . Variable ( name = \\' bbox _ weight \\' ) NEW_LINE rois = mx . symbol . Reshape ( data = rois , shape = ( - 1 , 5 ) , name = \\' rois _ reshape \\' ) NEW_LINE label = mx . symbol . Reshape ( data = label , shape = ( - 1 , ) , name = \\' label _ reshape \\' ) NEW_LINE bbox_target = mx . symbol . Reshape ( data = bbox_target , shape = ( - 1 , 4 * num_classes ) , name = \\' bbox _ target _ reshape \\' ) NEW_LINE bbox_weight = mx . symbol . Reshape ( data = bbox_weight , shape = ( - 1 , 4 * num_classes ) , name = \\' bbox _ weight _ reshape \\' ) NEW_LINE DEDENT else : NEW_LINE INDENT data = mx . sym . Variable ( name = \" data \" ) NEW_LINE rois = mx . symbol . Variable ( name = \\' rois \\' ) NEW_LINE rois = mx . symbol . Reshape ( data = rois , shape = ( - 1 , 5 ) , name = \\' rois _ reshape \\' ) NEW_LINE DEDENT conv_feat = self . get_resnet_v1_conv4 ( data ) NEW_LINE relu1 = self . get_resnet_v1_conv5 ( conv_feat ) NEW_LINE conv_new_1 = mx . sym . Convolution ( data = relu1 , kernel = ( 1 , 1 ) , num_filter = 256 , name = \" conv _ new _ 1\" ) NEW_LINE conv_new_1_relu = mx . sym . Activation ( data = conv_new_1 , act_type = \\' relu \\' , name = \\' conv _ new _ 1 _ relu \\' ) NEW_LINE roi_pool = mx . symbol . ROIPooling ( name = \\' roi _ pool \\' , data = conv_new_1_relu , rois = rois , pooled_size = ( 7 , 7 ) , spatial_scale = 0.0625 ) NEW_LINE fc_new_1 = mx . symbol . FullyConnected ( name = \\' fc _ new _ 1\\' , data = roi_pool , num_hidden = 1024 ) NEW_LINE fc_new_1_relu = mx . sym . Activation ( data = fc_new_1 , act_type = \\' relu \\' , name = \\' fc _ new _ 1 _ relu \\' ) NEW_LINE fc_new_2 = mx . symbol . FullyConnected ( name = \\' fc _ new _ 2\\' , data = fc_new_1_relu , num_hidden = 1024 ) NEW_LINE fc_new_2_relu = mx . sym . Activation ( data = fc_new_2 , act_type = \\' relu \\' , name = \\' fc _ new _ 2 _ relu \\' ) NEW_LINE cls_score = mx . symbol . FullyConnected ( name = \\' cls _ score \\' , data = fc_new_2_relu , num_hidden = num_classes ) NEW_LINE bbox_pred = mx . symbol . FullyConnected ( name = \\' bbox _ pred \\' , data = fc_new_2_relu , num_hidden = num_reg_classes * 4 ) NEW_LINE if is_train : NEW_LINE INDENT if cfg . TRAIN . ENABLE_OHEM : NEW_LINE INDENT labels_ohem , bbox_weights_ohem = mx . sym . Custom ( op_type = \\' BoxAnnotatorOHEM \\' , num_classes = num_classes , num_reg_classes = num_reg_classes , roi_per_img = cfg . TRAIN . BATCH_ROIS_OHEM , cls_score = cls_score , bbox_pred = bbox_pred , labels = label , bbox_targets = bbox_target , bbox_weights = bbox_weight ) NEW_LINE cls_prob = mx . sym . SoftmaxOutput ( name = \\' cls _ prob \\' , data = cls_score , label = labels_ohem , normalization = \\' valid \\' , use_ignore = True , ignore_label = - 1 , grad_scale = 1.0 ) NEW_LINE bbox_loss_ = bbox_weights_ohem * mx . sym . smooth_l1 ( name = \\' bbox _ loss _ \\' , scalar = 1.0 , data = ( bbox_pred - bbox_target ) ) NEW_LINE bbox_loss = mx . sym . MakeLoss ( name = \\' bbox _ loss \\' , data = bbox_loss_ , grad_scale = 1.0 / cfg . TRAIN . BATCH_ROIS_OHEM ) NEW_LINE DEDENT else : NEW_LINE INDENT cls_prob = mx . sym . SoftmaxOutput ( name = \\' cls _ prob \\' , data = cls_score , label = label , normalization = \\' valid \\' , grad_scale = 1.0 ) NEW_LINE bbox_loss_ = bbox_weight * mx . sym . smooth_l1 ( name = \\' bbox _ loss _ \\' , scalar = 1.0 , data = ( bbox_pred - bbox_target ) ) NEW_LINE bbox_loss = mx . sym . MakeLoss ( name = \\' bbox _ loss \\' , data = bbox_loss_ , grad_scale = 1.0 / cfg . TRAIN . BATCH_ROIS ) NEW_LINE DEDENT cls_prob = mx . sym . Reshape ( data = cls_prob , shape = ( cfg . TRAIN . BATCH_IMAGES , - 1 , num_classes ) , name = \\' cls _ prob _ reshape \\' ) NEW_LINE bbox_loss = mx . sym . Reshape ( data = bbox_loss , shape = ( cfg . TRAIN . BATCH_IMAGES , - 1 , 4 * num_reg_classes ) , name = \\' bbox _ loss _ reshape \\' ) NEW_LINE group = mx . sym . Group ( [ cls_prob , bbox_loss ] ) NEW_LINE DEDENT else : NEW_LINE INDENT cls_prob = mx . sym . SoftmaxActivation ( name = \\' cls _ prob \\' , data = cls_score ) NEW_LINE cls_prob = mx . sym . Reshape ( data = cls_prob , shape = ( cfg . TEST . BATCH_IMAGES , - 1 , num_classes ) , name = \\' cls _ prob _ reshape \\' ) NEW_LINE bbox_pred = mx . sym . Reshape ( data = bbox_pred , shape = ( cfg . TEST . BATCH_IMAGES , - 1 , 4 * num_reg_classes ) , name = \\' bbox _ pred _ reshape \\' ) NEW_LINE group = mx . sym . Group ( [ cls_prob , bbox_pred ] ) NEW_LINE DEDENT self . sym = group NEW_LINE return group NEW_LINE DEDENT',), (\"def init_weight_rcnn ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT arg_params [ ' conv _ new _ 1 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' conv _ new _ 1 _ weight ' ] ) NEW_LINE arg_params [ ' conv _ new _ 1 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' conv _ new _ 1 _ bias ' ] ) NEW_LINE arg_params [ ' fc _ new _ 1 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fc _ new _ 1 _ weight ' ] ) NEW_LINE arg_params [ ' fc _ new _ 1 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fc _ new _ 1 _ bias ' ] ) NEW_LINE arg_params [ ' fc _ new _ 2 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fc _ new _ 2 _ weight ' ] ) NEW_LINE arg_params [ ' fc _ new _ 2 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fc _ new _ 2 _ bias ' ] ) NEW_LINE arg_params [ ' cls _ score _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' cls _ score _ weight ' ] ) NEW_LINE arg_params [ ' cls _ score _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' cls _ score _ bias ' ] ) NEW_LINE arg_params [ ' bbox _ pred _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' bbox _ pred _ weight ' ] ) NEW_LINE arg_params [ ' bbox _ pred _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' bbox _ pred _ bias ' ] ) NEW_LINE DEDENT\",), (\"def init_weight_rpn ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT arg_params [ ' rpn _ conv _ 3x3 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' rpn _ conv _ 3x3 _ weight ' ] ) NEW_LINE arg_params [ ' rpn _ conv _ 3x3 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' rpn _ conv _ 3x3 _ bias ' ] ) NEW_LINE arg_params [ ' rpn _ cls _ score _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' rpn _ cls _ score _ weight ' ] ) NEW_LINE arg_params [ ' rpn _ cls _ score _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' rpn _ cls _ score _ bias ' ] ) NEW_LINE arg_params [ ' rpn _ bbox _ pred _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' rpn _ bbox _ pred _ weight ' ] ) NEW_LINE arg_params [ ' rpn _ bbox _ pred _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' rpn _ bbox _ pred _ bias ' ] ) NEW_LINE DEDENT\",), ('def init_weight ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT self . init_weight_rpn ( cfg , arg_params , aux_params ) NEW_LINE self . init_weight_rcnn ( cfg , arg_params , aux_params ) NEW_LINE DEDENT',), (\"def __init__ ( self ) : NEW_LINE INDENT self . eps = 1e-5 NEW_LINE self . use_global_stats = True NEW_LINE self . workspace = 512 NEW_LINE self . units = ( 3 , 4 , 23 , 3 ) NEW_LINE self . filter_list = [ 256 , 512 , 1024 , 2048 ] NEW_LINE self . shared_param_list = [ ' conv _ new _ 1' , ' conv _ new _ 2' , ' conv _ new _ 3' , ' conv _ new _ 4' ] NEW_LINE self . shared_param_dict = { } NEW_LINE for name in self . shared_param_list : NEW_LINE INDENT self . shared_param_dict [ name + ' _ weight ' ] = mx . sym . Variable ( name + ' _ weight ' ) NEW_LINE self . shared_param_dict [ name + ' _ bias ' ] = mx . sym . Variable ( name + ' _ bias ' ) NEW_LINE DEDENT DEDENT\",), (\"def get_resnet_v1_conv4 ( self , data ) : NEW_LINE INDENT conv1 = mx . symbol . Convolution ( name = ' conv1' , data = data , num_filter = 64 , pad = ( 3 , 3 ) , kernel = ( 7 , 7 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn_conv1 = mx . symbol . BatchNorm ( name = ' bn _ conv1' , data = conv1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale_conv1 = bn_conv1 NEW_LINE conv1_relu = mx . symbol . Activation ( name = ' conv1 _ relu ' , data = scale_conv1 , act_type = ' relu ' ) NEW_LINE pool1 = mx . symbol . Pooling ( name = ' pool1' , data = conv1_relu , pooling_convention = ' full ' , pad = ( 0 , 0 ) , kernel = ( 3 , 3 ) , stride = ( 2 , 2 ) , pool_type = ' max ' ) NEW_LINE res2a_branch1 = mx . symbol . Convolution ( name = ' res2a _ branch1' , data = pool1 , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch1 = mx . symbol . BatchNorm ( name = ' bn2a _ branch1' , data = res2a_branch1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2a_branch1 = bn2a_branch1 NEW_LINE res2a_branch2a = mx . symbol . Convolution ( name = ' res2a _ branch2a ' , data = pool1 , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2a = mx . symbol . BatchNorm ( name = ' bn2a _ branch2a ' , data = res2a_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2a_branch2a = bn2a_branch2a NEW_LINE res2a_branch2a_relu = mx . symbol . Activation ( name = ' res2a _ branch2a _ relu ' , data = scale2a_branch2a , act_type = ' relu ' ) NEW_LINE res2a_branch2b = mx . symbol . Convolution ( name = ' res2a _ branch2b ' , data = res2a_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2b = mx . symbol . BatchNorm ( name = ' bn2a _ branch2b ' , data = res2a_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2a_branch2b = bn2a_branch2b NEW_LINE res2a_branch2b_relu = mx . symbol . Activation ( name = ' res2a _ branch2b _ relu ' , data = scale2a_branch2b , act_type = ' relu ' ) NEW_LINE res2a_branch2c = mx . symbol . Convolution ( name = ' res2a _ branch2c ' , data = res2a_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2c = mx . symbol . BatchNorm ( name = ' bn2a _ branch2c ' , data = res2a_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2a_branch2c = bn2a_branch2c NEW_LINE res2a = mx . symbol . broadcast_add ( name = ' res2a ' , * [ scale2a_branch1 , scale2a_branch2c ] ) NEW_LINE res2a_relu = mx . symbol . Activation ( name = ' res2a _ relu ' , data = res2a , act_type = ' relu ' ) NEW_LINE res2b_branch2a = mx . symbol . Convolution ( name = ' res2b _ branch2a ' , data = res2a_relu , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2a = mx . symbol . BatchNorm ( name = ' bn2b _ branch2a ' , data = res2b_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2b_branch2a = bn2b_branch2a NEW_LINE res2b_branch2a_relu = mx . symbol . Activation ( name = ' res2b _ branch2a _ relu ' , data = scale2b_branch2a , act_type = ' relu ' ) NEW_LINE res2b_branch2b = mx . symbol . Convolution ( name = ' res2b _ branch2b ' , data = res2b_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2b = mx . symbol . BatchNorm ( name = ' bn2b _ branch2b ' , data = res2b_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2b_branch2b = bn2b_branch2b NEW_LINE res2b_branch2b_relu = mx . symbol . Activation ( name = ' res2b _ branch2b _ relu ' , data = scale2b_branch2b , act_type = ' relu ' ) NEW_LINE res2b_branch2c = mx . symbol . Convolution ( name = ' res2b _ branch2c ' , data = res2b_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2c = mx . symbol . BatchNorm ( name = ' bn2b _ branch2c ' , data = res2b_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2b_branch2c = bn2b_branch2c NEW_LINE res2b = mx . symbol . broadcast_add ( name = ' res2b ' , * [ res2a_relu , scale2b_branch2c ] ) NEW_LINE res2b_relu = mx . symbol . Activation ( name = ' res2b _ relu ' , data = res2b , act_type = ' relu ' ) NEW_LINE res2c_branch2a = mx . symbol . Convolution ( name = ' res2c _ branch2a ' , data = res2b_relu , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2a = mx . symbol . BatchNorm ( name = ' bn2c _ branch2a ' , data = res2c_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2c_branch2a = bn2c_branch2a NEW_LINE res2c_branch2a_relu = mx . symbol . Activation ( name = ' res2c _ branch2a _ relu ' , data = scale2c_branch2a , act_type = ' relu ' ) NEW_LINE res2c_branch2b = mx . symbol . Convolution ( name = ' res2c _ branch2b ' , data = res2c_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2b = mx . symbol . BatchNorm ( name = ' bn2c _ branch2b ' , data = res2c_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2c_branch2b = bn2c_branch2b NEW_LINE res2c_branch2b_relu = mx . symbol . Activation ( name = ' res2c _ branch2b _ relu ' , data = scale2c_branch2b , act_type = ' relu ' ) NEW_LINE res2c_branch2c = mx . symbol . Convolution ( name = ' res2c _ branch2c ' , data = res2c_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2c = mx . symbol . BatchNorm ( name = ' bn2c _ branch2c ' , data = res2c_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale2c_branch2c = bn2c_branch2c NEW_LINE res2c = mx . symbol . broadcast_add ( name = ' res2c ' , * [ res2b_relu , scale2c_branch2c ] ) NEW_LINE res2c_relu = mx . symbol . Activation ( name = ' res2c _ relu ' , data = res2c , act_type = ' relu ' ) NEW_LINE res3a_branch1 = mx . symbol . Convolution ( name = ' res3a _ branch1' , data = res2c_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn3a_branch1 = mx . symbol . BatchNorm ( name = ' bn3a _ branch1' , data = res3a_branch1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3a_branch1 = bn3a_branch1 NEW_LINE res3a_branch2a = mx . symbol . Convolution ( name = ' res3a _ branch2a ' , data = res2c_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn3a_branch2a = mx . symbol . BatchNorm ( name = ' bn3a _ branch2a ' , data = res3a_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3a_branch2a = bn3a_branch2a NEW_LINE res3a_branch2a_relu = mx . symbol . Activation ( name = ' res3a _ branch2a _ relu ' , data = scale3a_branch2a , act_type = ' relu ' ) NEW_LINE res3a_branch2b = mx . symbol . Convolution ( name = ' res3a _ branch2b ' , data = res3a_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3a_branch2b = mx . symbol . BatchNorm ( name = ' bn3a _ branch2b ' , data = res3a_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3a_branch2b = bn3a_branch2b NEW_LINE res3a_branch2b_relu = mx . symbol . Activation ( name = ' res3a _ branch2b _ relu ' , data = scale3a_branch2b , act_type = ' relu ' ) NEW_LINE res3a_branch2c = mx . symbol . Convolution ( name = ' res3a _ branch2c ' , data = res3a_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3a_branch2c = mx . symbol . BatchNorm ( name = ' bn3a _ branch2c ' , data = res3a_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3a_branch2c = bn3a_branch2c NEW_LINE res3a = mx . symbol . broadcast_add ( name = ' res3a ' , * [ scale3a_branch1 , scale3a_branch2c ] ) NEW_LINE res3a_relu = mx . symbol . Activation ( name = ' res3a _ relu ' , data = res3a , act_type = ' relu ' ) NEW_LINE res3b1_branch2a = mx . symbol . Convolution ( name = ' res3b1 _ branch2a ' , data = res3a_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2a = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2a ' , data = res3b1_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b1_branch2a = bn3b1_branch2a NEW_LINE res3b1_branch2a_relu = mx . symbol . Activation ( name = ' res3b1 _ branch2a _ relu ' , data = scale3b1_branch2a , act_type = ' relu ' ) NEW_LINE res3b1_branch2b = mx . symbol . Convolution ( name = ' res3b1 _ branch2b ' , data = res3b1_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2b = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2b ' , data = res3b1_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b1_branch2b = bn3b1_branch2b NEW_LINE res3b1_branch2b_relu = mx . symbol . Activation ( name = ' res3b1 _ branch2b _ relu ' , data = scale3b1_branch2b , act_type = ' relu ' ) NEW_LINE res3b1_branch2c = mx . symbol . Convolution ( name = ' res3b1 _ branch2c ' , data = res3b1_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2c = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2c ' , data = res3b1_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b1_branch2c = bn3b1_branch2c NEW_LINE res3b1 = mx . symbol . broadcast_add ( name = ' res3b1' , * [ res3a_relu , scale3b1_branch2c ] ) NEW_LINE res3b1_relu = mx . symbol . Activation ( name = ' res3b1 _ relu ' , data = res3b1 , act_type = ' relu ' ) NEW_LINE res3b2_branch2a = mx . symbol . Convolution ( name = ' res3b2 _ branch2a ' , data = res3b1_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2a = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2a ' , data = res3b2_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b2_branch2a = bn3b2_branch2a NEW_LINE res3b2_branch2a_relu = mx . symbol . Activation ( name = ' res3b2 _ branch2a _ relu ' , data = scale3b2_branch2a , act_type = ' relu ' ) NEW_LINE res3b2_branch2b = mx . symbol . Convolution ( name = ' res3b2 _ branch2b ' , data = res3b2_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2b = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2b ' , data = res3b2_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b2_branch2b = bn3b2_branch2b NEW_LINE res3b2_branch2b_relu = mx . symbol . Activation ( name = ' res3b2 _ branch2b _ relu ' , data = scale3b2_branch2b , act_type = ' relu ' ) NEW_LINE res3b2_branch2c = mx . symbol . Convolution ( name = ' res3b2 _ branch2c ' , data = res3b2_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2c = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2c ' , data = res3b2_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b2_branch2c = bn3b2_branch2c NEW_LINE res3b2 = mx . symbol . broadcast_add ( name = ' res3b2' , * [ res3b1_relu , scale3b2_branch2c ] ) NEW_LINE res3b2_relu = mx . symbol . Activation ( name = ' res3b2 _ relu ' , data = res3b2 , act_type = ' relu ' ) NEW_LINE res3b3_branch2a = mx . symbol . Convolution ( name = ' res3b3 _ branch2a ' , data = res3b2_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b3_branch2a = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2a ' , data = res3b3_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b3_branch2a = bn3b3_branch2a NEW_LINE res3b3_branch2a_relu = mx . symbol . Activation ( name = ' res3b3 _ branch2a _ relu ' , data = scale3b3_branch2a , act_type = ' relu ' ) NEW_LINE res3b3_branch2b = mx . symbol . Convolution ( name = ' res3b3 _ branch2b ' , data = res3b3_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b3_branch2b = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2b ' , data = res3b3_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b3_branch2b = bn3b3_branch2b NEW_LINE res3b3_branch2b_relu = mx . symbol . Activation ( name = ' res3b3 _ branch2b _ relu ' , data = scale3b3_branch2b , act_type = ' relu ' ) NEW_LINE res3b3_branch2c = mx . symbol . Convolution ( name = ' res3b3 _ branch2c ' , data = res3b3_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b3_branch2c = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2c ' , data = res3b3_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale3b3_branch2c = bn3b3_branch2c NEW_LINE res3b3 = mx . symbol . broadcast_add ( name = ' res3b3' , * [ res3b2_relu , scale3b3_branch2c ] ) NEW_LINE res3b3_relu = mx . symbol . Activation ( name = ' res3b3 _ relu ' , data = res3b3 , act_type = ' relu ' ) NEW_LINE res4a_branch1 = mx . symbol . Convolution ( name = ' res4a _ branch1' , data = res3b3_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn4a_branch1 = mx . symbol . BatchNorm ( name = ' bn4a _ branch1' , data = res4a_branch1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4a_branch1 = bn4a_branch1 NEW_LINE res4a_branch2a = mx . symbol . Convolution ( name = ' res4a _ branch2a ' , data = res3b3_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn4a_branch2a = mx . symbol . BatchNorm ( name = ' bn4a _ branch2a ' , data = res4a_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4a_branch2a = bn4a_branch2a NEW_LINE res4a_branch2a_relu = mx . symbol . Activation ( name = ' res4a _ branch2a _ relu ' , data = scale4a_branch2a , act_type = ' relu ' ) NEW_LINE res4a_branch2b = mx . symbol . Convolution ( name = ' res4a _ branch2b ' , data = res4a_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4a_branch2b = mx . symbol . BatchNorm ( name = ' bn4a _ branch2b ' , data = res4a_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4a_branch2b = bn4a_branch2b NEW_LINE res4a_branch2b_relu = mx . symbol . Activation ( name = ' res4a _ branch2b _ relu ' , data = scale4a_branch2b , act_type = ' relu ' ) NEW_LINE res4a_branch2c = mx . symbol . Convolution ( name = ' res4a _ branch2c ' , data = res4a_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4a_branch2c = mx . symbol . BatchNorm ( name = ' bn4a _ branch2c ' , data = res4a_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4a_branch2c = bn4a_branch2c NEW_LINE res4a = mx . symbol . broadcast_add ( name = ' res4a ' , * [ scale4a_branch1 , scale4a_branch2c ] ) NEW_LINE res4a_relu = mx . symbol . Activation ( name = ' res4a _ relu ' , data = res4a , act_type = ' relu ' ) NEW_LINE res4b1_branch2a = mx . symbol . Convolution ( name = ' res4b1 _ branch2a ' , data = res4a_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2a = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2a ' , data = res4b1_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b1_branch2a = bn4b1_branch2a NEW_LINE res4b1_branch2a_relu = mx . symbol . Activation ( name = ' res4b1 _ branch2a _ relu ' , data = scale4b1_branch2a , act_type = ' relu ' ) NEW_LINE res4b1_branch2b = mx . symbol . Convolution ( name = ' res4b1 _ branch2b ' , data = res4b1_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2b = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2b ' , data = res4b1_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b1_branch2b = bn4b1_branch2b NEW_LINE res4b1_branch2b_relu = mx . symbol . Activation ( name = ' res4b1 _ branch2b _ relu ' , data = scale4b1_branch2b , act_type = ' relu ' ) NEW_LINE res4b1_branch2c = mx . symbol . Convolution ( name = ' res4b1 _ branch2c ' , data = res4b1_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2c = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2c ' , data = res4b1_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b1_branch2c = bn4b1_branch2c NEW_LINE res4b1 = mx . symbol . broadcast_add ( name = ' res4b1' , * [ res4a_relu , scale4b1_branch2c ] ) NEW_LINE res4b1_relu = mx . symbol . Activation ( name = ' res4b1 _ relu ' , data = res4b1 , act_type = ' relu ' ) NEW_LINE res4b2_branch2a = mx . symbol . Convolution ( name = ' res4b2 _ branch2a ' , data = res4b1_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2a = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2a ' , data = res4b2_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b2_branch2a = bn4b2_branch2a NEW_LINE res4b2_branch2a_relu = mx . symbol . Activation ( name = ' res4b2 _ branch2a _ relu ' , data = scale4b2_branch2a , act_type = ' relu ' ) NEW_LINE res4b2_branch2b = mx . symbol . Convolution ( name = ' res4b2 _ branch2b ' , data = res4b2_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2b = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2b ' , data = res4b2_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b2_branch2b = bn4b2_branch2b NEW_LINE res4b2_branch2b_relu = mx . symbol . Activation ( name = ' res4b2 _ branch2b _ relu ' , data = scale4b2_branch2b , act_type = ' relu ' ) NEW_LINE res4b2_branch2c = mx . symbol . Convolution ( name = ' res4b2 _ branch2c ' , data = res4b2_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2c = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2c ' , data = res4b2_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b2_branch2c = bn4b2_branch2c NEW_LINE res4b2 = mx . symbol . broadcast_add ( name = ' res4b2' , * [ res4b1_relu , scale4b2_branch2c ] ) NEW_LINE res4b2_relu = mx . symbol . Activation ( name = ' res4b2 _ relu ' , data = res4b2 , act_type = ' relu ' ) NEW_LINE res4b3_branch2a = mx . symbol . Convolution ( name = ' res4b3 _ branch2a ' , data = res4b2_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2a = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2a ' , data = res4b3_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b3_branch2a = bn4b3_branch2a NEW_LINE res4b3_branch2a_relu = mx . symbol . Activation ( name = ' res4b3 _ branch2a _ relu ' , data = scale4b3_branch2a , act_type = ' relu ' ) NEW_LINE res4b3_branch2b = mx . symbol . Convolution ( name = ' res4b3 _ branch2b ' , data = res4b3_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2b = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2b ' , data = res4b3_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b3_branch2b = bn4b3_branch2b NEW_LINE res4b3_branch2b_relu = mx . symbol . Activation ( name = ' res4b3 _ branch2b _ relu ' , data = scale4b3_branch2b , act_type = ' relu ' ) NEW_LINE res4b3_branch2c = mx . symbol . Convolution ( name = ' res4b3 _ branch2c ' , data = res4b3_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2c = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2c ' , data = res4b3_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b3_branch2c = bn4b3_branch2c NEW_LINE res4b3 = mx . symbol . broadcast_add ( name = ' res4b3' , * [ res4b2_relu , scale4b3_branch2c ] ) NEW_LINE res4b3_relu = mx . symbol . Activation ( name = ' res4b3 _ relu ' , data = res4b3 , act_type = ' relu ' ) NEW_LINE res4b4_branch2a = mx . symbol . Convolution ( name = ' res4b4 _ branch2a ' , data = res4b3_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2a = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2a ' , data = res4b4_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b4_branch2a = bn4b4_branch2a NEW_LINE res4b4_branch2a_relu = mx . symbol . Activation ( name = ' res4b4 _ branch2a _ relu ' , data = scale4b4_branch2a , act_type = ' relu ' ) NEW_LINE res4b4_branch2b = mx . symbol . Convolution ( name = ' res4b4 _ branch2b ' , data = res4b4_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2b = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2b ' , data = res4b4_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b4_branch2b = bn4b4_branch2b NEW_LINE res4b4_branch2b_relu = mx . symbol . Activation ( name = ' res4b4 _ branch2b _ relu ' , data = scale4b4_branch2b , act_type = ' relu ' ) NEW_LINE res4b4_branch2c = mx . symbol . Convolution ( name = ' res4b4 _ branch2c ' , data = res4b4_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2c = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2c ' , data = res4b4_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b4_branch2c = bn4b4_branch2c NEW_LINE res4b4 = mx . symbol . broadcast_add ( name = ' res4b4' , * [ res4b3_relu , scale4b4_branch2c ] ) NEW_LINE res4b4_relu = mx . symbol . Activation ( name = ' res4b4 _ relu ' , data = res4b4 , act_type = ' relu ' ) NEW_LINE res4b5_branch2a = mx . symbol . Convolution ( name = ' res4b5 _ branch2a ' , data = res4b4_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2a = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2a ' , data = res4b5_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b5_branch2a = bn4b5_branch2a NEW_LINE res4b5_branch2a_relu = mx . symbol . Activation ( name = ' res4b5 _ branch2a _ relu ' , data = scale4b5_branch2a , act_type = ' relu ' ) NEW_LINE res4b5_branch2b = mx . symbol . Convolution ( name = ' res4b5 _ branch2b ' , data = res4b5_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2b = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2b ' , data = res4b5_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b5_branch2b = bn4b5_branch2b NEW_LINE res4b5_branch2b_relu = mx . symbol . Activation ( name = ' res4b5 _ branch2b _ relu ' , data = scale4b5_branch2b , act_type = ' relu ' ) NEW_LINE res4b5_branch2c = mx . symbol . Convolution ( name = ' res4b5 _ branch2c ' , data = res4b5_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2c = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2c ' , data = res4b5_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b5_branch2c = bn4b5_branch2c NEW_LINE res4b5 = mx . symbol . broadcast_add ( name = ' res4b5' , * [ res4b4_relu , scale4b5_branch2c ] ) NEW_LINE res4b5_relu = mx . symbol . Activation ( name = ' res4b5 _ relu ' , data = res4b5 , act_type = ' relu ' ) NEW_LINE res4b6_branch2a = mx . symbol . Convolution ( name = ' res4b6 _ branch2a ' , data = res4b5_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2a = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2a ' , data = res4b6_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b6_branch2a = bn4b6_branch2a NEW_LINE res4b6_branch2a_relu = mx . symbol . Activation ( name = ' res4b6 _ branch2a _ relu ' , data = scale4b6_branch2a , act_type = ' relu ' ) NEW_LINE res4b6_branch2b = mx . symbol . Convolution ( name = ' res4b6 _ branch2b ' , data = res4b6_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2b = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2b ' , data = res4b6_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b6_branch2b = bn4b6_branch2b NEW_LINE res4b6_branch2b_relu = mx . symbol . Activation ( name = ' res4b6 _ branch2b _ relu ' , data = scale4b6_branch2b , act_type = ' relu ' ) NEW_LINE res4b6_branch2c = mx . symbol . Convolution ( name = ' res4b6 _ branch2c ' , data = res4b6_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2c = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2c ' , data = res4b6_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b6_branch2c = bn4b6_branch2c NEW_LINE res4b6 = mx . symbol . broadcast_add ( name = ' res4b6' , * [ res4b5_relu , scale4b6_branch2c ] ) NEW_LINE res4b6_relu = mx . symbol . Activation ( name = ' res4b6 _ relu ' , data = res4b6 , act_type = ' relu ' ) NEW_LINE res4b7_branch2a = mx . symbol . Convolution ( name = ' res4b7 _ branch2a ' , data = res4b6_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2a = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2a ' , data = res4b7_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b7_branch2a = bn4b7_branch2a NEW_LINE res4b7_branch2a_relu = mx . symbol . Activation ( name = ' res4b7 _ branch2a _ relu ' , data = scale4b7_branch2a , act_type = ' relu ' ) NEW_LINE res4b7_branch2b = mx . symbol . Convolution ( name = ' res4b7 _ branch2b ' , data = res4b7_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2b = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2b ' , data = res4b7_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b7_branch2b = bn4b7_branch2b NEW_LINE res4b7_branch2b_relu = mx . symbol . Activation ( name = ' res4b7 _ branch2b _ relu ' , data = scale4b7_branch2b , act_type = ' relu ' ) NEW_LINE res4b7_branch2c = mx . symbol . Convolution ( name = ' res4b7 _ branch2c ' , data = res4b7_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2c = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2c ' , data = res4b7_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b7_branch2c = bn4b7_branch2c NEW_LINE res4b7 = mx . symbol . broadcast_add ( name = ' res4b7' , * [ res4b6_relu , scale4b7_branch2c ] ) NEW_LINE res4b7_relu = mx . symbol . Activation ( name = ' res4b7 _ relu ' , data = res4b7 , act_type = ' relu ' ) NEW_LINE res4b8_branch2a = mx . symbol . Convolution ( name = ' res4b8 _ branch2a ' , data = res4b7_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2a = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2a ' , data = res4b8_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b8_branch2a = bn4b8_branch2a NEW_LINE res4b8_branch2a_relu = mx . symbol . Activation ( name = ' res4b8 _ branch2a _ relu ' , data = scale4b8_branch2a , act_type = ' relu ' ) NEW_LINE res4b8_branch2b = mx . symbol . Convolution ( name = ' res4b8 _ branch2b ' , data = res4b8_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2b = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2b ' , data = res4b8_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b8_branch2b = bn4b8_branch2b NEW_LINE res4b8_branch2b_relu = mx . symbol . Activation ( name = ' res4b8 _ branch2b _ relu ' , data = scale4b8_branch2b , act_type = ' relu ' ) NEW_LINE res4b8_branch2c = mx . symbol . Convolution ( name = ' res4b8 _ branch2c ' , data = res4b8_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2c = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2c ' , data = res4b8_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b8_branch2c = bn4b8_branch2c NEW_LINE res4b8 = mx . symbol . broadcast_add ( name = ' res4b8' , * [ res4b7_relu , scale4b8_branch2c ] ) NEW_LINE res4b8_relu = mx . symbol . Activation ( name = ' res4b8 _ relu ' , data = res4b8 , act_type = ' relu ' ) NEW_LINE res4b9_branch2a = mx . symbol . Convolution ( name = ' res4b9 _ branch2a ' , data = res4b8_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2a = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2a ' , data = res4b9_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b9_branch2a = bn4b9_branch2a NEW_LINE res4b9_branch2a_relu = mx . symbol . Activation ( name = ' res4b9 _ branch2a _ relu ' , data = scale4b9_branch2a , act_type = ' relu ' ) NEW_LINE res4b9_branch2b = mx . symbol . Convolution ( name = ' res4b9 _ branch2b ' , data = res4b9_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2b = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2b ' , data = res4b9_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b9_branch2b = bn4b9_branch2b NEW_LINE res4b9_branch2b_relu = mx . symbol . Activation ( name = ' res4b9 _ branch2b _ relu ' , data = scale4b9_branch2b , act_type = ' relu ' ) NEW_LINE res4b9_branch2c = mx . symbol . Convolution ( name = ' res4b9 _ branch2c ' , data = res4b9_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2c = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2c ' , data = res4b9_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b9_branch2c = bn4b9_branch2c NEW_LINE res4b9 = mx . symbol . broadcast_add ( name = ' res4b9' , * [ res4b8_relu , scale4b9_branch2c ] ) NEW_LINE res4b9_relu = mx . symbol . Activation ( name = ' res4b9 _ relu ' , data = res4b9 , act_type = ' relu ' ) NEW_LINE res4b10_branch2a = mx . symbol . Convolution ( name = ' res4b10 _ branch2a ' , data = res4b9_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2a = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2a ' , data = res4b10_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b10_branch2a = bn4b10_branch2a NEW_LINE res4b10_branch2a_relu = mx . symbol . Activation ( name = ' res4b10 _ branch2a _ relu ' , data = scale4b10_branch2a , act_type = ' relu ' ) NEW_LINE res4b10_branch2b = mx . symbol . Convolution ( name = ' res4b10 _ branch2b ' , data = res4b10_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2b = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2b ' , data = res4b10_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b10_branch2b = bn4b10_branch2b NEW_LINE res4b10_branch2b_relu = mx . symbol . Activation ( name = ' res4b10 _ branch2b _ relu ' , data = scale4b10_branch2b , act_type = ' relu ' ) NEW_LINE res4b10_branch2c = mx . symbol . Convolution ( name = ' res4b10 _ branch2c ' , data = res4b10_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2c = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2c ' , data = res4b10_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b10_branch2c = bn4b10_branch2c NEW_LINE res4b10 = mx . symbol . broadcast_add ( name = ' res4b10' , * [ res4b9_relu , scale4b10_branch2c ] ) NEW_LINE res4b10_relu = mx . symbol . Activation ( name = ' res4b10 _ relu ' , data = res4b10 , act_type = ' relu ' ) NEW_LINE res4b11_branch2a = mx . symbol . Convolution ( name = ' res4b11 _ branch2a ' , data = res4b10_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2a = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2a ' , data = res4b11_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b11_branch2a = bn4b11_branch2a NEW_LINE res4b11_branch2a_relu = mx . symbol . Activation ( name = ' res4b11 _ branch2a _ relu ' , data = scale4b11_branch2a , act_type = ' relu ' ) NEW_LINE res4b11_branch2b = mx . symbol . Convolution ( name = ' res4b11 _ branch2b ' , data = res4b11_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2b = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2b ' , data = res4b11_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b11_branch2b = bn4b11_branch2b NEW_LINE res4b11_branch2b_relu = mx . symbol . Activation ( name = ' res4b11 _ branch2b _ relu ' , data = scale4b11_branch2b , act_type = ' relu ' ) NEW_LINE res4b11_branch2c = mx . symbol . Convolution ( name = ' res4b11 _ branch2c ' , data = res4b11_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2c = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2c ' , data = res4b11_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b11_branch2c = bn4b11_branch2c NEW_LINE res4b11 = mx . symbol . broadcast_add ( name = ' res4b11' , * [ res4b10_relu , scale4b11_branch2c ] ) NEW_LINE res4b11_relu = mx . symbol . Activation ( name = ' res4b11 _ relu ' , data = res4b11 , act_type = ' relu ' ) NEW_LINE res4b12_branch2a = mx . symbol . Convolution ( name = ' res4b12 _ branch2a ' , data = res4b11_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2a = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2a ' , data = res4b12_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b12_branch2a = bn4b12_branch2a NEW_LINE res4b12_branch2a_relu = mx . symbol . Activation ( name = ' res4b12 _ branch2a _ relu ' , data = scale4b12_branch2a , act_type = ' relu ' ) NEW_LINE res4b12_branch2b = mx . symbol . Convolution ( name = ' res4b12 _ branch2b ' , data = res4b12_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2b = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2b ' , data = res4b12_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b12_branch2b = bn4b12_branch2b NEW_LINE res4b12_branch2b_relu = mx . symbol . Activation ( name = ' res4b12 _ branch2b _ relu ' , data = scale4b12_branch2b , act_type = ' relu ' ) NEW_LINE res4b12_branch2c = mx . symbol . Convolution ( name = ' res4b12 _ branch2c ' , data = res4b12_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2c = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2c ' , data = res4b12_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b12_branch2c = bn4b12_branch2c NEW_LINE res4b12 = mx . symbol . broadcast_add ( name = ' res4b12' , * [ res4b11_relu , scale4b12_branch2c ] ) NEW_LINE res4b12_relu = mx . symbol . Activation ( name = ' res4b12 _ relu ' , data = res4b12 , act_type = ' relu ' ) NEW_LINE res4b13_branch2a = mx . symbol . Convolution ( name = ' res4b13 _ branch2a ' , data = res4b12_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2a = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2a ' , data = res4b13_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b13_branch2a = bn4b13_branch2a NEW_LINE res4b13_branch2a_relu = mx . symbol . Activation ( name = ' res4b13 _ branch2a _ relu ' , data = scale4b13_branch2a , act_type = ' relu ' ) NEW_LINE res4b13_branch2b = mx . symbol . Convolution ( name = ' res4b13 _ branch2b ' , data = res4b13_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2b = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2b ' , data = res4b13_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b13_branch2b = bn4b13_branch2b NEW_LINE res4b13_branch2b_relu = mx . symbol . Activation ( name = ' res4b13 _ branch2b _ relu ' , data = scale4b13_branch2b , act_type = ' relu ' ) NEW_LINE res4b13_branch2c = mx . symbol . Convolution ( name = ' res4b13 _ branch2c ' , data = res4b13_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2c = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2c ' , data = res4b13_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b13_branch2c = bn4b13_branch2c NEW_LINE res4b13 = mx . symbol . broadcast_add ( name = ' res4b13' , * [ res4b12_relu , scale4b13_branch2c ] ) NEW_LINE res4b13_relu = mx . symbol . Activation ( name = ' res4b13 _ relu ' , data = res4b13 , act_type = ' relu ' ) NEW_LINE res4b14_branch2a = mx . symbol . Convolution ( name = ' res4b14 _ branch2a ' , data = res4b13_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2a = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2a ' , data = res4b14_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b14_branch2a = bn4b14_branch2a NEW_LINE res4b14_branch2a_relu = mx . symbol . Activation ( name = ' res4b14 _ branch2a _ relu ' , data = scale4b14_branch2a , act_type = ' relu ' ) NEW_LINE res4b14_branch2b = mx . symbol . Convolution ( name = ' res4b14 _ branch2b ' , data = res4b14_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2b = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2b ' , data = res4b14_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b14_branch2b = bn4b14_branch2b NEW_LINE res4b14_branch2b_relu = mx . symbol . Activation ( name = ' res4b14 _ branch2b _ relu ' , data = scale4b14_branch2b , act_type = ' relu ' ) NEW_LINE res4b14_branch2c = mx . symbol . Convolution ( name = ' res4b14 _ branch2c ' , data = res4b14_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2c = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2c ' , data = res4b14_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b14_branch2c = bn4b14_branch2c NEW_LINE res4b14 = mx . symbol . broadcast_add ( name = ' res4b14' , * [ res4b13_relu , scale4b14_branch2c ] ) NEW_LINE res4b14_relu = mx . symbol . Activation ( name = ' res4b14 _ relu ' , data = res4b14 , act_type = ' relu ' ) NEW_LINE res4b15_branch2a = mx . symbol . Convolution ( name = ' res4b15 _ branch2a ' , data = res4b14_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2a = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2a ' , data = res4b15_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b15_branch2a = bn4b15_branch2a NEW_LINE res4b15_branch2a_relu = mx . symbol . Activation ( name = ' res4b15 _ branch2a _ relu ' , data = scale4b15_branch2a , act_type = ' relu ' ) NEW_LINE res4b15_branch2b = mx . symbol . Convolution ( name = ' res4b15 _ branch2b ' , data = res4b15_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2b = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2b ' , data = res4b15_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b15_branch2b = bn4b15_branch2b NEW_LINE res4b15_branch2b_relu = mx . symbol . Activation ( name = ' res4b15 _ branch2b _ relu ' , data = scale4b15_branch2b , act_type = ' relu ' ) NEW_LINE res4b15_branch2c = mx . symbol . Convolution ( name = ' res4b15 _ branch2c ' , data = res4b15_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2c = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2c ' , data = res4b15_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b15_branch2c = bn4b15_branch2c NEW_LINE res4b15 = mx . symbol . broadcast_add ( name = ' res4b15' , * [ res4b14_relu , scale4b15_branch2c ] ) NEW_LINE res4b15_relu = mx . symbol . Activation ( name = ' res4b15 _ relu ' , data = res4b15 , act_type = ' relu ' ) NEW_LINE res4b16_branch2a = mx . symbol . Convolution ( name = ' res4b16 _ branch2a ' , data = res4b15_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2a = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2a ' , data = res4b16_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b16_branch2a = bn4b16_branch2a NEW_LINE res4b16_branch2a_relu = mx . symbol . Activation ( name = ' res4b16 _ branch2a _ relu ' , data = scale4b16_branch2a , act_type = ' relu ' ) NEW_LINE res4b16_branch2b = mx . symbol . Convolution ( name = ' res4b16 _ branch2b ' , data = res4b16_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2b = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2b ' , data = res4b16_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b16_branch2b = bn4b16_branch2b NEW_LINE res4b16_branch2b_relu = mx . symbol . Activation ( name = ' res4b16 _ branch2b _ relu ' , data = scale4b16_branch2b , act_type = ' relu ' ) NEW_LINE res4b16_branch2c = mx . symbol . Convolution ( name = ' res4b16 _ branch2c ' , data = res4b16_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2c = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2c ' , data = res4b16_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b16_branch2c = bn4b16_branch2c NEW_LINE res4b16 = mx . symbol . broadcast_add ( name = ' res4b16' , * [ res4b15_relu , scale4b16_branch2c ] ) NEW_LINE res4b16_relu = mx . symbol . Activation ( name = ' res4b16 _ relu ' , data = res4b16 , act_type = ' relu ' ) NEW_LINE res4b17_branch2a = mx . symbol . Convolution ( name = ' res4b17 _ branch2a ' , data = res4b16_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2a = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2a ' , data = res4b17_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b17_branch2a = bn4b17_branch2a NEW_LINE res4b17_branch2a_relu = mx . symbol . Activation ( name = ' res4b17 _ branch2a _ relu ' , data = scale4b17_branch2a , act_type = ' relu ' ) NEW_LINE res4b17_branch2b = mx . symbol . Convolution ( name = ' res4b17 _ branch2b ' , data = res4b17_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2b = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2b ' , data = res4b17_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b17_branch2b = bn4b17_branch2b NEW_LINE res4b17_branch2b_relu = mx . symbol . Activation ( name = ' res4b17 _ branch2b _ relu ' , data = scale4b17_branch2b , act_type = ' relu ' ) NEW_LINE res4b17_branch2c = mx . symbol . Convolution ( name = ' res4b17 _ branch2c ' , data = res4b17_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2c = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2c ' , data = res4b17_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b17_branch2c = bn4b17_branch2c NEW_LINE res4b17 = mx . symbol . broadcast_add ( name = ' res4b17' , * [ res4b16_relu , scale4b17_branch2c ] ) NEW_LINE res4b17_relu = mx . symbol . Activation ( name = ' res4b17 _ relu ' , data = res4b17 , act_type = ' relu ' ) NEW_LINE res4b18_branch2a = mx . symbol . Convolution ( name = ' res4b18 _ branch2a ' , data = res4b17_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2a = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2a ' , data = res4b18_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b18_branch2a = bn4b18_branch2a NEW_LINE res4b18_branch2a_relu = mx . symbol . Activation ( name = ' res4b18 _ branch2a _ relu ' , data = scale4b18_branch2a , act_type = ' relu ' ) NEW_LINE res4b18_branch2b = mx . symbol . Convolution ( name = ' res4b18 _ branch2b ' , data = res4b18_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2b = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2b ' , data = res4b18_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b18_branch2b = bn4b18_branch2b NEW_LINE res4b18_branch2b_relu = mx . symbol . Activation ( name = ' res4b18 _ branch2b _ relu ' , data = scale4b18_branch2b , act_type = ' relu ' ) NEW_LINE res4b18_branch2c = mx . symbol . Convolution ( name = ' res4b18 _ branch2c ' , data = res4b18_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2c = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2c ' , data = res4b18_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b18_branch2c = bn4b18_branch2c NEW_LINE res4b18 = mx . symbol . broadcast_add ( name = ' res4b18' , * [ res4b17_relu , scale4b18_branch2c ] ) NEW_LINE res4b18_relu = mx . symbol . Activation ( name = ' res4b18 _ relu ' , data = res4b18 , act_type = ' relu ' ) NEW_LINE res4b19_branch2a = mx . symbol . Convolution ( name = ' res4b19 _ branch2a ' , data = res4b18_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2a = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2a ' , data = res4b19_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b19_branch2a = bn4b19_branch2a NEW_LINE res4b19_branch2a_relu = mx . symbol . Activation ( name = ' res4b19 _ branch2a _ relu ' , data = scale4b19_branch2a , act_type = ' relu ' ) NEW_LINE res4b19_branch2b = mx . symbol . Convolution ( name = ' res4b19 _ branch2b ' , data = res4b19_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2b = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2b ' , data = res4b19_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b19_branch2b = bn4b19_branch2b NEW_LINE res4b19_branch2b_relu = mx . symbol . Activation ( name = ' res4b19 _ branch2b _ relu ' , data = scale4b19_branch2b , act_type = ' relu ' ) NEW_LINE res4b19_branch2c = mx . symbol . Convolution ( name = ' res4b19 _ branch2c ' , data = res4b19_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2c = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2c ' , data = res4b19_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b19_branch2c = bn4b19_branch2c NEW_LINE res4b19 = mx . symbol . broadcast_add ( name = ' res4b19' , * [ res4b18_relu , scale4b19_branch2c ] ) NEW_LINE res4b19_relu = mx . symbol . Activation ( name = ' res4b19 _ relu ' , data = res4b19 , act_type = ' relu ' ) NEW_LINE res4b20_branch2a = mx . symbol . Convolution ( name = ' res4b20 _ branch2a ' , data = res4b19_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2a = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2a ' , data = res4b20_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b20_branch2a = bn4b20_branch2a NEW_LINE res4b20_branch2a_relu = mx . symbol . Activation ( name = ' res4b20 _ branch2a _ relu ' , data = scale4b20_branch2a , act_type = ' relu ' ) NEW_LINE res4b20_branch2b = mx . symbol . Convolution ( name = ' res4b20 _ branch2b ' , data = res4b20_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2b = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2b ' , data = res4b20_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b20_branch2b = bn4b20_branch2b NEW_LINE res4b20_branch2b_relu = mx . symbol . Activation ( name = ' res4b20 _ branch2b _ relu ' , data = scale4b20_branch2b , act_type = ' relu ' ) NEW_LINE res4b20_branch2c = mx . symbol . Convolution ( name = ' res4b20 _ branch2c ' , data = res4b20_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2c = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2c ' , data = res4b20_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b20_branch2c = bn4b20_branch2c NEW_LINE res4b20 = mx . symbol . broadcast_add ( name = ' res4b20' , * [ res4b19_relu , scale4b20_branch2c ] ) NEW_LINE res4b20_relu = mx . symbol . Activation ( name = ' res4b20 _ relu ' , data = res4b20 , act_type = ' relu ' ) NEW_LINE res4b21_branch2a = mx . symbol . Convolution ( name = ' res4b21 _ branch2a ' , data = res4b20_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2a = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2a ' , data = res4b21_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b21_branch2a = bn4b21_branch2a NEW_LINE res4b21_branch2a_relu = mx . symbol . Activation ( name = ' res4b21 _ branch2a _ relu ' , data = scale4b21_branch2a , act_type = ' relu ' ) NEW_LINE res4b21_branch2b = mx . symbol . Convolution ( name = ' res4b21 _ branch2b ' , data = res4b21_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2b = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2b ' , data = res4b21_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b21_branch2b = bn4b21_branch2b NEW_LINE res4b21_branch2b_relu = mx . symbol . Activation ( name = ' res4b21 _ branch2b _ relu ' , data = scale4b21_branch2b , act_type = ' relu ' ) NEW_LINE res4b21_branch2c = mx . symbol . Convolution ( name = ' res4b21 _ branch2c ' , data = res4b21_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2c = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2c ' , data = res4b21_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b21_branch2c = bn4b21_branch2c NEW_LINE res4b21 = mx . symbol . broadcast_add ( name = ' res4b21' , * [ res4b20_relu , scale4b21_branch2c ] ) NEW_LINE res4b21_relu = mx . symbol . Activation ( name = ' res4b21 _ relu ' , data = res4b21 , act_type = ' relu ' ) NEW_LINE res4b22_branch2a = mx . symbol . Convolution ( name = ' res4b22 _ branch2a ' , data = res4b21_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b22_branch2a = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2a ' , data = res4b22_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b22_branch2a = bn4b22_branch2a NEW_LINE res4b22_branch2a_relu = mx . symbol . Activation ( name = ' res4b22 _ branch2a _ relu ' , data = scale4b22_branch2a , act_type = ' relu ' ) NEW_LINE res4b22_branch2b = mx . symbol . Convolution ( name = ' res4b22 _ branch2b ' , data = res4b22_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b22_branch2b = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2b ' , data = res4b22_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b22_branch2b = bn4b22_branch2b NEW_LINE res4b22_branch2b_relu = mx . symbol . Activation ( name = ' res4b22 _ branch2b _ relu ' , data = scale4b22_branch2b , act_type = ' relu ' ) NEW_LINE res4b22_branch2c = mx . symbol . Convolution ( name = ' res4b22 _ branch2c ' , data = res4b22_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b22_branch2c = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2c ' , data = res4b22_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale4b22_branch2c = bn4b22_branch2c NEW_LINE res4b22 = mx . symbol . broadcast_add ( name = ' res4b22' , * [ res4b21_relu , scale4b22_branch2c ] ) NEW_LINE res4b22_relu = mx . symbol . Activation ( name = ' res4b22 _ relu ' , data = res4b22 , act_type = ' relu ' ) NEW_LINE return res4b22_relu NEW_LINE DEDENT\",), (\"def get_resnet_v1_conv5 ( self , conv_feat ) : NEW_LINE INDENT res5a_branch1 = mx . symbol . Convolution ( name = ' res5a _ branch1' , data = conv_feat , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5a_branch1 = mx . symbol . BatchNorm ( name = ' bn5a _ branch1' , data = res5a_branch1 , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5a_branch1 = bn5a_branch1 NEW_LINE res5a_branch2a = mx . symbol . Convolution ( name = ' res5a _ branch2a ' , data = conv_feat , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5a_branch2a = mx . symbol . BatchNorm ( name = ' bn5a _ branch2a ' , data = res5a_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5a_branch2a = bn5a_branch2a NEW_LINE res5a_branch2a_relu = mx . symbol . Activation ( name = ' res5a _ branch2a _ relu ' , data = scale5a_branch2a , act_type = ' relu ' ) NEW_LINE res5a_branch2b = mx . symbol . Convolution ( name = ' res5a _ branch2b ' , data = res5a_branch2a_relu , num_filter = 512 , pad = ( 2 , 2 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn5a_branch2b = mx . symbol . BatchNorm ( name = ' bn5a _ branch2b ' , data = res5a_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5a_branch2b = bn5a_branch2b NEW_LINE res5a_branch2b_relu = mx . symbol . Activation ( name = ' res5a _ branch2b _ relu ' , data = scale5a_branch2b , act_type = ' relu ' ) NEW_LINE res5a_branch2c = mx . symbol . Convolution ( name = ' res5a _ branch2c ' , data = res5a_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5a_branch2c = mx . symbol . BatchNorm ( name = ' bn5a _ branch2c ' , data = res5a_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5a_branch2c = bn5a_branch2c NEW_LINE res5a = mx . symbol . broadcast_add ( name = ' res5a ' , * [ scale5a_branch1 , scale5a_branch2c ] ) NEW_LINE res5a_relu = mx . symbol . Activation ( name = ' res5a _ relu ' , data = res5a , act_type = ' relu ' ) NEW_LINE res5b_branch2a = mx . symbol . Convolution ( name = ' res5b _ branch2a ' , data = res5a_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5b_branch2a = mx . symbol . BatchNorm ( name = ' bn5b _ branch2a ' , data = res5b_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5b_branch2a = bn5b_branch2a NEW_LINE res5b_branch2a_relu = mx . symbol . Activation ( name = ' res5b _ branch2a _ relu ' , data = scale5b_branch2a , act_type = ' relu ' ) NEW_LINE res5b_branch2b = mx . symbol . Convolution ( name = ' res5b _ branch2b ' , data = res5b_branch2a_relu , num_filter = 512 , pad = ( 2 , 2 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn5b_branch2b = mx . symbol . BatchNorm ( name = ' bn5b _ branch2b ' , data = res5b_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5b_branch2b = bn5b_branch2b NEW_LINE res5b_branch2b_relu = mx . symbol . Activation ( name = ' res5b _ branch2b _ relu ' , data = scale5b_branch2b , act_type = ' relu ' ) NEW_LINE res5b_branch2c = mx . symbol . Convolution ( name = ' res5b _ branch2c ' , data = res5b_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5b_branch2c = mx . symbol . BatchNorm ( name = ' bn5b _ branch2c ' , data = res5b_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5b_branch2c = bn5b_branch2c NEW_LINE res5b = mx . symbol . broadcast_add ( name = ' res5b ' , * [ res5a_relu , scale5b_branch2c ] ) NEW_LINE res5b_relu = mx . symbol . Activation ( name = ' res5b _ relu ' , data = res5b , act_type = ' relu ' ) NEW_LINE res5c_branch2a = mx . symbol . Convolution ( name = ' res5c _ branch2a ' , data = res5b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5c_branch2a = mx . symbol . BatchNorm ( name = ' bn5c _ branch2a ' , data = res5c_branch2a , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5c_branch2a = bn5c_branch2a NEW_LINE res5c_branch2a_relu = mx . symbol . Activation ( name = ' res5c _ branch2a _ relu ' , data = scale5c_branch2a , act_type = ' relu ' ) NEW_LINE res5c_branch2b = mx . symbol . Convolution ( name = ' res5c _ branch2b ' , data = res5c_branch2a_relu , num_filter = 512 , pad = ( 2 , 2 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn5c_branch2b = mx . symbol . BatchNorm ( name = ' bn5c _ branch2b ' , data = res5c_branch2b , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5c_branch2b = bn5c_branch2b NEW_LINE res5c_branch2b_relu = mx . symbol . Activation ( name = ' res5c _ branch2b _ relu ' , data = scale5c_branch2b , act_type = ' relu ' ) NEW_LINE res5c_branch2c = mx . symbol . Convolution ( name = ' res5c _ branch2c ' , data = res5c_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5c_branch2c = mx . symbol . BatchNorm ( name = ' bn5c _ branch2c ' , data = res5c_branch2c , use_global_stats = True , fix_gamma = False , eps = self . eps ) NEW_LINE scale5c_branch2c = bn5c_branch2c NEW_LINE res5c = mx . symbol . broadcast_add ( name = ' res5c ' , * [ res5b_relu , scale5c_branch2c ] ) NEW_LINE res5c_relu = mx . symbol . Activation ( name = ' res5c _ relu ' , data = res5c , act_type = ' relu ' ) NEW_LINE return res5c_relu NEW_LINE DEDENT\",), ('def get_light_head ( self , data , mid_num_filter = 256 , suffix = \\' separable \\' ) : NEW_LINE INDENT conv_new_1 = mx . sym . Convolution ( data = data , kernel = ( 15 , 1 ) , pad = ( 7 , 0 ) , num_filter = mid_num_filter , name = \" conv _ new _ 1\" + suffix , weight = self . shared_param_dict [ \\' conv _ new _ 1 _ weight \\' ] , bias = self . shared_param_dict [ \\' conv _ new _ 1 _ bias \\' ] , lr_mult = 3.0 ) NEW_LINE relu_new_1 = mx . sym . Activation ( data = conv_new_1 , act_type = \\' relu \\' , name = \\' relu1\\' + suffix ) NEW_LINE conv_new_2 = mx . sym . Convolution ( data = relu_new_1 , kernel = ( 1 , 15 ) , pad = ( 0 , 7 ) , num_filter = 10 * 7 * 7 , name = \" conv _ new _ 2\" + suffix , weight = self . shared_param_dict [ \\' conv _ new _ 2 _ weight \\' ] , bias = self . shared_param_dict [ \\' conv _ new _ 2 _ bias \\' ] , lr_mult = 3.0 ) NEW_LINE relu_new_2 = mx . sym . Activation ( data = conv_new_2 , act_type = \\' relu \\' , name = \\' relu2\\' + suffix ) NEW_LINE conv_new_3 = mx . sym . Convolution ( data = data , kernel = ( 1 , 15 ) , pad = ( 0 , 7 ) , num_filter = mid_num_filter , name = \" conv _ new _ 3\" + suffix , weight = self . shared_param_dict [ \\' conv _ new _ 3 _ weight \\' ] , bias = self . shared_param_dict [ \\' conv _ new _ 3 _ bias \\' ] , lr_mult = 3.0 ) NEW_LINE relu_new_3 = mx . sym . Activation ( data = conv_new_3 , act_type = \\' relu \\' , name = \\' relu3\\' + suffix ) NEW_LINE conv_new_4 = mx . sym . Convolution ( data = relu_new_3 , kernel = ( 15 , 1 ) , pad = ( 7 , 0 ) , num_filter = 10 * 7 * 7 , name = \" conv _ new _ 4\" + suffix , weight = self . shared_param_dict [ \\' conv _ new _ 4 _ weight \\' ] , bias = self . shared_param_dict [ \\' conv _ new _ 4 _ bias \\' ] , lr_mult = 3.0 ) NEW_LINE relu_new_4 = mx . sym . Activation ( data = conv_new_4 , act_type = \\' relu \\' , name = \\' relu4\\' + suffix ) NEW_LINE light_head = mx . symbol . broadcast_add ( name = \\' light _ head \\' , * [ relu_new_2 , relu_new_4 ] ) NEW_LINE return light_head NEW_LINE DEDENT',), ('def get_rpn ( self , conv_feat , num_anchors ) : NEW_LINE INDENT rpn_conv = mx . sym . Convolution ( data = conv_feat , kernel = ( 3 , 3 ) , pad = ( 1 , 1 ) , num_filter = 512 , name = \" rpn _ conv _ 3x3\" ) NEW_LINE rpn_relu = mx . sym . Activation ( data = rpn_conv , act_type = \" relu \" , name = \" rpn _ relu \" ) NEW_LINE rpn_cls_score = mx . sym . Convolution ( data = rpn_relu , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , num_filter = 2 * num_anchors , name = \" rpn _ cls _ score \" ) NEW_LINE rpn_bbox_pred = mx . sym . Convolution ( data = rpn_relu , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , num_filter = 4 * num_anchors , name = \" rpn _ bbox _ pred \" ) NEW_LINE return rpn_cls_score , rpn_bbox_pred NEW_LINE DEDENT',), ('def get_symbol_rpn ( self , cfg , is_train = True ) : NEW_LINE INDENT num_anchors = cfg . network . NUM_ANCHORS NEW_LINE if is_train : NEW_LINE INDENT data = mx . sym . Variable ( name = \" data \" ) NEW_LINE rpn_label = mx . sym . Variable ( name = \\' label \\' ) NEW_LINE rpn_bbox_target = mx . sym . Variable ( name = \\' bbox _ target \\' ) NEW_LINE rpn_bbox_weight = mx . sym . Variable ( name = \\' bbox _ weight \\' ) NEW_LINE DEDENT else : NEW_LINE INDENT data = mx . sym . Variable ( name = \" data \" ) NEW_LINE im_info = mx . sym . Variable ( name = \" im _ info \" ) NEW_LINE DEDENT conv_feat = self . get_resnet_v1_conv4 ( data ) NEW_LINE rpn_cls_score , rpn_bbox_pred = self . get_rpn ( conv_feat , num_anchors ) NEW_LINE if is_train : NEW_LINE INDENT rpn_cls_score_reshape = mx . sym . Reshape ( data = rpn_cls_score , shape = ( 0 , 2 , - 1 , 0 ) , name = \" rpn _ cls _ score _ reshape \" ) NEW_LINE rpn_cls_prob = mx . sym . SoftmaxOutput ( data = rpn_cls_score_reshape , label = rpn_label , multi_output = True , normalization = \\' valid \\' , use_ignore = True , ignore_label = - 1 , name = \" rpn _ cls _ prob \" , grad_scale = 1.0 ) NEW_LINE rpn_bbox_loss_ = rpn_bbox_weight * mx . sym . smooth_l1 ( name = \\' rpn _ bbox _ loss _ \\' , scalar = 3.0 , data = ( rpn_bbox_pred - rpn_bbox_target ) ) NEW_LINE rpn_bbox_loss = mx . sym . MakeLoss ( name = \\' rpn _ bbox _ loss \\' , data = rpn_bbox_loss_ , grad_scale = 1.0 / cfg . TRAIN . RPN_BATCH_SIZE ) NEW_LINE group = mx . symbol . Group ( [ rpn_cls_prob , rpn_bbox_loss ] ) NEW_LINE DEDENT else : NEW_LINE INDENT rpn_cls_score_reshape = mx . sym . Reshape ( data = rpn_cls_score , shape = ( 0 , 2 , - 1 , 0 ) , name = \" rpn _ cls _ score _ reshape \" ) NEW_LINE rpn_cls_prob = mx . sym . SoftmaxActivation ( data = rpn_cls_score_reshape , mode = \" channel \" , name = \" rpn _ cls _ prob \" ) NEW_LINE rpn_cls_prob_reshape = mx . sym . Reshape ( data = rpn_cls_prob , shape = ( 0 , 2 * num_anchors , - 1 , 0 ) , name = \\' rpn _ cls _ prob _ reshape \\' ) NEW_LINE if cfg . TEST . CXX_PROPOSAL : NEW_LINE INDENT rois , score = mx . contrib . sym . Proposal ( cls_prob = rpn_cls_prob_reshape , bbox_pred = rpn_bbox_pred , im_info = im_info , name = \\' rois \\' , output_score = True , feature_stride = cfg . network . RPN_FEAT_STRIDE , scales = tuple ( cfg . network . ANCHOR_SCALES ) , ratios = tuple ( cfg . network . ANCHOR_RATIOS ) , rpn_pre_nms_top_n = cfg . TEST . RPN_PRE_NMS_TOP_N , rpn_post_nms_top_n = cfg . TEST . RPN_POST_NMS_TOP_N , threshold = cfg . TEST . RPN_NMS_THRESH , rpn_min_size = cfg . TEST . RPN_MIN_SIZE ) NEW_LINE DEDENT else : NEW_LINE INDENT rois , score = mx . sym . Custom ( cls_prob = rpn_cls_prob_reshape , bbox_pred = rpn_bbox_pred , im_info = im_info , name = \\' rois \\' , output_score = True , op_type = \\' proposal \\' , feat_stride = cfg . network . RPN_FEAT_STRIDE , scales = tuple ( cfg . network . ANCHOR_SCALES ) , ratios = tuple ( cfg . network . ANCHOR_RATIOS ) , rpn_pre_nms_top_n = cfg . TEST . RPN_PRE_NMS_TOP_N , rpn_post_nms_top_n = cfg . TEST . RPN_POST_NMS_TOP_N , threshold = cfg . TEST . RPN_NMS_THRESH , rpn_min_size = cfg . TEST . RPN_MIN_SIZE ) NEW_LINE group = mx . symbol . Group ( [ rois , score ] ) NEW_LINE DEDENT DEDENT self . sym = group NEW_LINE return group NEW_LINE DEDENT',), ('def get_symbol_rcnn ( self , cfg , is_train = True ) : NEW_LINE INDENT num_classes = cfg . dataset . NUM_CLASSES NEW_LINE num_reg_classes = ( 2 if cfg . CLASS_AGNOSTIC else num_classes ) NEW_LINE if is_train : NEW_LINE INDENT data = mx . symbol . Variable ( name = \" data \" ) NEW_LINE rois = mx . symbol . Variable ( name = \\' rois \\' ) NEW_LINE label = mx . symbol . Variable ( name = \\' label \\' ) NEW_LINE bbox_target = mx . symbol . Variable ( name = \\' bbox _ target \\' ) NEW_LINE bbox_weight = mx . symbol . Variable ( name = \\' bbox _ weight \\' ) NEW_LINE rois = mx . symbol . Reshape ( data = rois , shape = ( - 1 , 5 ) , name = \\' rois _ reshape \\' ) NEW_LINE label = mx . symbol . Reshape ( data = label , shape = ( - 1 , ) , name = \\' label _ reshape \\' ) NEW_LINE bbox_target = mx . symbol . Reshape ( data = bbox_target , shape = ( - 1 , 5 * num_classes ) , name = \\' bbox _ target _ reshape \\' ) NEW_LINE bbox_weight = mx . symbol . Reshape ( data = bbox_weight , shape = ( - 1 , 5 * num_classes ) , name = \\' bbox _ weight _ reshape \\' ) NEW_LINE DEDENT else : NEW_LINE INDENT data = mx . sym . Variable ( name = \" data \" ) NEW_LINE rois = mx . symbol . Variable ( name = \\' rois \\' ) NEW_LINE rois = mx . symbol . Reshape ( data = rois , shape = ( - 1 , 5 ) , name = \\' rois _ reshape \\' ) NEW_LINE DEDENT conv_feat = self . get_resnet_v1_conv4 ( data ) NEW_LINE relu1 = self . get_resnet_v1_conv5 ( conv_feat ) NEW_LINE conv_thin_feat = self . get_light_head ( data = relu1 , mid_num_filter = 256 ) NEW_LINE offset_t = mx . contrib . sym . DeformablePSROIPooling ( name = \\' offset _ t \\' , data = conv_thin_feat , rois = rois , group_size = 7 , pooled_size = 7 , sample_per_part = 4 , no_trans = True , part_size = 7 , output_dim = 10 , spatial_scale = 0.0625 ) NEW_LINE offset = mx . sym . FullyConnected ( name = \\' offset \\' , data = offset_t , num_hidden = 7 * 7 * 2 , lr_mult = 0.01 ) NEW_LINE offset_reshape = mx . sym . Reshape ( data = offset , shape = ( - 1 , 2 , 7 , 7 ) , name = \" offset _ reshape \" ) NEW_LINE deformable_roi_pool = mx . contrib . sym . DeformablePSROIPooling ( name = \\' deformable _ roi _ pool \\' , data = conv_thin_feat , rois = rois , trans = offset_reshape , group_size = 7 , pooled_size = 7 , sample_per_part = 4 , no_trans = False , part_size = 7 , output_dim = 10 , spatial_scale = 0.0625 , trans_std = 0.1 ) NEW_LINE fc_new_1 = mx . symbol . FullyConnected ( name = \\' fc _ new _ 1\\' , data = deformable_roi_pool , num_hidden = 1024 ) NEW_LINE fc_new_1_relu = mx . sym . Activation ( data = fc_new_1 , act_type = \\' relu \\' , name = \\' fc _ new _ 1 _ relu \\' ) NEW_LINE cls_score = mx . symbol . FullyConnected ( name = \\' cls _ score \\' , data = fc_new_1_relu , num_hidden = num_classes ) NEW_LINE bbox_pred = mx . symbol . FullyConnected ( name = \\' bbox _ pred \\' , data = fc_new_1_relu , num_hidden = num_reg_classes * 5 ) NEW_LINE if is_train : NEW_LINE INDENT if cfg . TRAIN . ENABLE_OHEM : NEW_LINE INDENT labels_ohem , bbox_weights_ohem = mx . sym . Custom ( op_type = \\' BoxAnnotatorOHEM \\' , num_classes = num_classes , num_reg_classes = num_reg_classes , roi_per_img = cfg . TRAIN . BATCH_ROIS_OHEM , cls_score = cls_score , bbox_pred = bbox_pred , labels = label , bbox_targets = bbox_target , bbox_weights = bbox_weight ) NEW_LINE cls_prob = mx . sym . SoftmaxOutput ( name = \\' cls _ prob \\' , data = cls_score , label = labels_ohem , normalization = \\' valid \\' , use_ignore = True , ignore_label = - 1 , grad_scale = 1.0 ) NEW_LINE bbox_loss_ = bbox_weights_ohem * mx . sym . smooth_l1 ( name = \\' bbox _ loss _ \\' , scalar = 1.0 , data = ( bbox_pred - bbox_target ) ) NEW_LINE bbox_loss = mx . sym . MakeLoss ( name = \\' bbox _ loss \\' , data = bbox_loss_ , grad_scale = 1.0 / cfg . TRAIN . BATCH_ROIS_OHEM ) NEW_LINE DEDENT else : NEW_LINE INDENT cls_prob = mx . sym . SoftmaxOutput ( name = \\' cls _ prob \\' , data = cls_score , label = label , normalization = \\' valid \\' , grad_scale = 1.0 ) NEW_LINE bbox_loss_ = bbox_weight * mx . sym . smooth_l1 ( name = \\' bbox _ loss _ \\' , scalar = 1.0 , data = ( bbox_pred - bbox_target ) ) NEW_LINE bbox_loss = mx . sym . MakeLoss ( name = \\' bbox _ loss \\' , data = bbox_loss_ , grad_scale = 1.0 / cfg . TRAIN . BATCH_ROIS ) NEW_LINE DEDENT cls_prob = mx . sym . Reshape ( data = cls_prob , shape = ( cfg . TRAIN . BATCH_IMAGES , - 1 , num_classes ) , name = \\' cls _ prob _ reshape \\' ) NEW_LINE bbox_loss = mx . sym . Reshape ( data = bbox_loss , shape = ( cfg . TRAIN . BATCH_IMAGES , - 1 , 5 * num_reg_classes ) , name = \\' bbox _ loss _ reshape \\' ) NEW_LINE group = mx . sym . Group ( [ cls_prob , bbox_loss ] ) NEW_LINE DEDENT else : NEW_LINE INDENT cls_prob = mx . sym . SoftmaxActivation ( name = \\' cls _ prob \\' , data = cls_score ) NEW_LINE cls_prob = mx . sym . Reshape ( data = cls_prob , shape = ( cfg . TEST . BATCH_IMAGES , - 1 , num_classes ) , name = \\' cls _ prob _ reshape \\' ) NEW_LINE bbox_pred = mx . sym . Reshape ( data = bbox_pred , shape = ( cfg . TEST . BATCH_IMAGES , - 1 , 5 * num_reg_classes ) , name = \\' bbox _ pred _ reshape \\' ) NEW_LINE group = mx . sym . Group ( [ cls_prob , bbox_pred ] ) NEW_LINE DEDENT self . sym = group NEW_LINE return group NEW_LINE DEDENT',), (\"def init_weight_rcnn ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT arg_params [ ' fc _ new _ 1 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fc _ new _ 1 _ weight ' ] ) NEW_LINE arg_params [ ' fc _ new _ 1 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fc _ new _ 1 _ bias ' ] ) NEW_LINE arg_params [ ' cls _ score _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' cls _ score _ weight ' ] ) NEW_LINE arg_params [ ' cls _ score _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' cls _ score _ bias ' ] ) NEW_LINE arg_params [ ' offset _ weight ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' offset _ weight ' ] ) NEW_LINE arg_params [ ' offset _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' offset _ bias ' ] ) NEW_LINE arg_params [ ' bbox _ pred _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' bbox _ pred _ weight ' ] ) NEW_LINE arg_params [ ' bbox _ pred _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' bbox _ pred _ bias ' ] ) NEW_LINE DEDENT\",), (\"def init_weight_rpn ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT arg_params [ ' rpn _ conv _ 3x3 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' rpn _ conv _ 3x3 _ weight ' ] ) NEW_LINE arg_params [ ' rpn _ conv _ 3x3 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' rpn _ conv _ 3x3 _ bias ' ] ) NEW_LINE arg_params [ ' rpn _ cls _ score _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' rpn _ cls _ score _ weight ' ] ) NEW_LINE arg_params [ ' rpn _ cls _ score _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' rpn _ cls _ score _ bias ' ] ) NEW_LINE arg_params [ ' rpn _ bbox _ pred _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' rpn _ bbox _ pred _ weight ' ] ) NEW_LINE arg_params [ ' rpn _ bbox _ pred _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' rpn _ bbox _ pred _ bias ' ] ) NEW_LINE DEDENT\",), (\"def init_weight ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT self . init_weight_rpn ( cfg , arg_params , aux_params ) NEW_LINE self . init_weight_rcnn ( cfg , arg_params , aux_params ) NEW_LINE for name in self . shared_param_list : NEW_LINE INDENT arg_params [ name + ' _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ name + ' _ weight ' ] ) NEW_LINE arg_params [ name + ' _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ name + ' _ bias ' ] ) NEW_LINE DEDENT DEDENT\",), (\"def __init__ ( self , roidb , config , batch_size = 1 , shuffle = False , has_rpn = False ) : NEW_LINE INDENT super ( TestLoader , self ) . __init__ ( ) NEW_LINE self . cfg = config NEW_LINE self . roidb = roidb NEW_LINE self . batch_size = batch_size NEW_LINE self . shuffle = shuffle NEW_LINE self . has_rpn = has_rpn NEW_LINE self . size = len ( self . roidb ) NEW_LINE self . index = np . arange ( self . size ) NEW_LINE if has_rpn : NEW_LINE INDENT self . data_name = [ ' data ' , ' im _ info ' ] NEW_LINE DEDENT else : NEW_LINE INDENT self . data_name = [ ' data ' , ' rois ' ] NEW_LINE DEDENT self . label_name = None NEW_LINE self . cur = 0 NEW_LINE self . data = None NEW_LINE self . label = [ ] NEW_LINE self . im_info = None NEW_LINE self . reset ( ) NEW_LINE self . get_batch ( ) NEW_LINE DEDENT\",), ('def provide_data ( self ) : NEW_LINE INDENT return [ [ ( k , v . shape ) for k , v in zip ( self . data_name , idata ) ] for idata in self . data ] NEW_LINE DEDENT',), ('def provide_label ( self ) : NEW_LINE INDENT return [ None for _ in range ( len ( self . data ) ) ] NEW_LINE DEDENT',), ('def provide_data_single ( self ) : NEW_LINE INDENT return [ ( k , v . shape ) for k , v in zip ( self . data_name , self . data [ 0 ] ) ] NEW_LINE DEDENT',), ('def provide_label_single ( self ) : NEW_LINE INDENT return None NEW_LINE DEDENT',), ('def reset ( self ) : NEW_LINE INDENT self . cur = 0 NEW_LINE if self . shuffle : NEW_LINE INDENT np . random . shuffle ( self . index ) NEW_LINE DEDENT DEDENT',), ('def iter_next ( self ) : NEW_LINE INDENT return self . cur < self . size NEW_LINE DEDENT',), ('def next ( self ) : NEW_LINE INDENT if self . iter_next ( ) : NEW_LINE INDENT self . get_batch ( ) NEW_LINE self . cur += self . batch_size NEW_LINE return self . im_info , mx . io . DataBatch ( data = self . data , label = self . label , pad = self . getpad ( ) , index = self . getindex ( ) , provide_data = self . provide_data , provide_label = self . provide_label ) NEW_LINE DEDENT else : NEW_LINE INDENT raise StopIteration NEW_LINE DEDENT DEDENT',), ('def getindex ( self ) : NEW_LINE INDENT return self . cur / self . batch_size NEW_LINE DEDENT',), ('def getpad ( self ) : NEW_LINE INDENT if self . cur + self . batch_size > self . size : NEW_LINE INDENT return self . cur + self . batch_size - self . size NEW_LINE DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT',), ('def get_batch ( self ) : NEW_LINE INDENT cur_from = self . cur NEW_LINE cur_to = min ( cur_from + self . batch_size , self . size ) NEW_LINE roidb = [ self . roidb [ self . index [ i ] ] for i in range ( cur_from , cur_to ) ] NEW_LINE if self . has_rpn : NEW_LINE INDENT data , label , im_info = get_rpn_testbatch ( roidb , self . cfg ) NEW_LINE DEDENT else : NEW_LINE INDENT data , label , im_info = get_rcnn_testbatch ( roidb , self . cfg ) NEW_LINE DEDENT self . data = [ [ mx . nd . array ( idata [ name ] ) for name in self . data_name ] for idata in data ] NEW_LINE self . im_info = im_info NEW_LINE DEDENT',), ('def get_batch_individual ( self ) : NEW_LINE INDENT cur_from = self . cur NEW_LINE cur_to = min ( cur_from + self . batch_size , self . size ) NEW_LINE roidb = [ self . roidb [ self . index [ i ] ] for i in range ( cur_from , cur_to ) ] NEW_LINE if self . has_rpn : NEW_LINE INDENT data , label , im_info = get_rpn_testbatch ( roidb , self . cfg ) NEW_LINE DEDENT else : NEW_LINE INDENT data , label , im_info = get_rcnn_testbatch ( roidb , self . cfg ) NEW_LINE DEDENT self . data = [ mx . nd . array ( data [ name ] ) for name in self . data_name ] NEW_LINE self . im_info = im_info NEW_LINE DEDENT',), (\"def __init__ ( self , roidb , config , batch_size = 2 , shuffle = False , ctx = None , work_load_list = None , aspect_grouping = False ) : NEW_LINE INDENT super ( ROIIter , self ) . __init__ ( ) NEW_LINE self . roidb = roidb NEW_LINE self . cfg = config NEW_LINE self . batch_size = batch_size NEW_LINE self . shuffle = shuffle NEW_LINE self . ctx = ctx NEW_LINE if self . ctx is None : NEW_LINE INDENT self . ctx = [ mx . cpu ( ) ] NEW_LINE DEDENT self . work_load_list = work_load_list NEW_LINE self . aspect_grouping = aspect_grouping NEW_LINE self . size = len ( roidb ) NEW_LINE self . index = np . arange ( self . size ) NEW_LINE self . data_name = [ ' data ' , ' rois ' ] NEW_LINE self . label_name = [ ' label ' , ' bbox _ target ' , ' bbox _ weight ' ] NEW_LINE self . cur = 0 NEW_LINE self . batch = None NEW_LINE self . data = None NEW_LINE self . label = None NEW_LINE self . reset ( ) NEW_LINE self . get_batch_individual ( ) NEW_LINE DEDENT\",), ('def provide_data_single ( self ) : NEW_LINE INDENT return [ ( k , v . shape ) for k , v in zip ( self . data_name , self . data [ 0 ] ) ] NEW_LINE DEDENT',), ('def provide_label_single ( self ) : NEW_LINE INDENT return [ ( k , v . shape ) for k , v in zip ( self . label_name , self . label [ 0 ] ) ] NEW_LINE DEDENT',), (\"def reset ( self ) : NEW_LINE INDENT self . cur = 0 NEW_LINE if self . shuffle : NEW_LINE INDENT if self . aspect_grouping : NEW_LINE INDENT widths = np . array ( [ r [ ' width ' ] for r in self . roidb ] ) NEW_LINE heights = np . array ( [ r [ ' height ' ] for r in self . roidb ] ) NEW_LINE horz = ( widths >= heights ) NEW_LINE vert = np . logical_not ( horz ) NEW_LINE horz_inds = np . where ( horz ) [ 0 ] NEW_LINE vert_inds = np . where ( vert ) [ 0 ] NEW_LINE inds = np . hstack ( ( np . random . permutation ( horz_inds ) , np . random . permutation ( vert_inds ) ) ) NEW_LINE extra = inds . shape [ 0 ] % self . batch_size NEW_LINE inds_ = np . reshape ( inds [ : - extra ] , ( - 1 , self . batch_size ) ) NEW_LINE row_perm = np . random . permutation ( np . arange ( inds_ . shape [ 0 ] ) ) NEW_LINE inds [ : - extra ] = np . reshape ( inds_ [ row_perm , : ] , ( - 1 , ) ) NEW_LINE self . index = inds NEW_LINE DEDENT else : NEW_LINE INDENT np . random . shuffle ( self . index ) NEW_LINE DEDENT DEDENT DEDENT\",), ('def iter_next ( self ) : NEW_LINE INDENT return self . cur + self . batch_size <= self . size NEW_LINE DEDENT',), ('def next ( self ) : NEW_LINE INDENT if self . iter_next ( ) : NEW_LINE INDENT self . get_batch_individual ( ) NEW_LINE self . cur += self . batch_size NEW_LINE return mx . io . DataBatch ( data = self . data , label = self . label , pad = self . getpad ( ) , index = self . getindex ( ) , provide_data = self . provide_data , provide_label = self . provide_label ) NEW_LINE DEDENT else : NEW_LINE INDENT raise StopIteration NEW_LINE DEDENT DEDENT',), ('def getindex ( self ) : NEW_LINE INDENT return self . cur / self . batch_size NEW_LINE DEDENT',), ('def getpad ( self ) : NEW_LINE INDENT if self . cur + self . batch_size > self . size : NEW_LINE INDENT return self . cur + self . batch_size - self . size NEW_LINE DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT',), ('def get_batch ( self ) : NEW_LINE INDENT cur_from = self . cur NEW_LINE cur_to = min ( cur_from + self . batch_size , self . size ) NEW_LINE roidb = [ self . roidb [ self . index [ i ] ] for i in range ( cur_from , cur_to ) ] NEW_LINE work_load_list = self . work_load_list NEW_LINE ctx = self . ctx NEW_LINE if work_load_list is None : NEW_LINE INDENT work_load_list = [ 1 ] * len ( ctx ) NEW_LINE DEDENT assert isinstance ( work_load_list , list ) and len ( work_load_list ) == len ( ctx ) , slices = _split_input_slice ( self . batch_size , work_load_list ) NEW_LINE data_list = [ ] NEW_LINE label_list = [ ] NEW_LINE for islice in slices : NEW_LINE INDENT iroidb = [ roidb [ i ] for i in range ( islice . start , islice . stop ) ] NEW_LINE data , label = get_rcnn_batch ( iroidb , self . cfg ) NEW_LINE data_list . append ( data ) NEW_LINE label_list . append ( label ) NEW_LINE DEDENT all_data = dict ( ) NEW_LINE for key in data_list [ 0 ] . keys ( ) : NEW_LINE INDENT all_data [ key ] = tensor_vstack ( [ batch [ key ] for batch in data_list ] ) NEW_LINE DEDENT all_label = dict ( ) NEW_LINE for key in label_list [ 0 ] . keys ( ) : NEW_LINE INDENT all_label [ key ] = tensor_vstack ( [ batch [ key ] for batch in label_list ] ) NEW_LINE DEDENT self . data = [ mx . nd . array ( all_data [ name ] ) for name in self . data_name ] NEW_LINE self . label = [ mx . nd . array ( all_label [ name ] ) for name in self . label_name ] NEW_LINE DEDENT',), (\"def get_batch_individual ( self ) : NEW_LINE INDENT cur_from = self . cur NEW_LINE cur_to = min ( cur_from + self . batch_size , self . size ) NEW_LINE roidb = [ self . roidb [ self . index [ i ] ] for i in range ( cur_from , cur_to ) ] NEW_LINE work_load_list = self . work_load_list NEW_LINE ctx = self . ctx NEW_LINE if work_load_list is None : NEW_LINE INDENT work_load_list = [ 1 ] * len ( ctx ) NEW_LINE DEDENT assert isinstance ( work_load_list , list ) and len ( work_load_list ) == len ( ctx ) , slices = _split_input_slice ( self . batch_size , work_load_list ) NEW_LINE rst = [ ] NEW_LINE for idx , islice in enumerate ( slices ) : NEW_LINE INDENT iroidb = [ roidb [ i ] for i in range ( islice . start , islice . stop ) ] NEW_LINE rst . append ( self . parfetch ( iroidb ) ) NEW_LINE DEDENT all_data = [ _ [ ' data ' ] for _ in rst ] NEW_LINE all_label = [ _ [ ' label ' ] for _ in rst ] NEW_LINE self . data = [ [ mx . nd . array ( data [ key ] ) for key in self . data_name ] for data in all_data ] NEW_LINE self . label = [ [ mx . nd . array ( label [ key ] ) for key in self . label_name ] for label in all_label ] NEW_LINE DEDENT\",), (\"def parfetch ( self , iroidb ) : NEW_LINE INDENT data , label = get_rcnn_batch ( iroidb , self . cfg ) NEW_LINE return { ' data ' : data , ' label ' : label } NEW_LINE DEDENT\",), (\"def __init__ ( self , feat_sym , roidb , cfg , batch_size = 1 , shuffle = False , ctx = None , work_load_list = None , feat_stride = 16 , anchor_scales = ( 8 , 16 , 32 ) , anchor_ratios = ( 0.5 , 1 , 2 ) , allowed_border = 0 , aspect_grouping = False ) : NEW_LINE INDENT super ( AnchorLoader , self ) . __init__ ( ) NEW_LINE self . feat_sym = feat_sym NEW_LINE self . roidb = roidb NEW_LINE self . cfg = cfg NEW_LINE self . batch_size = batch_size NEW_LINE self . shuffle = shuffle NEW_LINE self . ctx = ctx NEW_LINE if self . ctx is None : NEW_LINE INDENT self . ctx = [ mx . cpu ( ) ] NEW_LINE DEDENT self . work_load_list = work_load_list NEW_LINE self . feat_stride = feat_stride NEW_LINE self . anchor_scales = anchor_scales NEW_LINE self . anchor_ratios = anchor_ratios NEW_LINE self . allowed_border = allowed_border NEW_LINE self . aspect_grouping = aspect_grouping NEW_LINE self . size = len ( roidb ) NEW_LINE self . index = np . arange ( self . size ) NEW_LINE if config . TRAIN . END2END : NEW_LINE INDENT self . data_name = [ ' data ' , ' im _ info ' , ' gt _ boxes ' ] NEW_LINE DEDENT else : NEW_LINE INDENT self . data_name = [ ' data ' ] NEW_LINE DEDENT self . label_name = [ ' label ' , ' bbox _ target ' , ' bbox _ weight ' ] NEW_LINE self . cur = 0 NEW_LINE self . batch = None NEW_LINE self . data = None NEW_LINE self . label = None NEW_LINE self . reset ( ) NEW_LINE self . get_batch_individual ( ) NEW_LINE DEDENT\",), ('def provide_data_single ( self ) : NEW_LINE INDENT return [ ( k , v . shape ) for k , v in zip ( self . data_name , self . data [ 0 ] ) ] NEW_LINE DEDENT',), ('def provide_label_single ( self ) : NEW_LINE INDENT return [ ( k , v . shape ) for k , v in zip ( self . label_name , self . label [ 0 ] ) ] NEW_LINE DEDENT',), (\"def reset ( self ) : NEW_LINE INDENT self . cur = 0 NEW_LINE if self . shuffle : NEW_LINE INDENT if self . aspect_grouping : NEW_LINE INDENT widths = np . array ( [ r [ ' width ' ] for r in self . roidb ] ) NEW_LINE heights = np . array ( [ r [ ' height ' ] for r in self . roidb ] ) NEW_LINE horz = ( widths >= heights ) NEW_LINE vert = np . logical_not ( horz ) NEW_LINE horz_inds = np . where ( horz ) [ 0 ] NEW_LINE vert_inds = np . where ( vert ) [ 0 ] NEW_LINE inds = np . hstack ( ( np . random . permutation ( horz_inds ) , np . random . permutation ( vert_inds ) ) ) NEW_LINE extra = inds . shape [ 0 ] % self . batch_size NEW_LINE inds_ = np . reshape ( inds [ : - extra ] , ( - 1 , self . batch_size ) ) NEW_LINE row_perm = np . random . permutation ( np . arange ( inds_ . shape [ 0 ] ) ) NEW_LINE inds [ : - extra ] = np . reshape ( inds_ [ row_perm , : ] , ( - 1 , ) ) NEW_LINE self . index = inds NEW_LINE DEDENT else : NEW_LINE INDENT np . random . shuffle ( self . index ) NEW_LINE DEDENT DEDENT DEDENT\",), ('def iter_next ( self ) : NEW_LINE INDENT return self . cur + self . batch_size <= self . size NEW_LINE DEDENT',), ('def next ( self ) : NEW_LINE INDENT if self . iter_next ( ) : NEW_LINE INDENT self . get_batch_individual ( ) NEW_LINE self . cur += self . batch_size NEW_LINE return mx . io . DataBatch ( data = self . data , label = self . label , pad = self . getpad ( ) , index = self . getindex ( ) , provide_data = self . provide_data , provide_label = self . provide_label ) NEW_LINE DEDENT else : NEW_LINE INDENT raise StopIteration NEW_LINE DEDENT DEDENT',), ('def getindex ( self ) : NEW_LINE INDENT return self . cur / self . batch_size NEW_LINE DEDENT',), ('def getpad ( self ) : NEW_LINE INDENT if self . cur + self . batch_size > self . size : NEW_LINE INDENT return self . cur + self . batch_size - self . size NEW_LINE DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT',), (\"def infer_shape ( self , max_data_shape = None , max_label_shape = None ) : NEW_LINE INDENT if max_data_shape is None : NEW_LINE INDENT max_data_shape = [ ] NEW_LINE DEDENT if max_label_shape is None : NEW_LINE INDENT max_label_shape = [ ] NEW_LINE DEDENT max_shapes = dict ( max_data_shape + max_label_shape ) NEW_LINE input_batch_size = max_shapes [ ' data ' ] [ 0 ] NEW_LINE im_info = [ [ max_shapes [ ' data ' ] [ 2 ] , max_shapes [ ' data ' ] [ 3 ] , 1.0 ] ] NEW_LINE _ , feat_shape , _ = self . feat_sym . infer_shape ( ** max_shapes ) NEW_LINE label = assign_anchor ( feat_shape [ 0 ] , np . zeros ( ( 0 , 5 ) ) , im_info , self . cfg , self . feat_stride , self . anchor_scales , self . anchor_ratios , self . allowed_border ) NEW_LINE label = [ label [ k ] for k in self . label_name ] NEW_LINE label_shape = [ ( k , tuple ( [ input_batch_size ] + list ( v . shape [ 1 : ] ) ) ) for k , v in zip ( self . label_name , label ) ] NEW_LINE return max_data_shape , label_shape NEW_LINE DEDENT\",), (\"def get_batch ( self ) : NEW_LINE INDENT cur_from = self . cur NEW_LINE cur_to = min ( cur_from + self . batch_size , self . size ) NEW_LINE roidb = [ self . roidb [ self . index [ i ] ] for i in range ( cur_from , cur_to ) ] NEW_LINE work_load_list = self . work_load_list NEW_LINE ctx = self . ctx NEW_LINE if work_load_list is None : NEW_LINE INDENT work_load_list = [ 1 ] * len ( ctx ) NEW_LINE DEDENT assert isinstance ( work_load_list , list ) and len ( work_load_list ) == len ( ctx ) , slices = _split_input_slice ( self . batch_size , work_load_list ) NEW_LINE data_list = [ ] NEW_LINE label_list = [ ] NEW_LINE for islice in slices : NEW_LINE INDENT iroidb = [ roidb [ i ] for i in range ( islice . start , islice . stop ) ] NEW_LINE data , label = get_rpn_batch ( iroidb , self . cfg ) NEW_LINE data_list . append ( data ) NEW_LINE label_list . append ( label ) NEW_LINE DEDENT data_tensor = tensor_vstack ( [ batch [ ' data ' ] for batch in data_list ] ) NEW_LINE for data , data_pad in zip ( data_list , data_tensor ) : NEW_LINE INDENT data [ ' data ' ] = data_pad [ np . newaxis , : ] NEW_LINE DEDENT new_label_list = [ ] NEW_LINE for data , label in zip ( data_list , label_list ) : NEW_LINE INDENT data_shape = { k : v . shape for k , v in data . items ( ) } NEW_LINE del data_shape [ ' im _ info ' ] NEW_LINE _ , feat_shape , _ = self . feat_sym . infer_shape ( ** data_shape ) NEW_LINE feat_shape = [ int ( i ) for i in feat_shape [ 0 ] ] NEW_LINE data [ ' gt _ boxes ' ] = label [ ' gt _ boxes ' ] [ np . newaxis , : , : ] NEW_LINE label = assign_anchor ( feat_shape , label [ ' gt _ boxes ' ] , data [ ' im _ info ' ] , self . cfg , self . feat_stride , self . anchor_scales , self . anchor_ratios , self . allowed_border ) NEW_LINE new_label_list . append ( label ) NEW_LINE DEDENT all_data = dict ( ) NEW_LINE for key in self . data_name : NEW_LINE INDENT all_data [ key ] = tensor_vstack ( [ batch [ key ] for batch in data_list ] ) NEW_LINE DEDENT all_label = dict ( ) NEW_LINE for key in self . label_name : NEW_LINE INDENT pad = - 1 if key == ' label ' else 0 NEW_LINE all_label [ key ] = tensor_vstack ( [ batch [ key ] for batch in new_label_list ] , pad = pad ) NEW_LINE DEDENT self . data = [ mx . nd . array ( all_data [ key ] ) for key in self . data_name ] NEW_LINE self . label = [ mx . nd . array ( all_label [ key ] ) for key in self . label_name ] NEW_LINE DEDENT\",), (\"def get_batch_individual ( self ) : NEW_LINE INDENT cur_from = self . cur NEW_LINE cur_to = min ( cur_from + self . batch_size , self . size ) NEW_LINE roidb = [ self . roidb [ self . index [ i ] ] for i in range ( cur_from , cur_to ) ] NEW_LINE work_load_list = self . work_load_list NEW_LINE ctx = self . ctx NEW_LINE if work_load_list is None : NEW_LINE INDENT work_load_list = [ 1 ] * len ( ctx ) NEW_LINE DEDENT assert isinstance ( work_load_list , list ) and len ( work_load_list ) == len ( ctx ) , slices = _split_input_slice ( self . batch_size , work_load_list ) NEW_LINE rst = [ ] NEW_LINE for idx , islice in enumerate ( slices ) : NEW_LINE INDENT iroidb = [ roidb [ i ] for i in range ( islice . start , islice . stop ) ] NEW_LINE rst . append ( self . parfetch ( iroidb ) ) NEW_LINE DEDENT all_data = [ _ [ ' data ' ] for _ in rst ] NEW_LINE all_label = [ _ [ ' label ' ] for _ in rst ] NEW_LINE self . data = [ [ mx . nd . array ( data [ key ] ) for key in self . data_name ] for data in all_data ] NEW_LINE self . label = [ [ mx . nd . array ( label [ key ] ) for key in self . label_name ] for label in all_label ] NEW_LINE DEDENT\",), (\"def parfetch ( self , iroidb ) : NEW_LINE INDENT data , label = get_rpn_batch ( iroidb , self . cfg ) NEW_LINE data_shape = { k : v . shape for k , v in data . items ( ) } NEW_LINE del data_shape [ ' im _ info ' ] NEW_LINE _ , feat_shape , _ = self . feat_sym . infer_shape ( ** data_shape ) NEW_LINE feat_shape = [ int ( i ) for i in feat_shape [ 0 ] ] NEW_LINE data [ ' gt _ boxes ' ] = label [ ' gt _ boxes ' ] [ np . newaxis , : , : ] NEW_LINE label = assign_anchor ( feat_shape , label [ ' gt _ boxes ' ] , data [ ' im _ info ' ] , self . cfg , self . feat_stride , self . anchor_scales , self . anchor_ratios , self . allowed_border ) NEW_LINE return { ' data ' : data , ' label ' : label } NEW_LINE DEDENT\",), (\"def __init__ ( self , feat_sym , roidb , cfg , batch_size = 1 , shuffle = False , ctx = None , work_load_list = None , feat_stride = 16 , anchor_scales = ( 8 , 16 , 32 ) , anchor_ratios = ( 0.5 , 1 , 2 ) , allowed_border = 0 , aspect_grouping = False ) : NEW_LINE INDENT super ( AnchorLoader_poly , self ) . __init__ ( ) NEW_LINE self . feat_sym = feat_sym NEW_LINE self . roidb = roidb NEW_LINE self . cfg = cfg NEW_LINE self . batch_size = batch_size NEW_LINE self . shuffle = shuffle NEW_LINE self . ctx = ctx NEW_LINE if self . ctx is None : NEW_LINE INDENT self . ctx = [ mx . cpu ( ) ] NEW_LINE DEDENT self . work_load_list = work_load_list NEW_LINE self . feat_stride = feat_stride NEW_LINE self . anchor_scales = anchor_scales NEW_LINE self . anchor_ratios = anchor_ratios NEW_LINE self . allowed_border = allowed_border NEW_LINE self . aspect_grouping = aspect_grouping NEW_LINE self . size = len ( roidb ) NEW_LINE self . index = np . arange ( self . size ) NEW_LINE if config . TRAIN . END2END : NEW_LINE INDENT self . data_name = [ ' data ' , ' im _ info ' , ' gt _ boxes ' ] NEW_LINE DEDENT else : NEW_LINE INDENT self . data_name = [ ' data ' ] NEW_LINE DEDENT self . label_name = [ ' label ' , ' bbox _ target ' , ' bbox _ weight ' ] NEW_LINE self . cur = 0 NEW_LINE self . batch = None NEW_LINE self . data = None NEW_LINE self . label = None NEW_LINE self . reset ( ) NEW_LINE self . get_batch_individual ( ) NEW_LINE DEDENT\",), ('def provide_data_single ( self ) : NEW_LINE INDENT return [ ( k , v . shape ) for k , v in zip ( self . data_name , self . data [ 0 ] ) ] NEW_LINE DEDENT',), ('def provide_label_single ( self ) : NEW_LINE INDENT return [ ( k , v . shape ) for k , v in zip ( self . label_name , self . label [ 0 ] ) ] NEW_LINE DEDENT',), (\"def reset ( self ) : NEW_LINE INDENT self . cur = 0 NEW_LINE if self . shuffle : NEW_LINE INDENT if self . aspect_grouping : NEW_LINE INDENT widths = np . array ( [ r [ ' width ' ] for r in self . roidb ] ) NEW_LINE heights = np . array ( [ r [ ' height ' ] for r in self . roidb ] ) NEW_LINE horz = ( widths >= heights ) NEW_LINE vert = np . logical_not ( horz ) NEW_LINE horz_inds = np . where ( horz ) [ 0 ] NEW_LINE vert_inds = np . where ( vert ) [ 0 ] NEW_LINE inds = np . hstack ( ( np . random . permutation ( horz_inds ) , np . random . permutation ( vert_inds ) ) ) NEW_LINE extra = inds . shape [ 0 ] % self . batch_size NEW_LINE inds_ = np . reshape ( inds [ : - extra ] , ( - 1 , self . batch_size ) ) NEW_LINE row_perm = np . random . permutation ( np . arange ( inds_ . shape [ 0 ] ) ) NEW_LINE inds [ : - extra ] = np . reshape ( inds_ [ row_perm , : ] , ( - 1 , ) ) NEW_LINE self . index = inds NEW_LINE DEDENT else : NEW_LINE INDENT np . random . shuffle ( self . index ) NEW_LINE DEDENT DEDENT DEDENT\",), ('def iter_next ( self ) : NEW_LINE INDENT return self . cur + self . batch_size <= self . size NEW_LINE DEDENT',), ('def next ( self ) : NEW_LINE INDENT if self . iter_next ( ) : NEW_LINE INDENT self . get_batch_individual ( ) NEW_LINE self . cur += self . batch_size NEW_LINE return mx . io . DataBatch ( data = self . data , label = self . label , pad = self . getpad ( ) , index = self . getindex ( ) , provide_data = self . provide_data , provide_label = self . provide_label ) NEW_LINE DEDENT else : NEW_LINE INDENT raise StopIteration NEW_LINE DEDENT DEDENT',), ('def getindex ( self ) : NEW_LINE INDENT return self . cur / self . batch_size NEW_LINE DEDENT',), ('def getpad ( self ) : NEW_LINE INDENT if self . cur + self . batch_size > self . size : NEW_LINE INDENT return self . cur + self . batch_size - self . size NEW_LINE DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT',), (\"def infer_shape ( self , max_data_shape = None , max_label_shape = None ) : NEW_LINE INDENT if max_data_shape is None : NEW_LINE INDENT max_data_shape = [ ] NEW_LINE DEDENT if max_label_shape is None : NEW_LINE INDENT max_label_shape = [ ] NEW_LINE DEDENT max_shapes = dict ( max_data_shape + max_label_shape ) NEW_LINE input_batch_size = max_shapes [ ' data ' ] [ 0 ] NEW_LINE im_info = [ [ max_shapes [ ' data ' ] [ 2 ] , max_shapes [ ' data ' ] [ 3 ] , 1.0 ] ] NEW_LINE _ , feat_shape , _ = self . feat_sym . infer_shape ( ** max_shapes ) NEW_LINE label = assign_anchor_poly ( feat_shape [ 0 ] , np . zeros ( ( 0 , 9 ) ) , im_info , self . cfg , self . feat_stride , self . anchor_scales , self . anchor_ratios , self . allowed_border ) NEW_LINE label = [ label [ k ] for k in self . label_name ] NEW_LINE label_shape = [ ( k , tuple ( [ input_batch_size ] + list ( v . shape [ 1 : ] ) ) ) for k , v in zip ( self . label_name , label ) ] NEW_LINE return max_data_shape , label_shape NEW_LINE DEDENT\",), (\"def get_batch ( self ) : NEW_LINE INDENT cur_from = self . cur NEW_LINE cur_to = min ( cur_from + self . batch_size , self . size ) NEW_LINE roidb = [ self . roidb [ self . index [ i ] ] for i in range ( cur_from , cur_to ) ] NEW_LINE work_load_list = self . work_load_list NEW_LINE ctx = self . ctx NEW_LINE if work_load_list is None : NEW_LINE INDENT work_load_list = [ 1 ] * len ( ctx ) NEW_LINE DEDENT assert isinstance ( work_load_list , list ) and len ( work_load_list ) == len ( ctx ) , slices = _split_input_slice ( self . batch_size , work_load_list ) NEW_LINE data_list = [ ] NEW_LINE label_list = [ ] NEW_LINE for islice in slices : NEW_LINE INDENT iroidb = [ roidb [ i ] for i in range ( islice . start , islice . stop ) ] NEW_LINE data , label = get_rpn_batch_poly ( iroidb , self . cfg ) NEW_LINE data_list . append ( data ) NEW_LINE label_list . append ( label ) NEW_LINE DEDENT data_tensor = tensor_vstack ( [ batch [ ' data ' ] for batch in data_list ] ) NEW_LINE for data , data_pad in zip ( data_list , data_tensor ) : NEW_LINE INDENT data [ ' data ' ] = data_pad [ np . newaxis , : ] NEW_LINE DEDENT new_label_list = [ ] NEW_LINE for data , label in zip ( data_list , label_list ) : NEW_LINE INDENT data_shape = { k : v . shape for k , v in data . items ( ) } NEW_LINE del data_shape [ ' im _ info ' ] NEW_LINE _ , feat_shape , _ = self . feat_sym . infer_shape ( ** data_shape ) NEW_LINE feat_shape = [ int ( i ) for i in feat_shape [ 0 ] ] NEW_LINE data [ ' gt _ boxes ' ] = label [ ' gt _ boxes ' ] [ np . newaxis , : , : ] NEW_LINE label = assign_anchor_poly ( feat_shape , label [ ' gt _ boxes ' ] , data [ ' im _ info ' ] , self . cfg , self . feat_stride , self . anchor_scales , self . anchor_ratios , self . allowed_border ) NEW_LINE new_label_list . append ( label ) NEW_LINE DEDENT all_data = dict ( ) NEW_LINE for key in self . data_name : NEW_LINE INDENT all_data [ key ] = tensor_vstack ( [ batch [ key ] for batch in data_list ] ) NEW_LINE DEDENT all_label = dict ( ) NEW_LINE for key in self . label_name : NEW_LINE INDENT pad = - 1 if key == ' label ' else 0 NEW_LINE all_label [ key ] = tensor_vstack ( [ batch [ key ] for batch in new_label_list ] , pad = pad ) NEW_LINE DEDENT self . data = [ mx . nd . array ( all_data [ key ] ) for key in self . data_name ] NEW_LINE self . label = [ mx . nd . array ( all_label [ key ] ) for key in self . label_name ] NEW_LINE DEDENT\",), (\"def get_batch_individual ( self ) : NEW_LINE INDENT cur_from = self . cur NEW_LINE cur_to = min ( cur_from + self . batch_size , self . size ) NEW_LINE roidb = [ self . roidb [ self . index [ i ] ] for i in range ( cur_from , cur_to ) ] NEW_LINE work_load_list = self . work_load_list NEW_LINE ctx = self . ctx NEW_LINE if work_load_list is None : NEW_LINE INDENT work_load_list = [ 1 ] * len ( ctx ) NEW_LINE DEDENT assert isinstance ( work_load_list , list ) and len ( work_load_list ) == len ( ctx ) , slices = _split_input_slice ( self . batch_size , work_load_list ) NEW_LINE rst = [ ] NEW_LINE for idx , islice in enumerate ( slices ) : NEW_LINE INDENT iroidb = [ roidb [ i ] for i in range ( islice . start , islice . stop ) ] NEW_LINE rst . append ( self . parfetch ( iroidb ) ) NEW_LINE DEDENT all_data = [ _ [ ' data ' ] for _ in rst ] NEW_LINE all_label = [ _ [ ' label ' ] for _ in rst ] NEW_LINE self . data = [ [ mx . nd . array ( data [ key ] ) for key in self . data_name ] for data in all_data ] NEW_LINE self . label = [ [ mx . nd . array ( label [ key ] ) for key in self . label_name ] for label in all_label ] NEW_LINE DEDENT\",), (\"def parfetch ( self , iroidb ) : NEW_LINE INDENT data , label = get_rpn_batch_poly ( iroidb , self . cfg ) NEW_LINE data_shape = { k : v . shape for k , v in data . items ( ) } NEW_LINE del data_shape [ ' im _ info ' ] NEW_LINE _ , feat_shape , _ = self . feat_sym . infer_shape ( ** data_shape ) NEW_LINE feat_shape = [ int ( i ) for i in feat_shape [ 0 ] ] NEW_LINE data [ ' gt _ boxes ' ] = label [ ' gt _ boxes ' ] [ np . newaxis , : , : ] NEW_LINE label = assign_anchor_poly ( feat_shape , label [ ' gt _ boxes ' ] , data [ ' im _ info ' ] , self . cfg , self . feat_stride , self . anchor_scales , self . anchor_ratios , self . allowed_border ) NEW_LINE return { ' data ' : data , ' label ' : label } NEW_LINE DEDENT\",), ('def _load_general ( data , targets , major_axis ) : NEW_LINE INDENT for d_src , d_targets in zip ( data , targets ) : NEW_LINE INDENT if isinstance ( d_targets , nd . NDArray ) : NEW_LINE INDENT d_src . copyto ( d_targets ) NEW_LINE DEDENT elif isinstance ( d_src , ( list , tuple ) ) : NEW_LINE INDENT for src , dst in zip ( d_src , d_targets ) : NEW_LINE INDENT src . copyto ( dst ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT raise NotImplementedError NEW_LINE DEDENT DEDENT DEDENT',), ('def _load_data ( batch , targets , major_axis ) : NEW_LINE INDENT _load_general ( batch . data , targets , major_axis ) NEW_LINE DEDENT',), ('def _load_label ( batch , targets , major_axis ) : NEW_LINE INDENT _load_general ( batch . label , targets , major_axis ) NEW_LINE DEDENT',), ('def _merge_multi_context ( outputs , major_axis ) : NEW_LINE INDENT rets = [ ] NEW_LINE for tensors , axis in zip ( outputs , major_axis ) : NEW_LINE INDENT if axis >= 0 : NEW_LINE INDENT rets . append ( nd . concatenate ( tensors , axis = axis , always_copy = False ) ) NEW_LINE DEDENT else : NEW_LINE INDENT rets . append ( tensors [ 0 ] ) NEW_LINE DEDENT DEDENT return rets NEW_LINE DEDENT',), ('def __init__ ( self , symbol , contexts , workload , data_shapes , label_shapes , param_names , for_training , inputs_need_grad , shared_group = None , logger = logging , fixed_param_names = None , grad_req = \\' write \\' , state_names = None ) : NEW_LINE INDENT self . param_names = param_names NEW_LINE self . arg_names = symbol . list_arguments ( ) NEW_LINE self . aux_names = symbol . list_auxiliary_states ( ) NEW_LINE self . symbol = symbol NEW_LINE self . contexts = contexts NEW_LINE self . workload = workload NEW_LINE self . for_training = for_training NEW_LINE self . inputs_need_grad = inputs_need_grad NEW_LINE self . logger = logger NEW_LINE self . fixed_param_names = fixed_param_names NEW_LINE if self . fixed_param_names is None : NEW_LINE INDENT self . fixed_param_names = [ ] NEW_LINE DEDENT self . state_names = state_names NEW_LINE if self . state_names is None : NEW_LINE INDENT self . state_names = [ ] NEW_LINE DEDENT if not for_training : NEW_LINE INDENT grad_req = \\' null \\' NEW_LINE DEDENT data_names = [ x . name for x in data_shapes [ 0 ] ] NEW_LINE if isinstance ( grad_req , str ) : NEW_LINE INDENT self . grad_req = { } NEW_LINE for k in self . arg_names : NEW_LINE INDENT if k in self . param_names : NEW_LINE INDENT self . grad_req [ k ] = \\' null \\' if k in self . fixed_param_names else grad_req NEW_LINE DEDENT elif k in data_names : NEW_LINE INDENT self . grad_req [ k ] = grad_req if self . inputs_need_grad else \\' null \\' NEW_LINE DEDENT else : NEW_LINE INDENT self . grad_req [ k ] = \\' null \\' NEW_LINE DEDENT DEDENT DEDENT elif isinstance ( grad_req , ( list , tuple ) ) : NEW_LINE INDENT assert len ( grad_req ) == len ( self . arg_names ) NEW_LINE self . grad_req = dict ( zip ( self . arg_names , grad_req ) ) NEW_LINE DEDENT elif isinstance ( grad_req , dict ) : NEW_LINE INDENT self . grad_req = { } NEW_LINE for k in self . arg_names : NEW_LINE INDENT if k in self . param_names : NEW_LINE INDENT self . grad_req [ k ] = \\' null \\' if k in self . fixed_param_names else \\' write \\' NEW_LINE DEDENT elif k in data_names : NEW_LINE INDENT self . grad_req [ k ] = \\' write \\' if self . inputs_need_grad else \\' null \\' NEW_LINE DEDENT else : NEW_LINE INDENT self . grad_req [ k ] = \\' null \\' NEW_LINE DEDENT DEDENT self . grad_req . update ( grad_req ) NEW_LINE DEDENT else : NEW_LINE INDENT raise ValueError ( \" grad _ req ▁ must ▁ be ▁ one ▁ of ▁ str , ▁ list , ▁ tuple , ▁ or ▁ dict . \" ) NEW_LINE DEDENT if shared_group is not None : NEW_LINE INDENT self . shared_data_arrays = shared_group . shared_data_arrays NEW_LINE DEDENT else : NEW_LINE INDENT self . shared_data_arrays = [ { } for _ in contexts ] NEW_LINE DEDENT self . batch_size = len ( data_shapes ) NEW_LINE self . slices = None NEW_LINE self . execs = [ ] NEW_LINE self . _default_execs = None NEW_LINE self . data_arrays = None NEW_LINE self . label_arrays = None NEW_LINE self . param_arrays = None NEW_LINE self . state_arrays = None NEW_LINE self . grad_arrays = None NEW_LINE self . aux_arrays = None NEW_LINE self . input_grad_arrays = None NEW_LINE self . data_shapes = None NEW_LINE self . label_shapes = None NEW_LINE self . data_layouts = None NEW_LINE self . label_layouts = None NEW_LINE self . output_layouts = [ DataDesc . get_batch_axis ( self . symbol [ name ] . attr ( \\' _ _ layout _ _ \\' ) ) for name in self . symbol . list_outputs ( ) ] NEW_LINE self . bind_exec ( data_shapes , label_shapes , shared_group ) NEW_LINE DEDENT',), ('def decide_slices ( self , data_shapes ) : NEW_LINE INDENT assert len ( data_shapes ) > 0 NEW_LINE major_axis = [ DataDesc . get_batch_axis ( x . layout ) for x in data_shapes ] NEW_LINE for ( name , shape ) , axis in zip ( data_shapes , major_axis ) : NEW_LINE INDENT if axis == - 1 : NEW_LINE INDENT continue NEW_LINE DEDENT batch_size = shape [ axis ] NEW_LINE if self . batch_size is not None : NEW_LINE INDENT assert batch_size == self . batch_size , ( \" all ▁ data ▁ must ▁ have ▁ the ▁ same ▁ batch ▁ size : ▁ \" + ( \" batch _ size ▁ = ▁ % d , ▁ but ▁ \" % self . batch_size ) + ( \" % s ▁ has ▁ shape ▁ % s \" % ( name , shape ) ) ) NEW_LINE DEDENT else : NEW_LINE INDENT self . batch_size = batch_size NEW_LINE self . slices = _split_input_slice ( self . batch_size , self . workload ) NEW_LINE DEDENT DEDENT return major_axis NEW_LINE DEDENT',), ('def _collect_arrays ( self ) : NEW_LINE INDENT self . data_arrays = [ [ e . arg_dict [ name ] for name , _ in self . data_shapes [ 0 ] ] for e in self . execs ] NEW_LINE self . state_arrays = [ [ e . arg_dict [ name ] for e in self . execs ] for name in self . state_names ] NEW_LINE if self . label_shapes is not None : NEW_LINE INDENT self . label_arrays = [ [ e . arg_dict [ name ] for name , _ in self . label_shapes [ 0 ] ] for e in self . execs ] NEW_LINE DEDENT else : NEW_LINE INDENT self . label_arrays = None NEW_LINE DEDENT self . param_arrays = [ [ exec_ . arg_arrays [ i ] for exec_ in self . execs ] for i , name in enumerate ( self . arg_names ) if name in self . param_names ] NEW_LINE if self . for_training : NEW_LINE INDENT self . grad_arrays = [ [ exec_ . grad_arrays [ i ] for exec_ in self . execs ] for i , name in enumerate ( self . arg_names ) if name in self . param_names ] NEW_LINE DEDENT else : NEW_LINE INDENT self . grad_arrays = None NEW_LINE DEDENT data_names = [ x [ 0 ] for x in self . data_shapes ] NEW_LINE if self . inputs_need_grad : NEW_LINE INDENT self . input_grad_arrays = [ [ exec_ . grad_arrays [ i ] for exec_ in self . execs ] for i , name in enumerate ( self . arg_names ) if name in data_names ] NEW_LINE DEDENT else : NEW_LINE INDENT self . input_grad_arrays = None NEW_LINE DEDENT self . aux_arrays = [ [ exec_ . aux_arrays [ i ] for exec_ in self . execs ] for i in range ( len ( self . aux_names ) ) ] NEW_LINE DEDENT',), ('def bind_exec ( self , data_shapes , label_shapes , shared_group = None , reshape = False ) : NEW_LINE INDENT assert reshape or not self . execs NEW_LINE for i in range ( len ( self . contexts ) ) : NEW_LINE INDENT data_shapes_i = data_shapes [ i ] NEW_LINE if label_shapes is not None : NEW_LINE INDENT label_shapes_i = label_shapes [ i ] NEW_LINE DEDENT else : NEW_LINE INDENT label_shapes_i = [ ] NEW_LINE DEDENT if reshape : NEW_LINE INDENT self . execs [ i ] = self . _default_execs [ i ] . reshape ( allow_up_sizing = True , ** dict ( data_shapes_i + label_shapes_i ) ) NEW_LINE DEDENT else : NEW_LINE INDENT self . execs . append ( self . _bind_ith_exec ( i , data_shapes_i , label_shapes_i , shared_group ) ) NEW_LINE DEDENT DEDENT self . data_shapes = data_shapes NEW_LINE self . label_shapes = label_shapes NEW_LINE self . _collect_arrays ( ) NEW_LINE DEDENT',), ('def reshape ( self , data_shapes , label_shapes ) : NEW_LINE INDENT if self . _default_execs is None : NEW_LINE INDENT self . _default_execs = [ i for i in self . execs ] NEW_LINE DEDENT for i in range ( len ( self . contexts ) ) : NEW_LINE INDENT self . execs [ i ] = self . _default_execs [ i ] . reshape ( allow_up_sizing = True , ** dict ( data_shapes [ i ] + ( label_shapes [ i ] if label_shapes is not None else [ ] ) ) ) NEW_LINE DEDENT self . data_shapes = data_shapes NEW_LINE self . label_shapes = label_shapes NEW_LINE self . _collect_arrays ( ) NEW_LINE DEDENT',), ('def set_params ( self , arg_params , aux_params ) : NEW_LINE INDENT for exec_ in self . execs : NEW_LINE INDENT exec_ . copy_params_from ( arg_params , aux_params ) NEW_LINE DEDENT DEDENT',), ('def get_params ( self , arg_params , aux_params ) : NEW_LINE INDENT for name , block in zip ( self . param_names , self . param_arrays ) : NEW_LINE INDENT weight = sum ( w . copyto ( ctx . cpu ( ) ) for w in block ) / len ( block ) NEW_LINE weight . astype ( arg_params [ name ] . dtype ) . copyto ( arg_params [ name ] ) NEW_LINE DEDENT for name , block in zip ( self . aux_names , self . aux_arrays ) : NEW_LINE INDENT weight = sum ( w . copyto ( ctx . cpu ( ) ) for w in block ) / len ( block ) NEW_LINE weight . astype ( aux_params [ name ] . dtype ) . copyto ( aux_params [ name ] ) NEW_LINE DEDENT DEDENT',), ('def forward ( self , data_batch , is_train = None ) : NEW_LINE INDENT _load_data ( data_batch , self . data_arrays , self . data_layouts ) NEW_LINE if is_train is None : NEW_LINE INDENT is_train = self . for_training NEW_LINE DEDENT if self . label_arrays is not None : NEW_LINE INDENT assert not is_train or data_batch . label NEW_LINE if data_batch . label : NEW_LINE INDENT _load_label ( data_batch , self . label_arrays , self . label_layouts ) NEW_LINE DEDENT DEDENT for exec_ in self . execs : NEW_LINE INDENT exec_ . forward ( is_train = is_train ) NEW_LINE DEDENT DEDENT',), ('def get_outputs ( self , merge_multi_context = True ) : NEW_LINE INDENT outputs = [ [ exec_ . outputs [ i ] for exec_ in self . execs ] for i in range ( len ( self . execs [ 0 ] . outputs ) ) ] NEW_LINE if merge_multi_context : NEW_LINE INDENT outputs = _merge_multi_context ( outputs , self . output_layouts ) NEW_LINE DEDENT return outputs NEW_LINE DEDENT',), ('def get_states ( self , merge_multi_context = True ) : NEW_LINE INDENT assert not merge_multi_context , return self . state_arrays NEW_LINE DEDENT',), ('def set_states ( self , states = None , value = None ) : NEW_LINE INDENT if states is not None : NEW_LINE INDENT assert value is None , \" Only ▁ one ▁ of ▁ states ▁ & ▁ value ▁ can ▁ be ▁ specified . \" NEW_LINE _load_general ( states , self . state_arrays , ( 0 , ) * len ( states ) ) NEW_LINE DEDENT else : NEW_LINE INDENT assert value is not None , \" At ▁ least ▁ one ▁ of ▁ states ▁ & ▁ value ▁ must ▁ be ▁ specified . \" NEW_LINE assert states is None , \" Only ▁ one ▁ of ▁ states ▁ & ▁ value ▁ can ▁ be ▁ specified . \" NEW_LINE for d_dst in self . state_arrays : NEW_LINE INDENT for dst in d_dst : NEW_LINE INDENT dst [ : ] = value NEW_LINE DEDENT DEDENT DEDENT DEDENT',), ('def get_input_grads ( self , merge_multi_context = True ) : NEW_LINE INDENT assert self . inputs_need_grad NEW_LINE if merge_multi_context : NEW_LINE INDENT return _merge_multi_context ( self . input_grad_arrays , self . data_layouts ) NEW_LINE DEDENT return self . input_grad_arrays NEW_LINE DEDENT',), (\"def backward ( self , out_grads = None ) : NEW_LINE INDENT assert self . for_training , ' re - bind ▁ with ▁ for _ training = True ▁ to ▁ run ▁ backward ' NEW_LINE if out_grads is None : NEW_LINE INDENT out_grads = [ ] NEW_LINE DEDENT for i , exec_ in enumerate ( self . execs ) : NEW_LINE INDENT out_grads_slice = [ ] NEW_LINE exec_ . backward ( out_grads = out_grads_slice ) NEW_LINE DEDENT DEDENT\",), ('def update_metric ( self , eval_metric , labels ) : NEW_LINE INDENT for texec , labels in zip ( self . execs , labels ) : NEW_LINE INDENT eval_metric . update ( labels , texec . outputs ) NEW_LINE DEDENT DEDENT',), ('def _bind_ith_exec ( self , i , data_shapes , label_shapes , shared_group ) : NEW_LINE INDENT shared_exec = None if shared_group is None else shared_group . execs [ i ] NEW_LINE context = self . contexts [ i ] NEW_LINE shared_data_arrays = self . shared_data_arrays [ i ] NEW_LINE input_shapes = dict ( data_shapes ) NEW_LINE if label_shapes is not None : NEW_LINE INDENT input_shapes . update ( dict ( label_shapes ) ) NEW_LINE DEDENT arg_shapes , _ , aux_shapes = self . symbol . infer_shape ( ** input_shapes ) NEW_LINE assert arg_shapes is not None , \" shape ▁ inference ▁ failed \" NEW_LINE input_types = { x . name : x . dtype for x in data_shapes } NEW_LINE if label_shapes is not None : NEW_LINE INDENT input_types . update ( { x . name : x . dtype for x in label_shapes } ) NEW_LINE DEDENT arg_types , _ , aux_types = self . symbol . infer_type ( ** input_types ) NEW_LINE assert arg_types is not None , \" type ▁ inference ▁ failed \" NEW_LINE arg_arrays = [ ] NEW_LINE grad_arrays = { } if self . for_training else None NEW_LINE def _get_or_reshape ( name , shared_data_arrays , arg_shape , arg_type , context , logger ) : NEW_LINE INDENT if name in shared_data_arrays : NEW_LINE INDENT arg_arr = shared_data_arrays [ name ] NEW_LINE if np . prod ( arg_arr . shape ) >= np . prod ( arg_shape ) : NEW_LINE INDENT assert arg_arr . dtype == arg_type NEW_LINE arg_arr = arg_arr . reshape ( arg_shape ) NEW_LINE DEDENT else : NEW_LINE INDENT logger . warning ( ( \\' bucketing : ▁ data ▁ \" % s \" ▁ has ▁ a ▁ shape ▁ % s \\' % ( name , arg_shape ) ) + ( \\' , ▁ which ▁ is ▁ larger ▁ than ▁ already ▁ allocated ▁ \\' ) + ( \\' shape ▁ % s \\' % ( arg_arr . shape , ) ) + ( \\' . ▁ Need ▁ to ▁ re - allocate . ▁ Consider ▁ putting ▁ \\' ) + ( \\' default _ bucket _ key ▁ to \\' ) + ( \\' ▁ be ▁ the ▁ bucket ▁ taking ▁ the ▁ largest ▁ input ▁ for ▁ better ▁ \\' ) + ( \\' memory ▁ sharing . \\' ) ) NEW_LINE arg_arr = nd . zeros ( arg_shape , context , dtype = arg_type ) NEW_LINE shared_data_arrays [ name ] = arg_arr NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT arg_arr = nd . zeros ( arg_shape , context , dtype = arg_type ) NEW_LINE shared_data_arrays [ name ] = arg_arr NEW_LINE DEDENT return arg_arr NEW_LINE DEDENT for j in range ( len ( self . arg_names ) ) : NEW_LINE INDENT name = self . arg_names [ j ] NEW_LINE if name in self . param_names : NEW_LINE INDENT if shared_exec is None : NEW_LINE INDENT arg_arr = nd . zeros ( arg_shapes [ j ] , context , dtype = arg_types [ j ] ) NEW_LINE if self . grad_req [ name ] != \\' null \\' : NEW_LINE INDENT grad_arr = nd . zeros ( arg_shapes [ j ] , context , dtype = arg_types [ j ] ) NEW_LINE grad_arrays [ name ] = grad_arr NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT arg_arr = shared_exec . arg_dict [ name ] NEW_LINE assert arg_arr . shape == arg_shapes [ j ] NEW_LINE assert arg_arr . dtype == arg_types [ j ] NEW_LINE if self . grad_req [ name ] != \\' null \\' : NEW_LINE INDENT grad_arrays [ name ] = shared_exec . grad_dict [ name ] NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT arg_arr = _get_or_reshape ( name , shared_data_arrays , arg_shapes [ j ] , arg_types [ j ] , context , self . logger ) NEW_LINE if self . grad_req [ name ] != \\' null \\' : NEW_LINE INDENT grad_arrays [ name ] = _get_or_reshape ( \\' grad ▁ of ▁ \\' + name , shared_data_arrays , arg_shapes [ j ] , arg_types [ j ] , context , self . logger ) NEW_LINE DEDENT DEDENT arg_arrays . append ( arg_arr ) NEW_LINE DEDENT if shared_exec is None : NEW_LINE INDENT aux_arrays = [ nd . zeros ( s , context , dtype = t ) for s , t in zip ( aux_shapes , aux_types ) ] NEW_LINE DEDENT else : NEW_LINE INDENT for j , arr in enumerate ( shared_exec . aux_arrays ) : NEW_LINE INDENT assert aux_shapes [ j ] == arr . shape NEW_LINE assert aux_types [ j ] == arr . dtype NEW_LINE DEDENT aux_arrays = shared_exec . aux_arrays [ : ] NEW_LINE DEDENT executor = self . symbol . bind ( ctx = context , args = arg_arrays , args_grad = grad_arrays , aux_states = aux_arrays , grad_req = self . grad_req , shared_exec = shared_exec ) NEW_LINE return executor NEW_LINE DEDENT',), ('def _sliced_shape ( self , shapes , i , major_axis ) : NEW_LINE INDENT sliced_shapes = [ ] NEW_LINE for desc , axis in zip ( shapes , major_axis ) : NEW_LINE INDENT shape = list ( desc . shape ) NEW_LINE if axis >= 0 : NEW_LINE INDENT shape [ axis ] = self . slices [ i ] . stop - self . slices [ i ] . start NEW_LINE DEDENT sliced_shapes . append ( DataDesc ( desc . name , tuple ( shape ) , desc . dtype , desc . layout ) ) NEW_LINE DEDENT return sliced_shapes NEW_LINE DEDENT',), ('def install_monitor ( self , mon ) : NEW_LINE INDENT for exe in self . execs : NEW_LINE INDENT mon . install ( exe ) NEW_LINE DEDENT DEDENT',), (\"def get_rpn_names ( ) : NEW_LINE INDENT pred = [ ' rpn _ cls _ prob ' , ' rpn _ bbox _ loss ' ] NEW_LINE label = [ ' rpn _ label ' , ' rpn _ bbox _ target ' , ' rpn _ bbox _ weight ' ] NEW_LINE return pred , label NEW_LINE DEDENT\",), (\"def get_rcnn_names ( cfg ) : NEW_LINE INDENT pred = [ ' rcnn _ cls _ prob ' , ' rcnn _ bbox _ loss ' ] NEW_LINE label = [ ' rcnn _ label ' , ' rcnn _ bbox _ target ' , ' rcnn _ bbox _ weight ' ] NEW_LINE if cfg . TRAIN . ENABLE_OHEM or cfg . TRAIN . END2END : NEW_LINE INDENT pred . append ( ' rcnn _ label ' ) NEW_LINE DEDENT if cfg . TRAIN . END2END : NEW_LINE INDENT rpn_pred , rpn_label = get_rpn_names ( ) NEW_LINE pred = rpn_pred + pred NEW_LINE label = rpn_label NEW_LINE DEDENT return pred , label NEW_LINE DEDENT\",), (\"def get_Rroi_names ( cfg ) : NEW_LINE INDENT pred , label = get_rcnn_names ( cfg ) NEW_LINE pred . append ( ' Rroi _ rcnn _ cls _ prob ' ) NEW_LINE pred . append ( ' Rroi _ rcnn _ bbox _ loss ' ) NEW_LINE if cfg . TRAIN . ENABLE_OHEM or cfg . TRAIN . END2END : NEW_LINE INDENT pred . append ( ' Rroi _ rcnn _ label ' ) NEW_LINE DEDENT return pred , label NEW_LINE DEDENT\",), (\"def __init__ ( self ) : NEW_LINE INDENT super ( RPNAccMetric , self ) . __init__ ( ' RPNAcc ' ) NEW_LINE self . pred , self . label = get_rpn_names ( ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT pred = preds [ self . pred . index ( ' rpn _ cls _ prob ' ) ] NEW_LINE label = labels [ self . label . index ( ' rpn _ label ' ) ] NEW_LINE pred_label = mx . ndarray . argmax_channel ( pred ) . asnumpy ( ) . astype ( ' int32' ) NEW_LINE pred_label = pred_label . reshape ( ( pred_label . shape [ 0 ] , - 1 ) ) NEW_LINE label = label . asnumpy ( ) . astype ( ' int32' ) NEW_LINE keep_inds = np . where ( label != - 1 ) NEW_LINE pred_label = pred_label [ keep_inds ] NEW_LINE label = label [ keep_inds ] NEW_LINE self . sum_metric += np . sum ( pred_label . flat == label . flat ) NEW_LINE self . num_inst += len ( pred_label . flat ) NEW_LINE DEDENT\",), (\"def __init__ ( self ) : NEW_LINE INDENT super ( RPNLogLossMetric , self ) . __init__ ( ' RPNLogLoss ' ) NEW_LINE self . pred , self . label = get_rpn_names ( ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT pred = preds [ self . pred . index ( ' rpn _ cls _ prob ' ) ] NEW_LINE label = labels [ self . label . index ( ' rpn _ label ' ) ] NEW_LINE label = label . asnumpy ( ) . astype ( ' int32' ) . reshape ( ( - 1 ) ) NEW_LINE pred = pred . asnumpy ( ) . reshape ( ( pred . shape [ 0 ] , pred . shape [ 1 ] , - 1 ) ) . transpose ( ( 0 , 2 , 1 ) ) NEW_LINE pred = pred . reshape ( ( label . shape [ 0 ] , - 1 ) ) NEW_LINE keep_inds = np . where ( label != - 1 ) [ 0 ] NEW_LINE label = label [ keep_inds ] NEW_LINE cls = pred [ keep_inds , label ] NEW_LINE cls += 1e-14 NEW_LINE cls_loss = - 1 * np . log ( cls ) NEW_LINE cls_loss = np . sum ( cls_loss ) NEW_LINE self . sum_metric += cls_loss NEW_LINE self . num_inst += label . shape [ 0 ] NEW_LINE DEDENT\",), (\"def __init__ ( self ) : NEW_LINE INDENT super ( RPNL1LossMetric , self ) . __init__ ( ' RPNL1Loss ' ) NEW_LINE self . pred , self . label = get_rpn_names ( ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT bbox_loss = preds [ self . pred . index ( ' rpn _ bbox _ loss ' ) ] . asnumpy ( ) NEW_LINE label = labels [ self . label . index ( ' rpn _ label ' ) ] . asnumpy ( ) NEW_LINE num_inst = np . sum ( label != - 1 ) NEW_LINE self . sum_metric += np . sum ( bbox_loss ) NEW_LINE self . num_inst += num_inst NEW_LINE DEDENT\",), (\"def __init__ ( self , cfg ) : NEW_LINE INDENT super ( RPNFGFraction , self ) . __init__ ( ' Proposal ▁ FG ▁ Fraction ' ) NEW_LINE self . e2e = cfg . TRAIN . END2END NEW_LINE self . ohem = cfg . TRAIN . ENABLE_OHEM NEW_LINE self . pred , self . label = get_rcnn_names ( cfg ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT pred = preds [ self . pred . index ( ' rcnn _ cls _ prob ' ) ] NEW_LINE if self . ohem or self . e2e : NEW_LINE INDENT label = preds [ self . pred . index ( ' rcnn _ label ' ) ] NEW_LINE DEDENT else : NEW_LINE INDENT label = labels [ self . label . index ( ' rcnn _ label ' ) ] NEW_LINE DEDENT num_classes = pred . shape [ - 1 ] NEW_LINE label = label . asnumpy ( ) . reshape ( - 1 , ) . astype ( ' int32' ) NEW_LINE fg_inds = np . where ( label > 0 ) [ 0 ] NEW_LINE bg_inds = np . where ( label == 0 ) [ 0 ] NEW_LINE self . sum_metric += fg_inds . shape [ 0 ] NEW_LINE self . num_inst += ( fg_inds . shape [ 0 ] + bg_inds . shape [ 0 ] ) NEW_LINE DEDENT\",), (\"def __init__ ( self , cfg ) : NEW_LINE INDENT super ( RCNNFGAccuracy , self ) . __init__ ( ' R - CNN ▁ FG ▁ Accuracy ' ) NEW_LINE self . e2e = cfg . TRAIN . END2END NEW_LINE self . ohem = cfg . TRAIN . ENABLE_OHEM NEW_LINE self . pred , self . label = get_rcnn_names ( cfg ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT pred = preds [ self . pred . index ( ' rcnn _ cls _ prob ' ) ] NEW_LINE if self . ohem or self . e2e : NEW_LINE INDENT label = preds [ self . pred . index ( ' rcnn _ label ' ) ] NEW_LINE DEDENT else : NEW_LINE INDENT label = labels [ self . label . index ( ' rcnn _ label ' ) ] NEW_LINE DEDENT num_classes = pred . shape [ - 1 ] NEW_LINE pred_label = pred . asnumpy ( ) . reshape ( - 1 , num_classes ) . argmax ( axis = 1 ) . astype ( ' int32' ) NEW_LINE label = label . asnumpy ( ) . reshape ( - 1 , ) . astype ( ' int32' ) NEW_LINE keep_inds = np . where ( label > 0 ) NEW_LINE pred_label = pred_label [ keep_inds ] NEW_LINE label = label [ keep_inds ] NEW_LINE self . sum_metric += np . sum ( np . equal ( pred_label . flat , label . flat ) ) NEW_LINE self . num_inst += pred_label . shape [ 0 ] NEW_LINE DEDENT\",), (\"def __init__ ( self , cfg ) : NEW_LINE INDENT super ( RCNNAccMetric , self ) . __init__ ( ' RCNNAcc ' ) NEW_LINE self . e2e = cfg . TRAIN . END2END NEW_LINE self . ohem = cfg . TRAIN . ENABLE_OHEM NEW_LINE self . pred , self . label = get_rcnn_names ( cfg ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT pred = preds [ self . pred . index ( ' rcnn _ cls _ prob ' ) ] NEW_LINE if self . ohem or self . e2e : NEW_LINE INDENT label = preds [ self . pred . index ( ' rcnn _ label ' ) ] NEW_LINE DEDENT else : NEW_LINE INDENT label = labels [ self . label . index ( ' rcnn _ label ' ) ] NEW_LINE DEDENT last_dim = pred . shape [ - 1 ] NEW_LINE pred_label = pred . asnumpy ( ) . reshape ( - 1 , last_dim ) . argmax ( axis = 1 ) . astype ( ' int32' ) NEW_LINE label = label . asnumpy ( ) . reshape ( - 1 , ) . astype ( ' int32' ) NEW_LINE keep_inds = np . where ( label != - 1 ) NEW_LINE pred_label = pred_label [ keep_inds ] NEW_LINE label = label [ keep_inds ] NEW_LINE self . sum_metric += np . sum ( pred_label . flat == label . flat ) NEW_LINE self . num_inst += len ( pred_label . flat ) NEW_LINE DEDENT\",), (\"def __init__ ( self , cfg ) : NEW_LINE INDENT super ( RCNNLogLossMetric , self ) . __init__ ( ' RCNNLogLoss ' ) NEW_LINE self . e2e = cfg . TRAIN . END2END NEW_LINE self . ohem = cfg . TRAIN . ENABLE_OHEM NEW_LINE self . pred , self . label = get_rcnn_names ( cfg ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT pred = preds [ self . pred . index ( ' rcnn _ cls _ prob ' ) ] NEW_LINE if self . ohem or self . e2e : NEW_LINE INDENT label = preds [ self . pred . index ( ' rcnn _ label ' ) ] NEW_LINE DEDENT else : NEW_LINE INDENT label = labels [ self . label . index ( ' rcnn _ label ' ) ] NEW_LINE DEDENT last_dim = pred . shape [ - 1 ] NEW_LINE pred = pred . asnumpy ( ) . reshape ( - 1 , last_dim ) NEW_LINE label = label . asnumpy ( ) . reshape ( - 1 , ) . astype ( ' int32' ) NEW_LINE keep_inds = np . where ( label != - 1 ) [ 0 ] NEW_LINE label = label [ keep_inds ] NEW_LINE cls = pred [ keep_inds , label ] NEW_LINE cls += 1e-14 NEW_LINE cls_loss = - 1 * np . log ( cls ) NEW_LINE cls_loss = np . sum ( cls_loss ) NEW_LINE self . sum_metric += cls_loss NEW_LINE self . num_inst += label . shape [ 0 ] NEW_LINE DEDENT\",), (\"def __init__ ( self , cfg ) : NEW_LINE INDENT super ( RCNNL1LossMetric , self ) . __init__ ( ' RCNNL1Loss ' ) NEW_LINE self . e2e = cfg . TRAIN . END2END NEW_LINE self . ohem = cfg . TRAIN . ENABLE_OHEM NEW_LINE self . pred , self . label = get_rcnn_names ( cfg ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT bbox_loss = preds [ self . pred . index ( ' rcnn _ bbox _ loss ' ) ] . asnumpy ( ) NEW_LINE if self . ohem : NEW_LINE INDENT label = preds [ self . pred . index ( ' rcnn _ label ' ) ] . asnumpy ( ) NEW_LINE DEDENT else : NEW_LINE INDENT if self . e2e : NEW_LINE INDENT label = preds [ self . pred . index ( ' rcnn _ label ' ) ] . asnumpy ( ) NEW_LINE DEDENT else : NEW_LINE INDENT label = labels [ self . label . index ( ' rcnn _ label ' ) ] . asnumpy ( ) NEW_LINE DEDENT DEDENT num_inst = np . sum ( label != - 1 ) NEW_LINE self . sum_metric += np . sum ( bbox_loss ) NEW_LINE self . num_inst += num_inst NEW_LINE DEDENT\",), (\"def __init__ ( self , cfg ) : NEW_LINE INDENT super ( RCNNFGFraction , self ) . __init__ ( ' RRoI ▁ Proposal ▁ FG ▁ Fraction ' ) NEW_LINE self . e2e = cfg . TRAIN . END2END NEW_LINE self . ohem = cfg . TRAIN . ENABLE_OHEM NEW_LINE self . pred , self . label = get_Rroi_names ( cfg ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT pred = preds [ self . pred . index ( ' Rroi _ rcnn _ cls _ prob ' ) ] NEW_LINE if self . ohem or self . e2e : NEW_LINE INDENT label = preds [ self . pred . index ( ' Rroi _ rcnn _ label ' ) ] NEW_LINE DEDENT else : NEW_LINE INDENT label = labels [ self . label . index ( ' Rroi _ rcnn _ label ' ) ] NEW_LINE DEDENT num_classes = pred . shape [ - 1 ] NEW_LINE label = label . asnumpy ( ) . reshape ( - 1 , ) . astype ( ' int32' ) NEW_LINE fg_inds = np . where ( label > 0 ) [ 0 ] NEW_LINE bg_inds = np . where ( label == 0 ) [ 0 ] NEW_LINE self . sum_metric += fg_inds . shape [ 0 ] NEW_LINE self . num_inst += ( fg_inds . shape [ 0 ] + bg_inds . shape [ 0 ] ) NEW_LINE DEDENT\",), (\"def __init__ ( self , cfg ) : NEW_LINE INDENT super ( RRoIRCNNFGAccuracy , self ) . __init__ ( ' RRoIR - CNN ▁ FG ▁ Accuracy ' ) NEW_LINE self . e2e = cfg . TRAIN . END2END NEW_LINE self . ohem = cfg . TRAIN . ENABLE_OHEM NEW_LINE self . pred , self . label = get_Rroi_names ( cfg ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT pred = preds [ self . pred . index ( ' Rroi _ rcnn _ cls _ prob ' ) ] NEW_LINE if self . ohem or self . e2e : NEW_LINE INDENT label = preds [ self . pred . index ( ' Rroi _ rcnn _ label ' ) ] NEW_LINE DEDENT else : NEW_LINE INDENT label = labels [ self . label . index ( ' Rroi _ rcnn _ label ' ) ] NEW_LINE DEDENT num_classes = pred . shape [ - 1 ] NEW_LINE pred_label = pred . asnumpy ( ) . reshape ( - 1 , num_classes ) . argmax ( axis = 1 ) . astype ( ' int32' ) NEW_LINE label = label . asnumpy ( ) . reshape ( - 1 , ) . astype ( ' int32' ) NEW_LINE keep_inds = np . where ( label > 0 ) NEW_LINE pred_label = pred_label [ keep_inds ] NEW_LINE label = label [ keep_inds ] NEW_LINE self . sum_metric += np . sum ( np . equal ( pred_label . flat , label . flat ) ) NEW_LINE self . num_inst += pred_label . shape [ 0 ] NEW_LINE DEDENT\",), (\"def __init__ ( self , cfg ) : NEW_LINE INDENT super ( RRoIAccMetric , self ) . __init__ ( ' RRoIAcc ' ) NEW_LINE self . e2e = cfg . TRAIN . END2END NEW_LINE self . ohem = cfg . TRAIN . ENABLE_OHEM NEW_LINE self . pred , self . label = get_Rroi_names ( cfg ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT pred = preds [ self . pred . index ( ' Rroi _ rcnn _ cls _ prob ' ) ] NEW_LINE if self . ohem or self . e2e : NEW_LINE INDENT label = preds [ self . pred . index ( ' Rroi _ rcnn _ label ' ) ] NEW_LINE DEDENT else : NEW_LINE INDENT label = labels [ self . label . index ( ' Rroi _ rcnn _ label ' ) ] NEW_LINE DEDENT last_dim = pred . shape [ - 1 ] NEW_LINE pred_label = pred . asnumpy ( ) . reshape ( - 1 , last_dim ) . argmax ( axis = 1 ) . astype ( ' int32' ) NEW_LINE label = label . asnumpy ( ) . reshape ( - 1 , ) . astype ( ' int32' ) NEW_LINE keep_inds = np . where ( label != - 1 ) NEW_LINE pred_label = pred_label [ keep_inds ] NEW_LINE label = label [ keep_inds ] NEW_LINE self . sum_metric += np . sum ( pred_label . flat == label . flat ) NEW_LINE self . num_inst += len ( pred_label . flat ) NEW_LINE DEDENT\",), (\"def __init__ ( self , cfg ) : NEW_LINE INDENT super ( RRoIRCNNLogLossMetric , self ) . __init__ ( ' RRoIRCNNLogLoss ' ) NEW_LINE self . e2e = cfg . TRAIN . END2END NEW_LINE self . ohem = cfg . TRAIN . ENABLE_OHEM NEW_LINE self . pred , self . label = get_Rroi_names ( cfg ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT pred = preds [ self . pred . index ( ' Rroi _ rcnn _ cls _ prob ' ) ] NEW_LINE if self . ohem or self . e2e : NEW_LINE INDENT label = preds [ self . pred . index ( ' Rroi _ rcnn _ label ' ) ] NEW_LINE DEDENT else : NEW_LINE INDENT label = labels [ self . label . index ( ' Rroi _ rcnn _ label ' ) ] NEW_LINE DEDENT last_dim = pred . shape [ - 1 ] NEW_LINE pred = pred . asnumpy ( ) . reshape ( - 1 , last_dim ) NEW_LINE label = label . asnumpy ( ) . reshape ( - 1 , ) . astype ( ' int32' ) NEW_LINE keep_inds = np . where ( label != - 1 ) [ 0 ] NEW_LINE label = label [ keep_inds ] NEW_LINE cls = pred [ keep_inds , label ] NEW_LINE cls += 1e-14 NEW_LINE cls_loss = - 1 * np . log ( cls ) NEW_LINE cls_loss = np . sum ( cls_loss ) NEW_LINE self . sum_metric += cls_loss NEW_LINE self . num_inst += label . shape [ 0 ] NEW_LINE DEDENT\",), (\"def __init__ ( self , cfg ) : NEW_LINE INDENT super ( RRoIRCNNL1LossMetric , self ) . __init__ ( ' RRoIRCNNL1Loss ' ) NEW_LINE self . e2e = cfg . TRAIN . END2END NEW_LINE self . ohem = cfg . TRAIN . ENABLE_OHEM NEW_LINE self . pred , self . label = get_Rroi_names ( cfg ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT bbox_loss = preds [ self . pred . index ( ' Rroi _ rcnn _ bbox _ loss ' ) ] . asnumpy ( ) NEW_LINE if self . ohem : NEW_LINE INDENT label = preds [ self . pred . index ( ' Rroi _ rcnn _ label ' ) ] . asnumpy ( ) NEW_LINE DEDENT else : NEW_LINE INDENT if self . e2e : NEW_LINE INDENT label = preds [ self . pred . index ( ' Rroi _ rcnn _ label ' ) ] . asnumpy ( ) NEW_LINE DEDENT else : NEW_LINE INDENT label = labels [ self . label . index ( ' Rroi _ rcnn _ label ' ) ] . asnumpy ( ) NEW_LINE DEDENT DEDENT num_inst = np . sum ( label != - 1 ) NEW_LINE self . sum_metric += np . sum ( bbox_loss ) NEW_LINE self . num_inst += num_inst NEW_LINE DEDENT\",), (\"def __init__ ( self , cfg ) : NEW_LINE INDENT super ( STLogLossMetric , self ) . __init__ ( ' STLogLoss ' ) NEW_LINE self . e2e = cfg . TRAIN . END2END NEW_LINE self . ohem = cfg . TRAIN . ENABLE_OHEM NEW_LINE self . pred , self . label = get_rcnn_names ( cfg ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT pred = preds [ - 1 ] NEW_LINE label = preds [ - 2 ] NEW_LINE last_dim = pred . shape [ - 1 ] NEW_LINE pred = pred . asnumpy ( ) . reshape ( - 1 , last_dim ) NEW_LINE label = label . asnumpy ( ) . reshape ( - 1 , ) . astype ( ' int32' ) NEW_LINE keep_inds = np . where ( label != - 1 ) [ 0 ] NEW_LINE label = label [ keep_inds ] NEW_LINE cls = pred [ keep_inds , label ] NEW_LINE cls += 1e-14 NEW_LINE cls_loss = - 1 * np . log ( cls ) NEW_LINE cls_loss = np . sum ( cls_loss ) NEW_LINE self . sum_metric += cls_loss NEW_LINE self . num_inst += label . shape [ 0 ] NEW_LINE DEDENT\",), (\"def __init__ ( self , cfg ) : NEW_LINE INDENT super ( STL1LossMetric , self ) . __init__ ( ' STL1Loss ' ) NEW_LINE self . e2e = cfg . TRAIN . END2END NEW_LINE self . ohem = cfg . TRAIN . ENABLE_OHEM NEW_LINE self . pred , self . label = get_rcnn_names ( cfg ) NEW_LINE self . pred . append ( ' st _ loss ' ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT st_loss = preds [ self . pred . index ( ' st _ loss ' ) ] . asnumpy ( ) NEW_LINE label = preds [ - 2 ] . asnumpy ( ) NEW_LINE num_inst = np . sum ( label != 0 ) NEW_LINE self . sum_metric += np . sum ( st_loss ) NEW_LINE self . num_inst += num_inst NEW_LINE DEDENT\",), (\"def im_detect ( predictor , data_batch , data_names , scales , cfg ) : NEW_LINE INDENT output_all = predictor . predict ( data_batch ) NEW_LINE data_dict_all = [ dict ( zip ( data_names , idata ) ) for idata in data_batch . data ] NEW_LINE scores_all = [ ] NEW_LINE pred_boxes_all = [ ] NEW_LINE for output , data_dict , scale in zip ( output_all , data_dict_all , scales ) : NEW_LINE INDENT if cfg . TEST . HAS_RPN : NEW_LINE INDENT rois = output [ ' rois _ output ' ] . asnumpy ( ) [ : , 1 : ] NEW_LINE DEDENT else : NEW_LINE INDENT rois = data_dict [ ' rois ' ] . asnumpy ( ) . reshape ( ( - 1 , 5 ) ) [ : , 1 : ] NEW_LINE DEDENT im_shape = data_dict [ ' data ' ] . shape NEW_LINE scores = output [ ' cls _ prob _ reshape _ output ' ] . asnumpy ( ) [ 0 ] NEW_LINE bbox_deltas = output [ ' bbox _ pred _ reshape _ output ' ] . asnumpy ( ) [ 0 ] NEW_LINE pred_boxes = bbox_pred ( rois , bbox_deltas ) NEW_LINE pred_boxes = clip_boxes ( pred_boxes , im_shape [ - 2 : ] ) NEW_LINE pred_boxes = pred_boxes / scale NEW_LINE scores_all . append ( scores ) NEW_LINE pred_boxes_all . append ( pred_boxes ) NEW_LINE DEDENT return scores_all , pred_boxes_all , data_dict_all NEW_LINE DEDENT\",), (\"def vis_all_detection ( im_array , detections , class_names , scale , cfg , threshold = 1e-3 ) : NEW_LINE INDENT import matplotlib . pyplot as plt NEW_LINE import random NEW_LINE im = image . transform_inverse ( im_array , cfg . network . PIXEL_MEANS ) NEW_LINE plt . imshow ( im ) NEW_LINE for j , name in enumerate ( class_names ) : NEW_LINE INDENT if name == ' _ _ background _ _ ' : NEW_LINE INDENT continue NEW_LINE DEDENT color = ( random . random ( ) , random . random ( ) , random . random ( ) ) NEW_LINE dets = detections [ j ] NEW_LINE for det in dets : NEW_LINE INDENT bbox = det [ : 4 ] * scale NEW_LINE score = det [ - 1 ] NEW_LINE if score < threshold : NEW_LINE INDENT continue NEW_LINE DEDENT rect = plt . Rectangle ( ( bbox [ 0 ] , bbox [ 1 ] ) , bbox [ 2 ] - bbox [ 0 ] , bbox [ 3 ] - bbox [ 1 ] , fill = False , edgecolor = color , linewidth = 3.5 ) NEW_LINE plt . gca ( ) . add_patch ( rect ) NEW_LINE plt . gca ( ) . text ( bbox [ 0 ] , bbox [ 1 ] - 2 , ' { : s } ▁ { : . 3f } ' . format ( name , score ) , bbox = dict ( facecolor = color , alpha = 0.5 ) , fontsize = 12 , color = ' white ' ) NEW_LINE DEDENT DEDENT plt . show ( ) NEW_LINE DEDENT\",), (\"def draw_all_detection ( im_array , detections , class_names , scale , cfg , threshold = 1e-1 ) : NEW_LINE INDENT import cv2 NEW_LINE import random NEW_LINE color_white = ( 255 , 255 , 255 ) NEW_LINE im = image . transform_inverse ( im_array , cfg . network . PIXEL_MEANS ) NEW_LINE im = cv2 . cvtColor ( im , cv2 . COLOR_RGB2BGR ) NEW_LINE for j , name in enumerate ( class_names ) : NEW_LINE INDENT if name == ' _ _ background _ _ ' : NEW_LINE INDENT continue NEW_LINE DEDENT color = ( random . randint ( 0 , 256 ) , random . randint ( 0 , 256 ) , random . randint ( 0 , 256 ) ) NEW_LINE dets = detections [ j ] NEW_LINE for det in dets : NEW_LINE INDENT bbox = det [ : 4 ] * scale NEW_LINE score = det [ - 1 ] NEW_LINE if score < threshold : NEW_LINE INDENT continue NEW_LINE DEDENT bbox = map ( int , bbox ) NEW_LINE cv2 . rectangle ( im , ( bbox [ 0 ] , bbox [ 1 ] ) , ( bbox [ 2 ] , bbox [ 3 ] ) , color = color , thickness = 2 ) NEW_LINE cv2 . putText ( im , ' % s ▁ % .3f ' % ( class_names [ j ] , score ) , ( bbox [ 0 ] , bbox [ 1 ] + 10 ) , color = color_white , fontFace = cv2 . FONT_HERSHEY_COMPLEX , fontScale = 0.5 ) NEW_LINE DEDENT DEDENT return im NEW_LINE DEDENT\",), (\"def im_detect_rotbox ( predictor , data_batch , data_names , scales , cfg ) : NEW_LINE INDENT output_all = predictor . predict ( data_batch ) NEW_LINE data_dict_all = [ dict ( zip ( data_names , idata ) ) for idata in data_batch . data ] NEW_LINE scores_all = [ ] NEW_LINE pred_boxes_all = [ ] NEW_LINE for output , data_dict , scale in zip ( output_all , data_dict_all , scales ) : NEW_LINE INDENT if cfg . TEST . HAS_RPN : NEW_LINE INDENT rois = output [ ' rois _ output ' ] . asnumpy ( ) [ : , 1 : ] NEW_LINE DEDENT else : NEW_LINE INDENT rois = data_dict [ ' rois ' ] . asnumpy ( ) . reshape ( ( - 1 , 5 ) ) [ : , 1 : ] NEW_LINE DEDENT im_shape = data_dict [ ' data ' ] . shape NEW_LINE scores = output [ ' cls _ prob _ reshape _ output ' ] . asnumpy ( ) [ 0 ] NEW_LINE bbox_deltas = output [ ' bbox _ pred _ reshape _ output ' ] . asnumpy ( ) [ 0 ] NEW_LINE pred_boxes = dbbox_transform2_inv_warp ( rois , bbox_deltas ) NEW_LINE pred_polys = RotBox2Polys_multi_class ( pred_boxes ) NEW_LINE pred_polys = clip_polys ( pred_polys , im_shape [ - 2 : ] ) NEW_LINE pred_polys = pred_polys / scale NEW_LINE scores_all . append ( scores ) NEW_LINE pred_boxes_all . append ( pred_polys ) NEW_LINE DEDENT return scores_all , pred_boxes_all , data_dict_all NEW_LINE DEDENT\",), (\"def im_detect_rotbox_Rroi ( predictor , data_batch , data_names , scales , cfg ) : NEW_LINE INDENT output_all = predictor . predict ( data_batch ) NEW_LINE data_dict_all = [ dict ( zip ( data_names , idata ) ) for idata in data_batch . data ] NEW_LINE scores_all = [ ] NEW_LINE pred_boxes_all = [ ] NEW_LINE for output , data_dict , scale in zip ( output_all , data_dict_all , scales ) : NEW_LINE INDENT if cfg . TEST . HAS_RPN : NEW_LINE INDENT rois = output [ ' Rrois _ output ' ] . asnumpy ( ) [ : , 1 : ] NEW_LINE DEDENT else : NEW_LINE INDENT rois = data_dict [ ' Rrois _ rois ' ] . asnumpy ( ) . reshape ( ( - 1 , 6 ) ) [ : , 1 : ] NEW_LINE DEDENT im_shape = data_dict [ ' data ' ] . shape NEW_LINE scores = output [ ' Rroi _ cls _ prob _ reshape _ output ' ] . asnumpy ( ) [ 0 ] NEW_LINE bbox_deltas = output [ ' Rroi _ bbox _ pred _ reshape _ output ' ] . asnumpy ( ) [ 0 ] NEW_LINE if DEBUG : NEW_LINE INDENT bbox_deltas = np . zeros_like ( bbox_deltas ) NEW_LINE DEDENT pred_boxes = dbbox_transform2_inv_new ( rois , bbox_deltas , np . pi / 2. ) NEW_LINE pred_polys = RotBox2Polys_multi_class ( pred_boxes ) NEW_LINE pred_polys = clip_polys ( pred_polys , im_shape [ - 2 : ] ) NEW_LINE pred_polys = pred_polys / scale NEW_LINE scores_all . append ( scores ) NEW_LINE pred_boxes_all . append ( pred_polys ) NEW_LINE DEDENT return scores_all , pred_boxes_all , data_dict_all NEW_LINE DEDENT\",), (\"def draw_all_poly_detection ( im_array , detections , class_names , scale , cfg , threshold = 0.2 ) : NEW_LINE INDENT import cv2 NEW_LINE import random NEW_LINE color_white = ( 255 , 255 , 255 ) NEW_LINE im = image . transform_inverse ( im_array , cfg . network . PIXEL_MEANS ) NEW_LINE im = cv2 . cvtColor ( im , cv2 . COLOR_RGB2BGR ) NEW_LINE if DEBUG : NEW_LINE INDENT class_names = [ ' _ _ background _ _ ' , ' fg ' ] NEW_LINE DEDENT for j , name in enumerate ( class_names ) : NEW_LINE INDENT if name == ' _ _ background _ _ ' : NEW_LINE INDENT continue NEW_LINE DEDENT color = ( random . randint ( 0 , 256 ) , random . randint ( 0 , 256 ) , random . randint ( 0 , 256 ) ) NEW_LINE dets = detections [ j ] NEW_LINE for det in dets : NEW_LINE INDENT bbox = det [ : 8 ] * scale NEW_LINE score = det [ - 1 ] NEW_LINE if score < threshold : NEW_LINE INDENT continue NEW_LINE DEDENT bbox = map ( int , bbox ) NEW_LINE cv2 . circle ( im , ( bbox [ 0 ] , bbox [ 1 ] ) , 3 , ( 0 , 0 , 255 ) , - 1 ) NEW_LINE for i in range ( 3 ) : NEW_LINE INDENT cv2 . line ( im , ( bbox [ i * 2 ] , bbox [ i * 2 + 1 ] ) , ( bbox [ ( i + 1 ) * 2 ] , bbox [ ( i + 1 ) * 2 + 1 ] ) , color = color , thickness = 2 ) NEW_LINE DEDENT cv2 . line ( im , ( bbox [ 6 ] , bbox [ 7 ] ) , ( bbox [ 0 ] , bbox [ 1 ] ) , color = color , thickness = 2 ) NEW_LINE cv2 . putText ( im , ' % s ▁ % .3f ' % ( class_names [ j ] , score ) , ( bbox [ 0 ] , bbox [ 1 ] + 10 ) , color = color_white , fontFace = cv2 . FONT_HERSHEY_COMPLEX , fontScale = 0.5 ) NEW_LINE DEDENT DEDENT return im NEW_LINE DEDENT\",), ('def __init__ ( self , symbol , data_names , label_names , context = mx . cpu ( ) , max_data_shapes = None , provide_data = None , provide_label = None , arg_params = None , aux_params = None ) : NEW_LINE INDENT self . _mod = MutableModule ( symbol , data_names , label_names , context = context , max_data_shapes = max_data_shapes ) NEW_LINE self . _mod . bind ( provide_data , provide_label , for_training = False ) NEW_LINE self . _mod . init_params ( arg_params = arg_params , aux_params = aux_params ) NEW_LINE DEDENT',), ('def predict ( self , data_batch ) : NEW_LINE INDENT self . _mod . forward ( data_batch ) NEW_LINE return [ dict ( zip ( self . _mod . output_names , _ ) ) for _ in zip ( * self . _mod . get_outputs ( merge_multi_context = False ) ) ] NEW_LINE DEDENT',), (\"def do_checkpoint ( prefix , means , stds ) : NEW_LINE INDENT def _callback ( iter_no , sym , arg , aux ) : NEW_LINE INDENT arg [ ' bbox _ pred _ weight _ test ' ] = ( arg [ ' bbox _ pred _ weight ' ] . T * mx . nd . array ( stds ) ) . T NEW_LINE arg [ ' bbox _ pred _ bias _ test ' ] = arg [ ' bbox _ pred _ bias ' ] * mx . nd . array ( stds ) + mx . nd . array ( means ) NEW_LINE mx . model . save_checkpoint ( prefix , iter_no + 1 , sym , arg , aux ) NEW_LINE arg . pop ( ' bbox _ pred _ weight _ test ' ) NEW_LINE arg . pop ( ' bbox _ pred _ bias _ test ' ) NEW_LINE DEDENT return _callback NEW_LINE DEDENT\",), (\"def do_checkpoint_Rroi ( prefix , means , stds , Rroi_means , Rroi_stds ) : NEW_LINE INDENT def _callback ( iter_no , sym , arg , aux ) : NEW_LINE INDENT arg [ ' bbox _ pred _ weight _ test ' ] = ( arg [ ' bbox _ pred _ weight ' ] . T * mx . nd . array ( stds ) ) . T NEW_LINE arg [ ' bbox _ pred _ bias _ test ' ] = arg [ ' bbox _ pred _ bias ' ] * mx . nd . array ( stds ) + mx . nd . array ( means ) NEW_LINE arg [ ' Rroi _ bbox _ pred _ weight _ test ' ] = ( arg [ ' Rroi _ bbox _ pred _ weight ' ] . T * mx . nd . array ( Rroi_stds ) ) . T NEW_LINE arg [ ' Rroi _ bbox _ pred _ bias _ test ' ] = arg [ ' Rroi _ bbox _ pred _ bias ' ] * mx . nd . array ( Rroi_stds ) + mx . nd . array ( Rroi_means ) NEW_LINE mx . model . save_checkpoint ( prefix , iter_no + 1 , sym , arg , aux ) NEW_LINE arg . pop ( ' bbox _ pred _ weight _ test ' ) NEW_LINE arg . pop ( ' bbox _ pred _ bias _ test ' ) NEW_LINE arg . pop ( ' Rroi _ bbox _ pred _ weight _ test ' ) NEW_LINE arg . pop ( ' Rroi _ bbox _ pred _ bias _ test ' ) NEW_LINE DEDENT return _callback NEW_LINE DEDENT\",), ('def __init__ ( self , batch_size , frequent = 50 ) : NEW_LINE INDENT self . batch_size = batch_size NEW_LINE self . frequent = frequent NEW_LINE self . init = False NEW_LINE self . tic = 0 NEW_LINE self . last_count = 0 NEW_LINE DEDENT',), ('def __call__ ( self , param ) : NEW_LINE INDENT count = param . nbatch NEW_LINE if self . last_count > count : NEW_LINE INDENT self . init = False NEW_LINE DEDENT self . last_count = count NEW_LINE if self . init : NEW_LINE INDENT if count % self . frequent == 0 : NEW_LINE INDENT speed = self . frequent * self . batch_size / ( time . time ( ) - self . tic ) NEW_LINE s = \\' \\' NEW_LINE if param . eval_metric is not None : NEW_LINE INDENT name , value = param . eval_metric . get ( ) NEW_LINE s = \" Epoch [ % d ] ▁ Batch ▁ [ % d ] \\\\tSpeed : ▁ % .2f ▁ samples / sec\\\\tTrain - \" % ( param . epoch , count , speed ) NEW_LINE for n , v in zip ( name , value ) : NEW_LINE INDENT s += \" % s = % f , \\\\t \" % ( n , v ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT s = \" Iter [ % d ] ▁ Batch ▁ [ % d ] \\\\tSpeed : ▁ % .2f ▁ samples / sec \" % ( param . epoch , count , speed ) NEW_LINE DEDENT logging . info ( s ) NEW_LINE print ( s ) NEW_LINE self . tic = time . time ( ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT self . init = True NEW_LINE self . tic = time . time ( ) NEW_LINE DEDENT DEDENT',), (\"def load ( prefix , epoch , load_optimizer_states = False , ** kwargs ) : NEW_LINE INDENT sym , args , auxs = load_checkpoint ( prefix , epoch ) NEW_LINE mod = Module ( symbol = sym , ** kwargs ) NEW_LINE mod . _arg_params = args NEW_LINE mod . _aux_params = auxs NEW_LINE mod . params_initialized = True NEW_LINE if load_optimizer_states : NEW_LINE INDENT mod . _preload_opt_states = ' % s - %04d . states ' % ( prefix , epoch ) NEW_LINE DEDENT return mod NEW_LINE DEDENT\",), ('def __init__ ( self , symbol , data_names = ( \\' data \\' , ) , label_names = ( \\' softmax _ label \\' , ) , logger = logging , context = ctx . cpu ( ) , work_load_list = None , fixed_param_names = None , state_names = None ) : NEW_LINE INDENT super ( Module , self ) . __init__ ( logger = logger ) NEW_LINE if isinstance ( context , ctx . Context ) : NEW_LINE INDENT context = [ context ] NEW_LINE DEDENT self . _context = context NEW_LINE if work_load_list is None : NEW_LINE INDENT work_load_list = [ 1 ] * len ( self . _context ) NEW_LINE DEDENT assert len ( work_load_list ) == len ( self . _context ) NEW_LINE self . _work_load_list = work_load_list NEW_LINE self . _symbol = symbol NEW_LINE data_names = list ( data_names ) if data_names is not None else [ ] NEW_LINE label_names = list ( label_names ) if label_names is not None else [ ] NEW_LINE state_names = list ( state_names ) if state_names is not None else [ ] NEW_LINE fixed_param_names = list ( fixed_param_names ) if fixed_param_names is not None else [ ] NEW_LINE _check_input_names ( symbol , data_names , \" data \" , True ) NEW_LINE _check_input_names ( symbol , label_names , \" label \" , False ) NEW_LINE _check_input_names ( symbol , state_names , \" state \" , True ) NEW_LINE _check_input_names ( symbol , fixed_param_names , \" fixed _ param \" , True ) NEW_LINE arg_names = symbol . list_arguments ( ) NEW_LINE input_names = data_names + label_names + state_names NEW_LINE self . _param_names = [ x for x in arg_names if x not in input_names ] NEW_LINE self . _fixed_param_names = fixed_param_names NEW_LINE self . _aux_names = symbol . list_auxiliary_states ( ) NEW_LINE self . _data_names = data_names NEW_LINE self . _label_names = label_names NEW_LINE self . _state_names = state_names NEW_LINE self . _output_names = symbol . list_outputs ( ) NEW_LINE self . _arg_params = None NEW_LINE self . _aux_params = None NEW_LINE self . _params_dirty = False NEW_LINE self . _optimizer = None NEW_LINE self . _kvstore = None NEW_LINE self . _update_on_kvstore = None NEW_LINE self . _updater = None NEW_LINE self . _preload_opt_states = None NEW_LINE self . _grad_req = None NEW_LINE self . _exec_group = None NEW_LINE self . _data_shapes = None NEW_LINE self . _label_shapes = None NEW_LINE DEDENT',), ('def save_checkpoint ( self , prefix , epoch , save_optimizer_states = False ) : NEW_LINE INDENT self . _symbol . save ( \\' % s - symbol . json \\' % prefix ) NEW_LINE param_name = \\' % s - %04d . params \\' % ( prefix , epoch ) NEW_LINE self . save_params ( param_name ) NEW_LINE logging . info ( \\' Saved ▁ checkpoint ▁ to ▁ \\\\ \" % s\\\\ \" \\' , param_name ) NEW_LINE if save_optimizer_states : NEW_LINE INDENT state_name = \\' % s - %04d . states \\' % ( prefix , epoch ) NEW_LINE self . save_optimizer_states ( state_name ) NEW_LINE logging . info ( \\' Saved ▁ optimizer ▁ state ▁ to ▁ \\\\ \" % s\\\\ \" \\' , state_name ) NEW_LINE DEDENT DEDENT',), ('def _reset_bind ( self ) : NEW_LINE INDENT self . binded = False NEW_LINE self . _exec_group = None NEW_LINE self . _data_shapes = None NEW_LINE self . _label_shapes = None NEW_LINE DEDENT',), ('def data_names ( self ) : NEW_LINE INDENT return self . _data_names NEW_LINE DEDENT',), ('def label_names ( self ) : NEW_LINE INDENT return self . _label_names NEW_LINE DEDENT',), ('def output_names ( self ) : NEW_LINE INDENT return self . _output_names NEW_LINE DEDENT',), ('def data_shapes ( self ) : NEW_LINE INDENT assert self . binded NEW_LINE return self . _data_shapes NEW_LINE DEDENT',), ('def label_shapes ( self ) : NEW_LINE INDENT assert self . binded NEW_LINE return self . _label_shapes NEW_LINE DEDENT',), ('def output_shapes ( self ) : NEW_LINE INDENT assert self . binded NEW_LINE return self . _exec_group . get_output_shapes ( ) NEW_LINE DEDENT',), ('def get_params ( self ) : NEW_LINE INDENT assert self . binded and self . params_initialized NEW_LINE if self . _params_dirty : NEW_LINE INDENT self . _sync_params_from_devices ( ) NEW_LINE DEDENT return ( self . _arg_params , self . _aux_params ) NEW_LINE DEDENT',), ('def init_params ( self , initializer = Uniform ( 0.01 ) , arg_params = None , aux_params = None , allow_missing = False , force_init = False , allow_extra = False ) : NEW_LINE INDENT if self . params_initialized and not force_init : NEW_LINE INDENT warnings . warn ( \" Parameters ▁ already ▁ initialized ▁ and ▁ force _ init = False . ▁ \" \" init _ params ▁ call ▁ ignored . \" , stacklevel = 2 ) NEW_LINE return NEW_LINE DEDENT assert self . binded , \\' call ▁ bind ▁ before ▁ initializing ▁ the ▁ parameters \\' NEW_LINE def _impl ( name , arr , cache ) : NEW_LINE INDENT if cache is not None : NEW_LINE INDENT if name in cache : NEW_LINE INDENT cache_arr = cache [ name ] NEW_LINE if cache_arr is not arr : NEW_LINE INDENT cache_arr . copyto ( arr ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT if not allow_missing : NEW_LINE INDENT raise RuntimeError ( \" % s ▁ is ▁ not ▁ presented \" % name ) NEW_LINE DEDENT if initializer != None : NEW_LINE INDENT initializer ( name , arr ) NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT initializer ( name , arr ) NEW_LINE DEDENT DEDENT attrs = self . _symbol . attr_dict ( ) NEW_LINE for name , arr in self . _arg_params . items ( ) : NEW_LINE INDENT desc = InitDesc ( name , attrs . get ( name , None ) ) NEW_LINE _impl ( desc , arr , arg_params ) NEW_LINE DEDENT for name , arr in self . _aux_params . items ( ) : NEW_LINE INDENT desc = InitDesc ( name , attrs . get ( name , None ) ) NEW_LINE _impl ( desc , arr , aux_params ) NEW_LINE DEDENT self . params_initialized = True NEW_LINE self . _params_dirty = False NEW_LINE self . _exec_group . set_params ( self . _arg_params , self . _aux_params ) NEW_LINE DEDENT',), ('def set_params ( self , arg_params , aux_params , allow_missing = False , force_init = True ) : NEW_LINE INDENT if not allow_missing : NEW_LINE INDENT self . init_params ( initializer = None , arg_params = arg_params , aux_params = aux_params , allow_missing = allow_missing , force_init = force_init ) NEW_LINE return NEW_LINE DEDENT if self . params_initialized and not force_init : NEW_LINE INDENT warnings . warn ( \" Parameters ▁ already ▁ initialized ▁ and ▁ force _ init = False . ▁ \" \" set _ params ▁ call ▁ ignored . \" , stacklevel = 2 ) NEW_LINE return NEW_LINE DEDENT self . _exec_group . set_params ( arg_params , aux_params ) NEW_LINE self . _params_dirty = True NEW_LINE self . params_initialized = True NEW_LINE DEDENT',), (\"def bind ( self , data_shapes , label_shapes = None , for_training = True , inputs_need_grad = False , force_rebind = False , shared_module = None , grad_req = ' write ' ) : NEW_LINE INDENT if force_rebind : NEW_LINE INDENT self . _reset_bind ( ) NEW_LINE DEDENT if self . binded : NEW_LINE INDENT self . logger . warning ( ' Already ▁ binded , ▁ ignoring ▁ bind ( ) ' ) NEW_LINE return NEW_LINE DEDENT self . for_training = for_training NEW_LINE self . inputs_need_grad = inputs_need_grad NEW_LINE self . binded = True NEW_LINE self . _grad_req = grad_req NEW_LINE if not for_training : NEW_LINE INDENT assert not inputs_need_grad NEW_LINE DEDENT else : NEW_LINE INDENT pass NEW_LINE DEDENT self . _data_shapes , self . _label_shapes = zip ( * [ _parse_data_desc ( self . data_names , self . label_names , data_shape , label_shape ) for data_shape , label_shape in zip ( data_shapes , label_shapes ) ] ) NEW_LINE if self . _label_shapes . count ( None ) == len ( self . _label_shapes ) : NEW_LINE INDENT self . _label_shapes = None NEW_LINE DEDENT if shared_module is not None : NEW_LINE INDENT assert isinstance ( shared_module , Module ) and shared_module . binded and shared_module . params_initialized NEW_LINE shared_group = shared_module . _exec_group NEW_LINE DEDENT else : NEW_LINE INDENT shared_group = None NEW_LINE DEDENT self . _exec_group = DataParallelExecutorGroup ( self . _symbol , self . _context , self . _work_load_list , self . _data_shapes , self . _label_shapes , self . _param_names , for_training , inputs_need_grad , shared_group , logger = self . logger , fixed_param_names = self . _fixed_param_names , grad_req = grad_req , state_names = self . _state_names ) NEW_LINE if shared_module is not None : NEW_LINE INDENT self . params_initialized = True NEW_LINE self . _arg_params = shared_module . _arg_params NEW_LINE self . _aux_params = shared_module . _aux_params NEW_LINE DEDENT elif self . params_initialized : NEW_LINE INDENT self . _exec_group . set_params ( self . _arg_params , self . _aux_params ) NEW_LINE DEDENT else : NEW_LINE INDENT assert self . _arg_params is None and self . _aux_params is None NEW_LINE param_arrays = [ nd . zeros ( x [ 0 ] . shape , dtype = x [ 0 ] . dtype ) for x in self . _exec_group . param_arrays ] NEW_LINE self . _arg_params = { name : arr for name , arr in zip ( self . _param_names , param_arrays ) } NEW_LINE aux_arrays = [ nd . zeros ( x [ 0 ] . shape , dtype = x [ 0 ] . dtype ) for x in self . _exec_group . aux_arrays ] NEW_LINE self . _aux_params = { name : arr for name , arr in zip ( self . _aux_names , aux_arrays ) } NEW_LINE DEDENT if shared_module is not None and shared_module . optimizer_initialized : NEW_LINE INDENT self . borrow_optimizer ( shared_module ) NEW_LINE DEDENT DEDENT\",), ('def reshape ( self , data_shapes , label_shapes = None ) : NEW_LINE INDENT assert self . binded NEW_LINE self . _data_shapes , self . _label_shapes = zip ( * [ _parse_data_desc ( self . data_names , self . label_names , data_shape , label_shape ) for data_shape , label_shape in zip ( data_shapes , label_shapes ) ] ) NEW_LINE self . _exec_group . reshape ( self . _data_shapes , self . _label_shapes ) NEW_LINE DEDENT',), ('def init_optimizer ( self , kvstore = \\' local \\' , optimizer = \\' sgd \\' , optimizer_params = ( ( \\' learning _ rate \\' , 0.01 ) , ) , force_init = False ) : NEW_LINE INDENT assert self . binded and self . params_initialized NEW_LINE if self . optimizer_initialized and not force_init : NEW_LINE INDENT self . logger . warning ( \\' optimizer ▁ already ▁ initialized , ▁ ignoring . . . \\' ) NEW_LINE return NEW_LINE DEDENT ( kvstore , update_on_kvstore ) = _create_kvstore ( kvstore , len ( self . _context ) , self . _arg_params ) NEW_LINE batch_size = self . _exec_group . batch_size NEW_LINE if kvstore and \\' dist \\' in kvstore . type and \\' _ sync \\' in kvstore . type : NEW_LINE INDENT batch_size *= kvstore . num_workers NEW_LINE DEDENT rescale_grad = 1.0 / batch_size NEW_LINE if isinstance ( optimizer , str ) : NEW_LINE INDENT idx2name = { } NEW_LINE if update_on_kvstore : NEW_LINE INDENT idx2name . update ( enumerate ( self . _exec_group . param_names ) ) NEW_LINE DEDENT else : NEW_LINE INDENT for k in range ( len ( self . _context ) ) : NEW_LINE INDENT idx2name . update ( { i * len ( self . _context ) + k : n for i , n in enumerate ( self . _exec_group . param_names ) } ) NEW_LINE DEDENT DEDENT optimizer_params = dict ( optimizer_params ) NEW_LINE if \\' rescale _ grad \\' not in optimizer_params : NEW_LINE INDENT optimizer_params [ \\' rescale _ grad \\' ] = rescale_grad NEW_LINE DEDENT optimizer = opt . create ( optimizer , sym = self . symbol , param_idx2name = idx2name , ** optimizer_params ) NEW_LINE DEDENT else : NEW_LINE INDENT assert isinstance ( optimizer , opt . Optimizer ) NEW_LINE if optimizer . rescale_grad != rescale_grad : NEW_LINE INDENT warnings . warn ( \" Optimizer ▁ created ▁ manually ▁ outside ▁ Module ▁ but ▁ rescale _ grad ▁ \" + \" is ▁ not ▁ normalized ▁ to ▁ 1.0 / batch _ size / num _ workers ▁ ( % s ▁ vs . ▁ % s ) . ▁ \" % ( optimizer . rescale_grad , rescale_grad ) + \" Is ▁ this ▁ intended ? \" , stacklevel = 2 ) NEW_LINE DEDENT DEDENT self . _optimizer = optimizer NEW_LINE self . _kvstore = kvstore NEW_LINE self . _update_on_kvstore = update_on_kvstore NEW_LINE self . _updater = None NEW_LINE if kvstore : NEW_LINE INDENT _initialize_kvstore ( kvstore = kvstore , param_arrays = self . _exec_group . param_arrays , arg_params = self . _arg_params , param_names = self . _param_names , update_on_kvstore = update_on_kvstore ) NEW_LINE DEDENT if update_on_kvstore : NEW_LINE INDENT kvstore . set_optimizer ( self . _optimizer ) NEW_LINE DEDENT else : NEW_LINE INDENT self . _updater = opt . get_updater ( optimizer ) NEW_LINE DEDENT self . optimizer_initialized = True NEW_LINE if self . _preload_opt_states is not None : NEW_LINE INDENT self . load_optimizer_states ( self . _preload_opt_states ) NEW_LINE self . _preload_opt_states = None NEW_LINE DEDENT DEDENT',), ('def borrow_optimizer ( self , shared_module ) : NEW_LINE INDENT assert shared_module . optimizer_initialized NEW_LINE self . _optimizer = shared_module . _optimizer NEW_LINE self . _kvstore = shared_module . _kvstore NEW_LINE self . _update_on_kvstore = shared_module . _update_on_kvstore NEW_LINE self . _updater = shared_module . _updater NEW_LINE self . optimizer_initialized = True NEW_LINE DEDENT',), ('def forward ( self , data_batch , is_train = None ) : NEW_LINE INDENT assert self . binded and self . params_initialized NEW_LINE self . _exec_group . forward ( data_batch , is_train ) NEW_LINE DEDENT',), ('def backward ( self , out_grads = None ) : NEW_LINE INDENT assert self . binded and self . params_initialized NEW_LINE self . _exec_group . backward ( out_grads = out_grads ) NEW_LINE DEDENT',), ('def update ( self ) : NEW_LINE INDENT assert self . binded and self . params_initialized and self . optimizer_initialized NEW_LINE self . _params_dirty = True NEW_LINE if self . _update_on_kvstore : NEW_LINE INDENT try : NEW_LINE INDENT _update_params_on_kvstore ( self . _exec_group . param_arrays , self . _exec_group . grad_arrays , self . _kvstore ) NEW_LINE DEDENT except : NEW_LINE INDENT _update_params_on_kvstore ( self . _exec_group . param_arrays , self . _exec_group . grad_arrays , self . _kvstore , param_names = self . _exec_group . param_names ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT _update_params ( self . _exec_group . param_arrays , self . _exec_group . grad_arrays , updater = self . _updater , num_device = len ( self . _context ) , kvstore = self . _kvstore ) NEW_LINE DEDENT DEDENT',), ('def get_outputs ( self , merge_multi_context = True ) : NEW_LINE INDENT assert self . binded and self . params_initialized NEW_LINE return self . _exec_group . get_outputs ( merge_multi_context = merge_multi_context ) NEW_LINE DEDENT',), ('def get_input_grads ( self , merge_multi_context = True ) : NEW_LINE INDENT assert self . binded and self . params_initialized and self . inputs_need_grad NEW_LINE return self . _exec_group . get_input_grads ( merge_multi_context = merge_multi_context ) NEW_LINE DEDENT',), ('def get_states ( self , merge_multi_context = True ) : NEW_LINE INDENT assert self . binded and self . params_initialized NEW_LINE return self . _exec_group . get_states ( merge_multi_context = merge_multi_context ) NEW_LINE DEDENT',), ('def set_states ( self , states = None , value = None ) : NEW_LINE INDENT assert self . binded and self . params_initialized NEW_LINE self . _exec_group . set_states ( states , value ) NEW_LINE DEDENT',), ('def update_metric ( self , eval_metric , labels ) : NEW_LINE INDENT self . _exec_group . update_metric ( eval_metric , labels ) NEW_LINE DEDENT',), ('def _sync_params_from_devices ( self ) : NEW_LINE INDENT self . _exec_group . get_params ( self . _arg_params , self . _aux_params ) NEW_LINE self . _params_dirty = False NEW_LINE DEDENT',), (\"def save_optimizer_states ( self , fname ) : NEW_LINE INDENT assert self . optimizer_initialized NEW_LINE if self . _update_on_kvstore : NEW_LINE INDENT self . _kvstore . save_optimizer_states ( fname ) NEW_LINE DEDENT else : NEW_LINE INDENT with open ( fname , ' wb ' ) as fout : NEW_LINE INDENT fout . write ( self . _updater . get_states ( ) ) NEW_LINE DEDENT DEDENT DEDENT\",), (\"def load_optimizer_states ( self , fname ) : NEW_LINE INDENT assert self . optimizer_initialized NEW_LINE if self . _update_on_kvstore : NEW_LINE INDENT self . _kvstore . load_optimizer_states ( fname ) NEW_LINE DEDENT else : NEW_LINE INDENT self . _updater . set_states ( open ( fname , ' rb ' ) . read ( ) ) NEW_LINE DEDENT DEDENT\",), ('def install_monitor ( self , mon ) : NEW_LINE INDENT assert self . binded NEW_LINE self . _exec_group . install_monitor ( mon ) NEW_LINE DEDENT',), ('def __init__ ( self , symbol , data_names , label_names , logger = logging , context = ctx . cpu ( ) , work_load_list = None , max_data_shapes = None , max_label_shapes = None , fixed_param_prefix = None ) : NEW_LINE INDENT super ( MutableModule , self ) . __init__ ( logger = logger ) NEW_LINE self . _symbol = symbol NEW_LINE self . _data_names = data_names NEW_LINE self . _label_names = label_names NEW_LINE self . _context = context NEW_LINE self . _work_load_list = work_load_list NEW_LINE self . _curr_module = None NEW_LINE self . _max_data_shapes = max_data_shapes NEW_LINE self . _max_label_shapes = max_label_shapes NEW_LINE self . _fixed_param_prefix = fixed_param_prefix NEW_LINE fixed_param_names = list ( ) NEW_LINE if fixed_param_prefix is not None : NEW_LINE INDENT for name in self . _symbol . list_arguments ( ) : NEW_LINE INDENT for prefix in self . _fixed_param_prefix : NEW_LINE INDENT if prefix in name : NEW_LINE INDENT fixed_param_names . append ( name ) NEW_LINE DEDENT DEDENT DEDENT DEDENT self . _fixed_param_names = fixed_param_names NEW_LINE self . _preload_opt_states = None NEW_LINE DEDENT',), ('def _reset_bind ( self ) : NEW_LINE INDENT self . binded = False NEW_LINE self . _curr_module = None NEW_LINE DEDENT',), ('def data_names ( self ) : NEW_LINE INDENT return self . _data_names NEW_LINE DEDENT',), ('def output_names ( self ) : NEW_LINE INDENT return self . _symbol . list_outputs ( ) NEW_LINE DEDENT',), ('def data_shapes ( self ) : NEW_LINE INDENT assert self . binded NEW_LINE return self . _curr_module . data_shapes NEW_LINE DEDENT',), ('def label_shapes ( self ) : NEW_LINE INDENT assert self . binded NEW_LINE return self . _curr_module . label_shapes NEW_LINE DEDENT',), ('def output_shapes ( self ) : NEW_LINE INDENT assert self . binded NEW_LINE return self . _curr_module . output_shapes NEW_LINE DEDENT',), ('def get_params ( self ) : NEW_LINE INDENT assert self . binded and self . params_initialized NEW_LINE return self . _curr_module . get_params ( ) NEW_LINE DEDENT',), (\"def init_params ( self , initializer = Uniform ( 0.01 ) , arg_params = None , aux_params = None , allow_missing = False , force_init = False , allow_extra = False ) : NEW_LINE INDENT if self . params_initialized and not force_init : NEW_LINE INDENT return NEW_LINE DEDENT assert self . binded , ' call ▁ bind ▁ before ▁ initializing ▁ the ▁ parameters ' NEW_LINE self . _curr_module . init_params ( initializer = initializer , arg_params = arg_params , aux_params = aux_params , allow_missing = allow_missing , force_init = force_init ) NEW_LINE self . params_initialized = True NEW_LINE DEDENT\",), (\"def bind ( self , data_shapes , label_shapes = None , for_training = True , inputs_need_grad = False , force_rebind = False , shared_module = None , grad_req = ' write ' ) : NEW_LINE INDENT if self . params_initialized : NEW_LINE INDENT arg_params , aux_params = self . get_params ( ) NEW_LINE DEDENT if force_rebind : NEW_LINE INDENT self . _reset_bind ( ) NEW_LINE DEDENT if self . binded : NEW_LINE INDENT self . logger . warning ( ' Already ▁ binded , ▁ ignoring ▁ bind ( ) ' ) NEW_LINE return NEW_LINE DEDENT assert shared_module is None , ' shared _ module ▁ for ▁ MutableModule ▁ is ▁ not ▁ supported ' NEW_LINE self . for_training = for_training NEW_LINE self . inputs_need_grad = inputs_need_grad NEW_LINE self . binded = True NEW_LINE max_shapes_dict = dict ( ) NEW_LINE if self . _max_data_shapes is not None : NEW_LINE INDENT max_shapes_dict . update ( dict ( self . _max_data_shapes [ 0 ] ) ) NEW_LINE DEDENT if self . _max_label_shapes is not None : NEW_LINE INDENT max_shapes_dict . update ( dict ( self . _max_label_shapes [ 0 ] ) ) NEW_LINE DEDENT max_data_shapes = list ( ) NEW_LINE for name , shape in data_shapes [ 0 ] : NEW_LINE INDENT if name in max_shapes_dict : NEW_LINE INDENT max_data_shapes . append ( ( name , max_shapes_dict [ name ] ) ) NEW_LINE DEDENT else : NEW_LINE INDENT max_data_shapes . append ( ( name , shape ) ) NEW_LINE DEDENT DEDENT max_label_shapes = list ( ) NEW_LINE if not label_shapes . count ( None ) == len ( label_shapes ) : NEW_LINE INDENT for name , shape in label_shapes [ 0 ] : NEW_LINE INDENT if name in max_shapes_dict : NEW_LINE INDENT max_label_shapes . append ( ( name , max_shapes_dict [ name ] ) ) NEW_LINE DEDENT else : NEW_LINE INDENT max_label_shapes . append ( ( name , shape ) ) NEW_LINE DEDENT DEDENT DEDENT if len ( max_label_shapes ) == 0 : NEW_LINE INDENT max_label_shapes = None NEW_LINE DEDENT module = Module ( self . _symbol , self . _data_names , self . _label_names , logger = self . logger , context = self . _context , work_load_list = self . _work_load_list , fixed_param_names = self . _fixed_param_names ) NEW_LINE module . bind ( [ max_data_shapes for _ in range ( len ( self . _context ) ) ] , [ max_label_shapes for _ in range ( len ( self . _context ) ) ] , for_training , inputs_need_grad , force_rebind = False , shared_module = None ) NEW_LINE self . _curr_module = module NEW_LINE if self . params_initialized : NEW_LINE INDENT self . set_params ( arg_params , aux_params ) NEW_LINE DEDENT DEDENT\",), ('def save_checkpoint ( self , prefix , epoch , save_optimizer_states = False ) : NEW_LINE INDENT self . _curr_module . save_checkpoint ( prefix , epoch , save_optimizer_states ) NEW_LINE DEDENT',), (\"def init_optimizer ( self , kvstore = ' local ' , optimizer = ' sgd ' , optimizer_params = ( ( ' learning _ rate ' , 0.01 ) , ) , force_init = False ) : NEW_LINE INDENT assert self . binded and self . params_initialized NEW_LINE if self . optimizer_initialized and not force_init : NEW_LINE INDENT self . logger . warning ( ' optimizer ▁ already ▁ initialized , ▁ ignoring . ' ) NEW_LINE return NEW_LINE DEDENT self . _curr_module . _preload_opt_states = self . _preload_opt_states NEW_LINE self . _curr_module . init_optimizer ( kvstore , optimizer , optimizer_params , force_init = force_init ) NEW_LINE self . optimizer_initialized = True NEW_LINE DEDENT\",), (\"def fit ( self , train_data , eval_data = None , eval_metric = ' acc ' , epoch_end_callback = None , batch_end_callback = None , kvstore = ' local ' , optimizer = ' sgd ' , optimizer_params = ( ( ' learning _ rate ' , 0.01 ) , ) , eval_end_callback = None , eval_batch_end_callback = None , initializer = Uniform ( 0.01 ) , arg_params = None , aux_params = None , allow_missing = False , force_rebind = False , force_init = False , begin_epoch = 0 , num_epoch = None , validation_metric = None , monitor = None , prefix = None , state = None ) : NEW_LINE INDENT assert num_epoch is not None , ' please ▁ specify ▁ number ▁ of ▁ epochs ' NEW_LINE self . bind ( data_shapes = train_data . provide_data , label_shapes = train_data . provide_label , for_training = True , force_rebind = force_rebind ) NEW_LINE if monitor is not None : NEW_LINE INDENT self . install_monitor ( monitor ) NEW_LINE DEDENT self . init_params ( initializer = initializer , arg_params = arg_params , aux_params = aux_params , allow_missing = allow_missing , force_init = force_init ) NEW_LINE self . init_optimizer ( kvstore = kvstore , optimizer = optimizer , optimizer_params = optimizer_params ) NEW_LINE if state is not None : NEW_LINE INDENT self . _curr_module . load_optimizer_states ( state ) NEW_LINE DEDENT if validation_metric is None : NEW_LINE INDENT validation_metric = eval_metric NEW_LINE DEDENT if not isinstance ( eval_metric , metric . EvalMetric ) : NEW_LINE INDENT eval_metric = metric . create ( eval_metric ) NEW_LINE DEDENT for epoch in range ( begin_epoch , num_epoch ) : NEW_LINE INDENT tic = time . time ( ) NEW_LINE eval_metric . reset ( ) NEW_LINE ct = 0 NEW_LINE for nbatch , data_batch in enumerate ( train_data ) : NEW_LINE INDENT if monitor is not None : NEW_LINE INDENT monitor . tic ( ) NEW_LINE DEDENT self . forward_backward ( data_batch ) NEW_LINE self . update ( ) NEW_LINE ct = ct + 1 NEW_LINE if ct % 50 == 0 : NEW_LINE INDENT ct = 0 NEW_LINE self . update_metric ( eval_metric , data_batch . label ) NEW_LINE sys . stdout . flush ( ) NEW_LINE DEDENT if monitor is not None : NEW_LINE INDENT monitor . toc_print ( ) NEW_LINE DEDENT if batch_end_callback is not None : NEW_LINE INDENT batch_end_params = BatchEndParam ( epoch = epoch , nbatch = nbatch , eval_metric = eval_metric , locals = locals ( ) ) NEW_LINE for callback in _as_list ( batch_end_callback ) : NEW_LINE INDENT callback ( batch_end_params ) NEW_LINE DEDENT DEDENT DEDENT for name , val in eval_metric . get_name_value ( ) : NEW_LINE INDENT self . logger . info ( ' Epoch [ % d ] ▁ Train - % s = % f ' , epoch , name , val ) NEW_LINE DEDENT toc = time . time ( ) NEW_LINE self . logger . info ( ' Epoch [ % d ] ▁ Time ▁ cost = % .3f ' , epoch , ( toc - tic ) ) NEW_LINE arg_params , aux_params = self . get_params ( ) NEW_LINE self . set_params ( arg_params , aux_params ) NEW_LINE if epoch_end_callback is not None : NEW_LINE INDENT for callback in _as_list ( epoch_end_callback ) : NEW_LINE INDENT callback ( epoch , self . symbol , arg_params , aux_params ) NEW_LINE DEDENT DEDENT if eval_data : NEW_LINE INDENT res = self . score ( eval_data , validation_metric , score_end_callback = eval_end_callback , batch_end_callback = eval_batch_end_callback , epoch = epoch ) NEW_LINE for name , val in res : NEW_LINE INDENT self . logger . info ( ' Epoch [ % d ] ▁ Validation - % s = % f ' , epoch , name , val ) NEW_LINE DEDENT DEDENT train_data . reset ( ) NEW_LINE DEDENT DEDENT\",), ('def forward ( self , data_batch , is_train = None ) : NEW_LINE INDENT assert self . binded and self . params_initialized NEW_LINE if self . _curr_module . label_shapes is not None : NEW_LINE INDENT current_shapes = [ dict ( self . _curr_module . data_shapes [ i ] + self . _curr_module . label_shapes [ i ] ) for i in range ( len ( self . _context ) ) ] NEW_LINE DEDENT else : NEW_LINE INDENT current_shapes = [ dict ( self . _curr_module . data_shapes [ i ] ) for i in range ( len ( self . _context ) ) ] NEW_LINE DEDENT if is_train : NEW_LINE INDENT input_shapes = [ dict ( data_batch . provide_data [ i ] + data_batch . provide_label [ i ] ) for i in range ( len ( self . _context ) ) ] NEW_LINE DEDENT else : NEW_LINE INDENT input_shapes = [ dict ( data_batch . provide_data [ i ] ) for i in range ( len ( data_batch . provide_data ) ) ] NEW_LINE DEDENT shape_changed = len ( current_shapes ) != len ( input_shapes ) NEW_LINE for pre , cur in zip ( current_shapes , input_shapes ) : NEW_LINE INDENT for k , v in pre . items ( ) : NEW_LINE INDENT if v != cur [ k ] : NEW_LINE INDENT shape_changed = True NEW_LINE DEDENT DEDENT DEDENT if shape_changed : NEW_LINE INDENT module = Module ( self . _symbol , self . _data_names , self . _label_names , logger = self . logger , context = [ self . _context [ i ] for i in range ( len ( data_batch . provide_data ) ) ] , work_load_list = self . _work_load_list , fixed_param_names = self . _fixed_param_names ) NEW_LINE module . bind ( data_batch . provide_data , data_batch . provide_label , self . _curr_module . for_training , self . _curr_module . inputs_need_grad , force_rebind = False , shared_module = self . _curr_module ) NEW_LINE self . _curr_module = module NEW_LINE DEDENT self . _curr_module . forward ( data_batch , is_train = is_train ) NEW_LINE DEDENT',), ('def backward ( self , out_grads = None ) : NEW_LINE INDENT assert self . binded and self . params_initialized NEW_LINE self . _curr_module . backward ( out_grads = out_grads ) NEW_LINE DEDENT',), ('def update ( self ) : NEW_LINE INDENT assert self . binded and self . params_initialized and self . optimizer_initialized NEW_LINE self . _curr_module . update ( ) NEW_LINE DEDENT',), ('def get_outputs ( self , merge_multi_context = True ) : NEW_LINE INDENT assert self . binded and self . params_initialized NEW_LINE return self . _curr_module . get_outputs ( merge_multi_context = merge_multi_context ) NEW_LINE DEDENT',), ('def get_input_grads ( self , merge_multi_context = True ) : NEW_LINE INDENT assert self . binded and self . params_initialized and self . inputs_need_grad NEW_LINE return self . _curr_module . get_input_grads ( merge_multi_context = merge_multi_context ) NEW_LINE DEDENT',), ('def update_metric ( self , eval_metric , labels ) : NEW_LINE INDENT assert self . binded and self . params_initialized NEW_LINE self . _curr_module . update_metric ( eval_metric , labels ) NEW_LINE DEDENT',), ('def install_monitor ( self , mon ) : NEW_LINE INDENT assert self . binded NEW_LINE self . _curr_module . install_monitor ( mon ) NEW_LINE DEDENT',), (\"def get_rcnn_testbatch ( roidb , cfg ) : NEW_LINE INDENT imgs , roidb = get_image ( roidb , cfg ) NEW_LINE im_array = imgs NEW_LINE im_info = [ np . array ( [ roidb [ i ] [ ' im _ info ' ] ] , dtype = np . float32 ) for i in range ( len ( roidb ) ) ] NEW_LINE im_rois = [ roidb [ i ] [ ' boxes ' ] for i in range ( len ( roidb ) ) ] NEW_LINE rois = im_rois NEW_LINE rois_array = [ np . hstack ( ( 0 * np . ones ( ( rois [ i ] . shape [ 0 ] , 1 ) ) , rois [ i ] ) ) for i in range ( len ( rois ) ) ] NEW_LINE data = [ { ' data ' : im_array [ i ] , ' rois ' : rois_array [ i ] } for i in range ( len ( roidb ) ) ] NEW_LINE label = { } NEW_LINE return data , label , im_info NEW_LINE DEDENT\",), (\"def get_rcnn_batch ( roidb , cfg ) : NEW_LINE INDENT num_images = len ( roidb ) NEW_LINE imgs , roidb = get_image ( roidb , cfg ) NEW_LINE im_array = tensor_vstack ( imgs ) NEW_LINE assert cfg . TRAIN . BATCH_ROIS == - 1 or cfg . TRAIN . BATCH_ROIS % cfg . TRAIN . BATCH_IMAGES == 0 , ' BATCHIMAGES ▁ { } ▁ must ▁ divide ▁ BATCH _ ROIS ▁ { } ' . format ( cfg . TRAIN . BATCH_IMAGES , cfg . TRAIN . BATCH_ROIS ) NEW_LINE if cfg . TRAIN . BATCH_ROIS == - 1 : NEW_LINE INDENT rois_per_image = np . sum ( [ iroidb [ ' boxes ' ] . shape [ 0 ] for iroidb in roidb ] ) NEW_LINE fg_rois_per_image = rois_per_image NEW_LINE DEDENT else : NEW_LINE INDENT rois_per_image = cfg . TRAIN . BATCH_ROIS / cfg . TRAIN . BATCH_IMAGES NEW_LINE fg_rois_per_image = np . round ( cfg . TRAIN . FG_FRACTION * rois_per_image ) . astype ( int ) NEW_LINE DEDENT rois_array = list ( ) NEW_LINE labels_array = list ( ) NEW_LINE bbox_targets_array = list ( ) NEW_LINE bbox_weights_array = list ( ) NEW_LINE for im_i in range ( num_images ) : NEW_LINE INDENT roi_rec = roidb [ im_i ] NEW_LINE num_classes = roi_rec [ ' gt _ overlaps ' ] . shape [ 1 ] NEW_LINE rois = roi_rec [ ' boxes ' ] NEW_LINE labels = roi_rec [ ' max _ classes ' ] NEW_LINE overlaps = roi_rec [ ' max _ overlaps ' ] NEW_LINE bbox_targets = roi_rec [ ' bbox _ targets ' ] NEW_LINE im_rois , labels , bbox_targets , bbox_weights = sample_rois ( rois , fg_rois_per_image , rois_per_image , num_classes , cfg , labels , overlaps , bbox_targets ) NEW_LINE rois = im_rois NEW_LINE batch_index = im_i * np . ones ( ( rois . shape [ 0 ] , 1 ) ) NEW_LINE rois_array_this_image = np . hstack ( ( batch_index , rois ) ) NEW_LINE rois_array . append ( rois_array_this_image ) NEW_LINE labels_array . append ( labels ) NEW_LINE bbox_targets_array . append ( bbox_targets ) NEW_LINE bbox_weights_array . append ( bbox_weights ) NEW_LINE DEDENT rois_array = np . array ( rois_array ) NEW_LINE labels_array = np . array ( labels_array ) NEW_LINE bbox_targets_array = np . array ( bbox_targets_array ) NEW_LINE bbox_weights_array = np . array ( bbox_weights_array ) NEW_LINE data = { ' data ' : im_array , ' rois ' : rois_array } NEW_LINE label = { ' label ' : labels_array , ' bbox _ target ' : bbox_targets_array , ' bbox _ weight ' : bbox_weights_array } NEW_LINE return data , label NEW_LINE DEDENT\",), ('def sample_rois ( rois , fg_rois_per_image , rois_per_image , num_classes , cfg , labels = None , overlaps = None , bbox_targets = None , gt_boxes = None ) : NEW_LINE INDENT if labels is None : NEW_LINE INDENT overlaps = bbox_overlaps ( rois [ : , 1 : ] . astype ( np . float ) , gt_boxes [ : , : 4 ] . astype ( np . float ) ) NEW_LINE gt_assignment = overlaps . argmax ( axis = 1 ) NEW_LINE overlaps = overlaps . max ( axis = 1 ) NEW_LINE labels = gt_boxes [ gt_assignment , 4 ] NEW_LINE DEDENT fg_indexes = np . where ( overlaps >= cfg . TRAIN . FG_THRESH ) [ 0 ] NEW_LINE fg_rois_per_this_image = np . minimum ( fg_rois_per_image , fg_indexes . size ) NEW_LINE if len ( fg_indexes ) > fg_rois_per_this_image : NEW_LINE INDENT fg_indexes = npr . choice ( fg_indexes , size = fg_rois_per_this_image , replace = False ) NEW_LINE DEDENT bg_indexes = np . where ( ( overlaps < cfg . TRAIN . BG_THRESH_HI ) & ( overlaps >= cfg . TRAIN . BG_THRESH_LO ) ) [ 0 ] NEW_LINE bg_rois_per_this_image = rois_per_image - fg_rois_per_this_image NEW_LINE bg_rois_per_this_image = np . minimum ( bg_rois_per_this_image , bg_indexes . size ) NEW_LINE if len ( bg_indexes ) > bg_rois_per_this_image : NEW_LINE INDENT bg_indexes = npr . choice ( bg_indexes , size = bg_rois_per_this_image , replace = False ) NEW_LINE DEDENT keep_indexes = np . append ( fg_indexes , bg_indexes ) NEW_LINE while keep_indexes . shape [ 0 ] < rois_per_image : NEW_LINE INDENT gap = np . minimum ( len ( rois ) , rois_per_image - keep_indexes . shape [ 0 ] ) NEW_LINE gap_indexes = npr . choice ( range ( len ( rois ) ) , size = gap , replace = False ) NEW_LINE keep_indexes = np . append ( keep_indexes , gap_indexes ) NEW_LINE DEDENT labels = labels [ keep_indexes ] NEW_LINE labels [ fg_rois_per_this_image : ] = 0 NEW_LINE rois = rois [ keep_indexes ] NEW_LINE if bbox_targets is not None : NEW_LINE INDENT bbox_target_data = bbox_targets [ keep_indexes , : ] NEW_LINE DEDENT else : NEW_LINE INDENT targets = bbox_transform ( rois [ : , 1 : ] , gt_boxes [ gt_assignment [ keep_indexes ] , : 4 ] ) NEW_LINE if cfg . TRAIN . BBOX_NORMALIZATION_PRECOMPUTED : NEW_LINE INDENT targets = ( ( targets - np . array ( cfg . TRAIN . BBOX_MEANS ) ) / np . array ( cfg . TRAIN . BBOX_STDS ) ) NEW_LINE DEDENT bbox_target_data = np . hstack ( ( labels [ : , np . newaxis ] , targets ) ) NEW_LINE DEDENT bbox_targets , bbox_weights = expand_bbox_regression_targets ( bbox_target_data , num_classes , cfg ) NEW_LINE return rois , labels , bbox_targets , bbox_weights NEW_LINE DEDENT',), ('def sample_rotbox_rois ( rois , fg_rois_per_image , rois_per_image , num_classes , cfg , labels = None , overlaps = None , dbbox_targets = None , gt_boxes = None ) : NEW_LINE INDENT if labels is None : NEW_LINE INDENT hgt_boxes = bbox_poly2hbb ( gt_boxes ) NEW_LINE overlaps = bbox_overlaps ( rois [ : , 1 : ] . astype ( np . float ) , hgt_boxes [ : , : 4 ] . astype ( np . float ) ) NEW_LINE gt_assignment = overlaps . argmax ( axis = 1 ) NEW_LINE overlaps = overlaps . max ( axis = 1 ) NEW_LINE labels = hgt_boxes [ gt_assignment , 4 ] NEW_LINE DEDENT fg_indexes = np . where ( overlaps >= cfg . TRAIN . FG_THRESH ) [ 0 ] NEW_LINE fg_rois_per_this_image = np . minimum ( fg_rois_per_image , fg_indexes . size ) NEW_LINE if len ( fg_indexes ) > fg_rois_per_this_image : NEW_LINE INDENT fg_indexes = npr . choice ( fg_indexes , size = fg_rois_per_this_image , replace = False ) NEW_LINE DEDENT bg_indexes = np . where ( ( overlaps < cfg . TRAIN . BG_THRESH_HI ) & ( overlaps >= cfg . TRAIN . BG_THRESH_LO ) ) [ 0 ] NEW_LINE bg_rois_per_this_image = rois_per_image - fg_rois_per_this_image NEW_LINE bg_rois_per_this_image = np . minimum ( bg_rois_per_this_image , bg_indexes . size ) NEW_LINE if len ( bg_indexes ) > bg_rois_per_this_image : NEW_LINE INDENT bg_indexes = npr . choice ( bg_indexes , size = bg_rois_per_this_image , replace = False ) NEW_LINE DEDENT keep_indexes = np . append ( fg_indexes , bg_indexes ) NEW_LINE while keep_indexes . shape [ 0 ] < rois_per_image : NEW_LINE INDENT gap = np . minimum ( len ( rois ) , rois_per_image - keep_indexes . shape [ 0 ] ) NEW_LINE gap_indexes = npr . choice ( range ( len ( rois ) ) , size = gap , replace = False ) NEW_LINE keep_indexes = np . append ( keep_indexes , gap_indexes ) NEW_LINE DEDENT labels = labels [ keep_indexes ] NEW_LINE labels [ fg_rois_per_this_image : ] = 0 NEW_LINE rois = rois [ keep_indexes ] NEW_LINE if dbbox_targets is not None : NEW_LINE INDENT bbox_target_data = dbbox_targets [ keep_indexes , : ] NEW_LINE DEDENT else : NEW_LINE INDENT targets = dbbox_transform2_warp ( rois [ : , 1 : ] , gt_boxes [ gt_assignment [ keep_indexes ] , : 8 ] ) NEW_LINE if cfg . TRAIN . BBOX_NORMALIZATION_PRECOMPUTED : NEW_LINE INDENT targets = ( ( targets - np . array ( cfg . TRAIN . BBOX_MEANS ) ) / np . array ( cfg . TRAIN . BBOX_STDS ) ) NEW_LINE DEDENT bbox_target_data = np . hstack ( ( labels [ : , np . newaxis ] , targets ) ) NEW_LINE DEDENT bbox_targets , bbox_weights = expand_bbox_regression_targets_base ( bbox_target_data , num_classes , cfg ) NEW_LINE return rois , labels , bbox_targets , bbox_weights NEW_LINE DEDENT',), ('def sample_Rrois ( Rrois , fg_rois_per_image , rois_per_image , num_classes , cfg , labels = None , overlaps = None , dbbox_targets = None , gt_boxes = None , device_id = 0 ) : NEW_LINE INDENT if labels is None : NEW_LINE INDENT overlaps = poly_overlaps ( Rrois [ : , 1 : ] . astype ( np . float32 ) , gt_boxes [ : , : 5 ] . astype ( np . float32 ) , device_id ) NEW_LINE gt_assignment = overlaps . argmax ( axis = 1 ) NEW_LINE overlaps = overlaps . max ( axis = 1 ) NEW_LINE labels = gt_boxes [ gt_assignment , 5 ] NEW_LINE DEDENT fg_indexes = np . where ( overlaps >= cfg . TRAIN . RRoI_FG_THRESH ) [ 0 ] NEW_LINE fg_rois_per_this_image = np . minimum ( fg_rois_per_image , fg_indexes . size ) NEW_LINE if len ( fg_indexes ) > fg_rois_per_this_image : NEW_LINE INDENT fg_indexes = npr . choice ( fg_indexes , size = fg_rois_per_this_image , replace = False ) NEW_LINE DEDENT bg_indexes = np . where ( ( overlaps < cfg . TRAIN . BG_THRESH_HI ) & ( overlaps >= cfg . TRAIN . BG_THRESH_LO ) ) [ 0 ] NEW_LINE bg_rois_per_this_image = rois_per_image - fg_rois_per_this_image NEW_LINE bg_rois_per_this_image = np . minimum ( bg_rois_per_this_image , bg_indexes . size ) NEW_LINE if len ( bg_indexes ) > bg_rois_per_this_image : NEW_LINE INDENT bg_indexes = npr . choice ( bg_indexes , size = bg_rois_per_this_image , replace = False ) NEW_LINE DEDENT keep_indexes = np . append ( fg_indexes , bg_indexes ) NEW_LINE while keep_indexes . shape [ 0 ] < rois_per_image : NEW_LINE INDENT gap = np . minimum ( len ( Rrois ) , rois_per_image - keep_indexes . shape [ 0 ] ) NEW_LINE gap_indexes = npr . choice ( range ( len ( Rrois ) ) , size = gap , replace = False ) NEW_LINE keep_indexes = np . append ( keep_indexes , gap_indexes ) NEW_LINE DEDENT labels = labels [ keep_indexes ] NEW_LINE labels [ fg_rois_per_this_image : ] = 0 NEW_LINE Rrois = Rrois [ keep_indexes ] NEW_LINE if dbbox_targets is not None : NEW_LINE INDENT bbox_target_data = dbbox_targets [ keep_indexes , : ] NEW_LINE DEDENT else : NEW_LINE INDENT targets = dbbox_transform2_best_match_warp ( Rrois [ : , 1 : ] , gt_boxes [ gt_assignment [ keep_indexes ] , : 5 ] ) NEW_LINE if cfg . TRAIN . BBOX_NORMALIZATION_PRECOMPUTED : NEW_LINE INDENT targets = ( ( targets - np . array ( cfg . TRAIN . RRoI_BBOX_STDS ) ) / np . array ( cfg . TRAIN . RRoI_BBOX_STDS ) ) NEW_LINE DEDENT bbox_target_data = np . hstack ( ( labels [ : , np . newaxis ] , targets ) ) NEW_LINE DEDENT bbox_targets , bbox_weights = expand_bbox_regression_targets_base_new ( bbox_target_data , num_classes , cfg . network . RRoI_CLASS_AGNOSTIC ) NEW_LINE return Rrois , labels , bbox_targets , bbox_weights NEW_LINE DEDENT',), ('def py_cpu_nms_poly ( dets , thresh ) : NEW_LINE INDENT scores = dets [ : , 8 ] NEW_LINE polys = [ ] NEW_LINE areas = [ ] NEW_LINE for i in range ( len ( dets ) ) : NEW_LINE INDENT tm_polygon = polyiou . VectorDouble ( [ dets [ i ] [ 0 ] , dets [ i ] [ 1 ] , dets [ i ] [ 2 ] , dets [ i ] [ 3 ] , dets [ i ] [ 4 ] , dets [ i ] [ 5 ] , dets [ i ] [ 6 ] , dets [ i ] [ 7 ] ] ) NEW_LINE polys . append ( tm_polygon ) NEW_LINE DEDENT order = scores . argsort ( ) [ : : - 1 ] NEW_LINE keep = [ ] NEW_LINE while order . size > 0 : NEW_LINE INDENT ovr = [ ] NEW_LINE i = order [ 0 ] NEW_LINE keep . append ( i ) NEW_LINE for j in range ( order . size - 1 ) : NEW_LINE INDENT iou = polyiou . iou_poly ( polys [ i ] , polys [ order [ j + 1 ] ] ) NEW_LINE ovr . append ( iou ) NEW_LINE DEDENT ovr = np . array ( ovr ) NEW_LINE try : NEW_LINE INDENT if math . isnan ( ovr [ 0 ] ) : NEW_LINE INDENT pdb . set_trace ( ) NEW_LINE DEDENT DEDENT except : NEW_LINE INDENT pass NEW_LINE DEDENT inds = np . where ( ovr <= thresh ) [ 0 ] NEW_LINE order = order [ inds + 1 ] NEW_LINE DEDENT return keep NEW_LINE DEDENT',), ('def py_cpu_nms_poly_fast ( dets , thresh ) : NEW_LINE INDENT obbs = dets [ : , 0 : - 1 ] NEW_LINE x1 = np . min ( obbs [ : , 0 : : 2 ] , axis = 1 ) NEW_LINE y1 = np . min ( obbs [ : , 1 : : 2 ] , axis = 1 ) NEW_LINE x2 = np . max ( obbs [ : , 0 : : 2 ] , axis = 1 ) NEW_LINE y2 = np . max ( obbs [ : , 1 : : 2 ] , axis = 1 ) NEW_LINE scores = dets [ : , 8 ] NEW_LINE areas = ( x2 - x1 + 1 ) * ( y2 - y1 + 1 ) NEW_LINE polys = [ ] NEW_LINE for i in range ( len ( dets ) ) : NEW_LINE INDENT tm_polygon = polyiou . VectorDouble ( [ dets [ i ] [ 0 ] , dets [ i ] [ 1 ] , dets [ i ] [ 2 ] , dets [ i ] [ 3 ] , dets [ i ] [ 4 ] , dets [ i ] [ 5 ] , dets [ i ] [ 6 ] , dets [ i ] [ 7 ] ] ) NEW_LINE polys . append ( tm_polygon ) NEW_LINE DEDENT order = scores . argsort ( ) [ : : - 1 ] NEW_LINE keep = [ ] NEW_LINE while order . size > 0 : NEW_LINE INDENT ovr = [ ] NEW_LINE i = order [ 0 ] NEW_LINE keep . append ( i ) NEW_LINE xx1 = np . maximum ( x1 [ i ] , x1 [ order [ 1 : ] ] ) NEW_LINE yy1 = np . maximum ( y1 [ i ] , y1 [ order [ 1 : ] ] ) NEW_LINE xx2 = np . minimum ( x2 [ i ] , x2 [ order [ 1 : ] ] ) NEW_LINE yy2 = np . minimum ( y2 [ i ] , y2 [ order [ 1 : ] ] ) NEW_LINE w = np . maximum ( 0.0 , xx2 - xx1 ) NEW_LINE h = np . maximum ( 0.0 , yy2 - yy1 ) NEW_LINE hbb_inter = w * h NEW_LINE hbb_ovr = hbb_inter / ( areas [ i ] + areas [ order [ 1 : ] ] - hbb_inter ) NEW_LINE h_inds = np . where ( hbb_ovr > 0 ) [ 0 ] NEW_LINE tmp_order = order [ h_inds + 1 ] NEW_LINE for j in range ( tmp_order . size ) : NEW_LINE INDENT iou = polyiou . iou_poly ( polys [ i ] , polys [ tmp_order [ j ] ] ) NEW_LINE hbb_ovr [ h_inds [ j ] ] = iou NEW_LINE DEDENT try : NEW_LINE INDENT if math . isnan ( ovr [ 0 ] ) : NEW_LINE INDENT pdb . set_trace ( ) NEW_LINE DEDENT DEDENT except : NEW_LINE INDENT pass NEW_LINE DEDENT inds = np . where ( hbb_ovr <= thresh ) [ 0 ] NEW_LINE order = order [ inds + 1 ] NEW_LINE DEDENT return keep NEW_LINE DEDENT',), ('def py_cpu_nms ( dets , thresh ) : NEW_LINE INDENT x1 = dets [ : , 0 ] NEW_LINE y1 = dets [ : , 1 ] NEW_LINE x2 = dets [ : , 2 ] NEW_LINE y2 = dets [ : , 3 ] NEW_LINE scores = dets [ : , 4 ] NEW_LINE areas = ( x2 - x1 + 1 ) * ( y2 - y1 + 1 ) NEW_LINE order = scores . argsort ( ) [ : : - 1 ] NEW_LINE keep = [ ] NEW_LINE while order . size > 0 : NEW_LINE INDENT i = order [ 0 ] NEW_LINE keep . append ( i ) NEW_LINE xx1 = np . maximum ( x1 [ i ] , x1 [ order [ 1 : ] ] ) NEW_LINE yy1 = np . maximum ( y1 [ i ] , y1 [ order [ 1 : ] ] ) NEW_LINE xx2 = np . minimum ( x2 [ i ] , x2 [ order [ 1 : ] ] ) NEW_LINE yy2 = np . minimum ( y2 [ i ] , y2 [ order [ 1 : ] ] ) NEW_LINE w = np . maximum ( 0.0 , xx2 - xx1 + 1 ) NEW_LINE h = np . maximum ( 0.0 , yy2 - yy1 + 1 ) NEW_LINE inter = w * h NEW_LINE ovr = inter / ( areas [ i ] + areas [ order [ 1 : ] ] - inter ) NEW_LINE inds = np . where ( ovr <= thresh ) [ 0 ] NEW_LINE order = order [ inds + 1 ] NEW_LINE DEDENT return keep NEW_LINE DEDENT',), ('def nmsbynamedict ( nameboxdict , nms , thresh ) : NEW_LINE INDENT nameboxnmsdict = { x : [ ] for x in nameboxdict } NEW_LINE for imgname in nameboxdict : NEW_LINE INDENT keep = nms ( np . array ( nameboxdict [ imgname ] ) , thresh ) NEW_LINE outdets = [ ] NEW_LINE for index in keep : NEW_LINE INDENT outdets . append ( nameboxdict [ imgname ] [ index ] ) NEW_LINE DEDENT nameboxnmsdict [ imgname ] = outdets NEW_LINE DEDENT return nameboxnmsdict NEW_LINE DEDENT',), ('def poly2origpoly ( poly , x , y , rate ) : NEW_LINE INDENT origpoly = [ ] NEW_LINE for i in range ( int ( len ( poly ) / 2 ) ) : NEW_LINE INDENT tmp_x = float ( poly [ i * 2 ] + x ) / float ( rate ) NEW_LINE tmp_y = float ( poly [ i * 2 + 1 ] + y ) / float ( rate ) NEW_LINE origpoly . append ( tmp_x ) NEW_LINE origpoly . append ( tmp_y ) NEW_LINE DEDENT return origpoly NEW_LINE DEDENT',), (\"def mergesingle ( dstpath , nms , fullname ) : NEW_LINE INDENT name = util . custombasename ( fullname ) NEW_LINE dstname = os . path . join ( dstpath , name + ' . txt ' ) NEW_LINE with open ( fullname , ' r ' ) as f_in : NEW_LINE INDENT nameboxdict = { } NEW_LINE lines = f_in . readlines ( ) NEW_LINE splitlines = [ x . strip ( ) . split ( ' ▁ ' ) for x in lines ] NEW_LINE for splitline in splitlines : NEW_LINE INDENT subname = splitline [ 0 ] NEW_LINE splitname = subname . split ( ' _ _ ' ) NEW_LINE oriname = splitname [ 0 ] NEW_LINE pattern1 = re . compile ( r' _ _ \\\\d + _ _ _ \\\\d + ' ) NEW_LINE x_y = re . findall ( pattern1 , subname ) NEW_LINE x_y_2 = re . findall ( r' \\\\d + ' , x_y [ 0 ] ) NEW_LINE x , y = int ( x_y_2 [ 0 ] ) , int ( x_y_2 [ 1 ] ) NEW_LINE pattern2 = re . compile ( r' _ _ ( [ \\\\d + \\\\ . ] + ) _ _ \\\\d + _ _ _ ' ) NEW_LINE rate = re . findall ( pattern2 , subname ) [ 0 ] NEW_LINE confidence = splitline [ 1 ] NEW_LINE poly = list ( map ( float , splitline [ 2 : ] ) ) NEW_LINE origpoly = poly2origpoly ( poly , x , y , rate ) NEW_LINE det = origpoly NEW_LINE det . append ( confidence ) NEW_LINE det = list ( map ( float , det ) ) NEW_LINE if ( oriname not in nameboxdict ) : NEW_LINE INDENT nameboxdict [ oriname ] = [ ] NEW_LINE DEDENT nameboxdict [ oriname ] . append ( det ) NEW_LINE DEDENT nameboxnmsdict = nmsbynamedict ( nameboxdict , nms , nms_thresh ) NEW_LINE with open ( dstname , ' w ' ) as f_out : NEW_LINE INDENT for imgname in nameboxnmsdict : NEW_LINE INDENT for det in nameboxnmsdict [ imgname ] : NEW_LINE INDENT confidence = det [ - 1 ] NEW_LINE bbox = det [ 0 : - 1 ] NEW_LINE outline = imgname + ' ▁ ' + str ( confidence ) + ' ▁ ' + ' ▁ ' . join ( map ( str , bbox ) ) NEW_LINE f_out . write ( outline + ' \\\\n ' ) NEW_LINE DEDENT DEDENT DEDENT DEDENT DEDENT\",), ('def mergebase ( srcpath , dstpath , nms ) : NEW_LINE INDENT pool = Pool ( 32 ) NEW_LINE filelist = util . GetFileFromThisRootDir ( srcpath ) NEW_LINE mergesingle_fn = partial ( mergesingle , dstpath , nms ) NEW_LINE pool . map ( mergesingle_fn , filelist ) NEW_LINE DEDENT',), ('def mergebyrec ( srcpath , dstpath ) : NEW_LINE INDENT mergebase ( srcpath , dstpath , py_cpu_nms ) NEW_LINE DEDENT',), ('def mergebypoly ( srcpath , dstpath ) : NEW_LINE INDENT mergebase ( srcpath , dstpath , py_cpu_nms_poly_fast ) NEW_LINE DEDENT',), ('def py_cpu_nms_poly ( dets , thresh ) : NEW_LINE INDENT scores = dets [ : , 8 ] NEW_LINE polys = [ ] NEW_LINE areas = [ ] NEW_LINE for i in range ( len ( dets ) ) : NEW_LINE INDENT tm_polygon = polyiou . VectorDouble ( [ dets [ i ] [ 0 ] , dets [ i ] [ 1 ] , dets [ i ] [ 2 ] , dets [ i ] [ 3 ] , dets [ i ] [ 4 ] , dets [ i ] [ 5 ] , dets [ i ] [ 6 ] , dets [ i ] [ 7 ] ] ) NEW_LINE polys . append ( tm_polygon ) NEW_LINE DEDENT order = scores . argsort ( ) [ : : - 1 ] NEW_LINE keep = [ ] NEW_LINE while order . size > 0 : NEW_LINE INDENT ovr = [ ] NEW_LINE i = order [ 0 ] NEW_LINE keep . append ( i ) NEW_LINE for j in range ( order . size - 1 ) : NEW_LINE INDENT iou = polyiou . iou_poly ( polys [ i ] , polys [ order [ j + 1 ] ] ) NEW_LINE ovr . append ( iou ) NEW_LINE DEDENT ovr = np . array ( ovr ) NEW_LINE try : NEW_LINE INDENT if math . isnan ( ovr [ 0 ] ) : NEW_LINE INDENT pdb . set_trace ( ) NEW_LINE DEDENT DEDENT except : NEW_LINE INDENT pass NEW_LINE DEDENT inds = np . where ( ovr <= thresh ) [ 0 ] NEW_LINE order = order [ inds + 1 ] NEW_LINE DEDENT return keep NEW_LINE DEDENT',), ('def py_cpu_nms_poly_fast ( dets , thresh ) : NEW_LINE INDENT obbs = dets [ : , 0 : - 1 ] NEW_LINE x1 = np . min ( obbs [ : , 0 : : 2 ] , axis = 1 ) NEW_LINE y1 = np . min ( obbs [ : , 1 : : 2 ] , axis = 1 ) NEW_LINE x2 = np . max ( obbs [ : , 0 : : 2 ] , axis = 1 ) NEW_LINE y2 = np . max ( obbs [ : , 1 : : 2 ] , axis = 1 ) NEW_LINE scores = dets [ : , 8 ] NEW_LINE areas = ( x2 - x1 + 1 ) * ( y2 - y1 + 1 ) NEW_LINE polys = [ ] NEW_LINE for i in range ( len ( dets ) ) : NEW_LINE INDENT tm_polygon = polyiou . VectorDouble ( [ dets [ i ] [ 0 ] , dets [ i ] [ 1 ] , dets [ i ] [ 2 ] , dets [ i ] [ 3 ] , dets [ i ] [ 4 ] , dets [ i ] [ 5 ] , dets [ i ] [ 6 ] , dets [ i ] [ 7 ] ] ) NEW_LINE polys . append ( tm_polygon ) NEW_LINE DEDENT order = scores . argsort ( ) [ : : - 1 ] NEW_LINE keep = [ ] NEW_LINE while order . size > 0 : NEW_LINE INDENT ovr = [ ] NEW_LINE i = order [ 0 ] NEW_LINE keep . append ( i ) NEW_LINE xx1 = np . maximum ( x1 [ i ] , x1 [ order [ 1 : ] ] ) NEW_LINE yy1 = np . maximum ( y1 [ i ] , y1 [ order [ 1 : ] ] ) NEW_LINE xx2 = np . minimum ( x2 [ i ] , x2 [ order [ 1 : ] ] ) NEW_LINE yy2 = np . minimum ( y2 [ i ] , y2 [ order [ 1 : ] ] ) NEW_LINE w = np . maximum ( 0.0 , xx2 - xx1 ) NEW_LINE h = np . maximum ( 0.0 , yy2 - yy1 ) NEW_LINE hbb_inter = w * h NEW_LINE hbb_ovr = hbb_inter / ( areas [ i ] + areas [ order [ 1 : ] ] - hbb_inter ) NEW_LINE h_inds = np . where ( hbb_ovr > 0 ) [ 0 ] NEW_LINE tmp_order = order [ h_inds + 1 ] NEW_LINE for j in range ( tmp_order . size ) : NEW_LINE INDENT iou = polyiou . iou_poly ( polys [ i ] , polys [ tmp_order [ j ] ] ) NEW_LINE hbb_ovr [ h_inds [ j ] ] = iou NEW_LINE DEDENT try : NEW_LINE INDENT if math . isnan ( ovr [ 0 ] ) : NEW_LINE INDENT pdb . set_trace ( ) NEW_LINE DEDENT DEDENT except : NEW_LINE INDENT pass NEW_LINE DEDENT inds = np . where ( hbb_ovr <= thresh ) [ 0 ] NEW_LINE order = order [ inds + 1 ] NEW_LINE DEDENT return keep NEW_LINE DEDENT',), ('def py_cpu_nms ( dets , thresh ) : NEW_LINE INDENT x1 = dets [ : , 0 ] NEW_LINE y1 = dets [ : , 1 ] NEW_LINE x2 = dets [ : , 2 ] NEW_LINE y2 = dets [ : , 3 ] NEW_LINE scores = dets [ : , 4 ] NEW_LINE areas = ( x2 - x1 + 1 ) * ( y2 - y1 + 1 ) NEW_LINE order = scores . argsort ( ) [ : : - 1 ] NEW_LINE keep = [ ] NEW_LINE while order . size > 0 : NEW_LINE INDENT i = order [ 0 ] NEW_LINE keep . append ( i ) NEW_LINE xx1 = np . maximum ( x1 [ i ] , x1 [ order [ 1 : ] ] ) NEW_LINE yy1 = np . maximum ( y1 [ i ] , y1 [ order [ 1 : ] ] ) NEW_LINE xx2 = np . minimum ( x2 [ i ] , x2 [ order [ 1 : ] ] ) NEW_LINE yy2 = np . minimum ( y2 [ i ] , y2 [ order [ 1 : ] ] ) NEW_LINE w = np . maximum ( 0.0 , xx2 - xx1 + 1 ) NEW_LINE h = np . maximum ( 0.0 , yy2 - yy1 + 1 ) NEW_LINE inter = w * h NEW_LINE ovr = inter / ( areas [ i ] + areas [ order [ 1 : ] ] - inter ) NEW_LINE inds = np . where ( ovr <= thresh ) [ 0 ] NEW_LINE order = order [ inds + 1 ] NEW_LINE DEDENT return keep NEW_LINE DEDENT',), ('def nmsbynamedict ( nameboxdict , nms , thresh ) : NEW_LINE INDENT nameboxnmsdict = { x : [ ] for x in nameboxdict } NEW_LINE for imgname in nameboxdict : NEW_LINE INDENT keep = nms ( np . array ( nameboxdict [ imgname ] ) , thresh ) NEW_LINE outdets = [ ] NEW_LINE for index in keep : NEW_LINE INDENT outdets . append ( nameboxdict [ imgname ] [ index ] ) NEW_LINE DEDENT nameboxnmsdict [ imgname ] = outdets NEW_LINE DEDENT return nameboxnmsdict NEW_LINE DEDENT',), ('def poly2origpoly ( poly , x , y , rate ) : NEW_LINE INDENT origpoly = [ ] NEW_LINE for i in range ( int ( len ( poly ) / 2 ) ) : NEW_LINE INDENT tmp_x = float ( poly [ i * 2 ] + x ) / float ( rate ) NEW_LINE tmp_y = float ( poly [ i * 2 + 1 ] + y ) / float ( rate ) NEW_LINE origpoly . append ( tmp_x ) NEW_LINE origpoly . append ( tmp_y ) NEW_LINE DEDENT return origpoly NEW_LINE DEDENT',), (\"def mergebase ( srcpath , dstpath , nms ) : NEW_LINE INDENT filelist = util . GetFileFromThisRootDir ( srcpath ) NEW_LINE for fullname in filelist : NEW_LINE INDENT name = util . custombasename ( fullname ) NEW_LINE dstname = os . path . join ( dstpath , name + ' . txt ' ) NEW_LINE with open ( fullname , ' r ' ) as f_in : NEW_LINE INDENT nameboxdict = { } NEW_LINE lines = f_in . readlines ( ) NEW_LINE splitlines = [ x . strip ( ) . split ( ' ▁ ' ) for x in lines ] NEW_LINE for splitline in splitlines : NEW_LINE INDENT subname = splitline [ 0 ] NEW_LINE splitname = subname . split ( ' _ _ ' ) NEW_LINE oriname = splitname [ 0 ] NEW_LINE pattern1 = re . compile ( r' _ _ \\\\d + _ _ _ \\\\d + ' ) NEW_LINE x_y = re . findall ( pattern1 , subname ) NEW_LINE x_y_2 = re . findall ( r' \\\\d + ' , x_y [ 0 ] ) NEW_LINE x , y = int ( x_y_2 [ 0 ] ) , int ( x_y_2 [ 1 ] ) NEW_LINE pattern2 = re . compile ( r' _ _ ( [ \\\\d + \\\\ . ] + ) _ _ \\\\d + _ _ _ ' ) NEW_LINE rate = re . findall ( pattern2 , subname ) [ 0 ] NEW_LINE confidence = splitline [ 1 ] NEW_LINE poly = list ( map ( float , splitline [ 2 : ] ) ) NEW_LINE origpoly = poly2origpoly ( poly , x , y , rate ) NEW_LINE det = origpoly NEW_LINE det . append ( confidence ) NEW_LINE det = list ( map ( float , det ) ) NEW_LINE if ( oriname not in nameboxdict ) : NEW_LINE INDENT nameboxdict [ oriname ] = [ ] NEW_LINE DEDENT nameboxdict [ oriname ] . append ( det ) NEW_LINE DEDENT nameboxnmsdict = nmsbynamedict ( nameboxdict , nms , nms_thresh ) NEW_LINE with open ( dstname , ' w ' ) as f_out : NEW_LINE INDENT for imgname in nameboxnmsdict : NEW_LINE INDENT for det in nameboxnmsdict [ imgname ] : NEW_LINE INDENT confidence = det [ - 1 ] NEW_LINE bbox = det [ 0 : - 1 ] NEW_LINE outline = imgname + ' ▁ ' + str ( confidence ) + ' ▁ ' + ' ▁ ' . join ( map ( str , bbox ) ) NEW_LINE f_out . write ( outline + ' \\\\n ' ) NEW_LINE DEDENT DEDENT DEDENT DEDENT DEDENT DEDENT\",), ('def mergebyrec ( srcpath , dstpath ) : NEW_LINE INDENT mergebase ( srcpath , dstpath , py_cpu_nms ) NEW_LINE DEDENT',), ('def mergebypoly ( srcpath , dstpath ) : NEW_LINE INDENT mergebase ( srcpath , dstpath , py_cpu_nms_poly ) NEW_LINE DEDENT',), (\"def _isArrayLike ( obj ) : NEW_LINE INDENT if type ( obj ) == str : NEW_LINE INDENT return False NEW_LINE DEDENT return hasattr ( obj , ' _ _ iter _ _ ' ) and hasattr ( obj , ' _ _ len _ _ ' ) NEW_LINE DEDENT\",), (\"def __init__ ( self , basepath ) : NEW_LINE INDENT self . basepath = basepath NEW_LINE self . labelpath = os . path . join ( basepath , ' labelTxt ' ) NEW_LINE self . imagepath = os . path . join ( basepath , ' images ' ) NEW_LINE self . imgpaths = util . GetFileFromThisRootDir ( self . labelpath ) NEW_LINE self . imglist = [ util . custombasename ( x ) for x in self . imgpaths ] NEW_LINE self . catToImgs = defaultdict ( list ) NEW_LINE self . ImgToAnns = defaultdict ( list ) NEW_LINE self . createIndex ( ) NEW_LINE DEDENT\",), (\"def createIndex ( self ) : NEW_LINE INDENT for filename in self . imgpaths : NEW_LINE INDENT objects = util . parse_dota_poly ( filename ) NEW_LINE imgid = util . custombasename ( filename ) NEW_LINE self . ImgToAnns [ imgid ] = objects NEW_LINE for obj in objects : NEW_LINE INDENT cat = obj [ ' name ' ] NEW_LINE self . catToImgs [ cat ] . append ( imgid ) NEW_LINE DEDENT DEDENT DEDENT\",), ('def getImgIds ( self , catNms = [ ] ) : NEW_LINE INDENT catNms = catNms if _isArrayLike ( catNms ) else [ catNms ] NEW_LINE if len ( catNms ) == 0 : NEW_LINE INDENT return self . imglist NEW_LINE DEDENT else : NEW_LINE INDENT imgids = [ ] NEW_LINE for i , cat in enumerate ( catNms ) : NEW_LINE INDENT if i == 0 : NEW_LINE INDENT imgids = set ( self . catToImgs [ cat ] ) NEW_LINE DEDENT else : NEW_LINE INDENT imgids &= set ( self . catToImgs [ cat ] ) NEW_LINE DEDENT DEDENT DEDENT return list ( imgids ) NEW_LINE DEDENT',), (\"def loadAnns ( self , catNms = [ ] , imgId = None , difficult = None ) : NEW_LINE INDENT catNms = catNms if _isArrayLike ( catNms ) else [ catNms ] NEW_LINE objects = self . ImgToAnns [ imgId ] NEW_LINE if len ( catNms ) == 0 : NEW_LINE INDENT return objects NEW_LINE DEDENT pdb . set_trace ( ) NEW_LINE outobjects = [ obj for obj in objects if ( obj [ ' name ' ] in catNms ) ] NEW_LINE return outobjects NEW_LINE DEDENT\",), (\"def showAnns ( self , objects , imgId , range ) : NEW_LINE INDENT img = self . loadImgs ( imgId ) [ 0 ] NEW_LINE plt . imshow ( img ) NEW_LINE plt . axis ( ' off ' ) NEW_LINE ax = plt . gca ( ) NEW_LINE ax . set_autoscale_on ( False ) NEW_LINE polygons = [ ] NEW_LINE color = [ ] NEW_LINE circles = [ ] NEW_LINE r = 5 NEW_LINE for obj in objects : NEW_LINE INDENT if obj [ ' difficult ' ] != '0' : NEW_LINE INDENT continue NEW_LINE DEDENT c = ( np . random . random ( ( 1 , 3 ) ) * 0.6 + 0.4 ) . tolist ( ) [ 0 ] NEW_LINE poly = obj [ ' poly ' ] NEW_LINE import pdb NEW_LINE polygons . append ( Polygon ( poly ) ) NEW_LINE color . append ( c ) NEW_LINE point = poly [ 0 ] NEW_LINE circle = Circle ( ( point [ 0 ] , point [ 1 ] ) , r ) NEW_LINE circles . append ( circle ) NEW_LINE DEDENT p = PatchCollection ( polygons , facecolors = color , linewidths = 0 , alpha = 0.4 ) NEW_LINE ax . add_collection ( p ) NEW_LINE p = PatchCollection ( polygons , facecolors = ' none ' , edgecolors = color , linewidths = 2 ) NEW_LINE ax . add_collection ( p ) NEW_LINE p = PatchCollection ( circles , facecolors = ' red ' ) NEW_LINE ax . add_collection ( p ) NEW_LINE plt . show ( ) NEW_LINE DEDENT\",), (\"def loadImgs ( self , imgids = [ ] ) : NEW_LINE INDENT print ( ' isarralike : ' , _isArrayLike ( imgids ) ) NEW_LINE imgids = imgids if _isArrayLike ( imgids ) else [ imgids ] NEW_LINE print ( ' imgids : ' , imgids ) NEW_LINE imgs = [ ] NEW_LINE for imgid in imgids : NEW_LINE INDENT filename = os . path . join ( self . imagepath , imgid + ' . png ' ) NEW_LINE print ( ' filename : ' , filename ) NEW_LINE img = cv2 . imread ( filename ) NEW_LINE imgs . append ( img ) NEW_LINE DEDENT return imgs NEW_LINE DEDENT\",), (\"def parse_gt ( filename ) : NEW_LINE INDENT objects = [ ] NEW_LINE with open ( filename , ' r ' ) as f : NEW_LINE INDENT while True : NEW_LINE INDENT line = f . readline ( ) NEW_LINE if line : NEW_LINE INDENT splitlines = line . strip ( ) . split ( ' ▁ ' ) NEW_LINE object_struct = { } NEW_LINE if ( len ( splitlines ) < 9 ) : NEW_LINE INDENT continue NEW_LINE DEDENT object_struct [ ' name ' ] = splitlines [ 8 ] NEW_LINE if ( len ( splitlines ) == 9 ) : NEW_LINE INDENT object_struct [ ' difficult ' ] = 0 NEW_LINE DEDENT elif ( len ( splitlines ) == 10 ) : NEW_LINE INDENT object_struct [ ' difficult ' ] = int ( splitlines [ 9 ] ) NEW_LINE DEDENT object_struct [ ' bbox ' ] = [ float ( splitlines [ 0 ] ) , float ( splitlines [ 1 ] ) , float ( splitlines [ 2 ] ) , float ( splitlines [ 3 ] ) , float ( splitlines [ 4 ] ) , float ( splitlines [ 5 ] ) , float ( splitlines [ 6 ] ) , float ( splitlines [ 7 ] ) ] NEW_LINE objects . append ( object_struct ) NEW_LINE DEDENT else : NEW_LINE INDENT break NEW_LINE DEDENT DEDENT DEDENT return objects NEW_LINE DEDENT\",), ('def voc_ap ( rec , prec , use_07_metric = False ) : NEW_LINE INDENT if use_07_metric : NEW_LINE INDENT ap = 0. NEW_LINE for t in np . arange ( 0. , 1.1 , 0.1 ) : NEW_LINE INDENT if np . sum ( rec >= t ) == 0 : NEW_LINE INDENT p = 0 NEW_LINE DEDENT else : NEW_LINE INDENT p = np . max ( prec [ rec >= t ] ) NEW_LINE DEDENT ap = ap + p / 11. NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT mrec = np . concatenate ( ( [ 0. ] , rec , [ 1. ] ) ) NEW_LINE mpre = np . concatenate ( ( [ 0. ] , prec , [ 0. ] ) ) NEW_LINE for i in range ( mpre . size - 1 , 0 , - 1 ) : NEW_LINE INDENT mpre [ i - 1 ] = np . maximum ( mpre [ i - 1 ] , mpre [ i ] ) NEW_LINE DEDENT i = np . where ( mrec [ 1 : ] != mrec [ : - 1 ] ) [ 0 ] NEW_LINE ap = np . sum ( ( mrec [ i + 1 ] - mrec [ i ] ) * mpre [ i + 1 ] ) NEW_LINE DEDENT return ap NEW_LINE DEDENT',), (\"def voc_eval ( detpath , annopath , imagesetfile , classname , ovthresh = 0.5 , use_07_metric = False ) : NEW_LINE INDENT print ( ' eval ▁ ' + classname ) NEW_LINE with open ( imagesetfile , ' r ' ) as f : NEW_LINE INDENT lines = f . readlines ( ) NEW_LINE DEDENT imagenames = [ x . strip ( ) for x in lines ] NEW_LINE recs = { } NEW_LINE for i , imagename in enumerate ( imagenames ) : NEW_LINE INDENT recs [ imagename ] = parse_gt ( annopath . format ( imagename ) ) NEW_LINE DEDENT class_recs = { } NEW_LINE npos = 0 NEW_LINE for imagename in imagenames : NEW_LINE INDENT R = [ obj for obj in recs [ imagename ] if obj [ ' name ' ] == classname ] NEW_LINE bbox = np . array ( [ x [ ' bbox ' ] for x in R ] ) NEW_LINE difficult = np . array ( [ x [ ' difficult ' ] for x in R ] ) . astype ( np . bool ) NEW_LINE det = [ False ] * len ( R ) NEW_LINE npos = npos + sum ( ~ difficult ) NEW_LINE class_recs [ imagename ] = { ' bbox ' : bbox , ' difficult ' : difficult , ' det ' : det } NEW_LINE DEDENT detfile = detpath . format ( classname ) NEW_LINE with open ( detfile , ' r ' ) as f : NEW_LINE INDENT lines = f . readlines ( ) NEW_LINE DEDENT splitlines = [ x . strip ( ) . split ( ' ▁ ' ) for x in lines ] NEW_LINE image_ids = [ x [ 0 ] for x in splitlines ] NEW_LINE confidence = np . array ( [ float ( x [ 1 ] ) for x in splitlines ] ) NEW_LINE BB = np . array ( [ [ float ( z ) for z in x [ 2 : ] ] for x in splitlines ] ) NEW_LINE sorted_ind = np . argsort ( - confidence ) NEW_LINE sorted_scores = np . sort ( - confidence ) NEW_LINE BB = BB [ sorted_ind , : ] NEW_LINE image_ids = [ image_ids [ x ] for x in sorted_ind ] NEW_LINE nd = len ( image_ids ) NEW_LINE tp = np . zeros ( nd ) NEW_LINE fp = np . zeros ( nd ) NEW_LINE for d in range ( nd ) : NEW_LINE INDENT R = class_recs [ image_ids [ d ] ] NEW_LINE bb = BB [ d , : ] . astype ( float ) NEW_LINE ovmax = - np . inf NEW_LINE BBGT = R [ ' bbox ' ] . astype ( float ) NEW_LINE if BBGT . size > 0 : NEW_LINE INDENT def calcoverlaps ( BBGT , bb ) : NEW_LINE INDENT overlaps = [ ] NEW_LINE for index , GT in enumerate ( BBGT ) : NEW_LINE INDENT overlap = polyiou . iou_poly ( polyiou . VectorDouble ( BBGT [ index ] ) , polyiou . VectorDouble ( bb ) ) NEW_LINE overlaps . append ( overlap ) NEW_LINE DEDENT return overlaps NEW_LINE DEDENT overlaps = calcoverlaps ( BBGT , bb ) NEW_LINE ovmax = np . max ( overlaps ) NEW_LINE jmax = np . argmax ( overlaps ) NEW_LINE DEDENT if ovmax > ovthresh : NEW_LINE INDENT if not R [ ' difficult ' ] [ jmax ] : NEW_LINE INDENT if not R [ ' det ' ] [ jmax ] : NEW_LINE INDENT tp [ d ] = 1. NEW_LINE R [ ' det ' ] [ jmax ] = 1 NEW_LINE DEDENT else : NEW_LINE INDENT fp [ d ] = 1. NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT fp [ d ] = 1. NEW_LINE DEDENT DEDENT print ( ' check ▁ fp : ' , fp ) NEW_LINE print ( ' check ▁ tp ' , tp ) NEW_LINE print ( ' npos ▁ num : ' , npos ) NEW_LINE fp = np . cumsum ( fp ) NEW_LINE tp = np . cumsum ( tp ) NEW_LINE rec = tp / float ( npos ) NEW_LINE prec = tp / np . maximum ( tp + fp , np . finfo ( np . float64 ) . eps ) NEW_LINE ap = voc_ap ( rec , prec , use_07_metric ) NEW_LINE return rec , prec , ap NEW_LINE DEDENT\",), ('def single_voc_eval_warp ( detpath , annopath , imagesetfile , classname , ovthresh = 0.5 , use_07_metric = False ) : NEW_LINE INDENT rec , prec , ap = voc_eval ( detpath , annopath , imagesetfile , classname , ovthresh = ovthresh , use_07_metric = use_07_metric ) NEW_LINE return ap NEW_LINE DEDENT',), (\"def main ( ) : NEW_LINE INDENT detpath = r' PATH _ TO _ BE _ CONFIGURED / Task1 _ { : s } . txt ' NEW_LINE annopath = r' PATH _ TO _ BE _ CONFIGURED / { : s } . txt ' NEW_LINE imagesetfile = r' PATH _ TO _ BE _ CONFIGURED / valset . txt ' NEW_LINE classnames = [ ' plane ' , ' baseball - diamond ' , ' bridge ' , ' ground - track - field ' , ' small - vehicle ' , ' large - vehicle ' , ' ship ' , ' tennis - court ' , ' basketball - court ' , ' storage - tank ' , ' soccer - ball - field ' , ' roundabout ' , ' harbor ' , ' swimming - pool ' , ' helicopter ' ] NEW_LINE classaps = [ ] NEW_LINE map = 0 NEW_LINE for classname in classnames : NEW_LINE INDENT print ( ' classname : ' , classname ) NEW_LINE rec , prec , ap = voc_eval ( detpath , annopath , imagesetfile , classname , ovthresh = 0.5 , use_07_metric = True ) NEW_LINE map = map + ap NEW_LINE print ( ' ap : ▁ ' , ap ) NEW_LINE classaps . append ( ap ) NEW_LINE DEDENT map = map / len ( classnames ) NEW_LINE print ( ' map : ' , map ) NEW_LINE classaps = 100 * np . array ( classaps ) NEW_LINE print ( ' classaps : ▁ ' , classaps ) NEW_LINE DEDENT\",), (\"def eval_DOTA_Task1 ( detpath , annopath , imagesetfile ) : NEW_LINE INDENT classnames = [ ' plane ' , ' baseball - diamond ' , ' bridge ' , ' ground - track - field ' , ' small - vehicle ' , ' large - vehicle ' , ' ship ' , ' tennis - court ' , ' basketball - court ' , ' storage - tank ' , ' soccer - ball - field ' , ' roundabout ' , ' harbor ' , ' swimming - pool ' , ' helicopter ' ] NEW_LINE classaps = [ ] NEW_LINE map = 0 NEW_LINE for classname in classnames : NEW_LINE INDENT print ( ' classname : ' , classname ) NEW_LINE rec , prec , ap = voc_eval ( detpath , annopath , imagesetfile , classname , ovthresh = 0.5 , use_07_metric = True ) NEW_LINE map = map + ap NEW_LINE print ( ' ap : ▁ ' , ap ) NEW_LINE classaps . append ( ap ) NEW_LINE DEDENT map = map / len ( classnames ) NEW_LINE print ( ' map : ' , map ) NEW_LINE classaps = 100 * np . array ( classaps ) NEW_LINE print ( ' classaps : ▁ ' , classaps ) NEW_LINE return map , classaps NEW_LINE DEDENT\",), (\"def eval_HRSC_L1 ( detpath , annopath , imagesetfile ) : NEW_LINE INDENT classnames = [ ' ship ' ] NEW_LINE classaps = [ ] NEW_LINE map = 0 NEW_LINE for classname in classnames : NEW_LINE INDENT print ( ' classname : ' , classname ) NEW_LINE rec , prec , ap = voc_eval ( detpath , annopath , imagesetfile , classname , ovthresh = 0.5 , use_07_metric = True ) NEW_LINE map = map + ap NEW_LINE print ( ' ap : ▁ ' , ap ) NEW_LINE classaps . append ( ap ) NEW_LINE DEDENT map = map / len ( classnames ) NEW_LINE print ( ' map : ' , map ) NEW_LINE classaps = 100 * np . array ( classaps ) NEW_LINE print ( ' classaps : ▁ ' , classaps ) NEW_LINE return map , classaps NEW_LINE DEDENT\",), (\"def eval_vehicle ( detpath , annopath , imagesetfile ) : NEW_LINE INDENT classnames = [ ' vehicle ' ] NEW_LINE classaps = [ ] NEW_LINE map = 0 NEW_LINE for classname in classnames : NEW_LINE INDENT print ( ' classname : ' , classname ) NEW_LINE rec , prec , ap = voc_eval ( detpath , annopath , imagesetfile , classname , ovthresh = 0.5 , use_07_metric = True ) NEW_LINE map = map + ap NEW_LINE print ( ' ap : ▁ ' , ap ) NEW_LINE classaps . append ( ap ) NEW_LINE DEDENT map = map / len ( classnames ) NEW_LINE print ( ' map : ' , map ) NEW_LINE classaps = 100 * np . array ( classaps ) NEW_LINE print ( ' classaps : ▁ ' , classaps ) NEW_LINE return map , classaps NEW_LINE DEDENT\",), (\"def eval_DOTA_Task1_multi_process ( detpath , annopath , imagesetfile ) : NEW_LINE INDENT classnames = [ ' plane ' , ' baseball - diamond ' , ' bridge ' , ' ground - track - field ' , ' small - vehicle ' , ' large - vehicle ' , ' ship ' , ' tennis - court ' , ' basketball - court ' , ' storage - tank ' , ' soccer - ball - field ' , ' roundabout ' , ' harbor ' , ' swimming - pool ' , ' helicopter ' ] NEW_LINE pool = Pool ( 80 ) NEW_LINE classaps = [ ] NEW_LINE mAP = 0 NEW_LINE eval_fn = partial ( single_voc_eval_warp , detpath , annopath , imagesetfile , ovthresh = 0.5 , use_07_metric = True ) NEW_LINE aps = pool . map ( eval_fn , classnames ) NEW_LINE for i in range ( len ( classnames ) ) : NEW_LINE INDENT print ( ' classname : ' , classnames [ i ] ) NEW_LINE mAP = mAP + aps [ i ] NEW_LINE print ( ' ap : ▁ ' , aps [ i ] ) NEW_LINE DEDENT mAP = mAP / len ( classnames ) NEW_LINE print ( ' map : ' , mAP ) NEW_LINE classaps = 100 * np . array ( aps ) NEW_LINE print ( ' classaps : ▁ ' , classaps ) NEW_LINE return mAP , classaps NEW_LINE DEDENT\",), ('def custombasename ( fullname ) : NEW_LINE INDENT return os . path . basename ( os . path . splitext ( fullname ) [ 0 ] ) NEW_LINE DEDENT',), ('def GetFileFromThisRootDir ( dir , ext = None ) : NEW_LINE INDENT allfiles = [ ] NEW_LINE needExtFilter = ( ext != None ) NEW_LINE for root , dirs , files in os . walk ( dir ) : NEW_LINE INDENT for filespath in files : NEW_LINE INDENT filepath = os . path . join ( root , filespath ) NEW_LINE extension = os . path . splitext ( filepath ) [ 1 ] [ 1 : ] NEW_LINE if needExtFilter and extension in ext : NEW_LINE INDENT allfiles . append ( filepath ) NEW_LINE DEDENT elif not needExtFilter : NEW_LINE INDENT allfiles . append ( filepath ) NEW_LINE DEDENT DEDENT DEDENT return allfiles NEW_LINE DEDENT',), ('def TuplePoly2Poly ( poly ) : NEW_LINE INDENT outpoly = [ poly [ 0 ] [ 0 ] , poly [ 0 ] [ 1 ] , poly [ 1 ] [ 0 ] , poly [ 1 ] [ 1 ] , poly [ 2 ] [ 0 ] , poly [ 2 ] [ 1 ] , poly [ 3 ] [ 0 ] , poly [ 3 ] [ 1 ] ] NEW_LINE return outpoly NEW_LINE DEDENT',), (\"def parse_dota_poly ( filename ) : NEW_LINE INDENT objects = [ ] NEW_LINE f = [ ] NEW_LINE if ( sys . version_info >= ( 3 , 5 ) ) : NEW_LINE INDENT fd = open ( filename , ' r ' ) NEW_LINE f = fd NEW_LINE DEDENT elif ( sys . version_info >= 2.7 ) : NEW_LINE INDENT fd = codecs . open ( filename , ' r ' ) NEW_LINE f = fd NEW_LINE DEDENT while True : NEW_LINE INDENT line = f . readline ( ) NEW_LINE if line : NEW_LINE INDENT splitlines = line . strip ( ) . split ( ' ▁ ' ) NEW_LINE object_struct = { } NEW_LINE if ( len ( splitlines ) < 9 ) : NEW_LINE INDENT continue NEW_LINE DEDENT if ( len ( splitlines ) >= 9 ) : NEW_LINE INDENT object_struct [ ' name ' ] = splitlines [ 8 ] NEW_LINE DEDENT if ( len ( splitlines ) == 9 ) : NEW_LINE INDENT object_struct [ ' difficult ' ] = '0' NEW_LINE DEDENT elif ( len ( splitlines ) >= 10 ) : NEW_LINE INDENT object_struct [ ' difficult ' ] = splitlines [ 9 ] NEW_LINE DEDENT object_struct [ ' poly ' ] = [ ( float ( splitlines [ 0 ] ) , float ( splitlines [ 1 ] ) ) , ( float ( splitlines [ 2 ] ) , float ( splitlines [ 3 ] ) ) , ( float ( splitlines [ 4 ] ) , float ( splitlines [ 5 ] ) ) , ( float ( splitlines [ 6 ] ) , float ( splitlines [ 7 ] ) ) ] NEW_LINE gtpoly = shgeo . Polygon ( object_struct [ ' poly ' ] ) NEW_LINE object_struct [ ' area ' ] = gtpoly . area NEW_LINE objects . append ( object_struct ) NEW_LINE DEDENT else : NEW_LINE INDENT break NEW_LINE DEDENT DEDENT return objects NEW_LINE DEDENT\",), (\"def parse_dota_poly2 ( filename ) : NEW_LINE INDENT objects = parse_dota_poly ( filename ) NEW_LINE for obj in objects : NEW_LINE INDENT obj [ ' poly ' ] = TuplePoly2Poly ( obj [ ' poly ' ] ) NEW_LINE obj [ ' poly ' ] = list ( map ( int , obj [ ' poly ' ] ) ) NEW_LINE DEDENT return objects NEW_LINE DEDENT\",), (\"def parse_dota_rec ( filename ) : NEW_LINE INDENT objects = parse_dota_poly ( filename ) NEW_LINE for obj in objects : NEW_LINE INDENT poly = obj [ ' poly ' ] NEW_LINE bbox = dots4ToRec4 ( poly ) NEW_LINE obj [ ' bndbox ' ] = bbox NEW_LINE DEDENT return objects NEW_LINE DEDENT\",), ('def dots4ToRec4 ( poly ) : NEW_LINE INDENT xmin , xmax , ymin , ymax = min ( poly [ 0 ] [ 0 ] , min ( poly [ 1 ] [ 0 ] , min ( poly [ 2 ] [ 0 ] , poly [ 3 ] [ 0 ] ) ) ) , max ( poly [ 0 ] [ 0 ] , max ( poly [ 1 ] [ 0 ] , max ( poly [ 2 ] [ 0 ] , poly [ 3 ] [ 0 ] ) ) ) , min ( poly [ 0 ] [ 1 ] , min ( poly [ 1 ] [ 1 ] , min ( poly [ 2 ] [ 1 ] , poly [ 3 ] [ 1 ] ) ) ) , max ( poly [ 0 ] [ 1 ] , max ( poly [ 1 ] [ 1 ] , max ( poly [ 2 ] [ 1 ] , poly [ 3 ] [ 1 ] ) ) ) NEW_LINE return xmin , ymin , xmax , ymax NEW_LINE DEDENT',), ('def dots4ToRec8 ( poly ) : NEW_LINE INDENT xmin , ymin , xmax , ymax = dots4ToRec4 ( poly ) NEW_LINE return xmin , ymin , xmax , ymin , xmax , ymax , xmin , ymax NEW_LINE DEDENT',), ('def dots2ToRec8 ( rec ) : NEW_LINE INDENT xmin , ymin , xmax , ymax = rec [ 0 ] , rec [ 1 ] , rec [ 2 ] , rec [ 3 ] NEW_LINE return xmin , ymin , xmax , ymin , xmax , ymax , xmin , ymax NEW_LINE DEDENT',), (\"def groundtruth2Task1 ( srcpath , dstpath ) : NEW_LINE INDENT filelist = GetFileFromThisRootDir ( srcpath ) NEW_LINE filedict = { } NEW_LINE for cls in wordname_15 : NEW_LINE INDENT fd = open ( os . path . join ( dstpath , ' Task1 _ ' ) + cls + r' . txt ' , ' w ' ) NEW_LINE filedict [ cls ] = fd NEW_LINE DEDENT for filepath in filelist : NEW_LINE INDENT objects = parse_dota_poly2 ( filepath ) NEW_LINE subname = custombasename ( filepath ) NEW_LINE pattern2 = re . compile ( r' _ _ ( [ \\\\d + \\\\ . ] + ) _ _ \\\\d + _ _ _ ' ) NEW_LINE rate = re . findall ( pattern2 , subname ) [ 0 ] NEW_LINE for obj in objects : NEW_LINE INDENT category = obj [ ' name ' ] NEW_LINE difficult = obj [ ' difficult ' ] NEW_LINE poly = obj [ ' poly ' ] NEW_LINE if difficult == '2' : NEW_LINE INDENT continue NEW_LINE DEDENT if rate == '0.5' : NEW_LINE INDENT outline = custombasename ( filepath ) + ' ▁ ' + '1' + ' ▁ ' + ' ▁ ' . join ( map ( str , poly ) ) NEW_LINE DEDENT elif rate == '1' : NEW_LINE INDENT outline = custombasename ( filepath ) + ' ▁ ' + '0.8' + ' ▁ ' + ' ▁ ' . join ( map ( str , poly ) ) NEW_LINE DEDENT elif rate == '2' : NEW_LINE INDENT outline = custombasename ( filepath ) + ' ▁ ' + '0.6' + ' ▁ ' + ' ▁ ' . join ( map ( str , poly ) ) NEW_LINE DEDENT filedict [ category ] . write ( outline + ' \\\\n ' ) NEW_LINE DEDENT DEDENT DEDENT\",), (\"def Task2groundtruth_poly ( srcpath , dstpath ) : NEW_LINE INDENT thresh = 0.1 NEW_LINE filedict = { } NEW_LINE Tasklist = GetFileFromThisRootDir ( srcpath , ' . txt ' ) NEW_LINE for Taskfile in Tasklist : NEW_LINE INDENT idname = custombasename ( Taskfile ) . split ( ' _ ' ) [ - 1 ] NEW_LINE f = open ( Taskfile , ' r ' ) NEW_LINE lines = f . readlines ( ) NEW_LINE for line in lines : NEW_LINE INDENT if len ( line ) == 0 : NEW_LINE INDENT continue NEW_LINE DEDENT splitline = line . strip ( ) . split ( ' ▁ ' ) NEW_LINE filename = splitline [ 0 ] NEW_LINE confidence = splitline [ 1 ] NEW_LINE bbox = splitline [ 2 : ] NEW_LINE if float ( confidence ) > thresh : NEW_LINE INDENT if filename not in filedict : NEW_LINE INDENT filedict [ filename ] = codecs . open ( os . path . join ( dstpath , filename + ' . txt ' ) , ' w ' ) NEW_LINE DEDENT poly = bbox NEW_LINE DEDENT filedict [ filename ] . write ( ' ▁ ' . join ( poly ) + ' ▁ ' + idname + ' \\\\n ' ) NEW_LINE DEDENT DEDENT DEDENT\",), (\"def polygonToRotRectangle ( bbox ) : NEW_LINE INDENT bbox = np . array ( bbox , dtype = np . float32 ) NEW_LINE bbox = np . reshape ( bbox , newshape = ( 2 , 4 ) , order = ' F ' ) NEW_LINE angle = math . atan2 ( - ( bbox [ 0 , 1 ] - bbox [ 0 , 0 ] ) , bbox [ 1 , 1 ] - bbox [ 1 , 0 ] ) NEW_LINE center = [ [ 0 ] , [ 0 ] ] NEW_LINE for i in range ( 4 ) : NEW_LINE INDENT center [ 0 ] += bbox [ 0 , i ] NEW_LINE center [ 1 ] += bbox [ 1 , i ] NEW_LINE DEDENT center = np . array ( center , dtype = np . float32 ) / 4.0 NEW_LINE R = np . array ( [ [ math . cos ( angle ) , - math . sin ( angle ) ] , [ math . sin ( angle ) , math . cos ( angle ) ] ] , dtype = np . float32 ) NEW_LINE normalized = np . matmul ( R . transpose ( ) , bbox - center ) NEW_LINE xmin = np . min ( normalized [ 0 , : ] ) NEW_LINE xmax = np . max ( normalized [ 0 , : ] ) NEW_LINE ymin = np . min ( normalized [ 1 , : ] ) NEW_LINE ymax = np . max ( normalized [ 1 , : ] ) NEW_LINE w = xmax - xmin + 1 NEW_LINE h = ymax - ymin + 1 NEW_LINE return [ float ( center [ 0 ] ) , float ( center [ 1 ] ) , w , h , angle ] NEW_LINE DEDENT\",), (\"def __init__ ( self , srcpath , dstpath , gap = 512 , subsize = 1024 , ext = ' . png ' ) : NEW_LINE INDENT self . gap = gap NEW_LINE self . subsize = subsize NEW_LINE self . slide = self . subsize - self . gap NEW_LINE self . srcpath = srcpath NEW_LINE self . dstpath = dstpath NEW_LINE self . ext = ext NEW_LINE DEDENT\",), (\"def saveimagepatches ( self , img , subimgname , left , up , ext = ' . png ' ) : NEW_LINE INDENT subimg = copy . deepcopy ( img [ up : ( up + self . subsize ) , left : ( left + self . subsize ) ] ) NEW_LINE outdir = os . path . join ( self . dstpath , subimgname + ext ) NEW_LINE cv2 . imwrite ( outdir , subimg ) NEW_LINE DEDENT\",), (\"def SplitSingle ( self , name , rate , extent ) : NEW_LINE INDENT img = cv2 . imread ( os . path . join ( self . srcpath , name + extent ) ) NEW_LINE assert np . shape ( img ) != ( ) NEW_LINE if ( rate != 1 ) : NEW_LINE INDENT resizeimg = cv2 . resize ( img , None , fx = rate , fy = rate , interpolation = cv2 . INTER_CUBIC ) NEW_LINE DEDENT else : NEW_LINE INDENT resizeimg = img NEW_LINE DEDENT outbasename = name + ' _ _ ' + str ( rate ) + ' _ _ ' NEW_LINE weight = np . shape ( resizeimg ) [ 1 ] NEW_LINE height = np . shape ( resizeimg ) [ 0 ] NEW_LINE left , up = 0 , 0 NEW_LINE while ( left < weight ) : NEW_LINE INDENT if ( left + self . subsize >= weight ) : NEW_LINE INDENT left = max ( weight - self . subsize , 0 ) NEW_LINE DEDENT up = 0 NEW_LINE while ( up < height ) : NEW_LINE INDENT if ( up + self . subsize >= height ) : NEW_LINE INDENT up = max ( height - self . subsize , 0 ) NEW_LINE DEDENT subimgname = outbasename + str ( left ) + ' _ _ _ ' + str ( up ) NEW_LINE self . saveimagepatches ( resizeimg , subimgname , left , up ) NEW_LINE if ( up + self . subsize >= height ) : NEW_LINE INDENT break NEW_LINE DEDENT else : NEW_LINE INDENT up = up + self . slide NEW_LINE DEDENT DEDENT if ( left + self . subsize >= weight ) : NEW_LINE INDENT break NEW_LINE DEDENT else : NEW_LINE INDENT left = left + self . slide NEW_LINE DEDENT DEDENT DEDENT\",), (\"def splitdata ( self , rate ) : NEW_LINE INDENT imagelist = util . GetFileFromThisRootDir ( self . srcpath ) NEW_LINE imagenames = [ util . custombasename ( x ) for x in imagelist if ( util . custombasename ( x ) != ' Thumbs ' ) ] NEW_LINE for name in imagenames : NEW_LINE INDENT self . SplitSingle ( name , rate , self . ext ) NEW_LINE DEDENT DEDENT\",), (\"def swig_import_helper ( ) : NEW_LINE INDENT from os . path import dirname NEW_LINE import imp NEW_LINE fp = None NEW_LINE try : NEW_LINE INDENT fp , pathname , description = imp . find_module ( ' _ polyiou ' , [ dirname ( __file__ ) ] ) NEW_LINE DEDENT except ImportError : NEW_LINE INDENT import _polyiou NEW_LINE return _polyiou NEW_LINE DEDENT if fp is not None : NEW_LINE INDENT try : NEW_LINE INDENT _mod = imp . load_module ( ' _ polyiou ' , fp , pathname , description ) NEW_LINE DEDENT finally : NEW_LINE INDENT fp . close ( ) NEW_LINE DEDENT return _mod NEW_LINE DEDENT DEDENT\",), ('def iou_poly ( p , q ) : NEW_LINE INDENT return _polyiou . iou_poly ( p , q ) NEW_LINE DEDENT',), ('def _swig_setattr_nondynamic ( self , class_type , name , value , static = 1 ) : NEW_LINE INDENT if ( name == \" thisown \" ) : NEW_LINE INDENT return self . this . own ( value ) NEW_LINE DEDENT if ( name == \" this \" ) : NEW_LINE INDENT if type ( value ) . __name__ == \\' SwigPyObject \\' : NEW_LINE INDENT self . __dict__ [ name ] = value NEW_LINE return NEW_LINE DEDENT DEDENT method = class_type . __swig_setmethods__ . get ( name , None ) NEW_LINE if method : NEW_LINE INDENT return method ( self , value ) NEW_LINE DEDENT if ( not static ) : NEW_LINE INDENT if _newclass : NEW_LINE INDENT object . __setattr__ ( self , name , value ) NEW_LINE DEDENT else : NEW_LINE INDENT self . __dict__ [ name ] = value NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT raise AttributeError ( \" You ▁ cannot ▁ add ▁ attributes ▁ to ▁ % s \" % self ) NEW_LINE DEDENT DEDENT',), ('def _swig_setattr ( self , class_type , name , value ) : NEW_LINE INDENT return _swig_setattr_nondynamic ( self , class_type , name , value , 0 ) NEW_LINE DEDENT',), ('def _swig_getattr_nondynamic ( self , class_type , name , static = 1 ) : NEW_LINE INDENT if ( name == \" thisown \" ) : NEW_LINE INDENT return self . this . own ( ) NEW_LINE DEDENT method = class_type . __swig_getmethods__ . get ( name , None ) NEW_LINE if method : NEW_LINE INDENT return method ( self ) NEW_LINE DEDENT if ( not static ) : NEW_LINE INDENT return object . __getattr__ ( self , name ) NEW_LINE DEDENT else : NEW_LINE INDENT raise AttributeError ( name ) NEW_LINE DEDENT DEDENT',), ('def _swig_getattr ( self , class_type , name ) : NEW_LINE INDENT return _swig_getattr_nondynamic ( self , class_type , name , 0 ) NEW_LINE DEDENT',), ('def _swig_repr ( self ) : NEW_LINE INDENT try : NEW_LINE INDENT strthis = \" proxy ▁ of ▁ \" + self . this . __repr__ ( ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT strthis = \" \" NEW_LINE DEDENT return \" < % s . % s ; ▁ % s ▁ > \" % ( self . __class__ . __module__ , self . __class__ . __name__ , strthis , ) NEW_LINE DEDENT',), ('def __init__ ( self , * args , ** kwargs ) : NEW_LINE INDENT raise AttributeError ( \" No ▁ constructor ▁ defined ▁ - ▁ class ▁ is ▁ abstract \" ) NEW_LINE DEDENT',), ('def value ( self ) : NEW_LINE INDENT return _polyiou . SwigPyIterator_value ( self ) NEW_LINE DEDENT',), ('def incr ( self , n = 1 ) : NEW_LINE INDENT return _polyiou . SwigPyIterator_incr ( self , n ) NEW_LINE DEDENT',), ('def decr ( self , n = 1 ) : NEW_LINE INDENT return _polyiou . SwigPyIterator_decr ( self , n ) NEW_LINE DEDENT',), ('def distance ( self , x ) : NEW_LINE INDENT return _polyiou . SwigPyIterator_distance ( self , x ) NEW_LINE DEDENT',), ('def equal ( self , x ) : NEW_LINE INDENT return _polyiou . SwigPyIterator_equal ( self , x ) NEW_LINE DEDENT',), ('def copy ( self ) : NEW_LINE INDENT return _polyiou . SwigPyIterator_copy ( self ) NEW_LINE DEDENT',), ('def next ( self ) : NEW_LINE INDENT return _polyiou . SwigPyIterator_next ( self ) NEW_LINE DEDENT',), ('def __next__ ( self ) : NEW_LINE INDENT return _polyiou . SwigPyIterator___next__ ( self ) NEW_LINE DEDENT',), ('def previous ( self ) : NEW_LINE INDENT return _polyiou . SwigPyIterator_previous ( self ) NEW_LINE DEDENT',), ('def advance ( self , n ) : NEW_LINE INDENT return _polyiou . SwigPyIterator_advance ( self , n ) NEW_LINE DEDENT',), ('def __eq__ ( self , x ) : NEW_LINE INDENT return _polyiou . SwigPyIterator___eq__ ( self , x ) NEW_LINE DEDENT',), ('def __ne__ ( self , x ) : NEW_LINE INDENT return _polyiou . SwigPyIterator___ne__ ( self , x ) NEW_LINE DEDENT',), ('def __iadd__ ( self , n ) : NEW_LINE INDENT return _polyiou . SwigPyIterator___iadd__ ( self , n ) NEW_LINE DEDENT',), ('def __isub__ ( self , n ) : NEW_LINE INDENT return _polyiou . SwigPyIterator___isub__ ( self , n ) NEW_LINE DEDENT',), ('def __add__ ( self , n ) : NEW_LINE INDENT return _polyiou . SwigPyIterator___add__ ( self , n ) NEW_LINE DEDENT',), ('def __sub__ ( self , * args ) : NEW_LINE INDENT return _polyiou . SwigPyIterator___sub__ ( self , * args ) NEW_LINE DEDENT',), ('def __iter__ ( self ) : NEW_LINE INDENT return self NEW_LINE DEDENT',), ('def iterator ( self ) : NEW_LINE INDENT return _polyiou . VectorDouble_iterator ( self ) NEW_LINE DEDENT',), ('def __iter__ ( self ) : NEW_LINE INDENT return self . iterator ( ) NEW_LINE DEDENT',), ('def __nonzero__ ( self ) : NEW_LINE INDENT return _polyiou . VectorDouble___nonzero__ ( self ) NEW_LINE DEDENT',), ('def __bool__ ( self ) : NEW_LINE INDENT return _polyiou . VectorDouble___bool__ ( self ) NEW_LINE DEDENT',), ('def __len__ ( self ) : NEW_LINE INDENT return _polyiou . VectorDouble___len__ ( self ) NEW_LINE DEDENT',), ('def __getslice__ ( self , i , j ) : NEW_LINE INDENT return _polyiou . VectorDouble___getslice__ ( self , i , j ) NEW_LINE DEDENT',), ('def __setslice__ ( self , * args ) : NEW_LINE INDENT return _polyiou . VectorDouble___setslice__ ( self , * args ) NEW_LINE DEDENT',), ('def __delslice__ ( self , i , j ) : NEW_LINE INDENT return _polyiou . VectorDouble___delslice__ ( self , i , j ) NEW_LINE DEDENT',), ('def __delitem__ ( self , * args ) : NEW_LINE INDENT return _polyiou . VectorDouble___delitem__ ( self , * args ) NEW_LINE DEDENT',), ('def __getitem__ ( self , * args ) : NEW_LINE INDENT return _polyiou . VectorDouble___getitem__ ( self , * args ) NEW_LINE DEDENT',), ('def __setitem__ ( self , * args ) : NEW_LINE INDENT return _polyiou . VectorDouble___setitem__ ( self , * args ) NEW_LINE DEDENT',), ('def pop ( self ) : NEW_LINE INDENT return _polyiou . VectorDouble_pop ( self ) NEW_LINE DEDENT',), ('def append ( self , x ) : NEW_LINE INDENT return _polyiou . VectorDouble_append ( self , x ) NEW_LINE DEDENT',), ('def empty ( self ) : NEW_LINE INDENT return _polyiou . VectorDouble_empty ( self ) NEW_LINE DEDENT',), ('def size ( self ) : NEW_LINE INDENT return _polyiou . VectorDouble_size ( self ) NEW_LINE DEDENT',), ('def swap ( self , v ) : NEW_LINE INDENT return _polyiou . VectorDouble_swap ( self , v ) NEW_LINE DEDENT',), ('def begin ( self ) : NEW_LINE INDENT return _polyiou . VectorDouble_begin ( self ) NEW_LINE DEDENT',), ('def end ( self ) : NEW_LINE INDENT return _polyiou . VectorDouble_end ( self ) NEW_LINE DEDENT',), ('def rbegin ( self ) : NEW_LINE INDENT return _polyiou . VectorDouble_rbegin ( self ) NEW_LINE DEDENT',), ('def rend ( self ) : NEW_LINE INDENT return _polyiou . VectorDouble_rend ( self ) NEW_LINE DEDENT',), ('def clear ( self ) : NEW_LINE INDENT return _polyiou . VectorDouble_clear ( self ) NEW_LINE DEDENT',), ('def get_allocator ( self ) : NEW_LINE INDENT return _polyiou . VectorDouble_get_allocator ( self ) NEW_LINE DEDENT',), ('def pop_back ( self ) : NEW_LINE INDENT return _polyiou . VectorDouble_pop_back ( self ) NEW_LINE DEDENT',), ('def erase ( self , * args ) : NEW_LINE INDENT return _polyiou . VectorDouble_erase ( self , * args ) NEW_LINE DEDENT',), ('def __init__ ( self , * args ) : NEW_LINE INDENT this = _polyiou . new_VectorDouble ( * args ) NEW_LINE try : NEW_LINE INDENT self . this . append ( this ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT self . this = this NEW_LINE DEDENT DEDENT',), ('def push_back ( self , x ) : NEW_LINE INDENT return _polyiou . VectorDouble_push_back ( self , x ) NEW_LINE DEDENT',), ('def front ( self ) : NEW_LINE INDENT return _polyiou . VectorDouble_front ( self ) NEW_LINE DEDENT',), ('def back ( self ) : NEW_LINE INDENT return _polyiou . VectorDouble_back ( self ) NEW_LINE DEDENT',), ('def assign ( self , n , x ) : NEW_LINE INDENT return _polyiou . VectorDouble_assign ( self , n , x ) NEW_LINE DEDENT',), ('def resize ( self , * args ) : NEW_LINE INDENT return _polyiou . VectorDouble_resize ( self , * args ) NEW_LINE DEDENT',), ('def insert ( self , * args ) : NEW_LINE INDENT return _polyiou . VectorDouble_insert ( self , * args ) NEW_LINE DEDENT',), ('def reserve ( self , n ) : NEW_LINE INDENT return _polyiou . VectorDouble_reserve ( self , n ) NEW_LINE DEDENT',), ('def capacity ( self ) : NEW_LINE INDENT return _polyiou . VectorDouble_capacity ( self ) NEW_LINE DEDENT',), ('def choose_best_pointorder_fit_another ( poly1 , poly2 ) : NEW_LINE INDENT x1 = poly1 [ 0 ] NEW_LINE y1 = poly1 [ 1 ] NEW_LINE x2 = poly1 [ 2 ] NEW_LINE y2 = poly1 [ 3 ] NEW_LINE x3 = poly1 [ 4 ] NEW_LINE y3 = poly1 [ 5 ] NEW_LINE x4 = poly1 [ 6 ] NEW_LINE y4 = poly1 [ 7 ] NEW_LINE combinate = [ np . array ( [ x1 , y1 , x2 , y2 , x3 , y3 , x4 , y4 ] ) , np . array ( [ x2 , y2 , x3 , y3 , x4 , y4 , x1 , y1 ] ) , np . array ( [ x3 , y3 , x4 , y4 , x1 , y1 , x2 , y2 ] ) , np . array ( [ x4 , y4 , x1 , y1 , x2 , y2 , x3 , y3 ] ) ] NEW_LINE dst_coordinate = np . array ( poly2 ) NEW_LINE distances = np . array ( [ np . sum ( ( coord - dst_coordinate ) ** 2 ) for coord in combinate ] ) NEW_LINE sorted = distances . argsort ( ) NEW_LINE return combinate [ sorted [ 0 ] ] NEW_LINE DEDENT',), ('def cal_line_length ( point1 , point2 ) : NEW_LINE INDENT return math . sqrt ( math . pow ( point1 [ 0 ] - point2 [ 0 ] , 2 ) + math . pow ( point1 [ 1 ] - point2 [ 1 ] , 2 ) ) NEW_LINE DEDENT',), (\"def __init__ ( self , basepath , outpath , code = ' utf - 8' , gap = 512 , subsize = 1024 , thresh = 0.7 , choosebestpoint = True , ext = ' . png ' , padding = True ) : NEW_LINE INDENT self . basepath = basepath NEW_LINE self . outpath = outpath NEW_LINE self . code = code NEW_LINE self . gap = gap NEW_LINE self . subsize = subsize NEW_LINE self . slide = self . subsize - self . gap NEW_LINE self . thresh = thresh NEW_LINE self . imagepath = os . path . join ( self . basepath , ' images ' ) NEW_LINE self . labelpath = os . path . join ( self . basepath , ' labelTxt ' ) NEW_LINE self . outimagepath = os . path . join ( self . outpath , ' images ' ) NEW_LINE self . outlabelpath = os . path . join ( self . outpath , ' labelTxt ' ) NEW_LINE self . choosebestpoint = choosebestpoint NEW_LINE self . ext = ext NEW_LINE self . padding = padding NEW_LINE print ( ' padding : ' , padding ) NEW_LINE if not os . path . isdir ( self . outpath ) : NEW_LINE INDENT os . mkdir ( self . outpath ) NEW_LINE DEDENT if not os . path . isdir ( self . outimagepath ) : NEW_LINE INDENT os . mkdir ( self . outimagepath ) NEW_LINE DEDENT if not os . path . isdir ( self . outlabelpath ) : NEW_LINE INDENT os . mkdir ( self . outlabelpath ) NEW_LINE DEDENT DEDENT\",), ('def polyorig2sub ( self , left , up , poly ) : NEW_LINE INDENT polyInsub = np . zeros ( len ( poly ) ) NEW_LINE for i in range ( int ( len ( poly ) / 2 ) ) : NEW_LINE INDENT polyInsub [ i * 2 ] = int ( poly [ i * 2 ] - left ) NEW_LINE polyInsub [ i * 2 + 1 ] = int ( poly [ i * 2 + 1 ] - up ) NEW_LINE DEDENT return polyInsub NEW_LINE DEDENT',), ('def calchalf_iou ( self , poly1 , poly2 ) : NEW_LINE INDENT inter_poly = poly1 . intersection ( poly2 ) NEW_LINE inter_area = inter_poly . area NEW_LINE poly1_area = poly1 . area NEW_LINE half_iou = inter_area / poly1_area NEW_LINE return inter_poly , half_iou NEW_LINE DEDENT',), ('def saveimagepatches ( self , img , subimgname , left , up ) : NEW_LINE INDENT subimg = copy . deepcopy ( img [ up : ( up + self . subsize ) , left : ( left + self . subsize ) ] ) NEW_LINE outdir = os . path . join ( self . outimagepath , subimgname + self . ext ) NEW_LINE h , w , c = np . shape ( subimg ) NEW_LINE if ( self . padding ) : NEW_LINE INDENT outimg = np . zeros ( ( self . subsize , self . subsize , 3 ) ) NEW_LINE outimg [ 0 : h , 0 : w , : ] = subimg NEW_LINE cv2 . imwrite ( outdir , outimg ) NEW_LINE DEDENT else : NEW_LINE INDENT cv2 . imwrite ( outdir , subimg ) NEW_LINE DEDENT DEDENT',), ('def GetPoly4FromPoly5 ( self , poly ) : NEW_LINE INDENT distances = [ cal_line_length ( ( poly [ i * 2 ] , poly [ i * 2 + 1 ] ) , ( poly [ ( i + 1 ) * 2 ] , poly [ ( i + 1 ) * 2 + 1 ] ) ) for i in range ( int ( len ( poly ) / 2 - 1 ) ) ] NEW_LINE distances . append ( cal_line_length ( ( poly [ 0 ] , poly [ 1 ] ) , ( poly [ 8 ] , poly [ 9 ] ) ) ) NEW_LINE pos = np . array ( distances ) . argsort ( ) [ 0 ] NEW_LINE count = 0 NEW_LINE outpoly = [ ] NEW_LINE while count < 5 : NEW_LINE INDENT if ( count == pos ) : NEW_LINE INDENT outpoly . append ( ( poly [ count * 2 ] + poly [ ( count * 2 + 2 ) % 10 ] ) / 2 ) NEW_LINE outpoly . append ( ( poly [ ( count * 2 + 1 ) % 10 ] + poly [ ( count * 2 + 3 ) % 10 ] ) / 2 ) NEW_LINE count = count + 1 NEW_LINE DEDENT elif ( count == ( pos + 1 ) % 5 ) : NEW_LINE INDENT count = count + 1 NEW_LINE continue NEW_LINE DEDENT else : NEW_LINE INDENT outpoly . append ( poly [ count * 2 ] ) NEW_LINE outpoly . append ( poly [ count * 2 + 1 ] ) NEW_LINE count = count + 1 NEW_LINE DEDENT DEDENT return outpoly NEW_LINE DEDENT',), (\"def savepatches ( self , resizeimg , objects , subimgname , left , up , right , down ) : NEW_LINE INDENT outdir = os . path . join ( self . outlabelpath , subimgname + ' . txt ' ) NEW_LINE mask_poly = [ ] NEW_LINE imgpoly = shgeo . Polygon ( [ ( left , up ) , ( right , up ) , ( right , down ) , ( left , down ) ] ) NEW_LINE with codecs . open ( outdir , ' w ' , self . code ) as f_out : NEW_LINE INDENT for obj in objects : NEW_LINE INDENT gtpoly = shgeo . Polygon ( [ ( obj [ ' poly ' ] [ 0 ] , obj [ ' poly ' ] [ 1 ] ) , ( obj [ ' poly ' ] [ 2 ] , obj [ ' poly ' ] [ 3 ] ) , ( obj [ ' poly ' ] [ 4 ] , obj [ ' poly ' ] [ 5 ] ) , ( obj [ ' poly ' ] [ 6 ] , obj [ ' poly ' ] [ 7 ] ) ] ) NEW_LINE if ( gtpoly . area <= 0 ) : NEW_LINE INDENT continue NEW_LINE DEDENT inter_poly , half_iou = self . calchalf_iou ( gtpoly , imgpoly ) NEW_LINE if ( half_iou == 1 ) : NEW_LINE INDENT polyInsub = self . polyorig2sub ( left , up , obj [ ' poly ' ] ) NEW_LINE outline = ' ▁ ' . join ( list ( map ( str , polyInsub ) ) ) NEW_LINE outline = outline + ' ▁ ' + obj [ ' name ' ] + ' ▁ ' + str ( obj [ ' difficult ' ] ) NEW_LINE f_out . write ( outline + ' \\\\n ' ) NEW_LINE DEDENT elif ( half_iou > 0 ) : NEW_LINE INDENT inter_poly = shgeo . polygon . orient ( inter_poly , sign = 1 ) NEW_LINE out_poly = list ( inter_poly . exterior . coords ) [ 0 : - 1 ] NEW_LINE if len ( out_poly ) < 4 : NEW_LINE INDENT continue NEW_LINE DEDENT out_poly2 = [ ] NEW_LINE for i in range ( len ( out_poly ) ) : NEW_LINE INDENT out_poly2 . append ( out_poly [ i ] [ 0 ] ) NEW_LINE out_poly2 . append ( out_poly [ i ] [ 1 ] ) NEW_LINE DEDENT if ( len ( out_poly ) == 5 ) : NEW_LINE INDENT out_poly2 = self . GetPoly4FromPoly5 ( out_poly2 ) NEW_LINE DEDENT elif ( len ( out_poly ) > 5 ) : NEW_LINE INDENT continue NEW_LINE DEDENT if ( self . choosebestpoint ) : NEW_LINE INDENT out_poly2 = choose_best_pointorder_fit_another ( out_poly2 , obj [ ' poly ' ] ) NEW_LINE DEDENT polyInsub = self . polyorig2sub ( left , up , out_poly2 ) NEW_LINE for index , item in enumerate ( polyInsub ) : NEW_LINE INDENT if ( item <= 1 ) : NEW_LINE INDENT polyInsub [ index ] = 1 NEW_LINE DEDENT elif ( item >= self . subsize ) : NEW_LINE INDENT polyInsub [ index ] = self . subsize NEW_LINE DEDENT DEDENT outline = ' ▁ ' . join ( list ( map ( str , polyInsub ) ) ) NEW_LINE if ( half_iou > self . thresh ) : NEW_LINE INDENT outline = outline + ' ▁ ' + obj [ ' name ' ] + ' ▁ ' + str ( obj [ ' difficult ' ] ) NEW_LINE DEDENT else : NEW_LINE INDENT outline = outline + ' ▁ ' + obj [ ' name ' ] + ' ▁ ' + '2' NEW_LINE DEDENT f_out . write ( outline + ' \\\\n ' ) NEW_LINE DEDENT DEDENT DEDENT self . saveimagepatches ( resizeimg , subimgname , left , up ) NEW_LINE DEDENT\",), (\"def SplitSingle ( self , name , rate , extent ) : NEW_LINE INDENT img = cv2 . imread ( os . path . join ( self . imagepath , name + extent ) ) NEW_LINE if np . shape ( img ) == ( ) : NEW_LINE INDENT return NEW_LINE DEDENT fullname = os . path . join ( self . labelpath , name + ' . txt ' ) NEW_LINE objects = util . parse_dota_poly2 ( fullname ) NEW_LINE for obj in objects : NEW_LINE INDENT obj [ ' poly ' ] = list ( map ( lambda x : rate * x , obj [ ' poly ' ] ) ) NEW_LINE DEDENT if ( rate != 1 ) : NEW_LINE INDENT resizeimg = cv2 . resize ( img , None , fx = rate , fy = rate , interpolation = cv2 . INTER_CUBIC ) NEW_LINE DEDENT else : NEW_LINE INDENT resizeimg = img NEW_LINE DEDENT outbasename = name + ' _ _ ' + str ( rate ) + ' _ _ ' NEW_LINE weight = np . shape ( resizeimg ) [ 1 ] NEW_LINE height = np . shape ( resizeimg ) [ 0 ] NEW_LINE left , up = 0 , 0 NEW_LINE while ( left < weight ) : NEW_LINE INDENT if ( left + self . subsize >= weight ) : NEW_LINE INDENT left = max ( weight - self . subsize , 0 ) NEW_LINE DEDENT up = 0 NEW_LINE while ( up < height ) : NEW_LINE INDENT if ( up + self . subsize >= height ) : NEW_LINE INDENT up = max ( height - self . subsize , 0 ) NEW_LINE DEDENT right = min ( left + self . subsize , weight - 1 ) NEW_LINE down = min ( up + self . subsize , height - 1 ) NEW_LINE subimgname = outbasename + str ( left ) + ' _ _ _ ' + str ( up ) NEW_LINE self . savepatches ( resizeimg , objects , subimgname , left , up , right , down ) NEW_LINE if ( up + self . subsize >= height ) : NEW_LINE INDENT break NEW_LINE DEDENT else : NEW_LINE INDENT up = up + self . slide NEW_LINE DEDENT DEDENT if ( left + self . subsize >= weight ) : NEW_LINE INDENT break NEW_LINE DEDENT else : NEW_LINE INDENT left = left + self . slide NEW_LINE DEDENT DEDENT DEDENT\",), (\"def splitdata ( self , rate ) : NEW_LINE INDENT imagelist = GetFileFromThisRootDir ( self . imagepath ) NEW_LINE imagenames = [ util . custombasename ( x ) for x in imagelist if ( util . custombasename ( x ) != ' Thumbs ' ) ] NEW_LINE for name in imagenames : NEW_LINE INDENT self . SplitSingle ( name , rate , self . ext ) NEW_LINE DEDENT DEDENT\",), (\"def parse_gt ( filename ) : NEW_LINE INDENT objects = [ ] NEW_LINE with open ( filename , ' r ' ) as f : NEW_LINE INDENT lines = f . readlines ( ) NEW_LINE splitlines = [ x . strip ( ) . split ( ' ▁ ' ) for x in lines ] NEW_LINE for splitline in splitlines : NEW_LINE INDENT object_struct = { } NEW_LINE object_struct [ ' name ' ] = splitline [ 8 ] NEW_LINE if ( len ( splitline ) == 9 ) : NEW_LINE INDENT object_struct [ ' difficult ' ] = 0 NEW_LINE DEDENT elif ( len ( splitline ) == 10 ) : NEW_LINE INDENT object_struct [ ' difficult ' ] = int ( splitline [ 9 ] ) NEW_LINE DEDENT object_struct [ ' bbox ' ] = [ int ( float ( splitline [ 0 ] ) ) , int ( float ( splitline [ 1 ] ) ) , int ( float ( splitline [ 4 ] ) ) , int ( float ( splitline [ 5 ] ) ) ] NEW_LINE w = int ( float ( splitline [ 4 ] ) ) - int ( float ( splitline [ 0 ] ) ) NEW_LINE h = int ( float ( splitline [ 5 ] ) ) - int ( float ( splitline [ 1 ] ) ) NEW_LINE object_struct [ ' area ' ] = w * h NEW_LINE objects . append ( object_struct ) NEW_LINE DEDENT DEDENT return objects NEW_LINE DEDENT\",), ('def voc_ap ( rec , prec , use_07_metric = False ) : NEW_LINE INDENT if use_07_metric : NEW_LINE INDENT ap = 0. NEW_LINE for t in np . arange ( 0. , 1.1 , 0.1 ) : NEW_LINE INDENT if np . sum ( rec >= t ) == 0 : NEW_LINE INDENT p = 0 NEW_LINE DEDENT else : NEW_LINE INDENT p = np . max ( prec [ rec >= t ] ) NEW_LINE DEDENT ap = ap + p / 11. NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT mrec = np . concatenate ( ( [ 0. ] , rec , [ 1. ] ) ) NEW_LINE mpre = np . concatenate ( ( [ 0. ] , prec , [ 0. ] ) ) NEW_LINE for i in range ( mpre . size - 1 , 0 , - 1 ) : NEW_LINE INDENT mpre [ i - 1 ] = np . maximum ( mpre [ i - 1 ] , mpre [ i ] ) NEW_LINE DEDENT i = np . where ( mrec [ 1 : ] != mrec [ : - 1 ] ) [ 0 ] NEW_LINE ap = np . sum ( ( mrec [ i + 1 ] - mrec [ i ] ) * mpre [ i + 1 ] ) NEW_LINE DEDENT return ap NEW_LINE DEDENT',), (\"def voc_eval ( detpath , annopath , imagesetfile , classname , ovthresh = 0.5 , use_07_metric = False ) : NEW_LINE INDENT with open ( imagesetfile , ' r ' ) as f : NEW_LINE INDENT lines = f . readlines ( ) NEW_LINE DEDENT imagenames = [ x . strip ( ) for x in lines ] NEW_LINE recs = { } NEW_LINE for i , imagename in enumerate ( imagenames ) : NEW_LINE INDENT recs [ imagename ] = parse_gt ( annopath . format ( imagename ) ) NEW_LINE DEDENT class_recs = { } NEW_LINE npos = 0 NEW_LINE for imagename in imagenames : NEW_LINE INDENT R = [ obj for obj in recs [ imagename ] if obj [ ' name ' ] == classname ] NEW_LINE bbox = np . array ( [ x [ ' bbox ' ] for x in R ] ) NEW_LINE difficult = np . array ( [ x [ ' difficult ' ] for x in R ] ) . astype ( np . bool ) NEW_LINE det = [ False ] * len ( R ) NEW_LINE npos = npos + sum ( ~ difficult ) NEW_LINE class_recs [ imagename ] = { ' bbox ' : bbox , ' difficult ' : difficult , ' det ' : det } NEW_LINE DEDENT detfile = detpath . format ( classname ) NEW_LINE with open ( detfile , ' r ' ) as f : NEW_LINE INDENT lines = f . readlines ( ) NEW_LINE DEDENT splitlines = [ x . strip ( ) . split ( ' ▁ ' ) for x in lines ] NEW_LINE image_ids = [ x [ 0 ] for x in splitlines ] NEW_LINE confidence = np . array ( [ float ( x [ 1 ] ) for x in splitlines ] ) NEW_LINE BB = np . array ( [ [ float ( z ) for z in x [ 2 : ] ] for x in splitlines ] ) NEW_LINE sorted_ind = np . argsort ( - confidence ) NEW_LINE sorted_scores = np . sort ( - confidence ) NEW_LINE BB = BB [ sorted_ind , : ] NEW_LINE image_ids = [ image_ids [ x ] for x in sorted_ind ] NEW_LINE nd = len ( image_ids ) NEW_LINE tp = np . zeros ( nd ) NEW_LINE fp = np . zeros ( nd ) NEW_LINE for d in range ( nd ) : NEW_LINE INDENT R = class_recs [ image_ids [ d ] ] NEW_LINE bb = BB [ d , : ] . astype ( float ) NEW_LINE ovmax = - np . inf NEW_LINE BBGT = R [ ' bbox ' ] . astype ( float ) NEW_LINE if BBGT . size > 0 : NEW_LINE INDENT ixmin = np . maximum ( BBGT [ : , 0 ] , bb [ 0 ] ) NEW_LINE iymin = np . maximum ( BBGT [ : , 1 ] , bb [ 1 ] ) NEW_LINE ixmax = np . minimum ( BBGT [ : , 2 ] , bb [ 2 ] ) NEW_LINE iymax = np . minimum ( BBGT [ : , 3 ] , bb [ 3 ] ) NEW_LINE iw = np . maximum ( ixmax - ixmin + 1. , 0. ) NEW_LINE ih = np . maximum ( iymax - iymin + 1. , 0. ) NEW_LINE inters = iw * ih NEW_LINE uni = ( ( bb [ 2 ] - bb [ 0 ] + 1. ) * ( bb [ 3 ] - bb [ 1 ] + 1. ) + ( BBGT [ : , 2 ] - BBGT [ : , 0 ] + 1. ) * ( BBGT [ : , 3 ] - BBGT [ : , 1 ] + 1. ) - inters ) NEW_LINE overlaps = inters / uni NEW_LINE ovmax = np . max ( overlaps ) NEW_LINE jmax = np . argmax ( overlaps ) NEW_LINE DEDENT if ovmax > ovthresh : NEW_LINE INDENT if not R [ ' difficult ' ] [ jmax ] : NEW_LINE INDENT if not R [ ' det ' ] [ jmax ] : NEW_LINE INDENT tp [ d ] = 1. NEW_LINE R [ ' det ' ] [ jmax ] = 1 NEW_LINE DEDENT else : NEW_LINE INDENT fp [ d ] = 1. NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT fp [ d ] = 1. NEW_LINE DEDENT DEDENT print ( ' check ▁ fp : ' , fp ) NEW_LINE print ( ' check ▁ tp ' , tp ) NEW_LINE print ( ' npos ▁ num : ' , npos ) NEW_LINE fp = np . cumsum ( fp ) NEW_LINE tp = np . cumsum ( tp ) NEW_LINE rec = tp / float ( npos ) NEW_LINE prec = tp / np . maximum ( tp + fp , np . finfo ( np . float64 ) . eps ) NEW_LINE ap = voc_ap ( rec , prec , use_07_metric ) NEW_LINE return rec , prec , ap NEW_LINE DEDENT\",), (\"def main ( ) : NEW_LINE INDENT detpath = r' PATH _ TO _ BE _ CONFIGURED / Task1 _ { : s } . txt ' NEW_LINE annopath = r' PATH _ TO _ BE _ CONFIGURED / { : s } . txt ' NEW_LINE imagesetfile = r' PATH _ TO _ BE _ CONFIGURED / valset . txt ' NEW_LINE classnames = [ ' plane ' , ' baseball - diamond ' , ' bridge ' , ' ground - track - field ' , ' small - vehicle ' , ' large - vehicle ' , ' ship ' , ' tennis - court ' , ' basketball - court ' , ' storage - tank ' , ' soccer - ball - field ' , ' roundabout ' , ' harbor ' , ' swimming - pool ' , ' helicopter ' ] NEW_LINE classaps = [ ] NEW_LINE map = 0 NEW_LINE for classname in classnames : NEW_LINE INDENT print ( ' classname : ' , classname ) NEW_LINE rec , prec , ap = voc_eval ( detpath , annopath , imagesetfile , classname , ovthresh = 0.5 , use_07_metric = True ) NEW_LINE map = map + ap NEW_LINE print ( ' ap : ▁ ' , ap ) NEW_LINE classaps . append ( ap ) NEW_LINE DEDENT map = map / len ( classnames ) NEW_LINE print ( ' map : ' , map ) NEW_LINE classaps = 100 * np . array ( classaps ) NEW_LINE print ( ' classaps : ▁ ' , classaps ) NEW_LINE DEDENT\",), ('def poly_gpu_nms_wrapper ( thresh , device_id ) : NEW_LINE INDENT def _nms ( dets ) : NEW_LINE INDENT return poly_gpu_nms ( dets , thresh , device_id ) NEW_LINE DEDENT return _nms NEW_LINE DEDENT',), ('def poly_overlaps_nms_wrapper ( device_id ) : NEW_LINE INDENT def _overlaps ( boxes , query_boxes ) : NEW_LINE INDENT return poly_overlaps ( boxes , query_boxes , device_id ) NEW_LINE DEDENT return _overlaps NEW_LINE DEDENT',), ('def poly_nms_gpu ( dets , thresh , force_cpu = False ) : NEW_LINE INDENT if dets . shape [ 0 ] == 0 : NEW_LINE INDENT return [ ] NEW_LINE DEDENT return poly_gpu_nms ( dets , thresh , device_id = 0 ) NEW_LINE DEDENT',), ('def find_in_path ( name , path ) : NEW_LINE INDENT for dir in path . split ( os . pathsep ) : NEW_LINE INDENT binpath = pjoin ( dir , name ) NEW_LINE if os . path . exists ( binpath ) : NEW_LINE INDENT return os . path . abspath ( binpath ) NEW_LINE DEDENT DEDENT return None NEW_LINE DEDENT',), (\"def customize_compiler_for_nvcc ( self ) : NEW_LINE INDENT self . src_extensions . append ( ' . cu ' ) NEW_LINE default_compiler_so = self . compiler_so NEW_LINE super = self . _compile NEW_LINE def _compile ( obj , src , ext , cc_args , extra_postargs , pp_opts ) : NEW_LINE INDENT if os . path . splitext ( src ) [ 1 ] == ' . cu ' : NEW_LINE INDENT self . set_executable ( ' compiler _ so ' , CUDA [ ' nvcc ' ] ) NEW_LINE postargs = extra_postargs [ ' nvcc ' ] NEW_LINE DEDENT else : NEW_LINE INDENT postargs = extra_postargs [ ' gcc ' ] NEW_LINE DEDENT super ( obj , src , ext , cc_args , postargs , pp_opts ) NEW_LINE self . compiler_so = default_compiler_so NEW_LINE DEDENT self . _compile = _compile NEW_LINE DEDENT\",), ('def build_extensions ( self ) : NEW_LINE INDENT customize_compiler_for_nvcc ( self . compiler ) NEW_LINE build_ext . build_extensions ( self ) NEW_LINE DEDENT',), (\"def parse_args ( ) : NEW_LINE INDENT parser = argparse . ArgumentParser ( description = ' Train ▁ Faster - RCNN ▁ network ' ) NEW_LINE parser . add_argument ( ' - - cfg ' , help = ' experiment ▁ configure ▁ file ▁ name ' , required = True , type = str ) NEW_LINE args , rest = parser . parse_known_args ( ) NEW_LINE update_config ( args . cfg ) NEW_LINE parser . add_argument ( ' - - frequent ' , help = ' frequency ▁ of ▁ logging ' , default = config . default . frequent , type = int ) NEW_LINE args = parser . parse_args ( ) NEW_LINE return args NEW_LINE DEDENT\",), (\"def main ( ) : NEW_LINE INDENT print ( ' Called ▁ with ▁ argument : ' , args ) NEW_LINE ctx = [ mx . gpu ( int ( i ) ) for i in config . gpus . split ( ' , ' ) ] NEW_LINE train_net ( args , ctx , config . network . pretrained , config . network . pretrained_epoch , config . TRAIN . model_prefix , config . TRAIN . begin_epoch , config . TRAIN . end_epoch , config . TRAIN . lr , config . TRAIN . lr_step ) NEW_LINE DEDENT\",), (\"def parse_args ( ) : NEW_LINE INDENT parser = argparse . ArgumentParser ( description = ' Train ▁ Faster - RCNN ▁ network ' ) NEW_LINE parser . add_argument ( ' - - cfg ' , help = ' experiment ▁ configure ▁ file ▁ name ' , required = True , type = str ) NEW_LINE args , rest = parser . parse_known_args ( ) NEW_LINE update_config ( args . cfg ) NEW_LINE parser . add_argument ( ' - - frequent ' , help = ' frequency ▁ of ▁ logging ' , default = config . default . frequent , type = int ) NEW_LINE args = parser . parse_args ( ) NEW_LINE return args NEW_LINE DEDENT\",), (\"def main ( ) : NEW_LINE INDENT print ( ' Called ▁ with ▁ argument : ' , args ) NEW_LINE ctx = [ mx . gpu ( int ( i ) ) for i in config . gpus . split ( ' , ' ) ] NEW_LINE train_net ( args , ctx , config . network . pretrained , config . network . pretrained_epoch , config . TRAIN . model_prefix , config . TRAIN . begin_epoch , config . TRAIN . end_epoch , config . TRAIN . lr , config . TRAIN . lr_step ) NEW_LINE DEDENT\",), (\"def parse_args ( ) : NEW_LINE INDENT parser = argparse . ArgumentParser ( description = ' Train ▁ Faster - RCNN ▁ network ' ) NEW_LINE parser . add_argument ( ' - - cfg ' , help = ' experiment ▁ configure ▁ file ▁ name ' , required = True , type = str ) NEW_LINE args , rest = parser . parse_known_args ( ) NEW_LINE update_config ( args . cfg ) NEW_LINE parser . add_argument ( ' - - frequent ' , help = ' frequency ▁ of ▁ logging ' , default = config . default . frequent , type = int ) NEW_LINE args = parser . parse_args ( ) NEW_LINE return args NEW_LINE DEDENT\",), (\"def main ( ) : NEW_LINE INDENT print ( ' Called ▁ with ▁ argument : ' , args ) NEW_LINE ctx = [ mx . gpu ( int ( i ) ) for i in config . gpus . split ( ' , ' ) ] NEW_LINE train_net ( args , ctx , config . network . pretrained , config . network . pretrained_epoch , config . TRAIN . model_prefix , config . TRAIN . begin_epoch , config . TRAIN . end_epoch , config . TRAIN . lr , config . TRAIN . lr_step ) NEW_LINE DEDENT\",), (\"def parse_args ( ) : NEW_LINE INDENT parser = argparse . ArgumentParser ( description = ' Show ▁ Deformable ▁ ConvNets ▁ demo ' ) NEW_LINE parser . add_argument ( ' - - rfcn _ only ' , help = ' whether ▁ use ▁ fpn ▁ only ▁ ( w / o ▁ Deformable ▁ ConvNets ) ' , default = False , action = ' store _ true ' ) NEW_LINE args = parser . parse_args ( ) NEW_LINE return args NEW_LINE DEDENT\",), (\"def draw_all_poly_detection ( im_array , detections , class_names , scale , cfg , threshold = 0.2 ) : NEW_LINE INDENT import cv2 NEW_LINE import random NEW_LINE color_white = ( 255 , 255 , 255 ) NEW_LINE im = image . transform_inverse ( im_array , cfg . network . PIXEL_MEANS ) NEW_LINE im = cv2 . cvtColor ( im , cv2 . COLOR_RGB2BGR ) NEW_LINE for j , name in enumerate ( class_names ) : NEW_LINE INDENT if name == ' _ _ background _ _ ' : NEW_LINE INDENT continue NEW_LINE DEDENT color = ( random . randint ( 0 , 256 ) , random . randint ( 0 , 256 ) , random . randint ( 0 , 256 ) ) NEW_LINE try : NEW_LINE INDENT dets = detections [ j ] NEW_LINE DEDENT except : NEW_LINE INDENT pdb . set_trace ( ) NEW_LINE DEDENT for det in dets : NEW_LINE INDENT bbox = det [ : 8 ] * scale NEW_LINE score = det [ - 1 ] NEW_LINE if score < threshold : NEW_LINE INDENT continue NEW_LINE DEDENT bbox = map ( int , bbox ) NEW_LINE cv2 . circle ( im , ( bbox [ 0 ] , bbox [ 1 ] ) , 3 , ( 0 , 0 , 255 ) , - 1 ) NEW_LINE for i in range ( 3 ) : NEW_LINE INDENT cv2 . line ( im , ( bbox [ i * 2 ] , bbox [ i * 2 + 1 ] ) , ( bbox [ ( i + 1 ) * 2 ] , bbox [ ( i + 1 ) * 2 + 1 ] ) , color = color , thickness = 2 ) NEW_LINE DEDENT cv2 . line ( im , ( bbox [ 6 ] , bbox [ 7 ] ) , ( bbox [ 0 ] , bbox [ 1 ] ) , color = color , thickness = 2 ) NEW_LINE cv2 . putText ( im , ' % s ▁ % .3f ' % ( class_names [ j ] , score ) , ( bbox [ 0 ] , bbox [ 1 ] + 10 ) , color = color_white , fontFace = cv2 . FONT_HERSHEY_COMPLEX , fontScale = 0.5 ) NEW_LINE DEDENT DEDENT return im NEW_LINE DEDENT\",), (\"def parse_args ( ) : NEW_LINE INDENT parser = argparse . ArgumentParser ( description = ' Test ▁ a ▁ Faster ▁ R - CNN ▁ network ' ) NEW_LINE parser . add_argument ( ' - - cfg ' , help = ' experiment ▁ configure ▁ file ▁ name ' , required = True , type = str ) NEW_LINE args , rest = parser . parse_known_args ( ) NEW_LINE update_config ( args . cfg ) NEW_LINE parser . add_argument ( ' - - vis ' , help = ' turn ▁ on ▁ visualization ' , action = ' store _ true ' ) NEW_LINE parser . add_argument ( ' - - ignore _ cache ' , help = ' ignore ▁ cached ▁ results ▁ boxes ' , action = ' store _ true ' ) NEW_LINE parser . add_argument ( ' - - thresh ' , help = ' valid ▁ detection ▁ threshold ' , default = 1e-3 , type = float ) NEW_LINE parser . add_argument ( ' - - shuffle ' , help = ' shuffle ▁ data ▁ on ▁ visualization ' , action = ' store _ true ' ) NEW_LINE args = parser . parse_args ( ) NEW_LINE return args NEW_LINE DEDENT\",), (\"def parse_args ( ) : NEW_LINE INDENT parser = argparse . ArgumentParser ( description = ' Test ▁ a ▁ Faster ▁ R - CNN ▁ network ' ) NEW_LINE parser . add_argument ( ' - - cfg ' , help = ' experiment ▁ configure ▁ file ▁ name ' , required = True , type = str ) NEW_LINE args , rest = parser . parse_known_args ( ) NEW_LINE update_config ( args . cfg ) NEW_LINE parser . add_argument ( ' - - vis ' , help = ' turn ▁ on ▁ visualization ' , action = ' store _ true ' ) NEW_LINE parser . add_argument ( ' - - ignore _ cache ' , help = ' ignore ▁ cached ▁ results ▁ boxes ' , action = ' store _ true ' ) NEW_LINE parser . add_argument ( ' - - thresh ' , help = ' valid ▁ detection ▁ threshold ' , default = 1e-3 , type = float ) NEW_LINE parser . add_argument ( ' - - shuffle ' , help = ' shuffle ▁ data ▁ on ▁ visualization ' , action = ' store _ true ' ) NEW_LINE args = parser . parse_args ( ) NEW_LINE return args NEW_LINE DEDENT\",), ('def add_path ( path ) : NEW_LINE INDENT if path not in sys . path : NEW_LINE INDENT sys . path . insert ( 0 , path ) NEW_LINE DEDENT DEDENT',), ('def __init__ ( self , feat_strides , pooled_height , pooled_width , output_dim ) : NEW_LINE INDENT self . pooled_height = pooled_height NEW_LINE self . pooled_width = pooled_width NEW_LINE self . feat_strides = feat_strides NEW_LINE self . output_dim = output_dim NEW_LINE self . in_grad_hist_list = [ ] NEW_LINE self . num_strides = len ( self . feat_strides ) NEW_LINE self . roi_pool = [ None for _ in range ( self . num_strides ) ] NEW_LINE self . feat_idx = [ None for _ in range ( self . num_strides ) ] NEW_LINE DEDENT',), ('def forward ( self , is_train , req , in_data , out_data , aux ) : NEW_LINE INDENT rois = in_data [ - 1 ] . asnumpy ( ) NEW_LINE w = np . maximum ( rois [ : , 3 ] , 1 ) NEW_LINE h = np . maximum ( rois [ : , 4 ] , 1 ) NEW_LINE feat_id = np . clip ( np . floor ( 2 + np . log2 ( np . sqrt ( w * h ) / 224 ) ) , 0 , len ( self . feat_strides ) - 1 ) NEW_LINE pyramid_idx = [ ] NEW_LINE rois_p = [ None for _ in range ( self . num_strides ) ] NEW_LINE for i in range ( self . num_strides ) : NEW_LINE INDENT self . feat_idx [ i ] = np . where ( feat_id == i ) [ 0 ] NEW_LINE if len ( self . feat_idx [ i ] ) == 0 : NEW_LINE INDENT rois_p [ i ] = np . zeros ( ( 1 , 6 ) ) NEW_LINE pyramid_idx . append ( - 1 ) NEW_LINE DEDENT else : NEW_LINE INDENT rois_p [ i ] = rois [ self . feat_idx [ i ] ] NEW_LINE pyramid_idx . append ( self . feat_idx [ i ] ) NEW_LINE DEDENT DEDENT rois_idx = np . argsort ( np . hstack ( pyramid_idx ) ) [ - rois . shape [ 0 ] : ] NEW_LINE if is_train : NEW_LINE INDENT for i in range ( self . num_strides ) : NEW_LINE INDENT self . in_grad_hist_list . append ( mx . nd . zeros_like ( in_data [ i ] ) ) NEW_LINE DEDENT autograd . mark_variables ( [ in_data [ i ] for i in range ( self . num_strides ) ] , self . in_grad_hist_list ) NEW_LINE with autograd . train_section ( ) : NEW_LINE INDENT for i in range ( self . num_strides ) : NEW_LINE INDENT self . roi_pool [ i ] = mx . contrib . nd . PSROIALIGNAVERotatedPooling ( data = in_data [ i ] , rois = mx . nd . array ( rois_p [ i ] , in_data [ i ] . context ) , group_size = 7 , pooled_size = 7 , sampling_ratio = 2 , output_dim = 10 , spatial_scale = 1.0 / self . feat_strides [ i ] ) NEW_LINE DEDENT DEDENT roi_pool = mx . nd . concatenate ( self . roi_pool , axis = 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT roi_pool = [ None for _ in range ( self . num_strides ) ] NEW_LINE for i in range ( self . num_strides ) : NEW_LINE INDENT roi_pool [ i ] = mx . contrib . nd . PSROIALIGNAVERotatedPooling ( data = in_data [ i ] , rois = mx . nd . array ( rois_p [ i ] , in_data [ i ] . context ) , group_size = 7 , pooled_size = 7 , sampling_ratio = 2 , output_dim = 10 , spatial_scale = 1.0 / self . feat_strides [ i ] ) NEW_LINE DEDENT roi_pool = mx . nd . concatenate ( roi_pool , axis = 0 ) NEW_LINE DEDENT roi_pool = mx . nd . take ( roi_pool , mx . nd . array ( rois_idx , roi_pool . context ) ) NEW_LINE self . assign ( out_data [ 0 ] , req [ 0 ] , roi_pool ) NEW_LINE DEDENT',), ('def backward ( self , req , out_grad , in_data , out_data , in_grad , aux ) : NEW_LINE INDENT for i in range ( len ( in_grad ) ) : NEW_LINE INDENT self . assign ( in_grad [ i ] , req [ i ] , 0 ) NEW_LINE DEDENT with autograd . train_section ( ) : NEW_LINE INDENT for i in range ( self . num_strides ) : NEW_LINE INDENT if len ( self . feat_idx [ i ] > 0 ) : NEW_LINE INDENT autograd . compute_gradient ( [ mx . nd . take ( out_grad [ 0 ] , mx . nd . array ( self . feat_idx [ i ] , out_grad [ 0 ] . context ) ) * self . roi_pool [ i ] ] ) NEW_LINE DEDENT DEDENT DEDENT for i in range ( 0 , self . num_strides ) : NEW_LINE INDENT self . assign ( in_grad [ i ] , req [ i ] , self . in_grad_hist_list [ i ] ) NEW_LINE DEDENT gc . collect ( ) NEW_LINE DEDENT',), (\"def __init__ ( self , feat_strides = ' ( 4,8,16,32 ) ' , pooled_height = '7' , pooled_width = '7' , output_dim = '10' ) : NEW_LINE INDENT super ( FPNPSROIROTATEDAlignProp , self ) . __init__ ( need_top_grad = True ) NEW_LINE self . pooled_height = int ( pooled_height ) NEW_LINE self . pooled_width = int ( pooled_width ) NEW_LINE self . feat_strides = np . fromstring ( feat_strides [ 1 : - 1 ] , dtype = int , sep = ' , ' ) NEW_LINE self . output_dim = int ( output_dim ) NEW_LINE self . num_strides = len ( self . feat_strides ) NEW_LINE DEDENT\",), (\"def list_arguments ( self ) : NEW_LINE INDENT args_list = [ ] NEW_LINE for i in range ( self . num_strides ) : NEW_LINE INDENT args_list . append ( ' data _ p { } ' . format ( 2 + i ) ) NEW_LINE DEDENT args_list . append ( ' Rrois ' ) NEW_LINE return args_list NEW_LINE DEDENT\",), (\"def list_outputs ( self ) : NEW_LINE INDENT return [ ' output ' ] NEW_LINE DEDENT\",), ('def infer_shape ( self , in_shape ) : NEW_LINE INDENT output_feat_shape = [ in_shape [ - 1 ] [ 0 ] , self . output_dim , self . pooled_height , self . pooled_width ] NEW_LINE return in_shape , [ output_feat_shape ] NEW_LINE DEDENT',), ('def create_operator ( self , ctx , shapes , dtypes ) : NEW_LINE INDENT return FPNPSROIROTATEDAlignOperator ( self . feat_strides , self . pooled_height , self . pooled_width , self . output_dim ) NEW_LINE DEDENT',), ('def declare_backward_dependency ( self , out_grad , in_data , out_data ) : NEW_LINE INDENT return [ out_grad [ 0 ] ] NEW_LINE DEDENT',), ('def __init__ ( self , num_classes , batch_images , batch_rois , cfg , fg_fraction ) : NEW_LINE INDENT super ( RRoITargetRotBox_v2Operator , self ) . __init__ ( ) NEW_LINE self . _num_classes = num_classes NEW_LINE self . _batch_images = batch_images NEW_LINE self . _batch_rois = batch_rois NEW_LINE self . _cfg = cfg NEW_LINE self . _fg_fraction = fg_fraction NEW_LINE if DEBUG : NEW_LINE INDENT self . _count = 0 NEW_LINE self . _fg_num = 0 NEW_LINE self . _bg_num = 0 NEW_LINE DEDENT DEDENT',), ('def backward ( self , req , out_grad , in_data , out_data , in_grad , aux ) : NEW_LINE INDENT for i in range ( len ( in_grad ) ) : NEW_LINE INDENT self . assign ( in_grad [ i ] , req [ i ] , 0 ) NEW_LINE DEDENT DEDENT',), (\"def __init__ ( self , num_classes , batch_images , batch_rois , cfg , fg_fraction = '0.25' ) : NEW_LINE INDENT super ( RRoITargetRotbox_v2Prop , self ) . __init__ ( need_top_grad = False ) NEW_LINE self . _num_classes = int ( num_classes ) NEW_LINE self . _batch_images = int ( batch_images ) NEW_LINE self . _batch_rois = int ( batch_rois ) NEW_LINE self . _cfg = cPickle . loads ( cfg ) NEW_LINE self . _fg_fraction = float ( fg_fraction ) NEW_LINE DEDENT\",), (\"def list_arguments ( self ) : NEW_LINE INDENT return [ ' Rrois ' , ' gt _ boxes ' ] NEW_LINE DEDENT\",), (\"def list_outputs ( self ) : NEW_LINE INDENT return [ ' Rrois _ output ' , ' Rrois _ output _ elarge ' , ' Rlabel ' , ' Rbbox _ target ' , ' Rbbox _ weight ' ] NEW_LINE DEDENT\",), ('def infer_shape ( self , in_shape ) : NEW_LINE INDENT rpn_rois_shape = in_shape [ 0 ] NEW_LINE gt_boxes_shape = in_shape [ 1 ] NEW_LINE rois = rpn_rois_shape [ 0 ] + gt_boxes_shape [ 0 ] if self . _batch_rois == - 1 else self . _batch_rois NEW_LINE output_rois_shape = ( rois , 6 ) NEW_LINE label_shape = ( rois , ) NEW_LINE bbox_target_shape = ( rois , 5 * self . _num_classes ) NEW_LINE bbox_weight_shape = ( rois , 5 * self . _num_classes ) NEW_LINE return [ rpn_rois_shape , gt_boxes_shape ] , [ output_rois_shape , output_rois_shape , label_shape , bbox_target_shape , bbox_weight_shape ] NEW_LINE DEDENT',), ('def create_operator ( self , ctx , shapes , dtypes ) : NEW_LINE INDENT return RRoITargetRotBox_v2Operator ( self . _num_classes , self . _batch_images , self . _batch_rois , self . _cfg , self . _fg_fraction ) NEW_LINE DEDENT',), ('def declare_backward_dependency ( self , out_grad , in_data , out_data ) : NEW_LINE INDENT return [ ] NEW_LINE DEDENT',), ('def __init__ ( self , feat_strides , pooled_height , pooled_width , output_dim , with_deformable ) : NEW_LINE INDENT self . pooled_height = pooled_height NEW_LINE self . pooled_width = pooled_width NEW_LINE self . feat_strides = feat_strides NEW_LINE self . with_deformable = with_deformable NEW_LINE self . output_dim = output_dim NEW_LINE self . in_grad_hist_list = [ ] NEW_LINE self . num_strides = len ( self . feat_strides ) NEW_LINE self . roi_pool = [ None for _ in range ( self . num_strides ) ] NEW_LINE self . feat_idx = [ None for _ in range ( self . num_strides ) ] NEW_LINE DEDENT',), ('def forward ( self , is_train , req , in_data , out_data , aux ) : NEW_LINE INDENT rois = in_data [ - 1 ] . asnumpy ( ) NEW_LINE w = rois [ : , 3 ] - rois [ : , 1 ] + 1 NEW_LINE h = rois [ : , 4 ] - rois [ : , 2 ] + 1 NEW_LINE feat_id = np . clip ( np . floor ( 2 + np . log2 ( np . sqrt ( w * h ) / 224 ) ) , 0 , len ( self . feat_strides ) - 1 ) NEW_LINE pyramid_idx = [ ] NEW_LINE rois_p = [ None for _ in range ( self . num_strides ) ] NEW_LINE for i in range ( self . num_strides ) : NEW_LINE INDENT self . feat_idx [ i ] = np . where ( feat_id == i ) [ 0 ] NEW_LINE if len ( self . feat_idx [ i ] ) == 0 : NEW_LINE INDENT rois_p [ i ] = np . zeros ( ( 1 , 5 ) ) NEW_LINE pyramid_idx . append ( - 1 ) NEW_LINE DEDENT else : NEW_LINE INDENT rois_p [ i ] = rois [ self . feat_idx [ i ] ] NEW_LINE pyramid_idx . append ( self . feat_idx [ i ] ) NEW_LINE DEDENT DEDENT rois_idx = np . argsort ( np . hstack ( pyramid_idx ) ) [ - rois . shape [ 0 ] : ] NEW_LINE if is_train : NEW_LINE INDENT for i in range ( self . num_strides ) : NEW_LINE INDENT self . in_grad_hist_list . append ( mx . nd . zeros_like ( in_data [ i ] ) ) NEW_LINE DEDENT if self . with_deformable : NEW_LINE INDENT for i in range ( self . num_strides , self . num_strides * 3 ) : NEW_LINE INDENT self . in_grad_hist_list . append ( mx . nd . zeros_like ( in_data [ i ] ) ) NEW_LINE DEDENT autograd . mark_variables ( [ in_data [ i ] for i in range ( self . num_strides * 3 ) ] , self . in_grad_hist_list ) NEW_LINE with autograd . train_section ( ) : NEW_LINE INDENT for i in range ( self . num_strides ) : NEW_LINE INDENT roi_offset_t = mx . contrib . nd . DeformablePSROIPooling ( data = in_data [ i ] , rois = mx . nd . array ( rois_p [ i ] , in_data [ i ] . context ) , group_size = 1 , pooled_size = 7 , sample_per_part = 4 , no_trans = True , part_size = 7 , output_dim = 256 , spatial_scale = 1.0 / self . feat_strides [ i ] ) NEW_LINE roi_offset = mx . nd . FullyConnected ( data = roi_offset_t , num_hidden = 7 * 7 * 2 , weight = in_data [ i * 2 + self . num_strides ] , bias = in_data [ i * 2 + 1 + self . num_strides ] ) NEW_LINE roi_offset_reshape = mx . nd . reshape ( data = roi_offset , shape = ( - 1 , 2 , 7 , 7 ) ) NEW_LINE self . roi_pool [ i ] = mx . contrib . nd . DeformablePSROIPooling ( data = in_data [ i ] , rois = mx . nd . array ( rois_p [ i ] , in_data [ i ] . context ) , trans = roi_offset_reshape , group_size = 1 , pooled_size = 7 , sample_per_part = 4 , no_trans = False , part_size = 7 , output_dim = self . output_dim , spatial_scale = 1.0 / self . feat_strides [ i ] , trans_std = 0.1 ) NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT autograd . mark_variables ( [ in_data [ i ] for i in range ( self . num_strides ) ] , self . in_grad_hist_list ) NEW_LINE with autograd . train_section ( ) : NEW_LINE INDENT for i in range ( self . num_strides ) : NEW_LINE INDENT self . roi_pool [ i ] = mx . nd . ROIPooling ( in_data [ i ] , mx . nd . array ( rois_p [ i ] , in_data [ i ] . context ) , ( 7 , 7 ) , spatial_scale = 1.0 / self . feat_strides [ i ] ) NEW_LINE DEDENT DEDENT DEDENT roi_pool = mx . nd . concatenate ( self . roi_pool , axis = 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT roi_pool = [ None for _ in range ( self . num_strides ) ] NEW_LINE if self . with_deformable : NEW_LINE INDENT for i in range ( self . num_strides ) : NEW_LINE INDENT roi_offset_t = mx . contrib . nd . DeformablePSROIPooling ( data = in_data [ i ] , rois = mx . nd . array ( rois_p [ i ] , in_data [ i ] . context ) , group_size = 1 , pooled_size = 7 , sample_per_part = 4 , no_trans = True , part_size = 7 , output_dim = 256 , spatial_scale = 1.0 / self . feat_strides [ i ] ) NEW_LINE roi_offset = mx . nd . FullyConnected ( data = roi_offset_t , num_hidden = 7 * 7 * 2 , weight = in_data [ i * 2 + self . num_strides ] , bias = in_data [ i * 2 + 1 + self . num_strides ] ) NEW_LINE roi_offset_reshape = mx . nd . reshape ( data = roi_offset , shape = ( - 1 , 2 , 7 , 7 ) ) NEW_LINE roi_pool [ i ] = mx . contrib . nd . DeformablePSROIPooling ( data = in_data [ i ] , rois = mx . nd . array ( rois_p [ i ] , in_data [ i ] . context ) , trans = roi_offset_reshape , group_size = 1 , pooled_size = 7 , sample_per_part = 4 , no_trans = False , part_size = 7 , output_dim = self . output_dim , spatial_scale = 1.0 / self . feat_strides [ i ] , trans_std = 0.1 ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT for i in range ( self . num_strides ) : NEW_LINE INDENT roi_pool [ i ] = mx . nd . ROIPooling ( in_data [ i ] , mx . nd . array ( rois_p [ i ] , in_data [ i ] . context ) , ( 7 , 7 ) , spatial_scale = 1.0 / self . feat_strides [ i ] ) NEW_LINE DEDENT DEDENT roi_pool = mx . nd . concatenate ( roi_pool , axis = 0 ) NEW_LINE DEDENT roi_pool = mx . nd . take ( roi_pool , mx . nd . array ( rois_idx , roi_pool . context ) ) NEW_LINE self . assign ( out_data [ 0 ] , req [ 0 ] , roi_pool ) NEW_LINE DEDENT',), ('def backward ( self , req , out_grad , in_data , out_data , in_grad , aux ) : NEW_LINE INDENT for i in range ( len ( in_grad ) ) : NEW_LINE INDENT self . assign ( in_grad [ i ] , req [ i ] , 0 ) NEW_LINE DEDENT with autograd . train_section ( ) : NEW_LINE INDENT for i in range ( self . num_strides ) : NEW_LINE INDENT if len ( self . feat_idx [ i ] > 0 ) : NEW_LINE INDENT autograd . compute_gradient ( [ mx . nd . take ( out_grad [ 0 ] , mx . nd . array ( self . feat_idx [ i ] , out_grad [ 0 ] . context ) ) * self . roi_pool [ i ] ] ) NEW_LINE DEDENT DEDENT DEDENT if self . with_deformable : NEW_LINE INDENT for i in range ( 0 , self . num_strides * 3 ) : NEW_LINE INDENT self . assign ( in_grad [ i ] , req [ i ] , self . in_grad_hist_list [ i ] ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT for i in range ( 0 , self . num_strides ) : NEW_LINE INDENT self . assign ( in_grad [ i ] , req [ i ] , self . in_grad_hist_list [ i ] ) NEW_LINE DEDENT DEDENT gc . collect ( ) NEW_LINE DEDENT',), (\"def __init__ ( self , feat_strides = ' ( 4,8,16,32 ) ' , pooled_height = '7' , pooled_width = '7' , with_deformable = ' False ' , output_dim = '256' ) : NEW_LINE INDENT super ( FPNROIPoolingProp , self ) . __init__ ( need_top_grad = True ) NEW_LINE self . pooled_height = int ( pooled_height ) NEW_LINE self . pooled_width = int ( pooled_width ) NEW_LINE self . feat_strides = np . fromstring ( feat_strides [ 1 : - 1 ] , dtype = int , sep = ' , ' ) NEW_LINE self . with_deformable = with_deformable == ' True ' NEW_LINE self . output_dim = int ( output_dim ) NEW_LINE self . num_strides = len ( self . feat_strides ) NEW_LINE DEDENT\",), (\"def list_arguments ( self ) : NEW_LINE INDENT args_list = [ ] NEW_LINE for i in range ( self . num_strides ) : NEW_LINE INDENT args_list . append ( ' data _ p { } ' . format ( 2 + i ) ) NEW_LINE DEDENT if self . with_deformable : NEW_LINE INDENT for i in range ( self . num_strides ) : NEW_LINE INDENT args_list . extend ( [ ' offset _ weight _ p { } ' . format ( 2 + i ) , ' offset _ bias _ p { } ' . format ( 2 + i ) ] ) NEW_LINE DEDENT DEDENT args_list . append ( ' rois ' ) NEW_LINE return args_list NEW_LINE DEDENT\",), (\"def list_outputs ( self ) : NEW_LINE INDENT return [ ' output ' ] NEW_LINE DEDENT\",), ('def infer_shape ( self , in_shape ) : NEW_LINE INDENT output_feat_shape = [ in_shape [ - 1 ] [ 0 ] , in_shape [ 0 ] [ 1 ] , self . pooled_height , self . pooled_width ] NEW_LINE if self . with_deformable : NEW_LINE INDENT offset_dim = self . pooled_height * self . pooled_width * 2 NEW_LINE input_dim = self . pooled_height * self . pooled_width * self . output_dim NEW_LINE for i in range ( self . num_strides ) : NEW_LINE INDENT in_shape [ i * 2 + self . num_strides ] , in_shape [ i * 2 + 1 + self . num_strides ] = [ offset_dim , input_dim ] , [ offset_dim , ] NEW_LINE DEDENT DEDENT return in_shape , [ output_feat_shape ] NEW_LINE DEDENT',), ('def create_operator ( self , ctx , shapes , dtypes ) : NEW_LINE INDENT return FPNROIPoolingOperator ( self . feat_strides , self . pooled_height , self . pooled_width , self . output_dim , self . with_deformable ) NEW_LINE DEDENT',), ('def declare_backward_dependency ( self , out_grad , in_data , out_data ) : NEW_LINE INDENT return [ out_grad [ 0 ] ] NEW_LINE DEDENT',), ('def __init__ ( self , feat_strides , pooled_height , pooled_width , output_dim ) : NEW_LINE INDENT self . pooled_height = pooled_height NEW_LINE self . pooled_width = pooled_width NEW_LINE self . feat_strides = feat_strides NEW_LINE self . output_dim = output_dim NEW_LINE self . in_grad_hist_list = [ ] NEW_LINE self . num_strides = len ( self . feat_strides ) NEW_LINE self . roi_pool = [ None for _ in range ( self . num_strides ) ] NEW_LINE self . feat_idx = [ None for _ in range ( self . num_strides ) ] NEW_LINE DEDENT',), ('def forward ( self , is_train , req , in_data , out_data , aux ) : NEW_LINE INDENT rois = in_data [ - 1 ] . asnumpy ( ) NEW_LINE w = np . maximum ( rois [ : , 3 ] , 1 ) NEW_LINE h = np . maximum ( rois [ : , 4 ] , 1 ) NEW_LINE feat_id = np . clip ( np . floor ( 2 + np . log2 ( np . sqrt ( w * h ) / 224 ) ) , 0 , len ( self . feat_strides ) - 1 ) NEW_LINE pyramid_idx = [ ] NEW_LINE rois_p = [ None for _ in range ( self . num_strides ) ] NEW_LINE for i in range ( self . num_strides ) : NEW_LINE INDENT self . feat_idx [ i ] = np . where ( feat_id == i ) [ 0 ] NEW_LINE if len ( self . feat_idx [ i ] ) == 0 : NEW_LINE INDENT rois_p [ i ] = np . zeros ( ( 1 , 6 ) ) NEW_LINE pyramid_idx . append ( - 1 ) NEW_LINE DEDENT else : NEW_LINE INDENT rois_p [ i ] = rois [ self . feat_idx [ i ] ] NEW_LINE pyramid_idx . append ( self . feat_idx [ i ] ) NEW_LINE DEDENT DEDENT rois_idx = np . argsort ( np . hstack ( pyramid_idx ) ) [ - rois . shape [ 0 ] : ] NEW_LINE if is_train : NEW_LINE INDENT for i in range ( self . num_strides ) : NEW_LINE INDENT self . in_grad_hist_list . append ( mx . nd . zeros_like ( in_data [ i ] ) ) NEW_LINE DEDENT autograd . mark_variables ( [ in_data [ i ] for i in range ( self . num_strides ) ] , self . in_grad_hist_list ) NEW_LINE with autograd . train_section ( ) : NEW_LINE INDENT for i in range ( self . num_strides ) : NEW_LINE INDENT self . roi_pool [ i ] = mx . nd . contrib . ROIAlignRotated ( in_data [ i ] , mx . nd . array ( rois_p [ i ] , in_data [ i ] . context ) , ( 7 , 7 ) , spatial_scale = 1.0 / self . feat_strides [ i ] , sample_ratio = 4 ) NEW_LINE DEDENT DEDENT roi_pool = mx . nd . concatenate ( self . roi_pool , axis = 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT roi_pool = [ None for _ in range ( self . num_strides ) ] NEW_LINE for i in range ( self . num_strides ) : NEW_LINE INDENT roi_pool [ i ] = mx . nd . contrib . ROIAlignRotated ( in_data [ i ] , mx . nd . array ( rois_p [ i ] , in_data [ i ] . context ) , ( 7 , 7 ) , spatial_scale = 1.0 / self . feat_strides [ i ] , sample_ratio = 4 ) NEW_LINE DEDENT roi_pool = mx . nd . concatenate ( roi_pool , axis = 0 ) NEW_LINE DEDENT roi_pool = mx . nd . take ( roi_pool , mx . nd . array ( rois_idx , roi_pool . context ) ) NEW_LINE self . assign ( out_data [ 0 ] , req [ 0 ] , roi_pool ) NEW_LINE DEDENT',), ('def backward ( self , req , out_grad , in_data , out_data , in_grad , aux ) : NEW_LINE INDENT for i in range ( len ( in_grad ) ) : NEW_LINE INDENT self . assign ( in_grad [ i ] , req [ i ] , 0 ) NEW_LINE DEDENT with autograd . train_section ( ) : NEW_LINE INDENT for i in range ( self . num_strides ) : NEW_LINE INDENT if len ( self . feat_idx [ i ] > 0 ) : NEW_LINE INDENT autograd . compute_gradient ( [ mx . nd . take ( out_grad [ 0 ] , mx . nd . array ( self . feat_idx [ i ] , out_grad [ 0 ] . context ) ) * self . roi_pool [ i ] ] ) NEW_LINE DEDENT DEDENT DEDENT for i in range ( 0 , self . num_strides ) : NEW_LINE INDENT self . assign ( in_grad [ i ] , req [ i ] , self . in_grad_hist_list [ i ] ) NEW_LINE DEDENT gc . collect ( ) NEW_LINE DEDENT',), (\"def __init__ ( self , feat_strides = ' ( 4,8,16,32 ) ' , pooled_height = '7' , pooled_width = '7' , output_dim = '490' ) : NEW_LINE INDENT super ( FPNRotatedROIAlignProp , self ) . __init__ ( need_top_grad = True ) NEW_LINE self . pooled_height = int ( pooled_height ) NEW_LINE self . pooled_width = int ( pooled_width ) NEW_LINE self . feat_strides = np . fromstring ( feat_strides [ 1 : - 1 ] , dtype = int , sep = ' , ' ) NEW_LINE self . output_dim = int ( output_dim ) NEW_LINE self . num_strides = len ( self . feat_strides ) NEW_LINE DEDENT\",), (\"def list_arguments ( self ) : NEW_LINE INDENT args_list = [ ] NEW_LINE for i in range ( self . num_strides ) : NEW_LINE INDENT args_list . append ( ' data _ p { } ' . format ( 2 + i ) ) NEW_LINE DEDENT args_list . append ( ' Rrois ' ) NEW_LINE return args_list NEW_LINE DEDENT\",), (\"def list_outputs ( self ) : NEW_LINE INDENT return [ ' rotated _ pooled ' ] NEW_LINE DEDENT\",), ('def infer_shape ( self , in_shape ) : NEW_LINE INDENT output_feat_shape = [ in_shape [ - 1 ] [ 0 ] , in_shape [ 0 ] [ 1 ] , self . pooled_height , self . pooled_width ] NEW_LINE return in_shape , [ output_feat_shape ] NEW_LINE DEDENT',), ('def create_operator ( self , ctx , shapes , dtypes ) : NEW_LINE INDENT return FPNRotatedROIAlignOperator ( self . feat_strides , self . pooled_height , self . pooled_width , self . output_dim ) NEW_LINE DEDENT',), ('def declare_backward_dependency ( self , out_grad , in_data , out_data ) : NEW_LINE INDENT return [ out_grad [ 0 ] ] NEW_LINE DEDENT',), ('def _filter_boxes ( boxes , min_size ) : NEW_LINE INDENT ws = boxes [ : , 2 ] - boxes [ : , 0 ] + 1 NEW_LINE hs = boxes [ : , 3 ] - boxes [ : , 1 ] + 1 NEW_LINE keep = np . where ( ( ws >= min_size ) & ( hs >= min_size ) ) [ 0 ] NEW_LINE return keep NEW_LINE DEDENT',), ('def _clip_pad ( tensor , pad_shape ) : NEW_LINE INDENT H , W = tensor . shape [ 2 : ] NEW_LINE h , w = pad_shape NEW_LINE if h < H or w < W : NEW_LINE INDENT tensor = tensor [ : , : , : h , : w ] . copy ( ) NEW_LINE DEDENT return tensor NEW_LINE DEDENT',), (\"def __init__ ( self , feat_stride , scales , ratios , output_score , rpn_pre_nms_top_n , rpn_post_nms_top_n , threshold , rpn_min_size ) : NEW_LINE INDENT super ( PyramidProposalOperator , self ) . __init__ ( ) NEW_LINE self . _feat_stride = np . fromstring ( feat_stride [ 1 : - 1 ] , dtype = int , sep = ' , ' ) NEW_LINE self . _scales = np . fromstring ( scales [ 1 : - 1 ] , dtype = float , sep = ' , ' ) NEW_LINE self . _ratios = np . fromstring ( ratios [ 1 : - 1 ] , dtype = float , sep = ' , ' ) NEW_LINE self . _num_anchors = len ( self . _scales ) * len ( self . _ratios ) NEW_LINE self . _output_score = output_score NEW_LINE self . _rpn_pre_nms_top_n = rpn_pre_nms_top_n NEW_LINE self . _rpn_post_nms_top_n = rpn_post_nms_top_n NEW_LINE self . _threshold = threshold NEW_LINE self . _rpn_min_size = rpn_min_size NEW_LINE DEDENT\",), ('def forward ( self , is_train , req , in_data , out_data , aux ) : NEW_LINE INDENT nms = gpu_nms_wrapper ( self . _threshold , in_data [ 0 ] . context . device_id ) NEW_LINE batch_size = in_data [ 0 ] . shape [ 0 ] NEW_LINE if batch_size > 1 : NEW_LINE INDENT raise ValueError ( \" Sorry , ▁ multiple ▁ images ▁ each ▁ device ▁ is ▁ not ▁ implemented \" ) NEW_LINE DEDENT cls_prob_dict = { \\' stride64\\' : in_data [ 4 ] , \\' stride32\\' : in_data [ 3 ] , \\' stride16\\' : in_data [ 2 ] , \\' stride8\\' : in_data [ 1 ] , \\' stride4\\' : in_data [ 0 ] , } NEW_LINE bbox_pred_dict = { \\' stride64\\' : in_data [ 9 ] , \\' stride32\\' : in_data [ 8 ] , \\' stride16\\' : in_data [ 7 ] , \\' stride8\\' : in_data [ 6 ] , \\' stride4\\' : in_data [ 5 ] , } NEW_LINE pre_nms_topN = self . _rpn_pre_nms_top_n NEW_LINE post_nms_topN = self . _rpn_post_nms_top_n NEW_LINE min_size = self . _rpn_min_size NEW_LINE proposal_list = [ ] NEW_LINE score_list = [ ] NEW_LINE for s in self . _feat_stride : NEW_LINE INDENT stride = int ( s ) NEW_LINE sub_anchors = generate_anchors ( base_size = stride , scales = self . _scales , ratios = self . _ratios ) NEW_LINE scores = cls_prob_dict [ \\' stride \\' + str ( s ) ] . asnumpy ( ) [ : , self . _num_anchors : , : , : ] NEW_LINE bbox_deltas = bbox_pred_dict [ \\' stride \\' + str ( s ) ] . asnumpy ( ) NEW_LINE im_info = in_data [ - 1 ] . asnumpy ( ) [ 0 , : ] NEW_LINE height , width = int ( im_info [ 0 ] / stride ) , int ( im_info [ 1 ] / stride ) NEW_LINE shift_x = np . arange ( 0 , width ) * stride NEW_LINE shift_y = np . arange ( 0 , height ) * stride NEW_LINE shift_x , shift_y = np . meshgrid ( shift_x , shift_y ) NEW_LINE shifts = np . vstack ( ( shift_x . ravel ( ) , shift_y . ravel ( ) , shift_x . ravel ( ) , shift_y . ravel ( ) ) ) . transpose ( ) NEW_LINE A = self . _num_anchors NEW_LINE K = shifts . shape [ 0 ] NEW_LINE anchors = sub_anchors . reshape ( ( 1 , A , 4 ) ) + shifts . reshape ( ( 1 , K , 4 ) ) . transpose ( ( 1 , 0 , 2 ) ) NEW_LINE anchors = anchors . reshape ( ( K * A , 4 ) ) NEW_LINE bbox_deltas = self . _clip_pad ( bbox_deltas , ( height , width ) ) NEW_LINE bbox_deltas = bbox_deltas . transpose ( ( 0 , 2 , 3 , 1 ) ) . reshape ( ( - 1 , 4 ) ) NEW_LINE scores = self . _clip_pad ( scores , ( height , width ) ) NEW_LINE scores = scores . transpose ( ( 0 , 2 , 3 , 1 ) ) . reshape ( ( - 1 , 1 ) ) NEW_LINE proposals = bbox_pred ( anchors , bbox_deltas ) NEW_LINE proposals = clip_boxes ( proposals , im_info [ : 2 ] ) NEW_LINE keep = self . _filter_boxes ( proposals , min_size * im_info [ 2 ] ) NEW_LINE proposals = proposals [ keep , : ] NEW_LINE scores = scores [ keep ] NEW_LINE proposal_list . append ( proposals ) NEW_LINE score_list . append ( scores ) NEW_LINE DEDENT proposals = np . vstack ( proposal_list ) NEW_LINE scores = np . vstack ( score_list ) NEW_LINE order = scores . ravel ( ) . argsort ( ) [ : : - 1 ] NEW_LINE if pre_nms_topN > 0 : NEW_LINE INDENT order = order [ : pre_nms_topN ] NEW_LINE DEDENT proposals = proposals [ order , : ] NEW_LINE scores = scores [ order ] NEW_LINE det = np . hstack ( ( proposals , scores ) ) . astype ( np . float32 ) NEW_LINE keep = nms ( det ) NEW_LINE if post_nms_topN > 0 : NEW_LINE INDENT keep = keep [ : post_nms_topN ] NEW_LINE DEDENT if len ( keep ) < post_nms_topN : NEW_LINE INDENT pad = npr . choice ( keep , size = post_nms_topN - len ( keep ) ) NEW_LINE keep = np . hstack ( ( keep , pad ) ) NEW_LINE DEDENT proposals = proposals [ keep , : ] NEW_LINE scores = scores [ keep ] NEW_LINE batch_inds = np . zeros ( ( proposals . shape [ 0 ] , 1 ) , dtype = np . float32 ) NEW_LINE blob = np . hstack ( ( batch_inds , proposals . astype ( np . float32 , copy = False ) ) ) NEW_LINE self . assign ( out_data [ 0 ] , req [ 0 ] , blob ) NEW_LINE if self . _output_score : NEW_LINE INDENT self . assign ( out_data [ 1 ] , req [ 1 ] , scores . astype ( np . float32 , copy = False ) ) NEW_LINE DEDENT DEDENT',), ('def backward ( self , req , out_grad , in_data , out_data , in_grad , aux ) : NEW_LINE INDENT for i in range ( len ( in_grad ) ) : NEW_LINE INDENT self . assign ( in_grad [ i ] , req [ i ] , 0 ) NEW_LINE DEDENT DEDENT',), (\"def __init__ ( self , feat_stride = ' ( 64 , ▁ 32 , ▁ 16 , ▁ 8 , ▁ 4 ) ' , scales = ' ( 8 ) ' , ratios = ' ( 0.5 , ▁ 1 , ▁ 2 ) ' , output_score = ' False ' , rpn_pre_nms_top_n = '12000' , rpn_post_nms_top_n = '2000' , threshold = '0.3' , rpn_min_size = '16' , output_pyramid_rois = ' False ' ) : NEW_LINE INDENT super ( PyramidProposalProp , self ) . __init__ ( need_top_grad = False ) NEW_LINE self . _feat_stride = feat_stride NEW_LINE self . _scales = scales NEW_LINE self . _ratios = ratios NEW_LINE self . _output_score = strtobool ( output_score ) NEW_LINE self . _rpn_pre_nms_top_n = int ( rpn_pre_nms_top_n ) NEW_LINE self . _rpn_post_nms_top_n = int ( rpn_post_nms_top_n ) NEW_LINE self . _threshold = float ( threshold ) NEW_LINE self . _rpn_min_size = int ( rpn_min_size ) NEW_LINE self . output_pyramid_rois = strtobool ( output_pyramid_rois ) NEW_LINE DEDENT\",), (\"def list_arguments ( self ) : NEW_LINE INDENT arg_list = [ ] NEW_LINE for s in np . fromstring ( self . _feat_stride [ 1 : - 1 ] , dtype = int , sep = ' , ' ) : NEW_LINE INDENT arg_list . append ( ' rpn _ cls _ prob _ stride ' + str ( s ) ) NEW_LINE DEDENT for s in np . fromstring ( self . _feat_stride [ 1 : - 1 ] , dtype = int , sep = ' , ' ) : NEW_LINE INDENT arg_list . append ( ' rpn _ bbox _ pred _ stride ' + str ( s ) ) NEW_LINE DEDENT arg_list . append ( ' im _ info ' ) NEW_LINE return arg_list NEW_LINE DEDENT\",), (\"def list_outputs ( self ) : NEW_LINE INDENT if self . output_pyramid_rois : NEW_LINE INDENT return [ ' output ' , ' output _ p3' , ' output _ p4' , ' output _ p5' , ' output _ idx ' ] NEW_LINE DEDENT else : NEW_LINE INDENT if self . _output_score : NEW_LINE INDENT return [ ' output ' , ' score ' ] NEW_LINE DEDENT else : NEW_LINE INDENT return [ ' output ' ] NEW_LINE DEDENT DEDENT DEDENT\",), ('def infer_shape ( self , in_shape ) : NEW_LINE INDENT output_shape = ( self . _rpn_post_nms_top_n , 5 ) NEW_LINE score_shape = ( self . _rpn_post_nms_top_n , 1 ) NEW_LINE if self . output_pyramid_rois : NEW_LINE INDENT return in_shape , [ output_shape , output_shape , output_shape , output_shape , ( self . _rpn_post_nms_top_n , ) ] NEW_LINE DEDENT else : NEW_LINE INDENT if self . _output_score : NEW_LINE INDENT return in_shape , [ output_shape , score_shape ] NEW_LINE DEDENT else : NEW_LINE INDENT return in_shape , [ output_shape ] NEW_LINE DEDENT DEDENT DEDENT',), ('def create_operator ( self , ctx , shapes , dtypes ) : NEW_LINE INDENT return PyramidProposalOperator ( self . _feat_stride , self . _scales , self . _ratios , self . _output_score , self . _rpn_pre_nms_top_n , self . _rpn_post_nms_top_n , self . _threshold , self . _rpn_min_size ) NEW_LINE DEDENT',), ('def declare_backward_dependency ( self , out_grad , in_data , out_data ) : NEW_LINE INDENT return [ ] NEW_LINE DEDENT',), ('def __init__ ( self , num_classes , num_reg_classes , roi_per_img ) : NEW_LINE INDENT super ( BoxAnnotatorOHEMOperator , self ) . __init__ ( ) NEW_LINE self . _num_classes = num_classes NEW_LINE self . _num_reg_classes = num_reg_classes NEW_LINE self . _roi_per_img = roi_per_img NEW_LINE DEDENT',), (\"def forward ( self , is_train , req , in_data , out_data , aux ) : NEW_LINE INDENT cls_score = in_data [ 0 ] NEW_LINE bbox_pred = in_data [ 1 ] NEW_LINE labels = in_data [ 2 ] . asnumpy ( ) NEW_LINE bbox_targets = in_data [ 3 ] NEW_LINE bbox_weights = in_data [ 4 ] NEW_LINE per_roi_loss_cls = mx . nd . SoftmaxActivation ( cls_score ) + 1e-14 NEW_LINE per_roi_loss_cls = per_roi_loss_cls . asnumpy ( ) NEW_LINE per_roi_loss_cls = per_roi_loss_cls [ np . arange ( per_roi_loss_cls . shape [ 0 ] , dtype = ' int ' ) , labels . astype ( ' int ' ) ] NEW_LINE per_roi_loss_cls = - 1 * np . log ( per_roi_loss_cls ) NEW_LINE per_roi_loss_cls = np . reshape ( per_roi_loss_cls , newshape = ( - 1 , ) ) NEW_LINE per_roi_loss_bbox = bbox_weights * mx . nd . smooth_l1 ( ( bbox_pred - bbox_targets ) , scalar = 1.0 ) NEW_LINE per_roi_loss_bbox = mx . nd . sum ( per_roi_loss_bbox , axis = 1 ) . asnumpy ( ) NEW_LINE top_k_per_roi_loss = np . argsort ( per_roi_loss_cls + per_roi_loss_bbox ) NEW_LINE labels_ohem = labels NEW_LINE labels_ohem [ top_k_per_roi_loss [ : : - 1 ] [ self . _roi_per_img : ] ] = - 1 NEW_LINE bbox_weights_ohem = bbox_weights . asnumpy ( ) NEW_LINE bbox_weights_ohem [ top_k_per_roi_loss [ : : - 1 ] [ self . _roi_per_img : ] ] = 0 NEW_LINE labels_ohem = mx . nd . array ( labels_ohem ) NEW_LINE bbox_weights_ohem = mx . nd . array ( bbox_weights_ohem ) NEW_LINE for ind , val in enumerate ( [ labels_ohem , bbox_weights_ohem ] ) : NEW_LINE INDENT self . assign ( out_data [ ind ] , req [ ind ] , val ) NEW_LINE DEDENT DEDENT\",), ('def backward ( self , req , out_grad , in_data , out_data , in_grad , aux ) : NEW_LINE INDENT for i in range ( len ( in_grad ) ) : NEW_LINE INDENT self . assign ( in_grad [ i ] , req [ i ] , 0 ) NEW_LINE DEDENT DEDENT',), ('def __init__ ( self , num_classes , num_reg_classes , roi_per_img ) : NEW_LINE INDENT super ( BoxAnnotatorOHEMProp , self ) . __init__ ( need_top_grad = False ) NEW_LINE self . _num_classes = int ( num_classes ) NEW_LINE self . _num_reg_classes = int ( num_reg_classes ) NEW_LINE self . _roi_per_img = int ( roi_per_img ) NEW_LINE DEDENT',), (\"def list_arguments ( self ) : NEW_LINE INDENT return [ ' cls _ score ' , ' bbox _ pred ' , ' labels ' , ' bbox _ targets ' , ' bbox _ weights ' ] NEW_LINE DEDENT\",), (\"def list_outputs ( self ) : NEW_LINE INDENT return [ ' labels _ ohem ' , ' bbox _ weights _ ohem ' ] NEW_LINE DEDENT\",), ('def infer_shape ( self , in_shape ) : NEW_LINE INDENT labels_shape = in_shape [ 2 ] NEW_LINE bbox_weights_shape = in_shape [ 4 ] NEW_LINE return in_shape , [ labels_shape , bbox_weights_shape ] NEW_LINE DEDENT',), ('def create_operator ( self , ctx , shapes , dtypes ) : NEW_LINE INDENT return BoxAnnotatorOHEMOperator ( self . _num_classes , self . _num_reg_classes , self . _roi_per_img ) NEW_LINE DEDENT',), ('def declare_backward_dependency ( self , out_grad , in_data , out_data ) : NEW_LINE INDENT return [ ] NEW_LINE DEDENT',), ('def __init__ ( self , feat_strides , pooled_height , pooled_width , output_dim ) : NEW_LINE INDENT self . pooled_height = pooled_height NEW_LINE self . pooled_width = pooled_width NEW_LINE self . feat_strides = feat_strides NEW_LINE self . output_dim = output_dim NEW_LINE self . in_grad_hist_list = [ ] NEW_LINE self . num_strides = len ( self . feat_strides ) NEW_LINE self . roi_pool = [ None for _ in range ( self . num_strides ) ] NEW_LINE self . feat_idx = [ None for _ in range ( self . num_strides ) ] NEW_LINE DEDENT',), ('def forward ( self , is_train , req , in_data , out_data , aux ) : NEW_LINE INDENT rois = in_data [ - 1 ] . asnumpy ( ) NEW_LINE w = np . maximum ( rois [ : , 3 ] , 1 ) NEW_LINE h = np . maximum ( rois [ : , 4 ] , 1 ) NEW_LINE feat_id = np . clip ( np . floor ( 2 + np . log2 ( np . sqrt ( w * h ) / 224 ) ) , 0 , len ( self . feat_strides ) - 1 ) NEW_LINE pyramid_idx = [ ] NEW_LINE rois_p = [ None for _ in range ( self . num_strides ) ] NEW_LINE for i in range ( self . num_strides ) : NEW_LINE INDENT self . feat_idx [ i ] = np . where ( feat_id == i ) [ 0 ] NEW_LINE if len ( self . feat_idx [ i ] ) == 0 : NEW_LINE INDENT rois_p [ i ] = np . zeros ( ( 1 , 6 ) ) NEW_LINE pyramid_idx . append ( - 1 ) NEW_LINE DEDENT else : NEW_LINE INDENT rois_p [ i ] = rois [ self . feat_idx [ i ] ] NEW_LINE pyramid_idx . append ( self . feat_idx [ i ] ) NEW_LINE DEDENT DEDENT rois_idx = np . argsort ( np . hstack ( pyramid_idx ) ) [ - rois . shape [ 0 ] : ] NEW_LINE if is_train : NEW_LINE INDENT for i in range ( self . num_strides ) : NEW_LINE INDENT self . in_grad_hist_list . append ( mx . nd . zeros_like ( in_data [ i ] ) ) NEW_LINE DEDENT autograd . mark_variables ( [ in_data [ i ] for i in range ( self . num_strides ) ] , self . in_grad_hist_list ) NEW_LINE with autograd . train_section ( ) : NEW_LINE INDENT for i in range ( self . num_strides ) : NEW_LINE INDENT self . roi_pool [ i ] = mx . contrib . nd . PSROIROTATEDPooling ( data = in_data [ i ] , rois = mx . nd . array ( rois_p [ i ] , in_data [ i ] . context ) , group_size = 7 , pooled_size = 7 , output_dim = 10 , spatial_scale = 1.0 / self . feat_strides [ i ] ) NEW_LINE DEDENT DEDENT roi_pool = mx . nd . concatenate ( self . roi_pool , axis = 0 ) NEW_LINE DEDENT else : NEW_LINE INDENT roi_pool = [ None for _ in range ( self . num_strides ) ] NEW_LINE for i in range ( self . num_strides ) : NEW_LINE INDENT roi_pool [ i ] = mx . contrib . nd . PSROIROTATEDPooling ( data = in_data [ i ] , rois = mx . nd . array ( rois_p [ i ] , in_data [ i ] . context ) , group_size = 7 , pooled_size = 7 , output_dim = 10 , spatial_scale = 1.0 / self . feat_strides [ i ] ) NEW_LINE DEDENT roi_pool = mx . nd . concatenate ( roi_pool , axis = 0 ) NEW_LINE DEDENT roi_pool = mx . nd . take ( roi_pool , mx . nd . array ( rois_idx , roi_pool . context ) ) NEW_LINE self . assign ( out_data [ 0 ] , req [ 0 ] , roi_pool ) NEW_LINE DEDENT',), ('def backward ( self , req , out_grad , in_data , out_data , in_grad , aux ) : NEW_LINE INDENT for i in range ( len ( in_grad ) ) : NEW_LINE INDENT self . assign ( in_grad [ i ] , req [ i ] , 0 ) NEW_LINE DEDENT with autograd . train_section ( ) : NEW_LINE INDENT for i in range ( self . num_strides ) : NEW_LINE INDENT if len ( self . feat_idx [ i ] > 0 ) : NEW_LINE INDENT autograd . compute_gradient ( [ mx . nd . take ( out_grad [ 0 ] , mx . nd . array ( self . feat_idx [ i ] , out_grad [ 0 ] . context ) ) * self . roi_pool [ i ] ] ) NEW_LINE DEDENT DEDENT DEDENT for i in range ( 0 , self . num_strides ) : NEW_LINE INDENT self . assign ( in_grad [ i ] , req [ i ] , self . in_grad_hist_list [ i ] ) NEW_LINE DEDENT gc . collect ( ) NEW_LINE DEDENT',), (\"def __init__ ( self , feat_strides = ' ( 4,8,16,32 ) ' , pooled_height = '7' , pooled_width = '7' , output_dim = '10' ) : NEW_LINE INDENT super ( FPNPSROIROTATEDPoolingProp , self ) . __init__ ( need_top_grad = True ) NEW_LINE self . pooled_height = int ( pooled_height ) NEW_LINE self . pooled_width = int ( pooled_width ) NEW_LINE self . feat_strides = np . fromstring ( feat_strides [ 1 : - 1 ] , dtype = int , sep = ' , ' ) NEW_LINE self . output_dim = int ( output_dim ) NEW_LINE self . num_strides = len ( self . feat_strides ) NEW_LINE DEDENT\",), (\"def list_arguments ( self ) : NEW_LINE INDENT args_list = [ ] NEW_LINE for i in range ( self . num_strides ) : NEW_LINE INDENT args_list . append ( ' data _ p { } ' . format ( 2 + i ) ) NEW_LINE DEDENT args_list . append ( ' Rrois ' ) NEW_LINE return args_list NEW_LINE DEDENT\",), (\"def list_outputs ( self ) : NEW_LINE INDENT return [ ' output ' ] NEW_LINE DEDENT\",), ('def infer_shape ( self , in_shape ) : NEW_LINE INDENT output_feat_shape = [ in_shape [ - 1 ] [ 0 ] , self . output_dim , self . pooled_height , self . pooled_width ] NEW_LINE return in_shape , [ output_feat_shape ] NEW_LINE DEDENT',), ('def create_operator ( self , ctx , shapes , dtypes ) : NEW_LINE INDENT return FPNPSROIROTATEDPoolingOperator ( self . feat_strides , self . pooled_height , self . pooled_width , self . output_dim ) NEW_LINE DEDENT',), ('def declare_backward_dependency ( self , out_grad , in_data , out_data ) : NEW_LINE INDENT return [ out_grad [ 0 ] ] NEW_LINE DEDENT',), ('def __init__ ( self , feat_strides , pooled_height , pooled_width , output_dim , pooling_mode ) : NEW_LINE INDENT self . pooled_height = pooled_height NEW_LINE self . pooled_width = pooled_width NEW_LINE self . feat_strides = feat_strides NEW_LINE self . pooling_mode = pooling_mode NEW_LINE self . output_dim = output_dim NEW_LINE self . in_grad_hist_list = [ ] NEW_LINE self . num_strides = len ( self . feat_strides ) NEW_LINE self . roi_pool = [ None for _ in range ( self . num_strides ) ] NEW_LINE self . feat_idx = [ None for _ in range ( self . num_strides ) ] NEW_LINE DEDENT',), (\"def backward ( self , req , out_grad , in_data , out_data , in_grad , aux ) : NEW_LINE INDENT for i in range ( len ( in_grad ) ) : NEW_LINE INDENT self . assign ( in_grad [ i ] , req [ i ] , 0 ) NEW_LINE DEDENT with autograd . train_section ( ) : NEW_LINE INDENT for i in range ( self . num_strides ) : NEW_LINE INDENT if len ( self . feat_idx [ i ] > 0 ) : NEW_LINE INDENT autograd . compute_gradient ( [ mx . nd . take ( out_grad [ 0 ] , mx . nd . array ( self . feat_idx [ i ] , out_grad [ 0 ] . context ) ) * self . roi_pool [ i ] ] ) NEW_LINE DEDENT DEDENT DEDENT if self . pooling_mode == ' deform ' : NEW_LINE INDENT for i in range ( 0 , self . num_strides * 3 ) : NEW_LINE INDENT self . assign ( in_grad [ i ] , req [ i ] , self . in_grad_hist_list [ i ] ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT for i in range ( 0 , self . num_strides ) : NEW_LINE INDENT self . assign ( in_grad [ i ] , req [ i ] , self . in_grad_hist_list [ i ] ) NEW_LINE DEDENT DEDENT gc . collect ( ) NEW_LINE DEDENT\",), (\"def __init__ ( self , feat_strides = ' ( 4,8,16,32 ) ' , pooled_height = '7' , pooled_width = '7' , pooling_mode = ' alignave ' , output_dim = '10' ) : NEW_LINE INDENT super ( FPNPSROIPooling_v2Prop , self ) . __init__ ( need_top_grad = True ) NEW_LINE self . pooled_height = int ( pooled_height ) NEW_LINE self . pooled_width = int ( pooled_width ) NEW_LINE self . feat_strides = np . fromstring ( feat_strides [ 1 : - 1 ] , dtype = int , sep = ' , ' ) NEW_LINE self . pooling_mode = pooling_mode NEW_LINE self . output_dim = int ( output_dim ) NEW_LINE self . num_strides = len ( self . feat_strides ) NEW_LINE DEDENT\",), (\"def list_arguments ( self ) : NEW_LINE INDENT args_list = [ ] NEW_LINE for i in range ( self . num_strides ) : NEW_LINE INDENT args_list . append ( ' data _ p { } ' . format ( 2 + i ) ) NEW_LINE DEDENT if self . pooling_mode == ' deform ' : NEW_LINE INDENT for i in range ( self . num_strides ) : NEW_LINE INDENT args_list . extend ( [ ' offset _ weight _ p { } ' . format ( 2 + i ) , ' offset _ bias _ p { } ' . format ( 2 + i ) ] ) NEW_LINE DEDENT DEDENT args_list . append ( ' rois ' ) NEW_LINE return args_list NEW_LINE DEDENT\",), (\"def list_outputs ( self ) : NEW_LINE INDENT return [ ' output ' ] NEW_LINE DEDENT\",), (\"def infer_shape ( self , in_shape ) : NEW_LINE INDENT output_feat_shape = [ in_shape [ - 1 ] [ 0 ] , self . output_dim , self . pooled_height , self . pooled_width ] NEW_LINE if self . pooling_mode == ' deform ' : NEW_LINE INDENT offset_dim = self . pooled_height * self . pooled_width * 2 NEW_LINE input_dim = self . pooled_height * self . pooled_width * self . output_dim NEW_LINE for i in range ( self . num_strides ) : NEW_LINE INDENT in_shape [ i * 2 + self . num_strides ] , in_shape [ i * 2 + 1 + self . num_strides ] = [ offset_dim , input_dim ] , [ offset_dim , ] NEW_LINE DEDENT DEDENT return in_shape , [ output_feat_shape ] NEW_LINE DEDENT\",), ('def create_operator ( self , ctx , shapes , dtypes ) : NEW_LINE INDENT return FPNPSROIPooling_v2Operator ( self . feat_strides , self . pooled_height , self . pooled_width , self . output_dim , self . pooling_mode ) NEW_LINE DEDENT',), ('def declare_backward_dependency ( self , out_grad , in_data , out_data ) : NEW_LINE INDENT return [ out_grad [ 0 ] ] NEW_LINE DEDENT',), ('def __init__ ( self , num_classes , batch_images , batch_rois , cfg , fg_fraction ) : NEW_LINE INDENT super ( ProposalTargetOperator , self ) . __init__ ( ) NEW_LINE self . _num_classes = num_classes NEW_LINE self . _batch_images = batch_images NEW_LINE self . _batch_rois = batch_rois NEW_LINE self . _cfg = cfg NEW_LINE self . _fg_fraction = fg_fraction NEW_LINE if DEBUG : NEW_LINE INDENT self . _count = 0 NEW_LINE self . _fg_num = 0 NEW_LINE self . _bg_num = 0 NEW_LINE DEDENT DEDENT',), ('def backward ( self , req , out_grad , in_data , out_data , in_grad , aux ) : NEW_LINE INDENT for i in range ( len ( in_grad ) ) : NEW_LINE INDENT self . assign ( in_grad [ i ] , req [ i ] , 0 ) NEW_LINE DEDENT DEDENT',), (\"def __init__ ( self , num_classes , batch_images , batch_rois , cfg , fg_fraction = '0.25' ) : NEW_LINE INDENT super ( ProposalTargetProp , self ) . __init__ ( need_top_grad = False ) NEW_LINE self . _num_classes = int ( num_classes ) NEW_LINE self . _batch_images = int ( batch_images ) NEW_LINE self . _batch_rois = int ( batch_rois ) NEW_LINE self . _cfg = cPickle . loads ( cfg ) NEW_LINE self . _fg_fraction = float ( fg_fraction ) NEW_LINE DEDENT\",), (\"def list_arguments ( self ) : NEW_LINE INDENT return [ ' rois ' , ' gt _ boxes ' ] NEW_LINE DEDENT\",), (\"def list_outputs ( self ) : NEW_LINE INDENT return [ ' rois _ output ' , ' label ' , ' bbox _ target ' , ' bbox _ weight ' ] NEW_LINE DEDENT\",), ('def infer_shape ( self , in_shape ) : NEW_LINE INDENT rpn_rois_shape = in_shape [ 0 ] NEW_LINE gt_boxes_shape = in_shape [ 1 ] NEW_LINE rois = rpn_rois_shape [ 0 ] + gt_boxes_shape [ 0 ] if self . _batch_rois == - 1 else self . _batch_rois NEW_LINE output_rois_shape = ( rois , 5 ) NEW_LINE label_shape = ( rois , ) NEW_LINE bbox_target_shape = ( rois , self . _num_classes * 4 ) NEW_LINE bbox_weight_shape = ( rois , self . _num_classes * 4 ) NEW_LINE return [ rpn_rois_shape , gt_boxes_shape ] , [ output_rois_shape , label_shape , bbox_target_shape , bbox_weight_shape ] NEW_LINE DEDENT',), ('def create_operator ( self , ctx , shapes , dtypes ) : NEW_LINE INDENT return ProposalTargetOperator ( self . _num_classes , self . _batch_images , self . _batch_rois , self . _cfg , self . _fg_fraction ) NEW_LINE DEDENT',), ('def declare_backward_dependency ( self , out_grad , in_data , out_data ) : NEW_LINE INDENT return [ ] NEW_LINE DEDENT',), ('def __init__ ( self , num_classes , batch_images , batch_rois , cfg , fg_fraction , fg_class_agnostic ) : NEW_LINE INDENT super ( ProposalTargetRotBoxOperator , self ) . __init__ ( ) NEW_LINE self . _num_classes = num_classes NEW_LINE self . _batch_images = batch_images NEW_LINE self . _batch_rois = batch_rois NEW_LINE self . _cfg = cfg NEW_LINE self . _fg_fraction = fg_fraction NEW_LINE self . _fg_class_agnostic = fg_class_agnostic NEW_LINE if DEBUG : NEW_LINE INDENT self . _count = 0 NEW_LINE self . _fg_num = 0 NEW_LINE self . _bg_num = 0 NEW_LINE DEDENT DEDENT',), ('def backward ( self , req , out_grad , in_data , out_data , in_grad , aux ) : NEW_LINE INDENT for i in range ( len ( in_grad ) ) : NEW_LINE INDENT self . assign ( in_grad [ i ] , req [ i ] , 0 ) NEW_LINE DEDENT DEDENT',), (\"def __init__ ( self , num_classes , batch_images , batch_rois , cfg , fg_class_agnostic = ' False ' , fg_fraction = '0.25' ) : NEW_LINE INDENT super ( ProposalTargetRotboxtProp , self ) . __init__ ( need_top_grad = False ) NEW_LINE self . _num_classes = int ( num_classes ) NEW_LINE self . _batch_images = int ( batch_images ) NEW_LINE self . _batch_rois = int ( batch_rois ) NEW_LINE self . _cfg = cPickle . loads ( cfg ) NEW_LINE self . _fg_class_agnostic = fg_class_agnostic == ' True ' NEW_LINE self . _fg_fraction = float ( fg_fraction ) NEW_LINE DEDENT\",), (\"def list_arguments ( self ) : NEW_LINE INDENT return [ ' rois ' , ' gt _ boxes ' ] NEW_LINE DEDENT\",), (\"def list_outputs ( self ) : NEW_LINE INDENT return [ ' rois _ output ' , ' label ' , ' bbox _ target ' , ' bbox _ weight ' ] NEW_LINE DEDENT\",), ('def infer_shape ( self , in_shape ) : NEW_LINE INDENT rpn_rois_shape = in_shape [ 0 ] NEW_LINE gt_boxes_shape = in_shape [ 1 ] NEW_LINE rois = rpn_rois_shape [ 0 ] + gt_boxes_shape [ 0 ] if self . _batch_rois == - 1 else self . _batch_rois NEW_LINE output_rois_shape = ( rois , 5 ) NEW_LINE label_shape = ( rois , ) NEW_LINE bbox_target_shape = ( rois , 5 * self . _num_classes ) NEW_LINE bbox_weight_shape = ( rois , 5 * self . _num_classes ) NEW_LINE return [ rpn_rois_shape , gt_boxes_shape ] , [ output_rois_shape , label_shape , bbox_target_shape , bbox_weight_shape ] NEW_LINE DEDENT',), ('def create_operator ( self , ctx , shapes , dtypes ) : NEW_LINE INDENT return ProposalTargetRotBoxOperator ( self . _num_classes , self . _batch_images , self . _batch_rois , self . _cfg , self . _fg_fraction , self . _fg_class_agnostic ) NEW_LINE DEDENT',), ('def declare_backward_dependency ( self , out_grad , in_data , out_data ) : NEW_LINE INDENT return [ ] NEW_LINE DEDENT',), ('def _filter_boxes ( boxes , min_size ) : NEW_LINE INDENT ws = boxes [ : , 2 ] NEW_LINE hs = boxes [ : , 3 ] NEW_LINE keep = np . where ( ( ws >= min_size ) & ( hs >= min_size ) ) [ 0 ] NEW_LINE return keep NEW_LINE DEDENT',), ('def _filter_boxes_v2 ( boxes , area ) : NEW_LINE INDENT ws = boxes [ : , 2 ] NEW_LINE hs = boxes [ : , 3 ] NEW_LINE keep = np . where ( ws * hs >= area ) [ 0 ] NEW_LINE return keep NEW_LINE DEDENT',), ('def __init__ ( self , pre_nms_top_n , post_nms_top_n , threshold , min_size , cfg ) : NEW_LINE INDENT super ( RRoIDecoderOperator , self ) . __init__ ( ) NEW_LINE self . _pre_nms_top_n = pre_nms_top_n NEW_LINE self . _post_nms_top_n = post_nms_top_n NEW_LINE self . _threshold = threshold NEW_LINE self . _min_size = min_size NEW_LINE self . _cfg = cfg NEW_LINE DEDENT',), ('def forward ( self , is_train , req , in_data , out_data , aux ) : NEW_LINE INDENT batch_size = in_data [ 0 ] [ 0 ] [ 0 ] NEW_LINE if batch_size . asnumpy ( ) > 1 : NEW_LINE INDENT raise ValueError ( \" Sorry , ▁ multiple ▁ images ▁ each ▁ device ▁ is ▁ not ▁ implemented \" ) NEW_LINE DEDENT rois = in_data [ 0 ] . asnumpy ( ) NEW_LINE st_pred = in_data [ 1 ] . asnumpy ( ) NEW_LINE st_score = in_data [ 2 ] . asnumpy ( ) [ : , : , 1 ] . reshape ( - 1 , 1 ) NEW_LINE im_info = in_data [ - 1 ] . asnumpy ( ) [ 0 , : ] NEW_LINE pre_nms_topN = self . _pre_nms_top_n NEW_LINE post_nms_topN = self . _post_nms_top_n NEW_LINE min_size = self . _min_size NEW_LINE cfg = self . _cfg NEW_LINE if is_train : NEW_LINE INDENT if cfg . TRAIN . BBOX_NORMALIZATION_PRECOMPUTED : NEW_LINE INDENT means = np . tile ( np . array ( cfg . TRAIN . BBOX_MEANS ) , 2 if cfg . CLASS_AGNOSTIC else cfg . dataset . NUM_CLASSES ) NEW_LINE stds = np . tile ( np . array ( cfg . TRAIN . BBOX_STDS ) , 2 if cfg . CLASS_AGNOSTIC else cfg . dataset . NUM_CLASSES ) NEW_LINE st_pred = st_pred * stds + means NEW_LINE DEDENT DEDENT Rrois = dbbox_transform2_inv_warp ( rois [ : , 1 : ] , st_pred ) [ : , 5 : ] NEW_LINE if ( len ( Rrois ) == 0 ) : NEW_LINE INDENT pdb . set_trace ( ) NEW_LINE DEDENT keep = self . _filter_boxes_v2 ( Rrois , min_size * im_info [ 2 ] * min_size * im_info [ 2 ] ) NEW_LINE keep_Rrois = Rrois [ keep ] NEW_LINE scores = st_score [ keep ] NEW_LINE if len ( keep_Rrois ) == 0 : NEW_LINE INDENT Rrois [ : , 2 ] = np . maximum ( Rrois [ : , 2 ] , min_size * im_info [ 2 ] ) NEW_LINE Rrois [ : , 3 ] = np . maximum ( Rrois [ : , 3 ] , min_size * im_info [ 2 ] ) NEW_LINE keep_Rrois = Rrois NEW_LINE scores = st_score NEW_LINE DEDENT proposals = RotBox2Polys ( keep_Rrois ) NEW_LINE order = scores . ravel ( ) . argsort ( ) [ : : - 1 ] NEW_LINE if pre_nms_topN > 0 : NEW_LINE INDENT order = order [ : pre_nms_topN ] NEW_LINE DEDENT proposals = proposals [ order , : ] NEW_LINE scores = scores [ order ] NEW_LINE det = np . hstack ( ( proposals , scores ) ) . astype ( np . float32 ) NEW_LINE keep = np . arange ( len ( det ) ) NEW_LINE if post_nms_topN > 0 : NEW_LINE INDENT keep = keep [ : post_nms_topN ] NEW_LINE DEDENT if len ( keep ) < post_nms_topN : NEW_LINE INDENT pad = npr . choice ( keep , size = post_nms_topN - len ( keep ) ) NEW_LINE keep = np . hstack ( ( keep , pad ) ) NEW_LINE DEDENT proposals = proposals [ keep , : ] NEW_LINE scores = scores [ keep ] NEW_LINE proposals = polygonToRotRectangle_batch ( proposals ) NEW_LINE proposals = choose_best_Rroi_batch ( proposals ) NEW_LINE batch_inds = np . zeros ( ( proposals . shape [ 0 ] , 1 ) , dtype = np . float32 ) NEW_LINE blob = np . hstack ( ( batch_inds , proposals . astype ( np . float32 , copy = False ) ) ) NEW_LINE self . assign ( out_data [ 0 ] , req [ 0 ] , blob ) NEW_LINE elarge_proposals = copy . deepcopy ( proposals ) NEW_LINE elarge_proposals [ : , 2 ] = proposals [ : , 2 ] * 1.2 NEW_LINE elarge_proposals [ : , 3 ] = proposals [ : , 3 ] * 1.4 NEW_LINE elarge_blob = np . hstack ( ( batch_inds , elarge_proposals . astype ( np . float32 , copy = False ) ) ) NEW_LINE self . assign ( out_data [ 1 ] , req [ 1 ] , elarge_blob ) NEW_LINE DEDENT',), ('def backward ( self , req , out_grad , in_data , out_data , in_grad , aux ) : NEW_LINE INDENT for i in range ( len ( in_grad ) ) : NEW_LINE INDENT self . assign ( in_grad [ i ] , req [ i ] , 0 ) NEW_LINE DEDENT DEDENT',), (\"def __init__ ( self , cfg , Rroi_pre_nms_top_n = '12000' , Rroi_post_nms_top_n = '2000' , threshold = '0.5' , min_size = '10' ) : NEW_LINE INDENT super ( RRoIDecoderProp , self ) . __init__ ( need_top_grad = False ) NEW_LINE self . _cfg = cPickle . loads ( cfg ) NEW_LINE self . _Rroi_pre_nms_top_n = int ( Rroi_pre_nms_top_n ) NEW_LINE self . _Rroi_post_nms_top_n = int ( Rroi_post_nms_top_n ) NEW_LINE self . _threshold = float ( threshold ) NEW_LINE self . _min_size = int ( min_size ) NEW_LINE DEDENT\",), (\"def list_arguments ( self ) : NEW_LINE INDENT return [ ' rois ' , ' bbox _ pred ' , ' cls _ prob ' , ' im _ info ' ] NEW_LINE DEDENT\",), (\"def list_outputs ( self ) : NEW_LINE INDENT return [ ' output ' , ' output _ rois _ L ' ] NEW_LINE DEDENT\",), ('def infer_shape ( self , in_shape ) : NEW_LINE INDENT output_shape = ( self . _Rroi_post_nms_top_n , 6 ) NEW_LINE return in_shape , [ output_shape , output_shape ] NEW_LINE DEDENT',), ('def create_operator ( self , ctx , shapes , dtypes ) : NEW_LINE INDENT return RRoIDecoderOperator ( self . _Rroi_pre_nms_top_n , self . _Rroi_post_nms_top_n , self . _threshold , self . _min_size , self . _cfg ) NEW_LINE DEDENT',), ('def declare_backward_dependency ( self , out_grad , in_data , out_data ) : NEW_LINE INDENT return [ ] NEW_LINE DEDENT',), ('def update_config ( config_file ) : NEW_LINE INDENT exp_config = None NEW_LINE with open ( config_file ) as f : NEW_LINE INDENT exp_config = edict ( yaml . load ( f ) ) NEW_LINE for k , v in exp_config . items ( ) : NEW_LINE INDENT if k in config : NEW_LINE INDENT if isinstance ( v , dict ) : NEW_LINE INDENT if k == \\' TRAIN \\' : NEW_LINE INDENT if \\' BBOX _ WEIGHTS \\' in v : NEW_LINE INDENT v [ \\' BBOX _ WEIGHTS \\' ] = np . array ( v [ \\' BBOX _ WEIGHTS \\' ] ) NEW_LINE DEDENT DEDENT elif k == \\' network \\' : NEW_LINE INDENT if \\' PIXEL _ MEANS \\' in v : NEW_LINE INDENT v [ \\' PIXEL _ MEANS \\' ] = np . array ( v [ \\' PIXEL _ MEANS \\' ] ) NEW_LINE DEDENT DEDENT for vk , vv in v . items ( ) : NEW_LINE INDENT config [ k ] [ vk ] = vv NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT if k == \\' SCALES \\' : NEW_LINE INDENT config [ k ] [ 0 ] = ( tuple ( v ) ) NEW_LINE DEDENT else : NEW_LINE INDENT config [ k ] = v NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT raise ValueError ( \" key ▁ must ▁ exist ▁ in ▁ config . py \" ) NEW_LINE DEDENT DEDENT DEDENT DEDENT',), (\"def __init__ ( self ) : NEW_LINE INDENT self . shared_param_list = [ ' rpn _ conv ' , ' rpn _ cls _ score ' , ' rpn _ bbox _ pred ' , ' conv _ new _ 1' , ' conv _ new _ 2' , ' conv _ new _ 3' , ' conv _ new _ 4' ] NEW_LINE self . shared_param_dict = { } NEW_LINE for name in self . shared_param_list : NEW_LINE INDENT self . shared_param_dict [ name + ' _ weight ' ] = mx . sym . Variable ( name + ' _ weight ' ) NEW_LINE self . shared_param_dict [ name + ' _ bias ' ] = mx . sym . Variable ( name + ' _ bias ' ) NEW_LINE DEDENT DEDENT\",), (\"def get_resnet_backbone ( self , data , with_dilated = False , with_dconv = False , with_dpyramid = False , eps = 1e-5 ) : NEW_LINE INDENT conv1 = mx . symbol . Convolution ( name = ' conv1' , data = data , num_filter = 64 , pad = ( 3 , 3 ) , kernel = ( 7 , 7 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn_conv1 = mx . symbol . BatchNorm ( name = ' bn _ conv1' , data = conv1 , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale_conv1 = bn_conv1 NEW_LINE conv1_relu = mx . symbol . Activation ( name = ' conv1 _ relu ' , data = scale_conv1 , act_type = ' relu ' ) NEW_LINE pool1 = mx . symbol . Pooling ( name = ' pool1' , data = conv1_relu , pooling_convention = ' full ' , pad = ( 0 , 0 ) , kernel = ( 3 , 3 ) , stride = ( 2 , 2 ) , pool_type = ' max ' ) NEW_LINE res2a_branch1 = mx . symbol . Convolution ( name = ' res2a _ branch1' , data = pool1 , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch1 = mx . symbol . BatchNorm ( name = ' bn2a _ branch1' , data = res2a_branch1 , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2a_branch1 = bn2a_branch1 NEW_LINE res2a_branch2a = mx . symbol . Convolution ( name = ' res2a _ branch2a ' , data = pool1 , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2a = mx . symbol . BatchNorm ( name = ' bn2a _ branch2a ' , data = res2a_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2a_branch2a = bn2a_branch2a NEW_LINE res2a_branch2a_relu = mx . symbol . Activation ( name = ' res2a _ branch2a _ relu ' , data = scale2a_branch2a , act_type = ' relu ' ) NEW_LINE res2a_branch2b = mx . symbol . Convolution ( name = ' res2a _ branch2b ' , data = res2a_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2b = mx . symbol . BatchNorm ( name = ' bn2a _ branch2b ' , data = res2a_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2a_branch2b = bn2a_branch2b NEW_LINE res2a_branch2b_relu = mx . symbol . Activation ( name = ' res2a _ branch2b _ relu ' , data = scale2a_branch2b , act_type = ' relu ' ) NEW_LINE res2a_branch2c = mx . symbol . Convolution ( name = ' res2a _ branch2c ' , data = res2a_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2c = mx . symbol . BatchNorm ( name = ' bn2a _ branch2c ' , data = res2a_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2a_branch2c = bn2a_branch2c NEW_LINE res2a = mx . symbol . broadcast_add ( name = ' res2a ' , * [ scale2a_branch1 , scale2a_branch2c ] ) NEW_LINE res2a_relu = mx . symbol . Activation ( name = ' res2a _ relu ' , data = res2a , act_type = ' relu ' ) NEW_LINE res2b_branch2a = mx . symbol . Convolution ( name = ' res2b _ branch2a ' , data = res2a_relu , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2a = mx . symbol . BatchNorm ( name = ' bn2b _ branch2a ' , data = res2b_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2b_branch2a = bn2b_branch2a NEW_LINE res2b_branch2a_relu = mx . symbol . Activation ( name = ' res2b _ branch2a _ relu ' , data = scale2b_branch2a , act_type = ' relu ' ) NEW_LINE res2b_branch2b = mx . symbol . Convolution ( name = ' res2b _ branch2b ' , data = res2b_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2b = mx . symbol . BatchNorm ( name = ' bn2b _ branch2b ' , data = res2b_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2b_branch2b = bn2b_branch2b NEW_LINE res2b_branch2b_relu = mx . symbol . Activation ( name = ' res2b _ branch2b _ relu ' , data = scale2b_branch2b , act_type = ' relu ' ) NEW_LINE res2b_branch2c = mx . symbol . Convolution ( name = ' res2b _ branch2c ' , data = res2b_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2c = mx . symbol . BatchNorm ( name = ' bn2b _ branch2c ' , data = res2b_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2b_branch2c = bn2b_branch2c NEW_LINE res2b = mx . symbol . broadcast_add ( name = ' res2b ' , * [ res2a_relu , scale2b_branch2c ] ) NEW_LINE res2b_relu = mx . symbol . Activation ( name = ' res2b _ relu ' , data = res2b , act_type = ' relu ' ) NEW_LINE res2c_branch2a = mx . symbol . Convolution ( name = ' res2c _ branch2a ' , data = res2b_relu , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2a = mx . symbol . BatchNorm ( name = ' bn2c _ branch2a ' , data = res2c_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2c_branch2a = bn2c_branch2a NEW_LINE res2c_branch2a_relu = mx . symbol . Activation ( name = ' res2c _ branch2a _ relu ' , data = scale2c_branch2a , act_type = ' relu ' ) NEW_LINE res2c_branch2b = mx . symbol . Convolution ( name = ' res2c _ branch2b ' , data = res2c_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2b = mx . symbol . BatchNorm ( name = ' bn2c _ branch2b ' , data = res2c_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2c_branch2b = bn2c_branch2b NEW_LINE res2c_branch2b_relu = mx . symbol . Activation ( name = ' res2c _ branch2b _ relu ' , data = scale2c_branch2b , act_type = ' relu ' ) NEW_LINE res2c_branch2c = mx . symbol . Convolution ( name = ' res2c _ branch2c ' , data = res2c_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2c = mx . symbol . BatchNorm ( name = ' bn2c _ branch2c ' , data = res2c_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2c_branch2c = bn2c_branch2c NEW_LINE res2c = mx . symbol . broadcast_add ( name = ' res2c ' , * [ res2b_relu , scale2c_branch2c ] ) NEW_LINE res2c_relu = mx . symbol . Activation ( name = ' res2c _ relu ' , data = res2c , act_type = ' relu ' ) NEW_LINE res3a_branch1 = mx . symbol . Convolution ( name = ' res3a _ branch1' , data = res2c_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn3a_branch1 = mx . symbol . BatchNorm ( name = ' bn3a _ branch1' , data = res3a_branch1 , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3a_branch1 = bn3a_branch1 NEW_LINE res3a_branch2a = mx . symbol . Convolution ( name = ' res3a _ branch2a ' , data = res2c_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn3a_branch2a = mx . symbol . BatchNorm ( name = ' bn3a _ branch2a ' , data = res3a_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3a_branch2a = bn3a_branch2a NEW_LINE res3a_branch2a_relu = mx . symbol . Activation ( name = ' res3a _ branch2a _ relu ' , data = scale3a_branch2a , act_type = ' relu ' ) NEW_LINE res3a_branch2b = mx . symbol . Convolution ( name = ' res3a _ branch2b ' , data = res3a_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3a_branch2b = mx . symbol . BatchNorm ( name = ' bn3a _ branch2b ' , data = res3a_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3a_branch2b = bn3a_branch2b NEW_LINE res3a_branch2b_relu = mx . symbol . Activation ( name = ' res3a _ branch2b _ relu ' , data = scale3a_branch2b , act_type = ' relu ' ) NEW_LINE res3a_branch2c = mx . symbol . Convolution ( name = ' res3a _ branch2c ' , data = res3a_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3a_branch2c = mx . symbol . BatchNorm ( name = ' bn3a _ branch2c ' , data = res3a_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3a_branch2c = bn3a_branch2c NEW_LINE res3a = mx . symbol . broadcast_add ( name = ' res3a ' , * [ scale3a_branch1 , scale3a_branch2c ] ) NEW_LINE res3a_relu = mx . symbol . Activation ( name = ' res3a _ relu ' , data = res3a , act_type = ' relu ' ) NEW_LINE res3b1_branch2a = mx . symbol . Convolution ( name = ' res3b1 _ branch2a ' , data = res3a_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2a = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2a ' , data = res3b1_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b1_branch2a = bn3b1_branch2a NEW_LINE res3b1_branch2a_relu = mx . symbol . Activation ( name = ' res3b1 _ branch2a _ relu ' , data = scale3b1_branch2a , act_type = ' relu ' ) NEW_LINE res3b1_branch2b = mx . symbol . Convolution ( name = ' res3b1 _ branch2b ' , data = res3b1_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2b = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2b ' , data = res3b1_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b1_branch2b = bn3b1_branch2b NEW_LINE res3b1_branch2b_relu = mx . symbol . Activation ( name = ' res3b1 _ branch2b _ relu ' , data = scale3b1_branch2b , act_type = ' relu ' ) NEW_LINE res3b1_branch2c = mx . symbol . Convolution ( name = ' res3b1 _ branch2c ' , data = res3b1_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2c = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2c ' , data = res3b1_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b1_branch2c = bn3b1_branch2c NEW_LINE res3b1 = mx . symbol . broadcast_add ( name = ' res3b1' , * [ res3a_relu , scale3b1_branch2c ] ) NEW_LINE res3b1_relu = mx . symbol . Activation ( name = ' res3b1 _ relu ' , data = res3b1 , act_type = ' relu ' ) NEW_LINE res3b2_branch2a = mx . symbol . Convolution ( name = ' res3b2 _ branch2a ' , data = res3b1_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2a = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2a ' , data = res3b2_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b2_branch2a = bn3b2_branch2a NEW_LINE res3b2_branch2a_relu = mx . symbol . Activation ( name = ' res3b2 _ branch2a _ relu ' , data = scale3b2_branch2a , act_type = ' relu ' ) NEW_LINE res3b2_branch2b = mx . symbol . Convolution ( name = ' res3b2 _ branch2b ' , data = res3b2_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2b = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2b ' , data = res3b2_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b2_branch2b = bn3b2_branch2b NEW_LINE res3b2_branch2b_relu = mx . symbol . Activation ( name = ' res3b2 _ branch2b _ relu ' , data = scale3b2_branch2b , act_type = ' relu ' ) NEW_LINE res3b2_branch2c = mx . symbol . Convolution ( name = ' res3b2 _ branch2c ' , data = res3b2_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2c = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2c ' , data = res3b2_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b2_branch2c = bn3b2_branch2c NEW_LINE res3b2 = mx . symbol . broadcast_add ( name = ' res3b2' , * [ res3b1_relu , scale3b2_branch2c ] ) NEW_LINE res3b2_relu = mx . symbol . Activation ( name = ' res3b2 _ relu ' , data = res3b2 , act_type = ' relu ' ) NEW_LINE res3b3_branch2a = mx . symbol . Convolution ( name = ' res3b3 _ branch2a ' , data = res3b2_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b3_branch2a = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2a ' , data = res3b3_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b3_branch2a = bn3b3_branch2a NEW_LINE res3b3_branch2a_relu = mx . symbol . Activation ( name = ' res3b3 _ branch2a _ relu ' , data = scale3b3_branch2a , act_type = ' relu ' ) NEW_LINE if with_dpyramid : NEW_LINE INDENT res3b3_branch2b_offset = mx . symbol . Convolution ( name = ' res3b3 _ branch2b _ offset ' , data = res3b3_branch2a_relu , num_filter = 72 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) ) NEW_LINE res3b3_branch2b = mx . contrib . symbol . DeformableConvolution ( name = ' res3b3 _ branch2b ' , data = res3b3_branch2a_relu , offset = res3b3_branch2b_offset , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , num_deformable_group = 4 , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE DEDENT else : NEW_LINE INDENT res3b3_branch2b = mx . symbol . Convolution ( name = ' res3b3 _ branch2b ' , data = res3b3_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE DEDENT bn3b3_branch2b = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2b ' , data = res3b3_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b3_branch2b = bn3b3_branch2b NEW_LINE res3b3_branch2b_relu = mx . symbol . Activation ( name = ' res3b3 _ branch2b _ relu ' , data = scale3b3_branch2b , act_type = ' relu ' ) NEW_LINE res3b3_branch2c = mx . symbol . Convolution ( name = ' res3b3 _ branch2c ' , data = res3b3_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b3_branch2c = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2c ' , data = res3b3_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b3_branch2c = bn3b3_branch2c NEW_LINE res3b3 = mx . symbol . broadcast_add ( name = ' res3b3' , * [ res3b2_relu , scale3b3_branch2c ] ) NEW_LINE res3b3_relu = mx . symbol . Activation ( name = ' res3b3 _ relu ' , data = res3b3 , act_type = ' relu ' ) NEW_LINE res4a_branch1 = mx . symbol . Convolution ( name = ' res4a _ branch1' , data = res3b3_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn4a_branch1 = mx . symbol . BatchNorm ( name = ' bn4a _ branch1' , data = res4a_branch1 , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4a_branch1 = bn4a_branch1 NEW_LINE res4a_branch2a = mx . symbol . Convolution ( name = ' res4a _ branch2a ' , data = res3b3_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn4a_branch2a = mx . symbol . BatchNorm ( name = ' bn4a _ branch2a ' , data = res4a_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4a_branch2a = bn4a_branch2a NEW_LINE res4a_branch2a_relu = mx . symbol . Activation ( name = ' res4a _ branch2a _ relu ' , data = scale4a_branch2a , act_type = ' relu ' ) NEW_LINE res4a_branch2b = mx . symbol . Convolution ( name = ' res4a _ branch2b ' , data = res4a_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4a_branch2b = mx . symbol . BatchNorm ( name = ' bn4a _ branch2b ' , data = res4a_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4a_branch2b = bn4a_branch2b NEW_LINE res4a_branch2b_relu = mx . symbol . Activation ( name = ' res4a _ branch2b _ relu ' , data = scale4a_branch2b , act_type = ' relu ' ) NEW_LINE res4a_branch2c = mx . symbol . Convolution ( name = ' res4a _ branch2c ' , data = res4a_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4a_branch2c = mx . symbol . BatchNorm ( name = ' bn4a _ branch2c ' , data = res4a_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4a_branch2c = bn4a_branch2c NEW_LINE res4a = mx . symbol . broadcast_add ( name = ' res4a ' , * [ scale4a_branch1 , scale4a_branch2c ] ) NEW_LINE res4a_relu = mx . symbol . Activation ( name = ' res4a _ relu ' , data = res4a , act_type = ' relu ' ) NEW_LINE res4b1_branch2a = mx . symbol . Convolution ( name = ' res4b1 _ branch2a ' , data = res4a_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2a = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2a ' , data = res4b1_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b1_branch2a = bn4b1_branch2a NEW_LINE res4b1_branch2a_relu = mx . symbol . Activation ( name = ' res4b1 _ branch2a _ relu ' , data = scale4b1_branch2a , act_type = ' relu ' ) NEW_LINE res4b1_branch2b = mx . symbol . Convolution ( name = ' res4b1 _ branch2b ' , data = res4b1_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2b = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2b ' , data = res4b1_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b1_branch2b = bn4b1_branch2b NEW_LINE res4b1_branch2b_relu = mx . symbol . Activation ( name = ' res4b1 _ branch2b _ relu ' , data = scale4b1_branch2b , act_type = ' relu ' ) NEW_LINE res4b1_branch2c = mx . symbol . Convolution ( name = ' res4b1 _ branch2c ' , data = res4b1_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2c = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2c ' , data = res4b1_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b1_branch2c = bn4b1_branch2c NEW_LINE res4b1 = mx . symbol . broadcast_add ( name = ' res4b1' , * [ res4a_relu , scale4b1_branch2c ] ) NEW_LINE res4b1_relu = mx . symbol . Activation ( name = ' res4b1 _ relu ' , data = res4b1 , act_type = ' relu ' ) NEW_LINE res4b2_branch2a = mx . symbol . Convolution ( name = ' res4b2 _ branch2a ' , data = res4b1_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2a = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2a ' , data = res4b2_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b2_branch2a = bn4b2_branch2a NEW_LINE res4b2_branch2a_relu = mx . symbol . Activation ( name = ' res4b2 _ branch2a _ relu ' , data = scale4b2_branch2a , act_type = ' relu ' ) NEW_LINE res4b2_branch2b = mx . symbol . Convolution ( name = ' res4b2 _ branch2b ' , data = res4b2_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2b = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2b ' , data = res4b2_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b2_branch2b = bn4b2_branch2b NEW_LINE res4b2_branch2b_relu = mx . symbol . Activation ( name = ' res4b2 _ branch2b _ relu ' , data = scale4b2_branch2b , act_type = ' relu ' ) NEW_LINE res4b2_branch2c = mx . symbol . Convolution ( name = ' res4b2 _ branch2c ' , data = res4b2_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2c = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2c ' , data = res4b2_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b2_branch2c = bn4b2_branch2c NEW_LINE res4b2 = mx . symbol . broadcast_add ( name = ' res4b2' , * [ res4b1_relu , scale4b2_branch2c ] ) NEW_LINE res4b2_relu = mx . symbol . Activation ( name = ' res4b2 _ relu ' , data = res4b2 , act_type = ' relu ' ) NEW_LINE res4b3_branch2a = mx . symbol . Convolution ( name = ' res4b3 _ branch2a ' , data = res4b2_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2a = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2a ' , data = res4b3_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b3_branch2a = bn4b3_branch2a NEW_LINE res4b3_branch2a_relu = mx . symbol . Activation ( name = ' res4b3 _ branch2a _ relu ' , data = scale4b3_branch2a , act_type = ' relu ' ) NEW_LINE res4b3_branch2b = mx . symbol . Convolution ( name = ' res4b3 _ branch2b ' , data = res4b3_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2b = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2b ' , data = res4b3_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b3_branch2b = bn4b3_branch2b NEW_LINE res4b3_branch2b_relu = mx . symbol . Activation ( name = ' res4b3 _ branch2b _ relu ' , data = scale4b3_branch2b , act_type = ' relu ' ) NEW_LINE res4b3_branch2c = mx . symbol . Convolution ( name = ' res4b3 _ branch2c ' , data = res4b3_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2c = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2c ' , data = res4b3_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b3_branch2c = bn4b3_branch2c NEW_LINE res4b3 = mx . symbol . broadcast_add ( name = ' res4b3' , * [ res4b2_relu , scale4b3_branch2c ] ) NEW_LINE res4b3_relu = mx . symbol . Activation ( name = ' res4b3 _ relu ' , data = res4b3 , act_type = ' relu ' ) NEW_LINE res4b4_branch2a = mx . symbol . Convolution ( name = ' res4b4 _ branch2a ' , data = res4b3_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2a = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2a ' , data = res4b4_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b4_branch2a = bn4b4_branch2a NEW_LINE res4b4_branch2a_relu = mx . symbol . Activation ( name = ' res4b4 _ branch2a _ relu ' , data = scale4b4_branch2a , act_type = ' relu ' ) NEW_LINE res4b4_branch2b = mx . symbol . Convolution ( name = ' res4b4 _ branch2b ' , data = res4b4_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2b = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2b ' , data = res4b4_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b4_branch2b = bn4b4_branch2b NEW_LINE res4b4_branch2b_relu = mx . symbol . Activation ( name = ' res4b4 _ branch2b _ relu ' , data = scale4b4_branch2b , act_type = ' relu ' ) NEW_LINE res4b4_branch2c = mx . symbol . Convolution ( name = ' res4b4 _ branch2c ' , data = res4b4_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2c = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2c ' , data = res4b4_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b4_branch2c = bn4b4_branch2c NEW_LINE res4b4 = mx . symbol . broadcast_add ( name = ' res4b4' , * [ res4b3_relu , scale4b4_branch2c ] ) NEW_LINE res4b4_relu = mx . symbol . Activation ( name = ' res4b4 _ relu ' , data = res4b4 , act_type = ' relu ' ) NEW_LINE res4b5_branch2a = mx . symbol . Convolution ( name = ' res4b5 _ branch2a ' , data = res4b4_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2a = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2a ' , data = res4b5_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b5_branch2a = bn4b5_branch2a NEW_LINE res4b5_branch2a_relu = mx . symbol . Activation ( name = ' res4b5 _ branch2a _ relu ' , data = scale4b5_branch2a , act_type = ' relu ' ) NEW_LINE res4b5_branch2b = mx . symbol . Convolution ( name = ' res4b5 _ branch2b ' , data = res4b5_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2b = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2b ' , data = res4b5_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b5_branch2b = bn4b5_branch2b NEW_LINE res4b5_branch2b_relu = mx . symbol . Activation ( name = ' res4b5 _ branch2b _ relu ' , data = scale4b5_branch2b , act_type = ' relu ' ) NEW_LINE res4b5_branch2c = mx . symbol . Convolution ( name = ' res4b5 _ branch2c ' , data = res4b5_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2c = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2c ' , data = res4b5_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b5_branch2c = bn4b5_branch2c NEW_LINE res4b5 = mx . symbol . broadcast_add ( name = ' res4b5' , * [ res4b4_relu , scale4b5_branch2c ] ) NEW_LINE res4b5_relu = mx . symbol . Activation ( name = ' res4b5 _ relu ' , data = res4b5 , act_type = ' relu ' ) NEW_LINE res4b6_branch2a = mx . symbol . Convolution ( name = ' res4b6 _ branch2a ' , data = res4b5_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2a = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2a ' , data = res4b6_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b6_branch2a = bn4b6_branch2a NEW_LINE res4b6_branch2a_relu = mx . symbol . Activation ( name = ' res4b6 _ branch2a _ relu ' , data = scale4b6_branch2a , act_type = ' relu ' ) NEW_LINE res4b6_branch2b = mx . symbol . Convolution ( name = ' res4b6 _ branch2b ' , data = res4b6_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2b = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2b ' , data = res4b6_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b6_branch2b = bn4b6_branch2b NEW_LINE res4b6_branch2b_relu = mx . symbol . Activation ( name = ' res4b6 _ branch2b _ relu ' , data = scale4b6_branch2b , act_type = ' relu ' ) NEW_LINE res4b6_branch2c = mx . symbol . Convolution ( name = ' res4b6 _ branch2c ' , data = res4b6_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2c = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2c ' , data = res4b6_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b6_branch2c = bn4b6_branch2c NEW_LINE res4b6 = mx . symbol . broadcast_add ( name = ' res4b6' , * [ res4b5_relu , scale4b6_branch2c ] ) NEW_LINE res4b6_relu = mx . symbol . Activation ( name = ' res4b6 _ relu ' , data = res4b6 , act_type = ' relu ' ) NEW_LINE res4b7_branch2a = mx . symbol . Convolution ( name = ' res4b7 _ branch2a ' , data = res4b6_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2a = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2a ' , data = res4b7_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b7_branch2a = bn4b7_branch2a NEW_LINE res4b7_branch2a_relu = mx . symbol . Activation ( name = ' res4b7 _ branch2a _ relu ' , data = scale4b7_branch2a , act_type = ' relu ' ) NEW_LINE res4b7_branch2b = mx . symbol . Convolution ( name = ' res4b7 _ branch2b ' , data = res4b7_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2b = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2b ' , data = res4b7_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b7_branch2b = bn4b7_branch2b NEW_LINE res4b7_branch2b_relu = mx . symbol . Activation ( name = ' res4b7 _ branch2b _ relu ' , data = scale4b7_branch2b , act_type = ' relu ' ) NEW_LINE res4b7_branch2c = mx . symbol . Convolution ( name = ' res4b7 _ branch2c ' , data = res4b7_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2c = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2c ' , data = res4b7_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b7_branch2c = bn4b7_branch2c NEW_LINE res4b7 = mx . symbol . broadcast_add ( name = ' res4b7' , * [ res4b6_relu , scale4b7_branch2c ] ) NEW_LINE res4b7_relu = mx . symbol . Activation ( name = ' res4b7 _ relu ' , data = res4b7 , act_type = ' relu ' ) NEW_LINE res4b8_branch2a = mx . symbol . Convolution ( name = ' res4b8 _ branch2a ' , data = res4b7_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2a = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2a ' , data = res4b8_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b8_branch2a = bn4b8_branch2a NEW_LINE res4b8_branch2a_relu = mx . symbol . Activation ( name = ' res4b8 _ branch2a _ relu ' , data = scale4b8_branch2a , act_type = ' relu ' ) NEW_LINE res4b8_branch2b = mx . symbol . Convolution ( name = ' res4b8 _ branch2b ' , data = res4b8_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2b = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2b ' , data = res4b8_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b8_branch2b = bn4b8_branch2b NEW_LINE res4b8_branch2b_relu = mx . symbol . Activation ( name = ' res4b8 _ branch2b _ relu ' , data = scale4b8_branch2b , act_type = ' relu ' ) NEW_LINE res4b8_branch2c = mx . symbol . Convolution ( name = ' res4b8 _ branch2c ' , data = res4b8_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2c = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2c ' , data = res4b8_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b8_branch2c = bn4b8_branch2c NEW_LINE res4b8 = mx . symbol . broadcast_add ( name = ' res4b8' , * [ res4b7_relu , scale4b8_branch2c ] ) NEW_LINE res4b8_relu = mx . symbol . Activation ( name = ' res4b8 _ relu ' , data = res4b8 , act_type = ' relu ' ) NEW_LINE res4b9_branch2a = mx . symbol . Convolution ( name = ' res4b9 _ branch2a ' , data = res4b8_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2a = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2a ' , data = res4b9_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b9_branch2a = bn4b9_branch2a NEW_LINE res4b9_branch2a_relu = mx . symbol . Activation ( name = ' res4b9 _ branch2a _ relu ' , data = scale4b9_branch2a , act_type = ' relu ' ) NEW_LINE res4b9_branch2b = mx . symbol . Convolution ( name = ' res4b9 _ branch2b ' , data = res4b9_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2b = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2b ' , data = res4b9_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b9_branch2b = bn4b9_branch2b NEW_LINE res4b9_branch2b_relu = mx . symbol . Activation ( name = ' res4b9 _ branch2b _ relu ' , data = scale4b9_branch2b , act_type = ' relu ' ) NEW_LINE res4b9_branch2c = mx . symbol . Convolution ( name = ' res4b9 _ branch2c ' , data = res4b9_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2c = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2c ' , data = res4b9_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b9_branch2c = bn4b9_branch2c NEW_LINE res4b9 = mx . symbol . broadcast_add ( name = ' res4b9' , * [ res4b8_relu , scale4b9_branch2c ] ) NEW_LINE res4b9_relu = mx . symbol . Activation ( name = ' res4b9 _ relu ' , data = res4b9 , act_type = ' relu ' ) NEW_LINE res4b10_branch2a = mx . symbol . Convolution ( name = ' res4b10 _ branch2a ' , data = res4b9_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2a = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2a ' , data = res4b10_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b10_branch2a = bn4b10_branch2a NEW_LINE res4b10_branch2a_relu = mx . symbol . Activation ( name = ' res4b10 _ branch2a _ relu ' , data = scale4b10_branch2a , act_type = ' relu ' ) NEW_LINE res4b10_branch2b = mx . symbol . Convolution ( name = ' res4b10 _ branch2b ' , data = res4b10_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2b = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2b ' , data = res4b10_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b10_branch2b = bn4b10_branch2b NEW_LINE res4b10_branch2b_relu = mx . symbol . Activation ( name = ' res4b10 _ branch2b _ relu ' , data = scale4b10_branch2b , act_type = ' relu ' ) NEW_LINE res4b10_branch2c = mx . symbol . Convolution ( name = ' res4b10 _ branch2c ' , data = res4b10_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2c = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2c ' , data = res4b10_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b10_branch2c = bn4b10_branch2c NEW_LINE res4b10 = mx . symbol . broadcast_add ( name = ' res4b10' , * [ res4b9_relu , scale4b10_branch2c ] ) NEW_LINE res4b10_relu = mx . symbol . Activation ( name = ' res4b10 _ relu ' , data = res4b10 , act_type = ' relu ' ) NEW_LINE res4b11_branch2a = mx . symbol . Convolution ( name = ' res4b11 _ branch2a ' , data = res4b10_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2a = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2a ' , data = res4b11_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b11_branch2a = bn4b11_branch2a NEW_LINE res4b11_branch2a_relu = mx . symbol . Activation ( name = ' res4b11 _ branch2a _ relu ' , data = scale4b11_branch2a , act_type = ' relu ' ) NEW_LINE res4b11_branch2b = mx . symbol . Convolution ( name = ' res4b11 _ branch2b ' , data = res4b11_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2b = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2b ' , data = res4b11_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b11_branch2b = bn4b11_branch2b NEW_LINE res4b11_branch2b_relu = mx . symbol . Activation ( name = ' res4b11 _ branch2b _ relu ' , data = scale4b11_branch2b , act_type = ' relu ' ) NEW_LINE res4b11_branch2c = mx . symbol . Convolution ( name = ' res4b11 _ branch2c ' , data = res4b11_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2c = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2c ' , data = res4b11_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b11_branch2c = bn4b11_branch2c NEW_LINE res4b11 = mx . symbol . broadcast_add ( name = ' res4b11' , * [ res4b10_relu , scale4b11_branch2c ] ) NEW_LINE res4b11_relu = mx . symbol . Activation ( name = ' res4b11 _ relu ' , data = res4b11 , act_type = ' relu ' ) NEW_LINE res4b12_branch2a = mx . symbol . Convolution ( name = ' res4b12 _ branch2a ' , data = res4b11_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2a = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2a ' , data = res4b12_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b12_branch2a = bn4b12_branch2a NEW_LINE res4b12_branch2a_relu = mx . symbol . Activation ( name = ' res4b12 _ branch2a _ relu ' , data = scale4b12_branch2a , act_type = ' relu ' ) NEW_LINE res4b12_branch2b = mx . symbol . Convolution ( name = ' res4b12 _ branch2b ' , data = res4b12_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2b = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2b ' , data = res4b12_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b12_branch2b = bn4b12_branch2b NEW_LINE res4b12_branch2b_relu = mx . symbol . Activation ( name = ' res4b12 _ branch2b _ relu ' , data = scale4b12_branch2b , act_type = ' relu ' ) NEW_LINE res4b12_branch2c = mx . symbol . Convolution ( name = ' res4b12 _ branch2c ' , data = res4b12_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2c = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2c ' , data = res4b12_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b12_branch2c = bn4b12_branch2c NEW_LINE res4b12 = mx . symbol . broadcast_add ( name = ' res4b12' , * [ res4b11_relu , scale4b12_branch2c ] ) NEW_LINE res4b12_relu = mx . symbol . Activation ( name = ' res4b12 _ relu ' , data = res4b12 , act_type = ' relu ' ) NEW_LINE res4b13_branch2a = mx . symbol . Convolution ( name = ' res4b13 _ branch2a ' , data = res4b12_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2a = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2a ' , data = res4b13_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b13_branch2a = bn4b13_branch2a NEW_LINE res4b13_branch2a_relu = mx . symbol . Activation ( name = ' res4b13 _ branch2a _ relu ' , data = scale4b13_branch2a , act_type = ' relu ' ) NEW_LINE res4b13_branch2b = mx . symbol . Convolution ( name = ' res4b13 _ branch2b ' , data = res4b13_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2b = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2b ' , data = res4b13_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b13_branch2b = bn4b13_branch2b NEW_LINE res4b13_branch2b_relu = mx . symbol . Activation ( name = ' res4b13 _ branch2b _ relu ' , data = scale4b13_branch2b , act_type = ' relu ' ) NEW_LINE res4b13_branch2c = mx . symbol . Convolution ( name = ' res4b13 _ branch2c ' , data = res4b13_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2c = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2c ' , data = res4b13_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b13_branch2c = bn4b13_branch2c NEW_LINE res4b13 = mx . symbol . broadcast_add ( name = ' res4b13' , * [ res4b12_relu , scale4b13_branch2c ] ) NEW_LINE res4b13_relu = mx . symbol . Activation ( name = ' res4b13 _ relu ' , data = res4b13 , act_type = ' relu ' ) NEW_LINE res4b14_branch2a = mx . symbol . Convolution ( name = ' res4b14 _ branch2a ' , data = res4b13_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2a = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2a ' , data = res4b14_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b14_branch2a = bn4b14_branch2a NEW_LINE res4b14_branch2a_relu = mx . symbol . Activation ( name = ' res4b14 _ branch2a _ relu ' , data = scale4b14_branch2a , act_type = ' relu ' ) NEW_LINE res4b14_branch2b = mx . symbol . Convolution ( name = ' res4b14 _ branch2b ' , data = res4b14_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2b = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2b ' , data = res4b14_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b14_branch2b = bn4b14_branch2b NEW_LINE res4b14_branch2b_relu = mx . symbol . Activation ( name = ' res4b14 _ branch2b _ relu ' , data = scale4b14_branch2b , act_type = ' relu ' ) NEW_LINE res4b14_branch2c = mx . symbol . Convolution ( name = ' res4b14 _ branch2c ' , data = res4b14_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2c = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2c ' , data = res4b14_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b14_branch2c = bn4b14_branch2c NEW_LINE res4b14 = mx . symbol . broadcast_add ( name = ' res4b14' , * [ res4b13_relu , scale4b14_branch2c ] ) NEW_LINE res4b14_relu = mx . symbol . Activation ( name = ' res4b14 _ relu ' , data = res4b14 , act_type = ' relu ' ) NEW_LINE res4b15_branch2a = mx . symbol . Convolution ( name = ' res4b15 _ branch2a ' , data = res4b14_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2a = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2a ' , data = res4b15_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b15_branch2a = bn4b15_branch2a NEW_LINE res4b15_branch2a_relu = mx . symbol . Activation ( name = ' res4b15 _ branch2a _ relu ' , data = scale4b15_branch2a , act_type = ' relu ' ) NEW_LINE res4b15_branch2b = mx . symbol . Convolution ( name = ' res4b15 _ branch2b ' , data = res4b15_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2b = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2b ' , data = res4b15_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b15_branch2b = bn4b15_branch2b NEW_LINE res4b15_branch2b_relu = mx . symbol . Activation ( name = ' res4b15 _ branch2b _ relu ' , data = scale4b15_branch2b , act_type = ' relu ' ) NEW_LINE res4b15_branch2c = mx . symbol . Convolution ( name = ' res4b15 _ branch2c ' , data = res4b15_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2c = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2c ' , data = res4b15_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b15_branch2c = bn4b15_branch2c NEW_LINE res4b15 = mx . symbol . broadcast_add ( name = ' res4b15' , * [ res4b14_relu , scale4b15_branch2c ] ) NEW_LINE res4b15_relu = mx . symbol . Activation ( name = ' res4b15 _ relu ' , data = res4b15 , act_type = ' relu ' ) NEW_LINE res4b16_branch2a = mx . symbol . Convolution ( name = ' res4b16 _ branch2a ' , data = res4b15_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2a = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2a ' , data = res4b16_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b16_branch2a = bn4b16_branch2a NEW_LINE res4b16_branch2a_relu = mx . symbol . Activation ( name = ' res4b16 _ branch2a _ relu ' , data = scale4b16_branch2a , act_type = ' relu ' ) NEW_LINE res4b16_branch2b = mx . symbol . Convolution ( name = ' res4b16 _ branch2b ' , data = res4b16_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2b = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2b ' , data = res4b16_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b16_branch2b = bn4b16_branch2b NEW_LINE res4b16_branch2b_relu = mx . symbol . Activation ( name = ' res4b16 _ branch2b _ relu ' , data = scale4b16_branch2b , act_type = ' relu ' ) NEW_LINE res4b16_branch2c = mx . symbol . Convolution ( name = ' res4b16 _ branch2c ' , data = res4b16_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2c = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2c ' , data = res4b16_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b16_branch2c = bn4b16_branch2c NEW_LINE res4b16 = mx . symbol . broadcast_add ( name = ' res4b16' , * [ res4b15_relu , scale4b16_branch2c ] ) NEW_LINE res4b16_relu = mx . symbol . Activation ( name = ' res4b16 _ relu ' , data = res4b16 , act_type = ' relu ' ) NEW_LINE res4b17_branch2a = mx . symbol . Convolution ( name = ' res4b17 _ branch2a ' , data = res4b16_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2a = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2a ' , data = res4b17_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b17_branch2a = bn4b17_branch2a NEW_LINE res4b17_branch2a_relu = mx . symbol . Activation ( name = ' res4b17 _ branch2a _ relu ' , data = scale4b17_branch2a , act_type = ' relu ' ) NEW_LINE res4b17_branch2b = mx . symbol . Convolution ( name = ' res4b17 _ branch2b ' , data = res4b17_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2b = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2b ' , data = res4b17_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b17_branch2b = bn4b17_branch2b NEW_LINE res4b17_branch2b_relu = mx . symbol . Activation ( name = ' res4b17 _ branch2b _ relu ' , data = scale4b17_branch2b , act_type = ' relu ' ) NEW_LINE res4b17_branch2c = mx . symbol . Convolution ( name = ' res4b17 _ branch2c ' , data = res4b17_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2c = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2c ' , data = res4b17_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b17_branch2c = bn4b17_branch2c NEW_LINE res4b17 = mx . symbol . broadcast_add ( name = ' res4b17' , * [ res4b16_relu , scale4b17_branch2c ] ) NEW_LINE res4b17_relu = mx . symbol . Activation ( name = ' res4b17 _ relu ' , data = res4b17 , act_type = ' relu ' ) NEW_LINE res4b18_branch2a = mx . symbol . Convolution ( name = ' res4b18 _ branch2a ' , data = res4b17_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2a = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2a ' , data = res4b18_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b18_branch2a = bn4b18_branch2a NEW_LINE res4b18_branch2a_relu = mx . symbol . Activation ( name = ' res4b18 _ branch2a _ relu ' , data = scale4b18_branch2a , act_type = ' relu ' ) NEW_LINE res4b18_branch2b = mx . symbol . Convolution ( name = ' res4b18 _ branch2b ' , data = res4b18_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2b = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2b ' , data = res4b18_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b18_branch2b = bn4b18_branch2b NEW_LINE res4b18_branch2b_relu = mx . symbol . Activation ( name = ' res4b18 _ branch2b _ relu ' , data = scale4b18_branch2b , act_type = ' relu ' ) NEW_LINE res4b18_branch2c = mx . symbol . Convolution ( name = ' res4b18 _ branch2c ' , data = res4b18_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2c = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2c ' , data = res4b18_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b18_branch2c = bn4b18_branch2c NEW_LINE res4b18 = mx . symbol . broadcast_add ( name = ' res4b18' , * [ res4b17_relu , scale4b18_branch2c ] ) NEW_LINE res4b18_relu = mx . symbol . Activation ( name = ' res4b18 _ relu ' , data = res4b18 , act_type = ' relu ' ) NEW_LINE res4b19_branch2a = mx . symbol . Convolution ( name = ' res4b19 _ branch2a ' , data = res4b18_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2a = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2a ' , data = res4b19_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b19_branch2a = bn4b19_branch2a NEW_LINE res4b19_branch2a_relu = mx . symbol . Activation ( name = ' res4b19 _ branch2a _ relu ' , data = scale4b19_branch2a , act_type = ' relu ' ) NEW_LINE res4b19_branch2b = mx . symbol . Convolution ( name = ' res4b19 _ branch2b ' , data = res4b19_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2b = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2b ' , data = res4b19_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b19_branch2b = bn4b19_branch2b NEW_LINE res4b19_branch2b_relu = mx . symbol . Activation ( name = ' res4b19 _ branch2b _ relu ' , data = scale4b19_branch2b , act_type = ' relu ' ) NEW_LINE res4b19_branch2c = mx . symbol . Convolution ( name = ' res4b19 _ branch2c ' , data = res4b19_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2c = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2c ' , data = res4b19_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b19_branch2c = bn4b19_branch2c NEW_LINE res4b19 = mx . symbol . broadcast_add ( name = ' res4b19' , * [ res4b18_relu , scale4b19_branch2c ] ) NEW_LINE res4b19_relu = mx . symbol . Activation ( name = ' res4b19 _ relu ' , data = res4b19 , act_type = ' relu ' ) NEW_LINE res4b20_branch2a = mx . symbol . Convolution ( name = ' res4b20 _ branch2a ' , data = res4b19_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2a = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2a ' , data = res4b20_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b20_branch2a = bn4b20_branch2a NEW_LINE res4b20_branch2a_relu = mx . symbol . Activation ( name = ' res4b20 _ branch2a _ relu ' , data = scale4b20_branch2a , act_type = ' relu ' ) NEW_LINE res4b20_branch2b = mx . symbol . Convolution ( name = ' res4b20 _ branch2b ' , data = res4b20_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2b = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2b ' , data = res4b20_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b20_branch2b = bn4b20_branch2b NEW_LINE res4b20_branch2b_relu = mx . symbol . Activation ( name = ' res4b20 _ branch2b _ relu ' , data = scale4b20_branch2b , act_type = ' relu ' ) NEW_LINE res4b20_branch2c = mx . symbol . Convolution ( name = ' res4b20 _ branch2c ' , data = res4b20_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2c = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2c ' , data = res4b20_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b20_branch2c = bn4b20_branch2c NEW_LINE res4b20 = mx . symbol . broadcast_add ( name = ' res4b20' , * [ res4b19_relu , scale4b20_branch2c ] ) NEW_LINE res4b20_relu = mx . symbol . Activation ( name = ' res4b20 _ relu ' , data = res4b20 , act_type = ' relu ' ) NEW_LINE res4b21_branch2a = mx . symbol . Convolution ( name = ' res4b21 _ branch2a ' , data = res4b20_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2a = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2a ' , data = res4b21_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b21_branch2a = bn4b21_branch2a NEW_LINE res4b21_branch2a_relu = mx . symbol . Activation ( name = ' res4b21 _ branch2a _ relu ' , data = scale4b21_branch2a , act_type = ' relu ' ) NEW_LINE res4b21_branch2b = mx . symbol . Convolution ( name = ' res4b21 _ branch2b ' , data = res4b21_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2b = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2b ' , data = res4b21_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b21_branch2b = bn4b21_branch2b NEW_LINE res4b21_branch2b_relu = mx . symbol . Activation ( name = ' res4b21 _ branch2b _ relu ' , data = scale4b21_branch2b , act_type = ' relu ' ) NEW_LINE res4b21_branch2c = mx . symbol . Convolution ( name = ' res4b21 _ branch2c ' , data = res4b21_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2c = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2c ' , data = res4b21_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b21_branch2c = bn4b21_branch2c NEW_LINE res4b21 = mx . symbol . broadcast_add ( name = ' res4b21' , * [ res4b20_relu , scale4b21_branch2c ] ) NEW_LINE res4b21_relu = mx . symbol . Activation ( name = ' res4b21 _ relu ' , data = res4b21 , act_type = ' relu ' ) NEW_LINE res4b22_branch2a = mx . symbol . Convolution ( name = ' res4b22 _ branch2a ' , data = res4b21_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b22_branch2a = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2a ' , data = res4b22_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b22_branch2a = bn4b22_branch2a NEW_LINE res4b22_branch2a_relu = mx . symbol . Activation ( name = ' res4b22 _ branch2a _ relu ' , data = scale4b22_branch2a , act_type = ' relu ' ) NEW_LINE if with_dpyramid : NEW_LINE INDENT res4b22_branch2b_offset = mx . symbol . Convolution ( name = ' res4b22 _ branch2b _ offset ' , data = res4b22_branch2a_relu , num_filter = 72 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) ) NEW_LINE res4b22_branch2b = mx . contrib . symbol . DeformableConvolution ( name = ' res4b22 _ branch2b ' , data = res4b22_branch2a_relu , offset = res4b22_branch2b_offset , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , num_deformable_group = 4 , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE DEDENT else : NEW_LINE INDENT res4b22_branch2b = mx . symbol . Convolution ( name = ' res4b22 _ branch2b ' , data = res4b22_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE DEDENT bn4b22_branch2b = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2b ' , data = res4b22_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b22_branch2b = bn4b22_branch2b NEW_LINE res4b22_branch2b_relu = mx . symbol . Activation ( name = ' res4b22 _ branch2b _ relu ' , data = scale4b22_branch2b , act_type = ' relu ' ) NEW_LINE res4b22_branch2c = mx . symbol . Convolution ( name = ' res4b22 _ branch2c ' , data = res4b22_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b22_branch2c = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2c ' , data = res4b22_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b22_branch2c = bn4b22_branch2c NEW_LINE res4b22 = mx . symbol . broadcast_add ( name = ' res4b22' , * [ res4b21_relu , scale4b22_branch2c ] ) NEW_LINE res4b22_relu = mx . symbol . Activation ( name = ' res4b22 _ relu ' , data = res4b22 , act_type = ' relu ' ) NEW_LINE if with_dilated : NEW_LINE INDENT res5_stride = ( 1 , 1 ) NEW_LINE res5_dilate = ( 2 , 2 ) NEW_LINE DEDENT else : NEW_LINE INDENT res5_stride = ( 2 , 2 ) NEW_LINE res5_dilate = ( 1 , 1 ) NEW_LINE DEDENT res5a_branch2a = mx . symbol . Convolution ( name = ' res5a _ branch2a ' , data = res4b22_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = res5_stride , no_bias = True ) NEW_LINE bn5a_branch2a = mx . symbol . BatchNorm ( name = ' bn5a _ branch2a ' , data = res5a_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5a_branch2a = bn5a_branch2a NEW_LINE res5a_branch2a_relu = mx . symbol . Activation ( name = ' res5a _ branch2a _ relu ' , data = scale5a_branch2a , act_type = ' relu ' ) NEW_LINE if with_dconv : NEW_LINE INDENT res5a_branch2b_offset = mx . symbol . Convolution ( name = ' res5a _ branch2b _ offset ' , data = res5a_branch2a_relu , num_filter = 72 , pad = res5_dilate , kernel = ( 3 , 3 ) , dilate = res5_dilate ) NEW_LINE res5a_branch2b = mx . contrib . symbol . DeformableConvolution ( name = ' res5a _ branch2b ' , data = res5a_branch2a_relu , offset = res5a_branch2b_offset , num_filter = 512 , pad = res5_dilate , kernel = ( 3 , 3 ) , num_deformable_group = 4 , stride = ( 1 , 1 ) , dilate = res5_dilate , no_bias = True ) NEW_LINE DEDENT else : NEW_LINE INDENT res5a_branch2b = mx . symbol . Convolution ( name = ' res5a _ branch2b ' , data = res5a_branch2a_relu , num_filter = 512 , pad = res5_dilate , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = res5_dilate , no_bias = True ) NEW_LINE DEDENT bn5a_branch2b = mx . symbol . BatchNorm ( name = ' bn5a _ branch2b ' , data = res5a_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5a_branch2b = bn5a_branch2b NEW_LINE res5a_branch2b_relu = mx . symbol . Activation ( name = ' res5a _ branch2b _ relu ' , data = scale5a_branch2b , act_type = ' relu ' ) NEW_LINE res5a_branch2c = mx . symbol . Convolution ( name = ' res5a _ branch2c ' , data = res5a_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5a_branch2c = mx . symbol . BatchNorm ( name = ' bn5a _ branch2c ' , data = res5a_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5a_branch2c = bn5a_branch2c NEW_LINE res5a_branch1 = mx . symbol . Convolution ( name = ' res5a _ branch1' , data = res4b22_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = res5_stride , no_bias = True ) NEW_LINE bn5a_branch1 = mx . symbol . BatchNorm ( name = ' bn5a _ branch1' , data = res5a_branch1 , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5a_branch1 = bn5a_branch1 NEW_LINE res5a = mx . symbol . broadcast_add ( name = ' res5a ' , * [ scale5a_branch1 , scale5a_branch2c ] ) NEW_LINE res5a_relu = mx . symbol . Activation ( name = ' res5a _ relu ' , data = res5a , act_type = ' relu ' ) NEW_LINE res5b_branch2a = mx . symbol . Convolution ( name = ' res5b _ branch2a ' , data = res5a_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5b_branch2a = mx . symbol . BatchNorm ( name = ' bn5b _ branch2a ' , data = res5b_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5b_branch2a = bn5b_branch2a NEW_LINE res5b_branch2a_relu = mx . symbol . Activation ( name = ' res5b _ branch2a _ relu ' , data = scale5b_branch2a , act_type = ' relu ' ) NEW_LINE if with_dconv : NEW_LINE INDENT res5b_branch2b_offset = mx . symbol . Convolution ( name = ' res5b _ branch2b _ offset ' , data = res5b_branch2a_relu , num_filter = 72 , pad = res5_dilate , kernel = ( 3 , 3 ) , dilate = res5_dilate ) NEW_LINE res5b_branch2b = mx . contrib . symbol . DeformableConvolution ( name = ' res5b _ branch2b ' , data = res5b_branch2a_relu , offset = res5b_branch2b_offset , num_filter = 512 , pad = res5_dilate , kernel = ( 3 , 3 ) , num_deformable_group = 4 , dilate = res5_dilate , no_bias = True ) NEW_LINE DEDENT else : NEW_LINE INDENT res5b_branch2b = mx . symbol . Convolution ( name = ' res5b _ branch2b ' , data = res5b_branch2a_relu , num_filter = 512 , pad = res5_dilate , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = res5_dilate , no_bias = True ) NEW_LINE DEDENT bn5b_branch2b = mx . symbol . BatchNorm ( name = ' bn5b _ branch2b ' , data = res5b_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5b_branch2b = bn5b_branch2b NEW_LINE res5b_branch2b_relu = mx . symbol . Activation ( name = ' res5b _ branch2b _ relu ' , data = scale5b_branch2b , act_type = ' relu ' ) NEW_LINE res5b_branch2c = mx . symbol . Convolution ( name = ' res5b _ branch2c ' , data = res5b_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5b_branch2c = mx . symbol . BatchNorm ( name = ' bn5b _ branch2c ' , data = res5b_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5b_branch2c = bn5b_branch2c NEW_LINE res5b = mx . symbol . broadcast_add ( name = ' res5b ' , * [ res5a_relu , scale5b_branch2c ] ) NEW_LINE res5b_relu = mx . symbol . Activation ( name = ' res5b _ relu ' , data = res5b , act_type = ' relu ' ) NEW_LINE res5c_branch2a = mx . symbol . Convolution ( name = ' res5c _ branch2a ' , data = res5b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5c_branch2a = mx . symbol . BatchNorm ( name = ' bn5c _ branch2a ' , data = res5c_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5c_branch2a = bn5c_branch2a NEW_LINE res5c_branch2a_relu = mx . symbol . Activation ( name = ' res5c _ branch2a _ relu ' , data = scale5c_branch2a , act_type = ' relu ' ) NEW_LINE if with_dconv : NEW_LINE INDENT res5c_branch2b_offset = mx . symbol . Convolution ( name = ' res5c _ branch2b _ offset ' , data = res5c_branch2a_relu , num_filter = 72 , pad = res5_dilate , kernel = ( 3 , 3 ) , dilate = res5_dilate ) NEW_LINE res5c_branch2b = mx . contrib . symbol . DeformableConvolution ( name = ' res5c _ branch2b ' , data = res5c_branch2a_relu , offset = res5c_branch2b_offset , num_filter = 512 , pad = res5_dilate , kernel = ( 3 , 3 ) , num_deformable_group = 4 , dilate = res5_dilate , no_bias = True ) NEW_LINE DEDENT else : NEW_LINE INDENT res5c_branch2b = mx . symbol . Convolution ( name = ' res5c _ branch2b ' , data = res5c_branch2a_relu , num_filter = 512 , pad = res5_dilate , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = res5_dilate , no_bias = True ) NEW_LINE DEDENT bn5c_branch2b = mx . symbol . BatchNorm ( name = ' bn5c _ branch2b ' , data = res5c_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5c_branch2b = bn5c_branch2b NEW_LINE res5c_branch2b_relu = mx . symbol . Activation ( name = ' res5c _ branch2b _ relu ' , data = scale5c_branch2b , act_type = ' relu ' ) NEW_LINE res5c_branch2c = mx . symbol . Convolution ( name = ' res5c _ branch2c ' , data = res5c_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5c_branch2c = mx . symbol . BatchNorm ( name = ' bn5c _ branch2c ' , data = res5c_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5c_branch2c = bn5c_branch2c NEW_LINE res5c = mx . symbol . broadcast_add ( name = ' res5c ' , * [ res5b_relu , scale5c_branch2c ] ) NEW_LINE res5c_relu = mx . symbol . Activation ( name = ' res5c _ relu ' , data = res5c , act_type = ' relu ' ) NEW_LINE return res2c_relu , res3b3_relu , res4b22_relu , res5c_relu NEW_LINE DEDENT\",), (\"def get_fpn_feature ( self , c2 , c3 , c4 , c5 , feature_dim = 256 ) : NEW_LINE INDENT fpn_p5_1x1 = mx . symbol . Convolution ( data = c5 , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , stride = ( 1 , 1 ) , num_filter = feature_dim , name = ' fpn _ p5_1x1' ) NEW_LINE fpn_p4_1x1 = mx . symbol . Convolution ( data = c4 , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , stride = ( 1 , 1 ) , num_filter = feature_dim , name = ' fpn _ p4_1x1' ) NEW_LINE fpn_p3_1x1 = mx . symbol . Convolution ( data = c3 , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , stride = ( 1 , 1 ) , num_filter = feature_dim , name = ' fpn _ p3_1x1' ) NEW_LINE fpn_p2_1x1 = mx . symbol . Convolution ( data = c2 , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , stride = ( 1 , 1 ) , num_filter = feature_dim , name = ' fpn _ p2_1x1' ) NEW_LINE fpn_p5_upsample = mx . symbol . UpSampling ( fpn_p5_1x1 , scale = 2 , sample_type = ' nearest ' , name = ' fpn _ p5 _ upsample ' ) NEW_LINE fpn_p4_plus = mx . sym . ElementWiseSum ( * [ fpn_p5_upsample , fpn_p4_1x1 ] , name = ' fpn _ p4 _ sum ' ) NEW_LINE fpn_p4_upsample = mx . symbol . UpSampling ( fpn_p4_plus , scale = 2 , sample_type = ' nearest ' , name = ' fpn _ p4 _ upsample ' ) NEW_LINE fpn_p3_plus = mx . sym . ElementWiseSum ( * [ fpn_p4_upsample , fpn_p3_1x1 ] , name = ' fpn _ p3 _ sum ' ) NEW_LINE fpn_p3_upsample = mx . symbol . UpSampling ( fpn_p3_plus , scale = 2 , sample_type = ' nearest ' , name = ' fpn _ p3 _ upsample ' ) NEW_LINE fpn_p2_plus = mx . sym . ElementWiseSum ( * [ fpn_p3_upsample , fpn_p2_1x1 ] , name = ' fpn _ p2 _ sum ' ) NEW_LINE fpn_p6 = mx . sym . Convolution ( data = c5 , kernel = ( 3 , 3 ) , pad = ( 1 , 1 ) , stride = ( 2 , 2 ) , num_filter = feature_dim , name = ' fpn _ p6' ) NEW_LINE fpn_p5 = mx . symbol . Convolution ( data = fpn_p5_1x1 , kernel = ( 3 , 3 ) , pad = ( 1 , 1 ) , stride = ( 1 , 1 ) , num_filter = feature_dim , name = ' fpn _ p5' ) NEW_LINE fpn_p4 = mx . symbol . Convolution ( data = fpn_p4_plus , kernel = ( 3 , 3 ) , pad = ( 1 , 1 ) , stride = ( 1 , 1 ) , num_filter = feature_dim , name = ' fpn _ p4' ) NEW_LINE fpn_p3 = mx . symbol . Convolution ( data = fpn_p3_plus , kernel = ( 3 , 3 ) , pad = ( 1 , 1 ) , stride = ( 1 , 1 ) , num_filter = feature_dim , name = ' fpn _ p3' ) NEW_LINE fpn_p2 = mx . symbol . Convolution ( data = fpn_p2_plus , kernel = ( 3 , 3 ) , pad = ( 1 , 1 ) , stride = ( 1 , 1 ) , num_filter = feature_dim , name = ' fpn _ p2' ) NEW_LINE return fpn_p2 , fpn_p3 , fpn_p4 , fpn_p5 , fpn_p6 NEW_LINE DEDENT\",), ('def get_light_head ( self , data , suffix ) : NEW_LINE INDENT mid_num_filter = 64 NEW_LINE conv_new_1 = mx . sym . Convolution ( data = data , kernel = ( 15 , 1 ) , pad = ( 7 , 0 ) , num_filter = mid_num_filter , name = \" conv _ new _ 1\" + suffix , weight = self . shared_param_dict [ \\' conv _ new _ 1 _ weight \\' ] , bias = self . shared_param_dict [ \\' conv _ new _ 1 _ bias \\' ] , lr_mult = 3.0 ) NEW_LINE relu_new_1 = mx . sym . Activation ( data = conv_new_1 , act_type = \\' relu \\' , name = \\' relu1\\' + suffix ) NEW_LINE conv_new_2 = mx . sym . Convolution ( data = relu_new_1 , kernel = ( 1 , 15 ) , pad = ( 0 , 7 ) , num_filter = 10 * 7 * 7 , name = \" conv _ new _ 2\" + suffix , weight = self . shared_param_dict [ \\' conv _ new _ 2 _ weight \\' ] , bias = self . shared_param_dict [ \\' conv _ new _ 2 _ bias \\' ] , lr_mult = 3.0 ) NEW_LINE relu_new_2 = mx . sym . Activation ( data = conv_new_2 , act_type = \\' relu \\' , name = \\' relu2\\' + suffix ) NEW_LINE conv_new_3 = mx . sym . Convolution ( data = data , kernel = ( 1 , 15 ) , pad = ( 0 , 7 ) , num_filter = mid_num_filter , name = \" conv _ new _ 3\" + suffix , weight = self . shared_param_dict [ \\' conv _ new _ 3 _ weight \\' ] , bias = self . shared_param_dict [ \\' conv _ new _ 3 _ bias \\' ] , lr_mult = 3.0 ) NEW_LINE relu_new_3 = mx . sym . Activation ( data = conv_new_3 , act_type = \\' relu \\' , name = \\' relu3\\' + suffix ) NEW_LINE conv_new_4 = mx . sym . Convolution ( data = relu_new_3 , kernel = ( 15 , 1 ) , pad = ( 7 , 0 ) , num_filter = 10 * 7 * 7 , name = \" conv _ new _ 4\" + suffix , weight = self . shared_param_dict [ \\' conv _ new _ 4 _ weight \\' ] , bias = self . shared_param_dict [ \\' conv _ new _ 4 _ bias \\' ] , lr_mult = 3.0 ) NEW_LINE relu_new_4 = mx . sym . Activation ( data = conv_new_4 , act_type = \\' relu \\' , name = \\' relu4\\' + suffix ) NEW_LINE light_head = mx . symbol . broadcast_add ( name = \\' light _ head \\' + suffix , * [ relu_new_2 , relu_new_4 ] ) NEW_LINE return light_head NEW_LINE DEDENT',), (\"def get_rpn_subnet ( self , data , num_anchors , suffix ) : NEW_LINE INDENT rpn_conv = mx . sym . Convolution ( data = data , kernel = ( 3 , 3 ) , pad = ( 1 , 1 ) , num_filter = 512 , name = ' rpn _ conv _ ' + suffix , weight = self . shared_param_dict [ ' rpn _ conv _ weight ' ] , bias = self . shared_param_dict [ ' rpn _ conv _ bias ' ] ) NEW_LINE rpn_relu = mx . sym . Activation ( data = rpn_conv , act_type = ' relu ' , name = ' rpn _ relu _ ' + suffix ) NEW_LINE rpn_cls_score = mx . sym . Convolution ( data = rpn_relu , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , num_filter = 2 * num_anchors , name = ' rpn _ cls _ score _ ' + suffix , weight = self . shared_param_dict [ ' rpn _ cls _ score _ weight ' ] , bias = self . shared_param_dict [ ' rpn _ cls _ score _ bias ' ] ) NEW_LINE rpn_bbox_pred = mx . sym . Convolution ( data = rpn_relu , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , num_filter = 4 * num_anchors , name = ' rpn _ bbox _ pred _ ' + suffix , weight = self . shared_param_dict [ ' rpn _ bbox _ pred _ weight ' ] , bias = self . shared_param_dict [ ' rpn _ bbox _ pred _ bias ' ] ) NEW_LINE rpn_cls_score_t1 = mx . sym . Reshape ( data = rpn_cls_score , shape = ( 0 , 2 , - 1 , 0 ) , name = ' rpn _ cls _ score _ t1 _ ' + suffix ) NEW_LINE rpn_cls_score_t2 = mx . sym . Reshape ( data = rpn_cls_score_t1 , shape = ( 0 , 2 , - 1 ) , name = ' rpn _ cls _ score _ t2 _ ' + suffix ) NEW_LINE rpn_cls_prob = mx . sym . SoftmaxActivation ( data = rpn_cls_score_t1 , mode = ' channel ' , name = ' rpn _ cls _ prob _ ' + suffix ) NEW_LINE rpn_cls_prob_t = mx . sym . Reshape ( data = rpn_cls_prob , shape = ( 0 , 2 * num_anchors , - 1 , 0 ) , name = ' rpn _ cls _ prob _ t _ ' + suffix ) NEW_LINE rpn_bbox_pred_t = mx . sym . Reshape ( data = rpn_bbox_pred , shape = ( 0 , 0 , - 1 ) , name = ' rpn _ bbox _ pred _ t _ ' + suffix ) NEW_LINE return rpn_cls_score_t2 , rpn_cls_prob_t , rpn_bbox_pred_t , rpn_bbox_pred NEW_LINE DEDENT\",), ('def get_symbol ( self , cfg , is_train = True ) : NEW_LINE INDENT num_classes = cfg . dataset . NUM_CLASSES NEW_LINE num_reg_classes = ( 2 if cfg . CLASS_AGNOSTIC else num_classes ) NEW_LINE Rroi_num_reg_classes = ( 2 if cfg . network . RRoI_CLASS_AGNOSTIC else num_classes ) NEW_LINE data = mx . sym . Variable ( name = \" data \" ) NEW_LINE im_info = mx . sym . Variable ( name = \" im _ info \" ) NEW_LINE res2 , res3 , res4 , res5 = self . get_resnet_backbone ( data ) NEW_LINE fpn_p2 , fpn_p3 , fpn_p4 , fpn_p5 , fpn_p6 = self . get_fpn_feature ( res2 , res3 , res4 , res5 ) NEW_LINE fpn_p2_new = self . get_light_head ( fpn_p2 , \\' p2\\' ) NEW_LINE fpn_p3_new = self . get_light_head ( fpn_p3 , \\' p3\\' ) NEW_LINE fpn_p4_new = self . get_light_head ( fpn_p4 , \\' p4\\' ) NEW_LINE fpn_p5_new = self . get_light_head ( fpn_p5 , \\' p5\\' ) NEW_LINE rpn_cls_score_p2 , rpn_prob_p2 , rpn_bbox_loss_p2 , rpn_bbox_pred_p2 = self . get_rpn_subnet ( fpn_p2 , cfg . network . NUM_ANCHORS , \\' p2\\' ) NEW_LINE rpn_cls_score_p3 , rpn_prob_p3 , rpn_bbox_loss_p3 , rpn_bbox_pred_p3 = self . get_rpn_subnet ( fpn_p3 , cfg . network . NUM_ANCHORS , \\' p3\\' ) NEW_LINE rpn_cls_score_p4 , rpn_prob_p4 , rpn_bbox_loss_p4 , rpn_bbox_pred_p4 = self . get_rpn_subnet ( fpn_p4 , cfg . network . NUM_ANCHORS , \\' p4\\' ) NEW_LINE rpn_cls_score_p5 , rpn_prob_p5 , rpn_bbox_loss_p5 , rpn_bbox_pred_p5 = self . get_rpn_subnet ( fpn_p5 , cfg . network . NUM_ANCHORS , \\' p5\\' ) NEW_LINE rpn_cls_score_p6 , rpn_prob_p6 , rpn_bbox_loss_p6 , rpn_bbox_pred_p6 = self . get_rpn_subnet ( fpn_p6 , cfg . network . NUM_ANCHORS , \\' p6\\' ) NEW_LINE rpn_cls_prob_dict = { \\' rpn _ cls _ prob _ stride64\\' : rpn_prob_p6 , \\' rpn _ cls _ prob _ stride32\\' : rpn_prob_p5 , \\' rpn _ cls _ prob _ stride16\\' : rpn_prob_p4 , \\' rpn _ cls _ prob _ stride8\\' : rpn_prob_p3 , \\' rpn _ cls _ prob _ stride4\\' : rpn_prob_p2 , } NEW_LINE rpn_bbox_pred_dict = { \\' rpn _ bbox _ pred _ stride64\\' : rpn_bbox_pred_p6 , \\' rpn _ bbox _ pred _ stride32\\' : rpn_bbox_pred_p5 , \\' rpn _ bbox _ pred _ stride16\\' : rpn_bbox_pred_p4 , \\' rpn _ bbox _ pred _ stride8\\' : rpn_bbox_pred_p3 , \\' rpn _ bbox _ pred _ stride4\\' : rpn_bbox_pred_p2 , } NEW_LINE arg_dict = dict ( rpn_cls_prob_dict . items ( ) + rpn_bbox_pred_dict . items ( ) ) NEW_LINE if is_train : NEW_LINE INDENT rpn_label = mx . sym . Variable ( name = \\' label \\' ) NEW_LINE rpn_bbox_target = mx . sym . Variable ( name = \\' bbox _ target \\' ) NEW_LINE rpn_bbox_weight = mx . sym . Variable ( name = \\' bbox _ weight \\' ) NEW_LINE gt_boxes = mx . sym . Variable ( name = \" gt _ boxes \" ) NEW_LINE rpn_cls_score = mx . sym . Concat ( rpn_cls_score_p2 , rpn_cls_score_p3 , rpn_cls_score_p4 , rpn_cls_score_p5 , rpn_cls_score_p6 , dim = 2 ) NEW_LINE rpn_bbox_loss = mx . sym . Concat ( rpn_bbox_loss_p2 , rpn_bbox_loss_p3 , rpn_bbox_loss_p4 , rpn_bbox_loss_p5 , rpn_bbox_loss_p6 , dim = 2 ) NEW_LINE rpn_cls_output = mx . sym . SoftmaxOutput ( data = rpn_cls_score , label = rpn_label , multi_output = True , normalization = \\' valid \\' , use_ignore = True , ignore_label = - 1 , name = \\' rpn _ cls _ prob \\' ) NEW_LINE rpn_bbox_loss = rpn_bbox_weight * mx . sym . smooth_l1 ( name = \\' rpn _ bbox _ loss _ l1\\' , scalar = 3.0 , data = ( rpn_bbox_loss - rpn_bbox_target ) ) NEW_LINE rpn_bbox_loss = mx . sym . MakeLoss ( name = \\' rpn _ bbox _ loss \\' , data = rpn_bbox_loss , grad_scale = 1.0 / cfg . TRAIN . RPN_BATCH_SIZE ) NEW_LINE aux_dict = { \\' op _ type \\' : \\' pyramid _ proposal \\' , \\' name \\' : \\' rois \\' , \\' im _ info \\' : im_info , \\' feat _ stride \\' : tuple ( cfg . network . RPN_FEAT_STRIDE ) , \\' scales \\' : tuple ( cfg . network . ANCHOR_SCALES ) , \\' ratios \\' : tuple ( cfg . network . ANCHOR_RATIOS ) , \\' rpn _ pre _ nms _ top _ n \\' : cfg . TRAIN . RPN_PRE_NMS_TOP_N , \\' rpn _ post _ nms _ top _ n \\' : cfg . TRAIN . RPN_POST_NMS_TOP_N , \\' threshold \\' : cfg . TRAIN . RPN_NMS_THRESH , \\' rpn _ min _ size \\' : cfg . TRAIN . RPN_MIN_SIZE } NEW_LINE rois = mx . sym . Custom ( ** dict ( arg_dict . items ( ) + aux_dict . items ( ) ) ) NEW_LINE gt_boxes_reshape = mx . sym . Reshape ( data = gt_boxes , shape = ( - 1 , 9 ) , name = \\' gt _ boxes _ reshape \\' ) NEW_LINE rois , label , bbox_target , bbox_weight = mx . sym . Custom ( rois = rois , gt_boxes = gt_boxes_reshape , op_type = \\' proposal _ target _ rotbox \\' , num_classes = num_reg_classes , batch_images = cfg . TRAIN . BATCH_IMAGES , batch_rois = cfg . TRAIN . BATCH_ROIS , cfg = cPickle . dumps ( cfg ) , fg_class_agnostic = True , fg_fraction = cfg . TRAIN . FG_FRACTION ) NEW_LINE DEDENT else : NEW_LINE INDENT aux_dict = { \\' op _ type \\' : \\' pyramid _ proposal \\' , \\' name \\' : \\' rois \\' , \\' im _ info \\' : im_info , \\' feat _ stride \\' : tuple ( cfg . network . RPN_FEAT_STRIDE ) , \\' scales \\' : tuple ( cfg . network . ANCHOR_SCALES ) , \\' ratios \\' : tuple ( cfg . network . ANCHOR_RATIOS ) , \\' rpn _ pre _ nms _ top _ n \\' : cfg . TEST . RPN_PRE_NMS_TOP_N , \\' rpn _ post _ nms _ top _ n \\' : cfg . TEST . RPN_POST_NMS_TOP_N , \\' threshold \\' : cfg . TEST . RPN_NMS_THRESH , \\' rpn _ min _ size \\' : cfg . TEST . RPN_MIN_SIZE } NEW_LINE rois = mx . sym . Custom ( ** dict ( arg_dict . items ( ) + aux_dict . items ( ) ) ) NEW_LINE DEDENT roi_pool = mx . symbol . Custom ( data_p2 = fpn_p2_new , data_p3 = fpn_p3_new , data_p4 = fpn_p4_new , data_p5 = fpn_p5_new , rois = rois , op_type = \\' fpn _ psroi _ pooling _ v2\\' , name = \\' fpn _ psroi _ pooling _ v2\\' , pooling_mode = \\' alignave \\' ) NEW_LINE cls_score = mx . symbol . FullyConnected ( name = \\' cls _ score \\' , data = roi_pool , num_hidden = num_reg_classes ) NEW_LINE bbox_pred = mx . symbol . FullyConnected ( name = \\' bbox _ pred \\' , data = roi_pool , num_hidden = num_reg_classes * 5 ) NEW_LINE cls_prob = mx . sym . SoftmaxActivation ( name = \\' cls _ prob \\' , data = cls_score ) NEW_LINE cls_prob = mx . sym . Reshape ( data = cls_prob , shape = ( cfg . TEST . BATCH_IMAGES , - 1 , num_reg_classes ) , name = \\' cls _ prob _ reshape \\' ) NEW_LINE if is_train : NEW_LINE INDENT if cfg . TRAIN . ENABLE_OHEM : NEW_LINE INDENT labels_ohem , bbox_weights_ohem = mx . sym . Custom ( name = \\' ohem \\' , op_type = \\' BoxAnnotatorOHEM \\' , num_classes = num_classes , num_reg_classes = num_reg_classes , roi_per_img = cfg . TRAIN . BATCH_ROIS_OHEM , cls_score = cls_score , bbox_pred = bbox_pred , labels = label , bbox_targets = bbox_target , bbox_weights = bbox_weight ) NEW_LINE cls_prob_loss = mx . sym . SoftmaxOutput ( name = \\' cls _ prob _ loss \\' , data = cls_score , label = labels_ohem , normalization = \\' valid \\' , use_ignore = True , ignore_label = - 1 ) NEW_LINE bbox_loss_ = bbox_weights_ohem * mx . sym . smooth_l1 ( name = \\' bbox _ loss _ \\' , scalar = 1.0 , data = ( bbox_pred - bbox_target ) ) NEW_LINE bbox_loss = mx . sym . MakeLoss ( name = \\' bbox _ loss \\' , data = bbox_loss_ , grad_scale = 1.0 / cfg . TRAIN . BATCH_ROIS_OHEM ) NEW_LINE rcnn_label = labels_ohem NEW_LINE DEDENT else : NEW_LINE INDENT cls_prob_loss = mx . sym . SoftmaxOutput ( name = \\' cls _ prob _ loss \\' , data = cls_score , label = label , normalization = \\' valid \\' ) NEW_LINE bbox_loss_ = bbox_weight * mx . sym . smooth_l1 ( name = \\' bbox _ loss _ \\' , scalar = 1.0 , data = ( bbox_pred - bbox_target ) ) NEW_LINE bbox_loss = mx . sym . MakeLoss ( name = \\' bbox _ loss \\' , data = bbox_loss_ , grad_scale = 1.0 / cfg . TRAIN . BATCH_ROIS ) NEW_LINE rcnn_label = label NEW_LINE DEDENT rcnn_label = mx . sym . Reshape ( data = rcnn_label , shape = ( cfg . TRAIN . BATCH_IMAGES , - 1 ) , name = \\' label _ reshape \\' ) NEW_LINE cls_prob_loss = mx . sym . Reshape ( data = cls_prob_loss , shape = ( cfg . TRAIN . BATCH_IMAGES , - 1 , num_reg_classes ) , name = \\' cls _ prob _ loss _ reshape \\' ) NEW_LINE bbox_loss = mx . sym . Reshape ( data = bbox_loss , shape = ( cfg . TRAIN . BATCH_IMAGES , - 1 , 5 * num_reg_classes ) , name = \\' bbox _ loss _ reshape \\' ) NEW_LINE DEDENT Rroi_arg_dict = { \\' rois \\' : rois , \\' bbox _ pred \\' : bbox_pred , \\' cls _ prob \\' : cls_prob } NEW_LINE if is_train : NEW_LINE INDENT Rroi_aux_dict = { \\' op _ type \\' : \\' RRoIDecoder \\' , \\' name \\' : \\' Rrois \\' , \\' im _ info \\' : im_info , \\' Rroi _ pre _ nms _ top _ n \\' : cfg . TRAIN . RRoI_PRE_NMS_TOP_N , \\' Rroi _ post _ nms _ top _ n \\' : cfg . TRAIN . RRoI_POST_NMS_TOP_N , \\' threshold \\' : cfg . TRAIN . RRoI_NMS_THRESH , \\' min _ size \\' : cfg . TRAIN . RRoI_MIN_SIZE , \\' cfg \\' : cPickle . dumps ( cfg ) } NEW_LINE Rrois , Rrois_elarge = mx . symbol . Custom ( ** dict ( Rroi_arg_dict . items ( ) + Rroi_aux_dict . items ( ) ) ) NEW_LINE Rrois , Rrois_elarge_gt_ag , Rroi_label , Rroi_bbox_target , Rroi_bbox_weight = mx . symbol . Custom ( Rrois = Rrois , gt_boxes = gt_boxes_reshape , op_type = \\' RRoI _ target _ rotbox _ v2\\' , num_classes = Rroi_num_reg_classes , batch_images = cfg . TRAIN . BATCH_IMAGES , batch_rois = cfg . TRAIN . RRoI_BATCH_ROIS , cfg = cPickle . dumps ( cfg ) , fg_fraction = cfg . TRAIN . RRoI_FG_FRACTION ) NEW_LINE DEDENT else : NEW_LINE INDENT Rroi_aux_dict = { \\' op _ type \\' : \\' RRoIDecoder \\' , \\' name \\' : \\' Rrois \\' , \\' im _ info \\' : im_info , \\' Rroi _ pre _ nms _ top _ n \\' : cfg . TEST . RRoI_PRE_NMS_TOP_N , \\' Rroi _ post _ nms _ top _ n \\' : cfg . TEST . RRoI_POST_NMS_TOP_N , \\' threshold \\' : cfg . TEST . RRoI_NMS_THRESH , \\' min _ size \\' : cfg . TEST . RRoI_MIN_SIZE , \\' cfg \\' : cPickle . dumps ( cfg ) } NEW_LINE Rrois , Rrois_elarge = mx . symbol . Custom ( ** dict ( Rroi_arg_dict . items ( ) + Rroi_aux_dict . items ( ) ) ) NEW_LINE DEDENT if is_train : NEW_LINE INDENT rotated_pool = mx . symbol . Custom ( data_p2 = fpn_p2_new , data_p3 = fpn_p3_new , data_p4 = fpn_p4_new , data_p5 = fpn_p5_new , Rrois = Rrois_elarge_gt_ag , op_type = \\' fpn _ psroi _ rotatedalign \\' , name = \\' fpn _ psroi _ rotatedalign \\' ) NEW_LINE DEDENT else : NEW_LINE INDENT rotated_pool = mx . symbol . Custom ( data_p2 = fpn_p2_new , data_p3 = fpn_p3_new , data_p4 = fpn_p4_new , data_p5 = fpn_p5_new , Rrois = Rrois_elarge , op_type = \\' fpn _ psroi _ rotatedalign \\' , name = \\' fpn _ psroi _ rotatedalign \\' ) NEW_LINE DEDENT fc_new_3 = mx . symbol . FullyConnected ( name = \\' fc _ new _ 3\\' , data = rotated_pool , num_hidden = 2048 ) NEW_LINE fc_new_3_relu = mx . sym . Activation ( data = fc_new_3 , act_type = \\' relu \\' , name = \\' fc _ new _ 3 _ relu \\' ) NEW_LINE Rroi_cls_score = mx . symbol . FullyConnected ( name = \\' Rroi _ cls _ score \\' , data = fc_new_3_relu , num_hidden = num_classes ) NEW_LINE Rroi_bbox_pred = mx . symbol . FullyConnected ( name = \\' Rroi _ bbox _ pred \\' , data = fc_new_3_relu , num_hidden = Rroi_num_reg_classes * 5 ) NEW_LINE if is_train : NEW_LINE INDENT if cfg . TRAIN . RRoI_ENABLE_OHEM : NEW_LINE INDENT Rroi_labels_ohem , Rroi_bbox_weights_ohem = mx . sym . Custom ( name = \\' Rroi _ ohem \\' , op_type = \\' BoxAnnotatorOHEM \\' , num_classes = num_classes , num_reg_classes = Rroi_num_reg_classes , roi_per_img = cfg . TRAIN . RRoI_BATCH_ROIS_OHEM , cls_score = Rroi_cls_score , bbox_pred = Rroi_bbox_pred , labels = Rroi_label , bbox_targets = Rroi_bbox_target , bbox_weights = Rroi_bbox_weight ) NEW_LINE Rroi_cls_prob = mx . sym . SoftmaxOutput ( name = \\' Rroi _ cls _ prob \\' , data = Rroi_cls_score , label = Rroi_labels_ohem , normalization = \\' valid \\' , use_ignore = True , ignore_label = - 1 ) NEW_LINE Rroi_bbox_loss_ = Rroi_bbox_weights_ohem * mx . sym . smooth_l1 ( name = \\' Rroi _ bbox _ loss _ \\' , scalar = 1.0 , data = ( Rroi_bbox_pred - Rroi_bbox_target ) ) NEW_LINE Rroi_bbox_loss = mx . sym . MakeLoss ( name = \\' Rroi _ bbox _ loss \\' , data = Rroi_bbox_loss_ , grad_scale = 1.0 / cfg . TRAIN . RRoI_BATCH_ROIS_OHEM ) NEW_LINE Rroi_rcnn_label = Rroi_labels_ohem NEW_LINE DEDENT else : NEW_LINE INDENT Rroi_cls_prob = mx . sym . SoftmaxOutput ( name = \\' Rroi _ cls _ prob \\' , data = Rroi_cls_score , label = Rroi_label , normalization = \\' valid \\' ) NEW_LINE Rroi_bbox_loss_ = Rroi_bbox_weight * mx . sym . smooth_l1 ( name = \\' Rroi _ bbox _ loss _ \\' , scalar = 1.0 , data = ( Rroi_bbox_pred - Rroi_bbox_target ) ) NEW_LINE Rroi_bbox_loss = mx . sym . MakeLoss ( name = \\' Rroi _ bbox _ loss \\' , data = Rroi_bbox_loss_ , grad_scale = 1.0 / cfg . TRAIN . RRoI_BATCH_ROIS ) NEW_LINE Rroi_rcnn_label = Rroi_label NEW_LINE DEDENT Rroi_rcnn_label = mx . sym . Reshape ( data = Rroi_rcnn_label , shape = ( cfg . TRAIN . BATCH_IMAGES , - 1 ) , name = \\' Rroi _ label _ reshape \\' ) NEW_LINE Rroi_cls_prob = mx . sym . Reshape ( data = Rroi_cls_prob , shape = ( cfg . TRAIN . BATCH_IMAGES , - 1 , num_classes ) , name = \\' Rroi _ cls _ prob _ reshape \\' ) NEW_LINE Rroi_bbox_loss = mx . sym . Reshape ( data = Rroi_bbox_loss , shape = ( cfg . TRAIN . BATCH_IMAGES , - 1 , 5 * Rroi_num_reg_classes ) , name = \\' Rroi _ bbox _ loss _ reshape \\' ) NEW_LINE group = mx . sym . Group ( [ rpn_cls_output , rpn_bbox_loss , cls_prob_loss , bbox_loss , mx . sym . BlockGrad ( rcnn_label ) , Rroi_cls_prob , Rroi_bbox_loss , mx . sym . BlockGrad ( Rroi_rcnn_label ) ] ) NEW_LINE DEDENT else : NEW_LINE INDENT Rroi_cls_prob = mx . sym . SoftmaxActivation ( name = \\' Rroi _ cls _ prob \\' , data = Rroi_cls_score ) NEW_LINE Rroi_cls_prob = mx . sym . Reshape ( data = Rroi_cls_prob , shape = ( cfg . TEST . BATCH_IMAGES , - 1 , num_classes ) , name = \\' Rroi _ cls _ prob _ reshape \\' ) NEW_LINE Rroi_bbox_pred = mx . sym . Reshape ( data = Rroi_bbox_pred , shape = ( cfg . TEST . BATCH_IMAGES , - 1 , 5 * Rroi_num_reg_classes ) , name = \\' Rroi _ bbox _ pred _ reshape \\' ) NEW_LINE if DEBUG : NEW_LINE INDENT bbox_pred = mx . sym . Reshape ( data = bbox_pred , shape = ( cfg . TEST . BATCH_IMAGES , - 1 , 5 * num_reg_classes ) , name = \\' bbox _ pred _ reshape \\' ) NEW_LINE group = mx . sym . Group ( [ rois , cls_prob , bbox_pred ] ) NEW_LINE DEDENT else : NEW_LINE INDENT group = mx . sym . Group ( [ Rrois , Rroi_cls_prob , Rroi_bbox_pred ] ) NEW_LINE DEDENT DEDENT self . sym = group NEW_LINE return group NEW_LINE DEDENT',), (\"def init_weight_rcnn ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT arg_params [ ' cls _ score _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' cls _ score _ weight ' ] ) NEW_LINE arg_params [ ' cls _ score _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' cls _ score _ bias ' ] ) NEW_LINE arg_params [ ' bbox _ pred _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' bbox _ pred _ weight ' ] ) NEW_LINE arg_params [ ' bbox _ pred _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' bbox _ pred _ bias ' ] ) NEW_LINE arg_params [ ' fc _ new _ 3 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fc _ new _ 3 _ weight ' ] ) NEW_LINE arg_params [ ' fc _ new _ 3 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fc _ new _ 3 _ bias ' ] ) NEW_LINE arg_params [ ' Rroi _ cls _ score _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' Rroi _ cls _ score _ weight ' ] ) NEW_LINE arg_params [ ' Rroi _ cls _ score _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' Rroi _ cls _ score _ bias ' ] ) NEW_LINE arg_params [ ' Rroi _ bbox _ pred _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' Rroi _ bbox _ pred _ weight ' ] ) NEW_LINE arg_params [ ' Rroi _ bbox _ pred _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' Rroi _ bbox _ pred _ bias ' ] ) NEW_LINE DEDENT\",), (\"def init_weight_fpn ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT arg_params [ ' fpn _ p6 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p6 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p6 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p6 _ bias ' ] ) NEW_LINE arg_params [ ' fpn _ p5 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p5 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p5 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p5 _ bias ' ] ) NEW_LINE arg_params [ ' fpn _ p4 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p4 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p4 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p4 _ bias ' ] ) NEW_LINE arg_params [ ' fpn _ p3 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p3 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p3 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p3 _ bias ' ] ) NEW_LINE arg_params [ ' fpn _ p2 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p2 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p2 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p2 _ bias ' ] ) NEW_LINE arg_params [ ' fpn _ p5_1x1 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p5_1x1 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p5_1x1 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p5_1x1 _ bias ' ] ) NEW_LINE arg_params [ ' fpn _ p4_1x1 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p4_1x1 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p4_1x1 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p4_1x1 _ bias ' ] ) NEW_LINE arg_params [ ' fpn _ p3_1x1 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p3_1x1 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p3_1x1 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p3_1x1 _ bias ' ] ) NEW_LINE arg_params [ ' fpn _ p2_1x1 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p2_1x1 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p2_1x1 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p2_1x1 _ bias ' ] ) NEW_LINE DEDENT\",), (\"def init_weight ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT for name in self . shared_param_list : NEW_LINE INDENT arg_params [ name + ' _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ name + ' _ weight ' ] ) NEW_LINE arg_params [ name + ' _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ name + ' _ bias ' ] ) NEW_LINE DEDENT self . init_weight_rcnn ( cfg , arg_params , aux_params ) NEW_LINE self . init_weight_fpn ( cfg , arg_params , aux_params ) NEW_LINE DEDENT\",), (\"def __init__ ( self ) : NEW_LINE INDENT self . shared_param_list = [ ' rpn _ conv ' , ' rpn _ cls _ score ' , ' rpn _ bbox _ pred ' ] NEW_LINE self . shared_param_dict = { } NEW_LINE for name in self . shared_param_list : NEW_LINE INDENT self . shared_param_dict [ name + ' _ weight ' ] = mx . sym . Variable ( name + ' _ weight ' ) NEW_LINE self . shared_param_dict [ name + ' _ bias ' ] = mx . sym . Variable ( name + ' _ bias ' ) NEW_LINE DEDENT DEDENT\",), (\"def get_resnet_backbone ( self , data , with_dilated = False , with_dconv = False , with_dpyramid = False , eps = 1e-5 ) : NEW_LINE INDENT conv1 = mx . symbol . Convolution ( name = ' conv1' , data = data , num_filter = 64 , pad = ( 3 , 3 ) , kernel = ( 7 , 7 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn_conv1 = mx . symbol . BatchNorm ( name = ' bn _ conv1' , data = conv1 , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale_conv1 = bn_conv1 NEW_LINE conv1_relu = mx . symbol . Activation ( name = ' conv1 _ relu ' , data = scale_conv1 , act_type = ' relu ' ) NEW_LINE pool1 = mx . symbol . Pooling ( name = ' pool1' , data = conv1_relu , pooling_convention = ' full ' , pad = ( 0 , 0 ) , kernel = ( 3 , 3 ) , stride = ( 2 , 2 ) , pool_type = ' max ' ) NEW_LINE res2a_branch1 = mx . symbol . Convolution ( name = ' res2a _ branch1' , data = pool1 , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch1 = mx . symbol . BatchNorm ( name = ' bn2a _ branch1' , data = res2a_branch1 , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2a_branch1 = bn2a_branch1 NEW_LINE res2a_branch2a = mx . symbol . Convolution ( name = ' res2a _ branch2a ' , data = pool1 , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2a = mx . symbol . BatchNorm ( name = ' bn2a _ branch2a ' , data = res2a_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2a_branch2a = bn2a_branch2a NEW_LINE res2a_branch2a_relu = mx . symbol . Activation ( name = ' res2a _ branch2a _ relu ' , data = scale2a_branch2a , act_type = ' relu ' ) NEW_LINE res2a_branch2b = mx . symbol . Convolution ( name = ' res2a _ branch2b ' , data = res2a_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2b = mx . symbol . BatchNorm ( name = ' bn2a _ branch2b ' , data = res2a_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2a_branch2b = bn2a_branch2b NEW_LINE res2a_branch2b_relu = mx . symbol . Activation ( name = ' res2a _ branch2b _ relu ' , data = scale2a_branch2b , act_type = ' relu ' ) NEW_LINE res2a_branch2c = mx . symbol . Convolution ( name = ' res2a _ branch2c ' , data = res2a_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2c = mx . symbol . BatchNorm ( name = ' bn2a _ branch2c ' , data = res2a_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2a_branch2c = bn2a_branch2c NEW_LINE res2a = mx . symbol . broadcast_add ( name = ' res2a ' , * [ scale2a_branch1 , scale2a_branch2c ] ) NEW_LINE res2a_relu = mx . symbol . Activation ( name = ' res2a _ relu ' , data = res2a , act_type = ' relu ' ) NEW_LINE res2b_branch2a = mx . symbol . Convolution ( name = ' res2b _ branch2a ' , data = res2a_relu , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2a = mx . symbol . BatchNorm ( name = ' bn2b _ branch2a ' , data = res2b_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2b_branch2a = bn2b_branch2a NEW_LINE res2b_branch2a_relu = mx . symbol . Activation ( name = ' res2b _ branch2a _ relu ' , data = scale2b_branch2a , act_type = ' relu ' ) NEW_LINE res2b_branch2b = mx . symbol . Convolution ( name = ' res2b _ branch2b ' , data = res2b_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2b = mx . symbol . BatchNorm ( name = ' bn2b _ branch2b ' , data = res2b_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2b_branch2b = bn2b_branch2b NEW_LINE res2b_branch2b_relu = mx . symbol . Activation ( name = ' res2b _ branch2b _ relu ' , data = scale2b_branch2b , act_type = ' relu ' ) NEW_LINE res2b_branch2c = mx . symbol . Convolution ( name = ' res2b _ branch2c ' , data = res2b_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2c = mx . symbol . BatchNorm ( name = ' bn2b _ branch2c ' , data = res2b_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2b_branch2c = bn2b_branch2c NEW_LINE res2b = mx . symbol . broadcast_add ( name = ' res2b ' , * [ res2a_relu , scale2b_branch2c ] ) NEW_LINE res2b_relu = mx . symbol . Activation ( name = ' res2b _ relu ' , data = res2b , act_type = ' relu ' ) NEW_LINE res2c_branch2a = mx . symbol . Convolution ( name = ' res2c _ branch2a ' , data = res2b_relu , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2a = mx . symbol . BatchNorm ( name = ' bn2c _ branch2a ' , data = res2c_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2c_branch2a = bn2c_branch2a NEW_LINE res2c_branch2a_relu = mx . symbol . Activation ( name = ' res2c _ branch2a _ relu ' , data = scale2c_branch2a , act_type = ' relu ' ) NEW_LINE res2c_branch2b = mx . symbol . Convolution ( name = ' res2c _ branch2b ' , data = res2c_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2b = mx . symbol . BatchNorm ( name = ' bn2c _ branch2b ' , data = res2c_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2c_branch2b = bn2c_branch2b NEW_LINE res2c_branch2b_relu = mx . symbol . Activation ( name = ' res2c _ branch2b _ relu ' , data = scale2c_branch2b , act_type = ' relu ' ) NEW_LINE res2c_branch2c = mx . symbol . Convolution ( name = ' res2c _ branch2c ' , data = res2c_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2c = mx . symbol . BatchNorm ( name = ' bn2c _ branch2c ' , data = res2c_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2c_branch2c = bn2c_branch2c NEW_LINE res2c = mx . symbol . broadcast_add ( name = ' res2c ' , * [ res2b_relu , scale2c_branch2c ] ) NEW_LINE res2c_relu = mx . symbol . Activation ( name = ' res2c _ relu ' , data = res2c , act_type = ' relu ' ) NEW_LINE res3a_branch1 = mx . symbol . Convolution ( name = ' res3a _ branch1' , data = res2c_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn3a_branch1 = mx . symbol . BatchNorm ( name = ' bn3a _ branch1' , data = res3a_branch1 , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3a_branch1 = bn3a_branch1 NEW_LINE res3a_branch2a = mx . symbol . Convolution ( name = ' res3a _ branch2a ' , data = res2c_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn3a_branch2a = mx . symbol . BatchNorm ( name = ' bn3a _ branch2a ' , data = res3a_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3a_branch2a = bn3a_branch2a NEW_LINE res3a_branch2a_relu = mx . symbol . Activation ( name = ' res3a _ branch2a _ relu ' , data = scale3a_branch2a , act_type = ' relu ' ) NEW_LINE res3a_branch2b = mx . symbol . Convolution ( name = ' res3a _ branch2b ' , data = res3a_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3a_branch2b = mx . symbol . BatchNorm ( name = ' bn3a _ branch2b ' , data = res3a_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3a_branch2b = bn3a_branch2b NEW_LINE res3a_branch2b_relu = mx . symbol . Activation ( name = ' res3a _ branch2b _ relu ' , data = scale3a_branch2b , act_type = ' relu ' ) NEW_LINE res3a_branch2c = mx . symbol . Convolution ( name = ' res3a _ branch2c ' , data = res3a_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3a_branch2c = mx . symbol . BatchNorm ( name = ' bn3a _ branch2c ' , data = res3a_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3a_branch2c = bn3a_branch2c NEW_LINE res3a = mx . symbol . broadcast_add ( name = ' res3a ' , * [ scale3a_branch1 , scale3a_branch2c ] ) NEW_LINE res3a_relu = mx . symbol . Activation ( name = ' res3a _ relu ' , data = res3a , act_type = ' relu ' ) NEW_LINE res3b1_branch2a = mx . symbol . Convolution ( name = ' res3b1 _ branch2a ' , data = res3a_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2a = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2a ' , data = res3b1_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b1_branch2a = bn3b1_branch2a NEW_LINE res3b1_branch2a_relu = mx . symbol . Activation ( name = ' res3b1 _ branch2a _ relu ' , data = scale3b1_branch2a , act_type = ' relu ' ) NEW_LINE res3b1_branch2b = mx . symbol . Convolution ( name = ' res3b1 _ branch2b ' , data = res3b1_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2b = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2b ' , data = res3b1_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b1_branch2b = bn3b1_branch2b NEW_LINE res3b1_branch2b_relu = mx . symbol . Activation ( name = ' res3b1 _ branch2b _ relu ' , data = scale3b1_branch2b , act_type = ' relu ' ) NEW_LINE res3b1_branch2c = mx . symbol . Convolution ( name = ' res3b1 _ branch2c ' , data = res3b1_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2c = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2c ' , data = res3b1_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b1_branch2c = bn3b1_branch2c NEW_LINE res3b1 = mx . symbol . broadcast_add ( name = ' res3b1' , * [ res3a_relu , scale3b1_branch2c ] ) NEW_LINE res3b1_relu = mx . symbol . Activation ( name = ' res3b1 _ relu ' , data = res3b1 , act_type = ' relu ' ) NEW_LINE res3b2_branch2a = mx . symbol . Convolution ( name = ' res3b2 _ branch2a ' , data = res3b1_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2a = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2a ' , data = res3b2_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b2_branch2a = bn3b2_branch2a NEW_LINE res3b2_branch2a_relu = mx . symbol . Activation ( name = ' res3b2 _ branch2a _ relu ' , data = scale3b2_branch2a , act_type = ' relu ' ) NEW_LINE res3b2_branch2b = mx . symbol . Convolution ( name = ' res3b2 _ branch2b ' , data = res3b2_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2b = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2b ' , data = res3b2_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b2_branch2b = bn3b2_branch2b NEW_LINE res3b2_branch2b_relu = mx . symbol . Activation ( name = ' res3b2 _ branch2b _ relu ' , data = scale3b2_branch2b , act_type = ' relu ' ) NEW_LINE res3b2_branch2c = mx . symbol . Convolution ( name = ' res3b2 _ branch2c ' , data = res3b2_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2c = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2c ' , data = res3b2_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b2_branch2c = bn3b2_branch2c NEW_LINE res3b2 = mx . symbol . broadcast_add ( name = ' res3b2' , * [ res3b1_relu , scale3b2_branch2c ] ) NEW_LINE res3b2_relu = mx . symbol . Activation ( name = ' res3b2 _ relu ' , data = res3b2 , act_type = ' relu ' ) NEW_LINE res3b3_branch2a = mx . symbol . Convolution ( name = ' res3b3 _ branch2a ' , data = res3b2_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b3_branch2a = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2a ' , data = res3b3_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b3_branch2a = bn3b3_branch2a NEW_LINE res3b3_branch2a_relu = mx . symbol . Activation ( name = ' res3b3 _ branch2a _ relu ' , data = scale3b3_branch2a , act_type = ' relu ' ) NEW_LINE if with_dpyramid : NEW_LINE INDENT res3b3_branch2b_offset = mx . symbol . Convolution ( name = ' res3b3 _ branch2b _ offset ' , data = res3b3_branch2a_relu , num_filter = 72 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) ) NEW_LINE res3b3_branch2b = mx . contrib . symbol . DeformableConvolution ( name = ' res3b3 _ branch2b ' , data = res3b3_branch2a_relu , offset = res3b3_branch2b_offset , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , num_deformable_group = 4 , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE DEDENT else : NEW_LINE INDENT res3b3_branch2b = mx . symbol . Convolution ( name = ' res3b3 _ branch2b ' , data = res3b3_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE DEDENT bn3b3_branch2b = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2b ' , data = res3b3_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b3_branch2b = bn3b3_branch2b NEW_LINE res3b3_branch2b_relu = mx . symbol . Activation ( name = ' res3b3 _ branch2b _ relu ' , data = scale3b3_branch2b , act_type = ' relu ' ) NEW_LINE res3b3_branch2c = mx . symbol . Convolution ( name = ' res3b3 _ branch2c ' , data = res3b3_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b3_branch2c = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2c ' , data = res3b3_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b3_branch2c = bn3b3_branch2c NEW_LINE res3b3 = mx . symbol . broadcast_add ( name = ' res3b3' , * [ res3b2_relu , scale3b3_branch2c ] ) NEW_LINE res3b3_relu = mx . symbol . Activation ( name = ' res3b3 _ relu ' , data = res3b3 , act_type = ' relu ' ) NEW_LINE res4a_branch1 = mx . symbol . Convolution ( name = ' res4a _ branch1' , data = res3b3_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn4a_branch1 = mx . symbol . BatchNorm ( name = ' bn4a _ branch1' , data = res4a_branch1 , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4a_branch1 = bn4a_branch1 NEW_LINE res4a_branch2a = mx . symbol . Convolution ( name = ' res4a _ branch2a ' , data = res3b3_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn4a_branch2a = mx . symbol . BatchNorm ( name = ' bn4a _ branch2a ' , data = res4a_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4a_branch2a = bn4a_branch2a NEW_LINE res4a_branch2a_relu = mx . symbol . Activation ( name = ' res4a _ branch2a _ relu ' , data = scale4a_branch2a , act_type = ' relu ' ) NEW_LINE res4a_branch2b = mx . symbol . Convolution ( name = ' res4a _ branch2b ' , data = res4a_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4a_branch2b = mx . symbol . BatchNorm ( name = ' bn4a _ branch2b ' , data = res4a_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4a_branch2b = bn4a_branch2b NEW_LINE res4a_branch2b_relu = mx . symbol . Activation ( name = ' res4a _ branch2b _ relu ' , data = scale4a_branch2b , act_type = ' relu ' ) NEW_LINE res4a_branch2c = mx . symbol . Convolution ( name = ' res4a _ branch2c ' , data = res4a_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4a_branch2c = mx . symbol . BatchNorm ( name = ' bn4a _ branch2c ' , data = res4a_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4a_branch2c = bn4a_branch2c NEW_LINE res4a = mx . symbol . broadcast_add ( name = ' res4a ' , * [ scale4a_branch1 , scale4a_branch2c ] ) NEW_LINE res4a_relu = mx . symbol . Activation ( name = ' res4a _ relu ' , data = res4a , act_type = ' relu ' ) NEW_LINE res4b1_branch2a = mx . symbol . Convolution ( name = ' res4b1 _ branch2a ' , data = res4a_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2a = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2a ' , data = res4b1_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b1_branch2a = bn4b1_branch2a NEW_LINE res4b1_branch2a_relu = mx . symbol . Activation ( name = ' res4b1 _ branch2a _ relu ' , data = scale4b1_branch2a , act_type = ' relu ' ) NEW_LINE res4b1_branch2b = mx . symbol . Convolution ( name = ' res4b1 _ branch2b ' , data = res4b1_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2b = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2b ' , data = res4b1_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b1_branch2b = bn4b1_branch2b NEW_LINE res4b1_branch2b_relu = mx . symbol . Activation ( name = ' res4b1 _ branch2b _ relu ' , data = scale4b1_branch2b , act_type = ' relu ' ) NEW_LINE res4b1_branch2c = mx . symbol . Convolution ( name = ' res4b1 _ branch2c ' , data = res4b1_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2c = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2c ' , data = res4b1_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b1_branch2c = bn4b1_branch2c NEW_LINE res4b1 = mx . symbol . broadcast_add ( name = ' res4b1' , * [ res4a_relu , scale4b1_branch2c ] ) NEW_LINE res4b1_relu = mx . symbol . Activation ( name = ' res4b1 _ relu ' , data = res4b1 , act_type = ' relu ' ) NEW_LINE res4b2_branch2a = mx . symbol . Convolution ( name = ' res4b2 _ branch2a ' , data = res4b1_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2a = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2a ' , data = res4b2_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b2_branch2a = bn4b2_branch2a NEW_LINE res4b2_branch2a_relu = mx . symbol . Activation ( name = ' res4b2 _ branch2a _ relu ' , data = scale4b2_branch2a , act_type = ' relu ' ) NEW_LINE res4b2_branch2b = mx . symbol . Convolution ( name = ' res4b2 _ branch2b ' , data = res4b2_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2b = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2b ' , data = res4b2_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b2_branch2b = bn4b2_branch2b NEW_LINE res4b2_branch2b_relu = mx . symbol . Activation ( name = ' res4b2 _ branch2b _ relu ' , data = scale4b2_branch2b , act_type = ' relu ' ) NEW_LINE res4b2_branch2c = mx . symbol . Convolution ( name = ' res4b2 _ branch2c ' , data = res4b2_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2c = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2c ' , data = res4b2_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b2_branch2c = bn4b2_branch2c NEW_LINE res4b2 = mx . symbol . broadcast_add ( name = ' res4b2' , * [ res4b1_relu , scale4b2_branch2c ] ) NEW_LINE res4b2_relu = mx . symbol . Activation ( name = ' res4b2 _ relu ' , data = res4b2 , act_type = ' relu ' ) NEW_LINE res4b3_branch2a = mx . symbol . Convolution ( name = ' res4b3 _ branch2a ' , data = res4b2_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2a = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2a ' , data = res4b3_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b3_branch2a = bn4b3_branch2a NEW_LINE res4b3_branch2a_relu = mx . symbol . Activation ( name = ' res4b3 _ branch2a _ relu ' , data = scale4b3_branch2a , act_type = ' relu ' ) NEW_LINE res4b3_branch2b = mx . symbol . Convolution ( name = ' res4b3 _ branch2b ' , data = res4b3_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2b = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2b ' , data = res4b3_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b3_branch2b = bn4b3_branch2b NEW_LINE res4b3_branch2b_relu = mx . symbol . Activation ( name = ' res4b3 _ branch2b _ relu ' , data = scale4b3_branch2b , act_type = ' relu ' ) NEW_LINE res4b3_branch2c = mx . symbol . Convolution ( name = ' res4b3 _ branch2c ' , data = res4b3_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2c = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2c ' , data = res4b3_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b3_branch2c = bn4b3_branch2c NEW_LINE res4b3 = mx . symbol . broadcast_add ( name = ' res4b3' , * [ res4b2_relu , scale4b3_branch2c ] ) NEW_LINE res4b3_relu = mx . symbol . Activation ( name = ' res4b3 _ relu ' , data = res4b3 , act_type = ' relu ' ) NEW_LINE res4b4_branch2a = mx . symbol . Convolution ( name = ' res4b4 _ branch2a ' , data = res4b3_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2a = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2a ' , data = res4b4_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b4_branch2a = bn4b4_branch2a NEW_LINE res4b4_branch2a_relu = mx . symbol . Activation ( name = ' res4b4 _ branch2a _ relu ' , data = scale4b4_branch2a , act_type = ' relu ' ) NEW_LINE res4b4_branch2b = mx . symbol . Convolution ( name = ' res4b4 _ branch2b ' , data = res4b4_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2b = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2b ' , data = res4b4_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b4_branch2b = bn4b4_branch2b NEW_LINE res4b4_branch2b_relu = mx . symbol . Activation ( name = ' res4b4 _ branch2b _ relu ' , data = scale4b4_branch2b , act_type = ' relu ' ) NEW_LINE res4b4_branch2c = mx . symbol . Convolution ( name = ' res4b4 _ branch2c ' , data = res4b4_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2c = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2c ' , data = res4b4_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b4_branch2c = bn4b4_branch2c NEW_LINE res4b4 = mx . symbol . broadcast_add ( name = ' res4b4' , * [ res4b3_relu , scale4b4_branch2c ] ) NEW_LINE res4b4_relu = mx . symbol . Activation ( name = ' res4b4 _ relu ' , data = res4b4 , act_type = ' relu ' ) NEW_LINE res4b5_branch2a = mx . symbol . Convolution ( name = ' res4b5 _ branch2a ' , data = res4b4_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2a = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2a ' , data = res4b5_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b5_branch2a = bn4b5_branch2a NEW_LINE res4b5_branch2a_relu = mx . symbol . Activation ( name = ' res4b5 _ branch2a _ relu ' , data = scale4b5_branch2a , act_type = ' relu ' ) NEW_LINE res4b5_branch2b = mx . symbol . Convolution ( name = ' res4b5 _ branch2b ' , data = res4b5_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2b = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2b ' , data = res4b5_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b5_branch2b = bn4b5_branch2b NEW_LINE res4b5_branch2b_relu = mx . symbol . Activation ( name = ' res4b5 _ branch2b _ relu ' , data = scale4b5_branch2b , act_type = ' relu ' ) NEW_LINE res4b5_branch2c = mx . symbol . Convolution ( name = ' res4b5 _ branch2c ' , data = res4b5_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2c = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2c ' , data = res4b5_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b5_branch2c = bn4b5_branch2c NEW_LINE res4b5 = mx . symbol . broadcast_add ( name = ' res4b5' , * [ res4b4_relu , scale4b5_branch2c ] ) NEW_LINE res4b5_relu = mx . symbol . Activation ( name = ' res4b5 _ relu ' , data = res4b5 , act_type = ' relu ' ) NEW_LINE res4b6_branch2a = mx . symbol . Convolution ( name = ' res4b6 _ branch2a ' , data = res4b5_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2a = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2a ' , data = res4b6_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b6_branch2a = bn4b6_branch2a NEW_LINE res4b6_branch2a_relu = mx . symbol . Activation ( name = ' res4b6 _ branch2a _ relu ' , data = scale4b6_branch2a , act_type = ' relu ' ) NEW_LINE res4b6_branch2b = mx . symbol . Convolution ( name = ' res4b6 _ branch2b ' , data = res4b6_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2b = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2b ' , data = res4b6_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b6_branch2b = bn4b6_branch2b NEW_LINE res4b6_branch2b_relu = mx . symbol . Activation ( name = ' res4b6 _ branch2b _ relu ' , data = scale4b6_branch2b , act_type = ' relu ' ) NEW_LINE res4b6_branch2c = mx . symbol . Convolution ( name = ' res4b6 _ branch2c ' , data = res4b6_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2c = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2c ' , data = res4b6_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b6_branch2c = bn4b6_branch2c NEW_LINE res4b6 = mx . symbol . broadcast_add ( name = ' res4b6' , * [ res4b5_relu , scale4b6_branch2c ] ) NEW_LINE res4b6_relu = mx . symbol . Activation ( name = ' res4b6 _ relu ' , data = res4b6 , act_type = ' relu ' ) NEW_LINE res4b7_branch2a = mx . symbol . Convolution ( name = ' res4b7 _ branch2a ' , data = res4b6_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2a = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2a ' , data = res4b7_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b7_branch2a = bn4b7_branch2a NEW_LINE res4b7_branch2a_relu = mx . symbol . Activation ( name = ' res4b7 _ branch2a _ relu ' , data = scale4b7_branch2a , act_type = ' relu ' ) NEW_LINE res4b7_branch2b = mx . symbol . Convolution ( name = ' res4b7 _ branch2b ' , data = res4b7_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2b = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2b ' , data = res4b7_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b7_branch2b = bn4b7_branch2b NEW_LINE res4b7_branch2b_relu = mx . symbol . Activation ( name = ' res4b7 _ branch2b _ relu ' , data = scale4b7_branch2b , act_type = ' relu ' ) NEW_LINE res4b7_branch2c = mx . symbol . Convolution ( name = ' res4b7 _ branch2c ' , data = res4b7_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2c = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2c ' , data = res4b7_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b7_branch2c = bn4b7_branch2c NEW_LINE res4b7 = mx . symbol . broadcast_add ( name = ' res4b7' , * [ res4b6_relu , scale4b7_branch2c ] ) NEW_LINE res4b7_relu = mx . symbol . Activation ( name = ' res4b7 _ relu ' , data = res4b7 , act_type = ' relu ' ) NEW_LINE res4b8_branch2a = mx . symbol . Convolution ( name = ' res4b8 _ branch2a ' , data = res4b7_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2a = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2a ' , data = res4b8_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b8_branch2a = bn4b8_branch2a NEW_LINE res4b8_branch2a_relu = mx . symbol . Activation ( name = ' res4b8 _ branch2a _ relu ' , data = scale4b8_branch2a , act_type = ' relu ' ) NEW_LINE res4b8_branch2b = mx . symbol . Convolution ( name = ' res4b8 _ branch2b ' , data = res4b8_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2b = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2b ' , data = res4b8_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b8_branch2b = bn4b8_branch2b NEW_LINE res4b8_branch2b_relu = mx . symbol . Activation ( name = ' res4b8 _ branch2b _ relu ' , data = scale4b8_branch2b , act_type = ' relu ' ) NEW_LINE res4b8_branch2c = mx . symbol . Convolution ( name = ' res4b8 _ branch2c ' , data = res4b8_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2c = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2c ' , data = res4b8_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b8_branch2c = bn4b8_branch2c NEW_LINE res4b8 = mx . symbol . broadcast_add ( name = ' res4b8' , * [ res4b7_relu , scale4b8_branch2c ] ) NEW_LINE res4b8_relu = mx . symbol . Activation ( name = ' res4b8 _ relu ' , data = res4b8 , act_type = ' relu ' ) NEW_LINE res4b9_branch2a = mx . symbol . Convolution ( name = ' res4b9 _ branch2a ' , data = res4b8_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2a = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2a ' , data = res4b9_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b9_branch2a = bn4b9_branch2a NEW_LINE res4b9_branch2a_relu = mx . symbol . Activation ( name = ' res4b9 _ branch2a _ relu ' , data = scale4b9_branch2a , act_type = ' relu ' ) NEW_LINE res4b9_branch2b = mx . symbol . Convolution ( name = ' res4b9 _ branch2b ' , data = res4b9_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2b = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2b ' , data = res4b9_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b9_branch2b = bn4b9_branch2b NEW_LINE res4b9_branch2b_relu = mx . symbol . Activation ( name = ' res4b9 _ branch2b _ relu ' , data = scale4b9_branch2b , act_type = ' relu ' ) NEW_LINE res4b9_branch2c = mx . symbol . Convolution ( name = ' res4b9 _ branch2c ' , data = res4b9_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2c = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2c ' , data = res4b9_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b9_branch2c = bn4b9_branch2c NEW_LINE res4b9 = mx . symbol . broadcast_add ( name = ' res4b9' , * [ res4b8_relu , scale4b9_branch2c ] ) NEW_LINE res4b9_relu = mx . symbol . Activation ( name = ' res4b9 _ relu ' , data = res4b9 , act_type = ' relu ' ) NEW_LINE res4b10_branch2a = mx . symbol . Convolution ( name = ' res4b10 _ branch2a ' , data = res4b9_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2a = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2a ' , data = res4b10_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b10_branch2a = bn4b10_branch2a NEW_LINE res4b10_branch2a_relu = mx . symbol . Activation ( name = ' res4b10 _ branch2a _ relu ' , data = scale4b10_branch2a , act_type = ' relu ' ) NEW_LINE res4b10_branch2b = mx . symbol . Convolution ( name = ' res4b10 _ branch2b ' , data = res4b10_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2b = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2b ' , data = res4b10_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b10_branch2b = bn4b10_branch2b NEW_LINE res4b10_branch2b_relu = mx . symbol . Activation ( name = ' res4b10 _ branch2b _ relu ' , data = scale4b10_branch2b , act_type = ' relu ' ) NEW_LINE res4b10_branch2c = mx . symbol . Convolution ( name = ' res4b10 _ branch2c ' , data = res4b10_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2c = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2c ' , data = res4b10_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b10_branch2c = bn4b10_branch2c NEW_LINE res4b10 = mx . symbol . broadcast_add ( name = ' res4b10' , * [ res4b9_relu , scale4b10_branch2c ] ) NEW_LINE res4b10_relu = mx . symbol . Activation ( name = ' res4b10 _ relu ' , data = res4b10 , act_type = ' relu ' ) NEW_LINE res4b11_branch2a = mx . symbol . Convolution ( name = ' res4b11 _ branch2a ' , data = res4b10_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2a = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2a ' , data = res4b11_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b11_branch2a = bn4b11_branch2a NEW_LINE res4b11_branch2a_relu = mx . symbol . Activation ( name = ' res4b11 _ branch2a _ relu ' , data = scale4b11_branch2a , act_type = ' relu ' ) NEW_LINE res4b11_branch2b = mx . symbol . Convolution ( name = ' res4b11 _ branch2b ' , data = res4b11_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2b = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2b ' , data = res4b11_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b11_branch2b = bn4b11_branch2b NEW_LINE res4b11_branch2b_relu = mx . symbol . Activation ( name = ' res4b11 _ branch2b _ relu ' , data = scale4b11_branch2b , act_type = ' relu ' ) NEW_LINE res4b11_branch2c = mx . symbol . Convolution ( name = ' res4b11 _ branch2c ' , data = res4b11_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2c = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2c ' , data = res4b11_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b11_branch2c = bn4b11_branch2c NEW_LINE res4b11 = mx . symbol . broadcast_add ( name = ' res4b11' , * [ res4b10_relu , scale4b11_branch2c ] ) NEW_LINE res4b11_relu = mx . symbol . Activation ( name = ' res4b11 _ relu ' , data = res4b11 , act_type = ' relu ' ) NEW_LINE res4b12_branch2a = mx . symbol . Convolution ( name = ' res4b12 _ branch2a ' , data = res4b11_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2a = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2a ' , data = res4b12_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b12_branch2a = bn4b12_branch2a NEW_LINE res4b12_branch2a_relu = mx . symbol . Activation ( name = ' res4b12 _ branch2a _ relu ' , data = scale4b12_branch2a , act_type = ' relu ' ) NEW_LINE res4b12_branch2b = mx . symbol . Convolution ( name = ' res4b12 _ branch2b ' , data = res4b12_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2b = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2b ' , data = res4b12_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b12_branch2b = bn4b12_branch2b NEW_LINE res4b12_branch2b_relu = mx . symbol . Activation ( name = ' res4b12 _ branch2b _ relu ' , data = scale4b12_branch2b , act_type = ' relu ' ) NEW_LINE res4b12_branch2c = mx . symbol . Convolution ( name = ' res4b12 _ branch2c ' , data = res4b12_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2c = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2c ' , data = res4b12_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b12_branch2c = bn4b12_branch2c NEW_LINE res4b12 = mx . symbol . broadcast_add ( name = ' res4b12' , * [ res4b11_relu , scale4b12_branch2c ] ) NEW_LINE res4b12_relu = mx . symbol . Activation ( name = ' res4b12 _ relu ' , data = res4b12 , act_type = ' relu ' ) NEW_LINE res4b13_branch2a = mx . symbol . Convolution ( name = ' res4b13 _ branch2a ' , data = res4b12_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2a = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2a ' , data = res4b13_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b13_branch2a = bn4b13_branch2a NEW_LINE res4b13_branch2a_relu = mx . symbol . Activation ( name = ' res4b13 _ branch2a _ relu ' , data = scale4b13_branch2a , act_type = ' relu ' ) NEW_LINE res4b13_branch2b = mx . symbol . Convolution ( name = ' res4b13 _ branch2b ' , data = res4b13_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2b = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2b ' , data = res4b13_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b13_branch2b = bn4b13_branch2b NEW_LINE res4b13_branch2b_relu = mx . symbol . Activation ( name = ' res4b13 _ branch2b _ relu ' , data = scale4b13_branch2b , act_type = ' relu ' ) NEW_LINE res4b13_branch2c = mx . symbol . Convolution ( name = ' res4b13 _ branch2c ' , data = res4b13_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2c = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2c ' , data = res4b13_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b13_branch2c = bn4b13_branch2c NEW_LINE res4b13 = mx . symbol . broadcast_add ( name = ' res4b13' , * [ res4b12_relu , scale4b13_branch2c ] ) NEW_LINE res4b13_relu = mx . symbol . Activation ( name = ' res4b13 _ relu ' , data = res4b13 , act_type = ' relu ' ) NEW_LINE res4b14_branch2a = mx . symbol . Convolution ( name = ' res4b14 _ branch2a ' , data = res4b13_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2a = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2a ' , data = res4b14_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b14_branch2a = bn4b14_branch2a NEW_LINE res4b14_branch2a_relu = mx . symbol . Activation ( name = ' res4b14 _ branch2a _ relu ' , data = scale4b14_branch2a , act_type = ' relu ' ) NEW_LINE res4b14_branch2b = mx . symbol . Convolution ( name = ' res4b14 _ branch2b ' , data = res4b14_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2b = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2b ' , data = res4b14_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b14_branch2b = bn4b14_branch2b NEW_LINE res4b14_branch2b_relu = mx . symbol . Activation ( name = ' res4b14 _ branch2b _ relu ' , data = scale4b14_branch2b , act_type = ' relu ' ) NEW_LINE res4b14_branch2c = mx . symbol . Convolution ( name = ' res4b14 _ branch2c ' , data = res4b14_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2c = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2c ' , data = res4b14_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b14_branch2c = bn4b14_branch2c NEW_LINE res4b14 = mx . symbol . broadcast_add ( name = ' res4b14' , * [ res4b13_relu , scale4b14_branch2c ] ) NEW_LINE res4b14_relu = mx . symbol . Activation ( name = ' res4b14 _ relu ' , data = res4b14 , act_type = ' relu ' ) NEW_LINE res4b15_branch2a = mx . symbol . Convolution ( name = ' res4b15 _ branch2a ' , data = res4b14_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2a = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2a ' , data = res4b15_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b15_branch2a = bn4b15_branch2a NEW_LINE res4b15_branch2a_relu = mx . symbol . Activation ( name = ' res4b15 _ branch2a _ relu ' , data = scale4b15_branch2a , act_type = ' relu ' ) NEW_LINE res4b15_branch2b = mx . symbol . Convolution ( name = ' res4b15 _ branch2b ' , data = res4b15_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2b = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2b ' , data = res4b15_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b15_branch2b = bn4b15_branch2b NEW_LINE res4b15_branch2b_relu = mx . symbol . Activation ( name = ' res4b15 _ branch2b _ relu ' , data = scale4b15_branch2b , act_type = ' relu ' ) NEW_LINE res4b15_branch2c = mx . symbol . Convolution ( name = ' res4b15 _ branch2c ' , data = res4b15_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2c = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2c ' , data = res4b15_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b15_branch2c = bn4b15_branch2c NEW_LINE res4b15 = mx . symbol . broadcast_add ( name = ' res4b15' , * [ res4b14_relu , scale4b15_branch2c ] ) NEW_LINE res4b15_relu = mx . symbol . Activation ( name = ' res4b15 _ relu ' , data = res4b15 , act_type = ' relu ' ) NEW_LINE res4b16_branch2a = mx . symbol . Convolution ( name = ' res4b16 _ branch2a ' , data = res4b15_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2a = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2a ' , data = res4b16_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b16_branch2a = bn4b16_branch2a NEW_LINE res4b16_branch2a_relu = mx . symbol . Activation ( name = ' res4b16 _ branch2a _ relu ' , data = scale4b16_branch2a , act_type = ' relu ' ) NEW_LINE res4b16_branch2b = mx . symbol . Convolution ( name = ' res4b16 _ branch2b ' , data = res4b16_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2b = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2b ' , data = res4b16_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b16_branch2b = bn4b16_branch2b NEW_LINE res4b16_branch2b_relu = mx . symbol . Activation ( name = ' res4b16 _ branch2b _ relu ' , data = scale4b16_branch2b , act_type = ' relu ' ) NEW_LINE res4b16_branch2c = mx . symbol . Convolution ( name = ' res4b16 _ branch2c ' , data = res4b16_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2c = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2c ' , data = res4b16_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b16_branch2c = bn4b16_branch2c NEW_LINE res4b16 = mx . symbol . broadcast_add ( name = ' res4b16' , * [ res4b15_relu , scale4b16_branch2c ] ) NEW_LINE res4b16_relu = mx . symbol . Activation ( name = ' res4b16 _ relu ' , data = res4b16 , act_type = ' relu ' ) NEW_LINE res4b17_branch2a = mx . symbol . Convolution ( name = ' res4b17 _ branch2a ' , data = res4b16_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2a = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2a ' , data = res4b17_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b17_branch2a = bn4b17_branch2a NEW_LINE res4b17_branch2a_relu = mx . symbol . Activation ( name = ' res4b17 _ branch2a _ relu ' , data = scale4b17_branch2a , act_type = ' relu ' ) NEW_LINE res4b17_branch2b = mx . symbol . Convolution ( name = ' res4b17 _ branch2b ' , data = res4b17_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2b = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2b ' , data = res4b17_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b17_branch2b = bn4b17_branch2b NEW_LINE res4b17_branch2b_relu = mx . symbol . Activation ( name = ' res4b17 _ branch2b _ relu ' , data = scale4b17_branch2b , act_type = ' relu ' ) NEW_LINE res4b17_branch2c = mx . symbol . Convolution ( name = ' res4b17 _ branch2c ' , data = res4b17_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2c = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2c ' , data = res4b17_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b17_branch2c = bn4b17_branch2c NEW_LINE res4b17 = mx . symbol . broadcast_add ( name = ' res4b17' , * [ res4b16_relu , scale4b17_branch2c ] ) NEW_LINE res4b17_relu = mx . symbol . Activation ( name = ' res4b17 _ relu ' , data = res4b17 , act_type = ' relu ' ) NEW_LINE res4b18_branch2a = mx . symbol . Convolution ( name = ' res4b18 _ branch2a ' , data = res4b17_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2a = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2a ' , data = res4b18_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b18_branch2a = bn4b18_branch2a NEW_LINE res4b18_branch2a_relu = mx . symbol . Activation ( name = ' res4b18 _ branch2a _ relu ' , data = scale4b18_branch2a , act_type = ' relu ' ) NEW_LINE res4b18_branch2b = mx . symbol . Convolution ( name = ' res4b18 _ branch2b ' , data = res4b18_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2b = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2b ' , data = res4b18_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b18_branch2b = bn4b18_branch2b NEW_LINE res4b18_branch2b_relu = mx . symbol . Activation ( name = ' res4b18 _ branch2b _ relu ' , data = scale4b18_branch2b , act_type = ' relu ' ) NEW_LINE res4b18_branch2c = mx . symbol . Convolution ( name = ' res4b18 _ branch2c ' , data = res4b18_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2c = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2c ' , data = res4b18_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b18_branch2c = bn4b18_branch2c NEW_LINE res4b18 = mx . symbol . broadcast_add ( name = ' res4b18' , * [ res4b17_relu , scale4b18_branch2c ] ) NEW_LINE res4b18_relu = mx . symbol . Activation ( name = ' res4b18 _ relu ' , data = res4b18 , act_type = ' relu ' ) NEW_LINE res4b19_branch2a = mx . symbol . Convolution ( name = ' res4b19 _ branch2a ' , data = res4b18_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2a = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2a ' , data = res4b19_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b19_branch2a = bn4b19_branch2a NEW_LINE res4b19_branch2a_relu = mx . symbol . Activation ( name = ' res4b19 _ branch2a _ relu ' , data = scale4b19_branch2a , act_type = ' relu ' ) NEW_LINE res4b19_branch2b = mx . symbol . Convolution ( name = ' res4b19 _ branch2b ' , data = res4b19_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2b = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2b ' , data = res4b19_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b19_branch2b = bn4b19_branch2b NEW_LINE res4b19_branch2b_relu = mx . symbol . Activation ( name = ' res4b19 _ branch2b _ relu ' , data = scale4b19_branch2b , act_type = ' relu ' ) NEW_LINE res4b19_branch2c = mx . symbol . Convolution ( name = ' res4b19 _ branch2c ' , data = res4b19_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2c = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2c ' , data = res4b19_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b19_branch2c = bn4b19_branch2c NEW_LINE res4b19 = mx . symbol . broadcast_add ( name = ' res4b19' , * [ res4b18_relu , scale4b19_branch2c ] ) NEW_LINE res4b19_relu = mx . symbol . Activation ( name = ' res4b19 _ relu ' , data = res4b19 , act_type = ' relu ' ) NEW_LINE res4b20_branch2a = mx . symbol . Convolution ( name = ' res4b20 _ branch2a ' , data = res4b19_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2a = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2a ' , data = res4b20_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b20_branch2a = bn4b20_branch2a NEW_LINE res4b20_branch2a_relu = mx . symbol . Activation ( name = ' res4b20 _ branch2a _ relu ' , data = scale4b20_branch2a , act_type = ' relu ' ) NEW_LINE res4b20_branch2b = mx . symbol . Convolution ( name = ' res4b20 _ branch2b ' , data = res4b20_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2b = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2b ' , data = res4b20_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b20_branch2b = bn4b20_branch2b NEW_LINE res4b20_branch2b_relu = mx . symbol . Activation ( name = ' res4b20 _ branch2b _ relu ' , data = scale4b20_branch2b , act_type = ' relu ' ) NEW_LINE res4b20_branch2c = mx . symbol . Convolution ( name = ' res4b20 _ branch2c ' , data = res4b20_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2c = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2c ' , data = res4b20_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b20_branch2c = bn4b20_branch2c NEW_LINE res4b20 = mx . symbol . broadcast_add ( name = ' res4b20' , * [ res4b19_relu , scale4b20_branch2c ] ) NEW_LINE res4b20_relu = mx . symbol . Activation ( name = ' res4b20 _ relu ' , data = res4b20 , act_type = ' relu ' ) NEW_LINE res4b21_branch2a = mx . symbol . Convolution ( name = ' res4b21 _ branch2a ' , data = res4b20_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2a = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2a ' , data = res4b21_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b21_branch2a = bn4b21_branch2a NEW_LINE res4b21_branch2a_relu = mx . symbol . Activation ( name = ' res4b21 _ branch2a _ relu ' , data = scale4b21_branch2a , act_type = ' relu ' ) NEW_LINE res4b21_branch2b = mx . symbol . Convolution ( name = ' res4b21 _ branch2b ' , data = res4b21_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2b = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2b ' , data = res4b21_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b21_branch2b = bn4b21_branch2b NEW_LINE res4b21_branch2b_relu = mx . symbol . Activation ( name = ' res4b21 _ branch2b _ relu ' , data = scale4b21_branch2b , act_type = ' relu ' ) NEW_LINE res4b21_branch2c = mx . symbol . Convolution ( name = ' res4b21 _ branch2c ' , data = res4b21_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2c = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2c ' , data = res4b21_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b21_branch2c = bn4b21_branch2c NEW_LINE res4b21 = mx . symbol . broadcast_add ( name = ' res4b21' , * [ res4b20_relu , scale4b21_branch2c ] ) NEW_LINE res4b21_relu = mx . symbol . Activation ( name = ' res4b21 _ relu ' , data = res4b21 , act_type = ' relu ' ) NEW_LINE res4b22_branch2a = mx . symbol . Convolution ( name = ' res4b22 _ branch2a ' , data = res4b21_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b22_branch2a = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2a ' , data = res4b22_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b22_branch2a = bn4b22_branch2a NEW_LINE res4b22_branch2a_relu = mx . symbol . Activation ( name = ' res4b22 _ branch2a _ relu ' , data = scale4b22_branch2a , act_type = ' relu ' ) NEW_LINE if with_dpyramid : NEW_LINE INDENT res4b22_branch2b_offset = mx . symbol . Convolution ( name = ' res4b22 _ branch2b _ offset ' , data = res4b22_branch2a_relu , num_filter = 72 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) ) NEW_LINE res4b22_branch2b = mx . contrib . symbol . DeformableConvolution ( name = ' res4b22 _ branch2b ' , data = res4b22_branch2a_relu , offset = res4b22_branch2b_offset , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , num_deformable_group = 4 , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE DEDENT else : NEW_LINE INDENT res4b22_branch2b = mx . symbol . Convolution ( name = ' res4b22 _ branch2b ' , data = res4b22_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE DEDENT bn4b22_branch2b = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2b ' , data = res4b22_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b22_branch2b = bn4b22_branch2b NEW_LINE res4b22_branch2b_relu = mx . symbol . Activation ( name = ' res4b22 _ branch2b _ relu ' , data = scale4b22_branch2b , act_type = ' relu ' ) NEW_LINE res4b22_branch2c = mx . symbol . Convolution ( name = ' res4b22 _ branch2c ' , data = res4b22_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b22_branch2c = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2c ' , data = res4b22_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b22_branch2c = bn4b22_branch2c NEW_LINE res4b22 = mx . symbol . broadcast_add ( name = ' res4b22' , * [ res4b21_relu , scale4b22_branch2c ] ) NEW_LINE res4b22_relu = mx . symbol . Activation ( name = ' res4b22 _ relu ' , data = res4b22 , act_type = ' relu ' ) NEW_LINE if with_dilated : NEW_LINE INDENT res5_stride = ( 1 , 1 ) NEW_LINE res5_dilate = ( 2 , 2 ) NEW_LINE DEDENT else : NEW_LINE INDENT res5_stride = ( 2 , 2 ) NEW_LINE res5_dilate = ( 1 , 1 ) NEW_LINE DEDENT res5a_branch2a = mx . symbol . Convolution ( name = ' res5a _ branch2a ' , data = res4b22_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = res5_stride , no_bias = True ) NEW_LINE bn5a_branch2a = mx . symbol . BatchNorm ( name = ' bn5a _ branch2a ' , data = res5a_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5a_branch2a = bn5a_branch2a NEW_LINE res5a_branch2a_relu = mx . symbol . Activation ( name = ' res5a _ branch2a _ relu ' , data = scale5a_branch2a , act_type = ' relu ' ) NEW_LINE if with_dconv : NEW_LINE INDENT res5a_branch2b_offset = mx . symbol . Convolution ( name = ' res5a _ branch2b _ offset ' , data = res5a_branch2a_relu , num_filter = 72 , pad = res5_dilate , kernel = ( 3 , 3 ) , dilate = res5_dilate ) NEW_LINE res5a_branch2b = mx . contrib . symbol . DeformableConvolution ( name = ' res5a _ branch2b ' , data = res5a_branch2a_relu , offset = res5a_branch2b_offset , num_filter = 512 , pad = res5_dilate , kernel = ( 3 , 3 ) , num_deformable_group = 4 , stride = ( 1 , 1 ) , dilate = res5_dilate , no_bias = True ) NEW_LINE DEDENT else : NEW_LINE INDENT res5a_branch2b = mx . symbol . Convolution ( name = ' res5a _ branch2b ' , data = res5a_branch2a_relu , num_filter = 512 , pad = res5_dilate , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = res5_dilate , no_bias = True ) NEW_LINE DEDENT bn5a_branch2b = mx . symbol . BatchNorm ( name = ' bn5a _ branch2b ' , data = res5a_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5a_branch2b = bn5a_branch2b NEW_LINE res5a_branch2b_relu = mx . symbol . Activation ( name = ' res5a _ branch2b _ relu ' , data = scale5a_branch2b , act_type = ' relu ' ) NEW_LINE res5a_branch2c = mx . symbol . Convolution ( name = ' res5a _ branch2c ' , data = res5a_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5a_branch2c = mx . symbol . BatchNorm ( name = ' bn5a _ branch2c ' , data = res5a_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5a_branch2c = bn5a_branch2c NEW_LINE res5a_branch1 = mx . symbol . Convolution ( name = ' res5a _ branch1' , data = res4b22_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = res5_stride , no_bias = True ) NEW_LINE bn5a_branch1 = mx . symbol . BatchNorm ( name = ' bn5a _ branch1' , data = res5a_branch1 , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5a_branch1 = bn5a_branch1 NEW_LINE res5a = mx . symbol . broadcast_add ( name = ' res5a ' , * [ scale5a_branch1 , scale5a_branch2c ] ) NEW_LINE res5a_relu = mx . symbol . Activation ( name = ' res5a _ relu ' , data = res5a , act_type = ' relu ' ) NEW_LINE res5b_branch2a = mx . symbol . Convolution ( name = ' res5b _ branch2a ' , data = res5a_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5b_branch2a = mx . symbol . BatchNorm ( name = ' bn5b _ branch2a ' , data = res5b_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5b_branch2a = bn5b_branch2a NEW_LINE res5b_branch2a_relu = mx . symbol . Activation ( name = ' res5b _ branch2a _ relu ' , data = scale5b_branch2a , act_type = ' relu ' ) NEW_LINE if with_dconv : NEW_LINE INDENT res5b_branch2b_offset = mx . symbol . Convolution ( name = ' res5b _ branch2b _ offset ' , data = res5b_branch2a_relu , num_filter = 72 , pad = res5_dilate , kernel = ( 3 , 3 ) , dilate = res5_dilate ) NEW_LINE res5b_branch2b = mx . contrib . symbol . DeformableConvolution ( name = ' res5b _ branch2b ' , data = res5b_branch2a_relu , offset = res5b_branch2b_offset , num_filter = 512 , pad = res5_dilate , kernel = ( 3 , 3 ) , num_deformable_group = 4 , dilate = res5_dilate , no_bias = True ) NEW_LINE DEDENT else : NEW_LINE INDENT res5b_branch2b = mx . symbol . Convolution ( name = ' res5b _ branch2b ' , data = res5b_branch2a_relu , num_filter = 512 , pad = res5_dilate , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = res5_dilate , no_bias = True ) NEW_LINE DEDENT bn5b_branch2b = mx . symbol . BatchNorm ( name = ' bn5b _ branch2b ' , data = res5b_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5b_branch2b = bn5b_branch2b NEW_LINE res5b_branch2b_relu = mx . symbol . Activation ( name = ' res5b _ branch2b _ relu ' , data = scale5b_branch2b , act_type = ' relu ' ) NEW_LINE res5b_branch2c = mx . symbol . Convolution ( name = ' res5b _ branch2c ' , data = res5b_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5b_branch2c = mx . symbol . BatchNorm ( name = ' bn5b _ branch2c ' , data = res5b_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5b_branch2c = bn5b_branch2c NEW_LINE res5b = mx . symbol . broadcast_add ( name = ' res5b ' , * [ res5a_relu , scale5b_branch2c ] ) NEW_LINE res5b_relu = mx . symbol . Activation ( name = ' res5b _ relu ' , data = res5b , act_type = ' relu ' ) NEW_LINE res5c_branch2a = mx . symbol . Convolution ( name = ' res5c _ branch2a ' , data = res5b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5c_branch2a = mx . symbol . BatchNorm ( name = ' bn5c _ branch2a ' , data = res5c_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5c_branch2a = bn5c_branch2a NEW_LINE res5c_branch2a_relu = mx . symbol . Activation ( name = ' res5c _ branch2a _ relu ' , data = scale5c_branch2a , act_type = ' relu ' ) NEW_LINE if with_dconv : NEW_LINE INDENT res5c_branch2b_offset = mx . symbol . Convolution ( name = ' res5c _ branch2b _ offset ' , data = res5c_branch2a_relu , num_filter = 72 , pad = res5_dilate , kernel = ( 3 , 3 ) , dilate = res5_dilate ) NEW_LINE res5c_branch2b = mx . contrib . symbol . DeformableConvolution ( name = ' res5c _ branch2b ' , data = res5c_branch2a_relu , offset = res5c_branch2b_offset , num_filter = 512 , pad = res5_dilate , kernel = ( 3 , 3 ) , num_deformable_group = 4 , dilate = res5_dilate , no_bias = True ) NEW_LINE DEDENT else : NEW_LINE INDENT res5c_branch2b = mx . symbol . Convolution ( name = ' res5c _ branch2b ' , data = res5c_branch2a_relu , num_filter = 512 , pad = res5_dilate , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = res5_dilate , no_bias = True ) NEW_LINE DEDENT bn5c_branch2b = mx . symbol . BatchNorm ( name = ' bn5c _ branch2b ' , data = res5c_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5c_branch2b = bn5c_branch2b NEW_LINE res5c_branch2b_relu = mx . symbol . Activation ( name = ' res5c _ branch2b _ relu ' , data = scale5c_branch2b , act_type = ' relu ' ) NEW_LINE res5c_branch2c = mx . symbol . Convolution ( name = ' res5c _ branch2c ' , data = res5c_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5c_branch2c = mx . symbol . BatchNorm ( name = ' bn5c _ branch2c ' , data = res5c_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5c_branch2c = bn5c_branch2c NEW_LINE res5c = mx . symbol . broadcast_add ( name = ' res5c ' , * [ res5b_relu , scale5c_branch2c ] ) NEW_LINE res5c_relu = mx . symbol . Activation ( name = ' res5c _ relu ' , data = res5c , act_type = ' relu ' ) NEW_LINE return res2c_relu , res3b3_relu , res4b22_relu , res5c_relu NEW_LINE DEDENT\",), (\"def get_fpn_feature ( self , c2 , c3 , c4 , c5 , feature_dim = 256 ) : NEW_LINE INDENT fpn_p5_1x1 = mx . symbol . Convolution ( data = c5 , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , stride = ( 1 , 1 ) , num_filter = feature_dim , name = ' fpn _ p5_1x1' ) NEW_LINE fpn_p4_1x1 = mx . symbol . Convolution ( data = c4 , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , stride = ( 1 , 1 ) , num_filter = feature_dim , name = ' fpn _ p4_1x1' ) NEW_LINE fpn_p3_1x1 = mx . symbol . Convolution ( data = c3 , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , stride = ( 1 , 1 ) , num_filter = feature_dim , name = ' fpn _ p3_1x1' ) NEW_LINE fpn_p2_1x1 = mx . symbol . Convolution ( data = c2 , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , stride = ( 1 , 1 ) , num_filter = feature_dim , name = ' fpn _ p2_1x1' ) NEW_LINE fpn_p5_upsample = mx . symbol . UpSampling ( fpn_p5_1x1 , scale = 2 , sample_type = ' nearest ' , name = ' fpn _ p5 _ upsample ' ) NEW_LINE fpn_p4_plus = mx . sym . ElementWiseSum ( * [ fpn_p5_upsample , fpn_p4_1x1 ] , name = ' fpn _ p4 _ sum ' ) NEW_LINE fpn_p4_upsample = mx . symbol . UpSampling ( fpn_p4_plus , scale = 2 , sample_type = ' nearest ' , name = ' fpn _ p4 _ upsample ' ) NEW_LINE fpn_p3_plus = mx . sym . ElementWiseSum ( * [ fpn_p4_upsample , fpn_p3_1x1 ] , name = ' fpn _ p3 _ sum ' ) NEW_LINE fpn_p3_upsample = mx . symbol . UpSampling ( fpn_p3_plus , scale = 2 , sample_type = ' nearest ' , name = ' fpn _ p3 _ upsample ' ) NEW_LINE fpn_p2_plus = mx . sym . ElementWiseSum ( * [ fpn_p3_upsample , fpn_p2_1x1 ] , name = ' fpn _ p2 _ sum ' ) NEW_LINE fpn_p6 = mx . sym . Convolution ( data = c5 , kernel = ( 3 , 3 ) , pad = ( 1 , 1 ) , stride = ( 2 , 2 ) , num_filter = feature_dim , name = ' fpn _ p6' ) NEW_LINE fpn_p5 = mx . symbol . Convolution ( data = fpn_p5_1x1 , kernel = ( 3 , 3 ) , pad = ( 1 , 1 ) , stride = ( 1 , 1 ) , num_filter = feature_dim , name = ' fpn _ p5' ) NEW_LINE fpn_p4 = mx . symbol . Convolution ( data = fpn_p4_plus , kernel = ( 3 , 3 ) , pad = ( 1 , 1 ) , stride = ( 1 , 1 ) , num_filter = feature_dim , name = ' fpn _ p4' ) NEW_LINE fpn_p3 = mx . symbol . Convolution ( data = fpn_p3_plus , kernel = ( 3 , 3 ) , pad = ( 1 , 1 ) , stride = ( 1 , 1 ) , num_filter = feature_dim , name = ' fpn _ p3' ) NEW_LINE fpn_p2 = mx . symbol . Convolution ( data = fpn_p2_plus , kernel = ( 3 , 3 ) , pad = ( 1 , 1 ) , stride = ( 1 , 1 ) , num_filter = feature_dim , name = ' fpn _ p2' ) NEW_LINE return fpn_p2 , fpn_p3 , fpn_p4 , fpn_p5 , fpn_p6 NEW_LINE DEDENT\",), (\"def get_rpn_subnet ( self , data , num_anchors , suffix ) : NEW_LINE INDENT rpn_conv = mx . sym . Convolution ( data = data , kernel = ( 3 , 3 ) , pad = ( 1 , 1 ) , num_filter = 512 , name = ' rpn _ conv _ ' + suffix , weight = self . shared_param_dict [ ' rpn _ conv _ weight ' ] , bias = self . shared_param_dict [ ' rpn _ conv _ bias ' ] ) NEW_LINE rpn_relu = mx . sym . Activation ( data = rpn_conv , act_type = ' relu ' , name = ' rpn _ relu _ ' + suffix ) NEW_LINE rpn_cls_score = mx . sym . Convolution ( data = rpn_relu , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , num_filter = 2 * num_anchors , name = ' rpn _ cls _ score _ ' + suffix , weight = self . shared_param_dict [ ' rpn _ cls _ score _ weight ' ] , bias = self . shared_param_dict [ ' rpn _ cls _ score _ bias ' ] ) NEW_LINE rpn_bbox_pred = mx . sym . Convolution ( data = rpn_relu , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , num_filter = 4 * num_anchors , name = ' rpn _ bbox _ pred _ ' + suffix , weight = self . shared_param_dict [ ' rpn _ bbox _ pred _ weight ' ] , bias = self . shared_param_dict [ ' rpn _ bbox _ pred _ bias ' ] ) NEW_LINE rpn_cls_score_t1 = mx . sym . Reshape ( data = rpn_cls_score , shape = ( 0 , 2 , - 1 , 0 ) , name = ' rpn _ cls _ score _ t1 _ ' + suffix ) NEW_LINE rpn_cls_score_t2 = mx . sym . Reshape ( data = rpn_cls_score_t1 , shape = ( 0 , 2 , - 1 ) , name = ' rpn _ cls _ score _ t2 _ ' + suffix ) NEW_LINE rpn_cls_prob = mx . sym . SoftmaxActivation ( data = rpn_cls_score_t1 , mode = ' channel ' , name = ' rpn _ cls _ prob _ ' + suffix ) NEW_LINE rpn_cls_prob_t = mx . sym . Reshape ( data = rpn_cls_prob , shape = ( 0 , 2 * num_anchors , - 1 , 0 ) , name = ' rpn _ cls _ prob _ t _ ' + suffix ) NEW_LINE rpn_bbox_pred_t = mx . sym . Reshape ( data = rpn_bbox_pred , shape = ( 0 , 0 , - 1 ) , name = ' rpn _ bbox _ pred _ t _ ' + suffix ) NEW_LINE return rpn_cls_score_t2 , rpn_cls_prob_t , rpn_bbox_pred_t , rpn_bbox_pred NEW_LINE DEDENT\",), ('def get_symbol ( self , cfg , is_train = True ) : NEW_LINE INDENT num_classes = cfg . dataset . NUM_CLASSES NEW_LINE num_reg_classes = ( 2 if cfg . CLASS_AGNOSTIC else num_classes ) NEW_LINE data = mx . sym . Variable ( name = \" data \" ) NEW_LINE im_info = mx . sym . Variable ( name = \" im _ info \" ) NEW_LINE res2 , res3 , res4 , res5 = self . get_resnet_backbone ( data ) NEW_LINE fpn_p2 , fpn_p3 , fpn_p4 , fpn_p5 , fpn_p6 = self . get_fpn_feature ( res2 , res3 , res4 , res5 ) NEW_LINE rpn_cls_score_p2 , rpn_prob_p2 , rpn_bbox_loss_p2 , rpn_bbox_pred_p2 = self . get_rpn_subnet ( fpn_p2 , cfg . network . NUM_ANCHORS , \\' p2\\' ) NEW_LINE rpn_cls_score_p3 , rpn_prob_p3 , rpn_bbox_loss_p3 , rpn_bbox_pred_p3 = self . get_rpn_subnet ( fpn_p3 , cfg . network . NUM_ANCHORS , \\' p3\\' ) NEW_LINE rpn_cls_score_p4 , rpn_prob_p4 , rpn_bbox_loss_p4 , rpn_bbox_pred_p4 = self . get_rpn_subnet ( fpn_p4 , cfg . network . NUM_ANCHORS , \\' p4\\' ) NEW_LINE rpn_cls_score_p5 , rpn_prob_p5 , rpn_bbox_loss_p5 , rpn_bbox_pred_p5 = self . get_rpn_subnet ( fpn_p5 , cfg . network . NUM_ANCHORS , \\' p5\\' ) NEW_LINE rpn_cls_score_p6 , rpn_prob_p6 , rpn_bbox_loss_p6 , rpn_bbox_pred_p6 = self . get_rpn_subnet ( fpn_p6 , cfg . network . NUM_ANCHORS , \\' p6\\' ) NEW_LINE rpn_cls_prob_dict = { \\' rpn _ cls _ prob _ stride64\\' : rpn_prob_p6 , \\' rpn _ cls _ prob _ stride32\\' : rpn_prob_p5 , \\' rpn _ cls _ prob _ stride16\\' : rpn_prob_p4 , \\' rpn _ cls _ prob _ stride8\\' : rpn_prob_p3 , \\' rpn _ cls _ prob _ stride4\\' : rpn_prob_p2 , } NEW_LINE rpn_bbox_pred_dict = { \\' rpn _ bbox _ pred _ stride64\\' : rpn_bbox_pred_p6 , \\' rpn _ bbox _ pred _ stride32\\' : rpn_bbox_pred_p5 , \\' rpn _ bbox _ pred _ stride16\\' : rpn_bbox_pred_p4 , \\' rpn _ bbox _ pred _ stride8\\' : rpn_bbox_pred_p3 , \\' rpn _ bbox _ pred _ stride4\\' : rpn_bbox_pred_p2 , } NEW_LINE arg_dict = dict ( rpn_cls_prob_dict . items ( ) + rpn_bbox_pred_dict . items ( ) ) NEW_LINE if is_train : NEW_LINE INDENT rpn_label = mx . sym . Variable ( name = \\' label \\' ) NEW_LINE rpn_bbox_target = mx . sym . Variable ( name = \\' bbox _ target \\' ) NEW_LINE rpn_bbox_weight = mx . sym . Variable ( name = \\' bbox _ weight \\' ) NEW_LINE gt_boxes = mx . sym . Variable ( name = \" gt _ boxes \" ) NEW_LINE rpn_cls_score = mx . sym . Concat ( rpn_cls_score_p2 , rpn_cls_score_p3 , rpn_cls_score_p4 , rpn_cls_score_p5 , rpn_cls_score_p6 , dim = 2 ) NEW_LINE rpn_bbox_loss = mx . sym . Concat ( rpn_bbox_loss_p2 , rpn_bbox_loss_p3 , rpn_bbox_loss_p4 , rpn_bbox_loss_p5 , rpn_bbox_loss_p6 , dim = 2 ) NEW_LINE rpn_cls_output = mx . sym . SoftmaxOutput ( data = rpn_cls_score , label = rpn_label , multi_output = True , normalization = \\' valid \\' , use_ignore = True , ignore_label = - 1 , name = \\' rpn _ cls _ prob \\' ) NEW_LINE rpn_bbox_loss = rpn_bbox_weight * mx . sym . smooth_l1 ( name = \\' rpn _ bbox _ loss _ l1\\' , scalar = 3.0 , data = ( rpn_bbox_loss - rpn_bbox_target ) ) NEW_LINE rpn_bbox_loss = mx . sym . MakeLoss ( name = \\' rpn _ bbox _ loss \\' , data = rpn_bbox_loss , grad_scale = 1.0 / cfg . TRAIN . RPN_BATCH_SIZE ) NEW_LINE aux_dict = { \\' op _ type \\' : \\' pyramid _ proposal \\' , \\' name \\' : \\' rois \\' , \\' im _ info \\' : im_info , \\' feat _ stride \\' : tuple ( cfg . network . RPN_FEAT_STRIDE ) , \\' scales \\' : tuple ( cfg . network . ANCHOR_SCALES ) , \\' ratios \\' : tuple ( cfg . network . ANCHOR_RATIOS ) , \\' rpn _ pre _ nms _ top _ n \\' : cfg . TRAIN . RPN_PRE_NMS_TOP_N , \\' rpn _ post _ nms _ top _ n \\' : cfg . TRAIN . RPN_POST_NMS_TOP_N , \\' threshold \\' : cfg . TRAIN . RPN_NMS_THRESH , \\' rpn _ min _ size \\' : cfg . TRAIN . RPN_MIN_SIZE } NEW_LINE rois = mx . sym . Custom ( ** dict ( arg_dict . items ( ) + aux_dict . items ( ) ) ) NEW_LINE gt_boxes_reshape = mx . sym . Reshape ( data = gt_boxes , shape = ( - 1 , 5 ) , name = \\' gt _ boxes _ reshape \\' ) NEW_LINE rois , label , bbox_target , bbox_weight = mx . sym . Custom ( rois = rois , gt_boxes = gt_boxes_reshape , op_type = \\' proposal _ target \\' , num_classes = num_reg_classes , batch_images = cfg . TRAIN . BATCH_IMAGES , batch_rois = cfg . TRAIN . BATCH_ROIS , cfg = cPickle . dumps ( cfg ) , fg_fraction = cfg . TRAIN . FG_FRACTION ) NEW_LINE DEDENT else : NEW_LINE INDENT aux_dict = { \\' op _ type \\' : \\' pyramid _ proposal \\' , \\' name \\' : \\' rois \\' , \\' im _ info \\' : im_info , \\' feat _ stride \\' : tuple ( cfg . network . RPN_FEAT_STRIDE ) , \\' scales \\' : tuple ( cfg . network . ANCHOR_SCALES ) , \\' ratios \\' : tuple ( cfg . network . ANCHOR_RATIOS ) , \\' rpn _ pre _ nms _ top _ n \\' : cfg . TEST . RPN_PRE_NMS_TOP_N , \\' rpn _ post _ nms _ top _ n \\' : cfg . TEST . RPN_POST_NMS_TOP_N , \\' threshold \\' : cfg . TEST . RPN_NMS_THRESH , \\' rpn _ min _ size \\' : cfg . TEST . RPN_MIN_SIZE } NEW_LINE rois = mx . sym . Custom ( ** dict ( arg_dict . items ( ) + aux_dict . items ( ) ) ) NEW_LINE DEDENT roi_pool = mx . symbol . Custom ( data_p2 = fpn_p2 , data_p3 = fpn_p3 , data_p4 = fpn_p4 , data_p5 = fpn_p5 , rois = rois , op_type = \\' fpn _ roi _ pooling \\' , name = \\' fpn _ roi _ pooling \\' ) NEW_LINE fc_new_1 = mx . symbol . FullyConnected ( name = \\' fc _ new _ 1\\' , data = roi_pool , num_hidden = 1024 ) NEW_LINE fc_new_1_relu = mx . sym . Activation ( data = fc_new_1 , act_type = \\' relu \\' , name = \\' fc _ new _ 1 _ relu \\' ) NEW_LINE fc_new_2 = mx . symbol . FullyConnected ( name = \\' fc _ new _ 2\\' , data = fc_new_1_relu , num_hidden = 1024 ) NEW_LINE fc_new_2_relu = mx . sym . Activation ( data = fc_new_2 , act_type = \\' relu \\' , name = \\' fc _ new _ 2 _ relu \\' ) NEW_LINE cls_score = mx . symbol . FullyConnected ( name = \\' cls _ score \\' , data = fc_new_2_relu , num_hidden = num_classes ) NEW_LINE bbox_pred = mx . symbol . FullyConnected ( name = \\' bbox _ pred \\' , data = fc_new_2_relu , num_hidden = num_reg_classes * 4 ) NEW_LINE if is_train : NEW_LINE INDENT if cfg . TRAIN . ENABLE_OHEM : NEW_LINE INDENT labels_ohem , bbox_weights_ohem = mx . sym . Custom ( op_type = \\' BoxAnnotatorOHEM \\' , num_classes = num_classes , num_reg_classes = num_reg_classes , roi_per_img = cfg . TRAIN . BATCH_ROIS_OHEM , cls_score = cls_score , bbox_pred = bbox_pred , labels = label , bbox_targets = bbox_target , bbox_weights = bbox_weight ) NEW_LINE cls_prob = mx . sym . SoftmaxOutput ( name = \\' cls _ prob \\' , data = cls_score , label = labels_ohem , normalization = \\' valid \\' , use_ignore = True , ignore_label = - 1 ) NEW_LINE bbox_loss_ = bbox_weights_ohem * mx . sym . smooth_l1 ( name = \\' bbox _ loss _ \\' , scalar = 1.0 , data = ( bbox_pred - bbox_target ) ) NEW_LINE bbox_loss = mx . sym . MakeLoss ( name = \\' bbox _ loss \\' , data = bbox_loss_ , grad_scale = 1.0 / cfg . TRAIN . BATCH_ROIS_OHEM ) NEW_LINE rcnn_label = labels_ohem NEW_LINE DEDENT else : NEW_LINE INDENT cls_prob = mx . sym . SoftmaxOutput ( name = \\' cls _ prob \\' , data = cls_score , label = label , normalization = \\' valid \\' ) NEW_LINE bbox_loss_ = bbox_weight * mx . sym . smooth_l1 ( name = \\' bbox _ loss _ \\' , scalar = 1.0 , data = ( bbox_pred - bbox_target ) ) NEW_LINE bbox_loss = mx . sym . MakeLoss ( name = \\' bbox _ loss \\' , data = bbox_loss_ , grad_scale = 1.0 / cfg . TRAIN . BATCH_ROIS ) NEW_LINE rcnn_label = label NEW_LINE DEDENT rcnn_label = mx . sym . Reshape ( data = rcnn_label , shape = ( cfg . TRAIN . BATCH_IMAGES , - 1 ) , name = \\' label _ reshape \\' ) NEW_LINE cls_prob = mx . sym . Reshape ( data = cls_prob , shape = ( cfg . TRAIN . BATCH_IMAGES , - 1 , num_classes ) , name = \\' cls _ prob _ reshape \\' ) NEW_LINE bbox_loss = mx . sym . Reshape ( data = bbox_loss , shape = ( cfg . TRAIN . BATCH_IMAGES , - 1 , 4 * num_reg_classes ) , name = \\' bbox _ loss _ reshape \\' ) NEW_LINE group = mx . sym . Group ( [ rpn_cls_output , rpn_bbox_loss , cls_prob , bbox_loss , mx . sym . BlockGrad ( rcnn_label ) ] ) NEW_LINE DEDENT else : NEW_LINE INDENT cls_prob = mx . sym . SoftmaxActivation ( name = \\' cls _ prob \\' , data = cls_score ) NEW_LINE cls_prob = mx . sym . Reshape ( data = cls_prob , shape = ( cfg . TEST . BATCH_IMAGES , - 1 , num_classes ) , name = \\' cls _ prob _ reshape \\' ) NEW_LINE bbox_pred = mx . sym . Reshape ( data = bbox_pred , shape = ( cfg . TEST . BATCH_IMAGES , - 1 , 4 * num_reg_classes ) , name = \\' bbox _ pred _ reshape \\' ) NEW_LINE group = mx . sym . Group ( [ rois , cls_prob , bbox_pred ] ) NEW_LINE DEDENT self . sym = group NEW_LINE return group NEW_LINE DEDENT',), (\"def init_weight_rcnn ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT arg_params [ ' fc _ new _ 1 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fc _ new _ 1 _ weight ' ] ) NEW_LINE arg_params [ ' fc _ new _ 1 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fc _ new _ 1 _ bias ' ] ) NEW_LINE arg_params [ ' fc _ new _ 2 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fc _ new _ 2 _ weight ' ] ) NEW_LINE arg_params [ ' fc _ new _ 2 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fc _ new _ 2 _ bias ' ] ) NEW_LINE arg_params [ ' cls _ score _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' cls _ score _ weight ' ] ) NEW_LINE arg_params [ ' cls _ score _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' cls _ score _ bias ' ] ) NEW_LINE arg_params [ ' bbox _ pred _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' bbox _ pred _ weight ' ] ) NEW_LINE arg_params [ ' bbox _ pred _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' bbox _ pred _ bias ' ] ) NEW_LINE DEDENT\",), (\"def init_weight_fpn ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT arg_params [ ' fpn _ p6 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p6 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p6 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p6 _ bias ' ] ) NEW_LINE arg_params [ ' fpn _ p5 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p5 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p5 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p5 _ bias ' ] ) NEW_LINE arg_params [ ' fpn _ p4 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p4 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p4 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p4 _ bias ' ] ) NEW_LINE arg_params [ ' fpn _ p3 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p3 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p3 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p3 _ bias ' ] ) NEW_LINE arg_params [ ' fpn _ p2 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p2 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p2 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p2 _ bias ' ] ) NEW_LINE arg_params [ ' fpn _ p5_1x1 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p5_1x1 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p5_1x1 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p5_1x1 _ bias ' ] ) NEW_LINE arg_params [ ' fpn _ p4_1x1 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p4_1x1 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p4_1x1 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p4_1x1 _ bias ' ] ) NEW_LINE arg_params [ ' fpn _ p3_1x1 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p3_1x1 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p3_1x1 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p3_1x1 _ bias ' ] ) NEW_LINE arg_params [ ' fpn _ p2_1x1 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p2_1x1 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p2_1x1 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p2_1x1 _ bias ' ] ) NEW_LINE DEDENT\",), (\"def init_weight ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT for name in self . shared_param_list : NEW_LINE INDENT arg_params [ name + ' _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ name + ' _ weight ' ] ) NEW_LINE arg_params [ name + ' _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ name + ' _ bias ' ] ) NEW_LINE DEDENT self . init_weight_rcnn ( cfg , arg_params , aux_params ) NEW_LINE self . init_weight_fpn ( cfg , arg_params , aux_params ) NEW_LINE DEDENT\",), (\"def __init__ ( self ) : NEW_LINE INDENT self . shared_param_list = [ ' rpn _ conv ' , ' rpn _ cls _ score ' , ' rpn _ bbox _ pred ' , ' conv _ new _ 1' , ' conv _ new _ 2' , ' conv _ new _ 3' , ' conv _ new _ 4' ] NEW_LINE self . shared_param_dict = { } NEW_LINE for name in self . shared_param_list : NEW_LINE INDENT self . shared_param_dict [ name + ' _ weight ' ] = mx . sym . Variable ( name + ' _ weight ' ) NEW_LINE self . shared_param_dict [ name + ' _ bias ' ] = mx . sym . Variable ( name + ' _ bias ' ) NEW_LINE DEDENT DEDENT\",), (\"def get_resnet_backbone ( self , data , with_dilated = False , with_dconv = False , with_dpyramid = False , eps = 1e-5 ) : NEW_LINE INDENT conv1 = mx . symbol . Convolution ( name = ' conv1' , data = data , num_filter = 64 , pad = ( 3 , 3 ) , kernel = ( 7 , 7 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn_conv1 = mx . symbol . BatchNorm ( name = ' bn _ conv1' , data = conv1 , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale_conv1 = bn_conv1 NEW_LINE conv1_relu = mx . symbol . Activation ( name = ' conv1 _ relu ' , data = scale_conv1 , act_type = ' relu ' ) NEW_LINE pool1 = mx . symbol . Pooling ( name = ' pool1' , data = conv1_relu , pooling_convention = ' full ' , pad = ( 0 , 0 ) , kernel = ( 3 , 3 ) , stride = ( 2 , 2 ) , pool_type = ' max ' ) NEW_LINE res2a_branch1 = mx . symbol . Convolution ( name = ' res2a _ branch1' , data = pool1 , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch1 = mx . symbol . BatchNorm ( name = ' bn2a _ branch1' , data = res2a_branch1 , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2a_branch1 = bn2a_branch1 NEW_LINE res2a_branch2a = mx . symbol . Convolution ( name = ' res2a _ branch2a ' , data = pool1 , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2a = mx . symbol . BatchNorm ( name = ' bn2a _ branch2a ' , data = res2a_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2a_branch2a = bn2a_branch2a NEW_LINE res2a_branch2a_relu = mx . symbol . Activation ( name = ' res2a _ branch2a _ relu ' , data = scale2a_branch2a , act_type = ' relu ' ) NEW_LINE res2a_branch2b = mx . symbol . Convolution ( name = ' res2a _ branch2b ' , data = res2a_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2b = mx . symbol . BatchNorm ( name = ' bn2a _ branch2b ' , data = res2a_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2a_branch2b = bn2a_branch2b NEW_LINE res2a_branch2b_relu = mx . symbol . Activation ( name = ' res2a _ branch2b _ relu ' , data = scale2a_branch2b , act_type = ' relu ' ) NEW_LINE res2a_branch2c = mx . symbol . Convolution ( name = ' res2a _ branch2c ' , data = res2a_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2a_branch2c = mx . symbol . BatchNorm ( name = ' bn2a _ branch2c ' , data = res2a_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2a_branch2c = bn2a_branch2c NEW_LINE res2a = mx . symbol . broadcast_add ( name = ' res2a ' , * [ scale2a_branch1 , scale2a_branch2c ] ) NEW_LINE res2a_relu = mx . symbol . Activation ( name = ' res2a _ relu ' , data = res2a , act_type = ' relu ' ) NEW_LINE res2b_branch2a = mx . symbol . Convolution ( name = ' res2b _ branch2a ' , data = res2a_relu , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2a = mx . symbol . BatchNorm ( name = ' bn2b _ branch2a ' , data = res2b_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2b_branch2a = bn2b_branch2a NEW_LINE res2b_branch2a_relu = mx . symbol . Activation ( name = ' res2b _ branch2a _ relu ' , data = scale2b_branch2a , act_type = ' relu ' ) NEW_LINE res2b_branch2b = mx . symbol . Convolution ( name = ' res2b _ branch2b ' , data = res2b_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2b = mx . symbol . BatchNorm ( name = ' bn2b _ branch2b ' , data = res2b_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2b_branch2b = bn2b_branch2b NEW_LINE res2b_branch2b_relu = mx . symbol . Activation ( name = ' res2b _ branch2b _ relu ' , data = scale2b_branch2b , act_type = ' relu ' ) NEW_LINE res2b_branch2c = mx . symbol . Convolution ( name = ' res2b _ branch2c ' , data = res2b_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2b_branch2c = mx . symbol . BatchNorm ( name = ' bn2b _ branch2c ' , data = res2b_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2b_branch2c = bn2b_branch2c NEW_LINE res2b = mx . symbol . broadcast_add ( name = ' res2b ' , * [ res2a_relu , scale2b_branch2c ] ) NEW_LINE res2b_relu = mx . symbol . Activation ( name = ' res2b _ relu ' , data = res2b , act_type = ' relu ' ) NEW_LINE res2c_branch2a = mx . symbol . Convolution ( name = ' res2c _ branch2a ' , data = res2b_relu , num_filter = 64 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2a = mx . symbol . BatchNorm ( name = ' bn2c _ branch2a ' , data = res2c_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2c_branch2a = bn2c_branch2a NEW_LINE res2c_branch2a_relu = mx . symbol . Activation ( name = ' res2c _ branch2a _ relu ' , data = scale2c_branch2a , act_type = ' relu ' ) NEW_LINE res2c_branch2b = mx . symbol . Convolution ( name = ' res2c _ branch2b ' , data = res2c_branch2a_relu , num_filter = 64 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2b = mx . symbol . BatchNorm ( name = ' bn2c _ branch2b ' , data = res2c_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2c_branch2b = bn2c_branch2b NEW_LINE res2c_branch2b_relu = mx . symbol . Activation ( name = ' res2c _ branch2b _ relu ' , data = scale2c_branch2b , act_type = ' relu ' ) NEW_LINE res2c_branch2c = mx . symbol . Convolution ( name = ' res2c _ branch2c ' , data = res2c_branch2b_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn2c_branch2c = mx . symbol . BatchNorm ( name = ' bn2c _ branch2c ' , data = res2c_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale2c_branch2c = bn2c_branch2c NEW_LINE res2c = mx . symbol . broadcast_add ( name = ' res2c ' , * [ res2b_relu , scale2c_branch2c ] ) NEW_LINE res2c_relu = mx . symbol . Activation ( name = ' res2c _ relu ' , data = res2c , act_type = ' relu ' ) NEW_LINE res3a_branch1 = mx . symbol . Convolution ( name = ' res3a _ branch1' , data = res2c_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn3a_branch1 = mx . symbol . BatchNorm ( name = ' bn3a _ branch1' , data = res3a_branch1 , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3a_branch1 = bn3a_branch1 NEW_LINE res3a_branch2a = mx . symbol . Convolution ( name = ' res3a _ branch2a ' , data = res2c_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn3a_branch2a = mx . symbol . BatchNorm ( name = ' bn3a _ branch2a ' , data = res3a_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3a_branch2a = bn3a_branch2a NEW_LINE res3a_branch2a_relu = mx . symbol . Activation ( name = ' res3a _ branch2a _ relu ' , data = scale3a_branch2a , act_type = ' relu ' ) NEW_LINE res3a_branch2b = mx . symbol . Convolution ( name = ' res3a _ branch2b ' , data = res3a_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3a_branch2b = mx . symbol . BatchNorm ( name = ' bn3a _ branch2b ' , data = res3a_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3a_branch2b = bn3a_branch2b NEW_LINE res3a_branch2b_relu = mx . symbol . Activation ( name = ' res3a _ branch2b _ relu ' , data = scale3a_branch2b , act_type = ' relu ' ) NEW_LINE res3a_branch2c = mx . symbol . Convolution ( name = ' res3a _ branch2c ' , data = res3a_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3a_branch2c = mx . symbol . BatchNorm ( name = ' bn3a _ branch2c ' , data = res3a_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3a_branch2c = bn3a_branch2c NEW_LINE res3a = mx . symbol . broadcast_add ( name = ' res3a ' , * [ scale3a_branch1 , scale3a_branch2c ] ) NEW_LINE res3a_relu = mx . symbol . Activation ( name = ' res3a _ relu ' , data = res3a , act_type = ' relu ' ) NEW_LINE res3b1_branch2a = mx . symbol . Convolution ( name = ' res3b1 _ branch2a ' , data = res3a_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2a = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2a ' , data = res3b1_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b1_branch2a = bn3b1_branch2a NEW_LINE res3b1_branch2a_relu = mx . symbol . Activation ( name = ' res3b1 _ branch2a _ relu ' , data = scale3b1_branch2a , act_type = ' relu ' ) NEW_LINE res3b1_branch2b = mx . symbol . Convolution ( name = ' res3b1 _ branch2b ' , data = res3b1_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2b = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2b ' , data = res3b1_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b1_branch2b = bn3b1_branch2b NEW_LINE res3b1_branch2b_relu = mx . symbol . Activation ( name = ' res3b1 _ branch2b _ relu ' , data = scale3b1_branch2b , act_type = ' relu ' ) NEW_LINE res3b1_branch2c = mx . symbol . Convolution ( name = ' res3b1 _ branch2c ' , data = res3b1_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b1_branch2c = mx . symbol . BatchNorm ( name = ' bn3b1 _ branch2c ' , data = res3b1_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b1_branch2c = bn3b1_branch2c NEW_LINE res3b1 = mx . symbol . broadcast_add ( name = ' res3b1' , * [ res3a_relu , scale3b1_branch2c ] ) NEW_LINE res3b1_relu = mx . symbol . Activation ( name = ' res3b1 _ relu ' , data = res3b1 , act_type = ' relu ' ) NEW_LINE res3b2_branch2a = mx . symbol . Convolution ( name = ' res3b2 _ branch2a ' , data = res3b1_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2a = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2a ' , data = res3b2_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b2_branch2a = bn3b2_branch2a NEW_LINE res3b2_branch2a_relu = mx . symbol . Activation ( name = ' res3b2 _ branch2a _ relu ' , data = scale3b2_branch2a , act_type = ' relu ' ) NEW_LINE res3b2_branch2b = mx . symbol . Convolution ( name = ' res3b2 _ branch2b ' , data = res3b2_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2b = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2b ' , data = res3b2_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b2_branch2b = bn3b2_branch2b NEW_LINE res3b2_branch2b_relu = mx . symbol . Activation ( name = ' res3b2 _ branch2b _ relu ' , data = scale3b2_branch2b , act_type = ' relu ' ) NEW_LINE res3b2_branch2c = mx . symbol . Convolution ( name = ' res3b2 _ branch2c ' , data = res3b2_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b2_branch2c = mx . symbol . BatchNorm ( name = ' bn3b2 _ branch2c ' , data = res3b2_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b2_branch2c = bn3b2_branch2c NEW_LINE res3b2 = mx . symbol . broadcast_add ( name = ' res3b2' , * [ res3b1_relu , scale3b2_branch2c ] ) NEW_LINE res3b2_relu = mx . symbol . Activation ( name = ' res3b2 _ relu ' , data = res3b2 , act_type = ' relu ' ) NEW_LINE res3b3_branch2a = mx . symbol . Convolution ( name = ' res3b3 _ branch2a ' , data = res3b2_relu , num_filter = 128 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b3_branch2a = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2a ' , data = res3b3_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b3_branch2a = bn3b3_branch2a NEW_LINE res3b3_branch2a_relu = mx . symbol . Activation ( name = ' res3b3 _ branch2a _ relu ' , data = scale3b3_branch2a , act_type = ' relu ' ) NEW_LINE if with_dpyramid : NEW_LINE INDENT res3b3_branch2b_offset = mx . symbol . Convolution ( name = ' res3b3 _ branch2b _ offset ' , data = res3b3_branch2a_relu , num_filter = 72 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) ) NEW_LINE res3b3_branch2b = mx . contrib . symbol . DeformableConvolution ( name = ' res3b3 _ branch2b ' , data = res3b3_branch2a_relu , offset = res3b3_branch2b_offset , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , num_deformable_group = 4 , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE DEDENT else : NEW_LINE INDENT res3b3_branch2b = mx . symbol . Convolution ( name = ' res3b3 _ branch2b ' , data = res3b3_branch2a_relu , num_filter = 128 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE DEDENT bn3b3_branch2b = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2b ' , data = res3b3_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b3_branch2b = bn3b3_branch2b NEW_LINE res3b3_branch2b_relu = mx . symbol . Activation ( name = ' res3b3 _ branch2b _ relu ' , data = scale3b3_branch2b , act_type = ' relu ' ) NEW_LINE res3b3_branch2c = mx . symbol . Convolution ( name = ' res3b3 _ branch2c ' , data = res3b3_branch2b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn3b3_branch2c = mx . symbol . BatchNorm ( name = ' bn3b3 _ branch2c ' , data = res3b3_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale3b3_branch2c = bn3b3_branch2c NEW_LINE res3b3 = mx . symbol . broadcast_add ( name = ' res3b3' , * [ res3b2_relu , scale3b3_branch2c ] ) NEW_LINE res3b3_relu = mx . symbol . Activation ( name = ' res3b3 _ relu ' , data = res3b3 , act_type = ' relu ' ) NEW_LINE res4a_branch1 = mx . symbol . Convolution ( name = ' res4a _ branch1' , data = res3b3_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn4a_branch1 = mx . symbol . BatchNorm ( name = ' bn4a _ branch1' , data = res4a_branch1 , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4a_branch1 = bn4a_branch1 NEW_LINE res4a_branch2a = mx . symbol . Convolution ( name = ' res4a _ branch2a ' , data = res3b3_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 2 , 2 ) , no_bias = True ) NEW_LINE bn4a_branch2a = mx . symbol . BatchNorm ( name = ' bn4a _ branch2a ' , data = res4a_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4a_branch2a = bn4a_branch2a NEW_LINE res4a_branch2a_relu = mx . symbol . Activation ( name = ' res4a _ branch2a _ relu ' , data = scale4a_branch2a , act_type = ' relu ' ) NEW_LINE res4a_branch2b = mx . symbol . Convolution ( name = ' res4a _ branch2b ' , data = res4a_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4a_branch2b = mx . symbol . BatchNorm ( name = ' bn4a _ branch2b ' , data = res4a_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4a_branch2b = bn4a_branch2b NEW_LINE res4a_branch2b_relu = mx . symbol . Activation ( name = ' res4a _ branch2b _ relu ' , data = scale4a_branch2b , act_type = ' relu ' ) NEW_LINE res4a_branch2c = mx . symbol . Convolution ( name = ' res4a _ branch2c ' , data = res4a_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4a_branch2c = mx . symbol . BatchNorm ( name = ' bn4a _ branch2c ' , data = res4a_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4a_branch2c = bn4a_branch2c NEW_LINE res4a = mx . symbol . broadcast_add ( name = ' res4a ' , * [ scale4a_branch1 , scale4a_branch2c ] ) NEW_LINE res4a_relu = mx . symbol . Activation ( name = ' res4a _ relu ' , data = res4a , act_type = ' relu ' ) NEW_LINE res4b1_branch2a = mx . symbol . Convolution ( name = ' res4b1 _ branch2a ' , data = res4a_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2a = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2a ' , data = res4b1_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b1_branch2a = bn4b1_branch2a NEW_LINE res4b1_branch2a_relu = mx . symbol . Activation ( name = ' res4b1 _ branch2a _ relu ' , data = scale4b1_branch2a , act_type = ' relu ' ) NEW_LINE res4b1_branch2b = mx . symbol . Convolution ( name = ' res4b1 _ branch2b ' , data = res4b1_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2b = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2b ' , data = res4b1_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b1_branch2b = bn4b1_branch2b NEW_LINE res4b1_branch2b_relu = mx . symbol . Activation ( name = ' res4b1 _ branch2b _ relu ' , data = scale4b1_branch2b , act_type = ' relu ' ) NEW_LINE res4b1_branch2c = mx . symbol . Convolution ( name = ' res4b1 _ branch2c ' , data = res4b1_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b1_branch2c = mx . symbol . BatchNorm ( name = ' bn4b1 _ branch2c ' , data = res4b1_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b1_branch2c = bn4b1_branch2c NEW_LINE res4b1 = mx . symbol . broadcast_add ( name = ' res4b1' , * [ res4a_relu , scale4b1_branch2c ] ) NEW_LINE res4b1_relu = mx . symbol . Activation ( name = ' res4b1 _ relu ' , data = res4b1 , act_type = ' relu ' ) NEW_LINE res4b2_branch2a = mx . symbol . Convolution ( name = ' res4b2 _ branch2a ' , data = res4b1_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2a = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2a ' , data = res4b2_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b2_branch2a = bn4b2_branch2a NEW_LINE res4b2_branch2a_relu = mx . symbol . Activation ( name = ' res4b2 _ branch2a _ relu ' , data = scale4b2_branch2a , act_type = ' relu ' ) NEW_LINE res4b2_branch2b = mx . symbol . Convolution ( name = ' res4b2 _ branch2b ' , data = res4b2_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2b = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2b ' , data = res4b2_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b2_branch2b = bn4b2_branch2b NEW_LINE res4b2_branch2b_relu = mx . symbol . Activation ( name = ' res4b2 _ branch2b _ relu ' , data = scale4b2_branch2b , act_type = ' relu ' ) NEW_LINE res4b2_branch2c = mx . symbol . Convolution ( name = ' res4b2 _ branch2c ' , data = res4b2_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b2_branch2c = mx . symbol . BatchNorm ( name = ' bn4b2 _ branch2c ' , data = res4b2_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b2_branch2c = bn4b2_branch2c NEW_LINE res4b2 = mx . symbol . broadcast_add ( name = ' res4b2' , * [ res4b1_relu , scale4b2_branch2c ] ) NEW_LINE res4b2_relu = mx . symbol . Activation ( name = ' res4b2 _ relu ' , data = res4b2 , act_type = ' relu ' ) NEW_LINE res4b3_branch2a = mx . symbol . Convolution ( name = ' res4b3 _ branch2a ' , data = res4b2_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2a = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2a ' , data = res4b3_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b3_branch2a = bn4b3_branch2a NEW_LINE res4b3_branch2a_relu = mx . symbol . Activation ( name = ' res4b3 _ branch2a _ relu ' , data = scale4b3_branch2a , act_type = ' relu ' ) NEW_LINE res4b3_branch2b = mx . symbol . Convolution ( name = ' res4b3 _ branch2b ' , data = res4b3_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2b = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2b ' , data = res4b3_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b3_branch2b = bn4b3_branch2b NEW_LINE res4b3_branch2b_relu = mx . symbol . Activation ( name = ' res4b3 _ branch2b _ relu ' , data = scale4b3_branch2b , act_type = ' relu ' ) NEW_LINE res4b3_branch2c = mx . symbol . Convolution ( name = ' res4b3 _ branch2c ' , data = res4b3_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b3_branch2c = mx . symbol . BatchNorm ( name = ' bn4b3 _ branch2c ' , data = res4b3_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b3_branch2c = bn4b3_branch2c NEW_LINE res4b3 = mx . symbol . broadcast_add ( name = ' res4b3' , * [ res4b2_relu , scale4b3_branch2c ] ) NEW_LINE res4b3_relu = mx . symbol . Activation ( name = ' res4b3 _ relu ' , data = res4b3 , act_type = ' relu ' ) NEW_LINE res4b4_branch2a = mx . symbol . Convolution ( name = ' res4b4 _ branch2a ' , data = res4b3_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2a = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2a ' , data = res4b4_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b4_branch2a = bn4b4_branch2a NEW_LINE res4b4_branch2a_relu = mx . symbol . Activation ( name = ' res4b4 _ branch2a _ relu ' , data = scale4b4_branch2a , act_type = ' relu ' ) NEW_LINE res4b4_branch2b = mx . symbol . Convolution ( name = ' res4b4 _ branch2b ' , data = res4b4_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2b = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2b ' , data = res4b4_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b4_branch2b = bn4b4_branch2b NEW_LINE res4b4_branch2b_relu = mx . symbol . Activation ( name = ' res4b4 _ branch2b _ relu ' , data = scale4b4_branch2b , act_type = ' relu ' ) NEW_LINE res4b4_branch2c = mx . symbol . Convolution ( name = ' res4b4 _ branch2c ' , data = res4b4_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b4_branch2c = mx . symbol . BatchNorm ( name = ' bn4b4 _ branch2c ' , data = res4b4_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b4_branch2c = bn4b4_branch2c NEW_LINE res4b4 = mx . symbol . broadcast_add ( name = ' res4b4' , * [ res4b3_relu , scale4b4_branch2c ] ) NEW_LINE res4b4_relu = mx . symbol . Activation ( name = ' res4b4 _ relu ' , data = res4b4 , act_type = ' relu ' ) NEW_LINE res4b5_branch2a = mx . symbol . Convolution ( name = ' res4b5 _ branch2a ' , data = res4b4_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2a = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2a ' , data = res4b5_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b5_branch2a = bn4b5_branch2a NEW_LINE res4b5_branch2a_relu = mx . symbol . Activation ( name = ' res4b5 _ branch2a _ relu ' , data = scale4b5_branch2a , act_type = ' relu ' ) NEW_LINE res4b5_branch2b = mx . symbol . Convolution ( name = ' res4b5 _ branch2b ' , data = res4b5_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2b = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2b ' , data = res4b5_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b5_branch2b = bn4b5_branch2b NEW_LINE res4b5_branch2b_relu = mx . symbol . Activation ( name = ' res4b5 _ branch2b _ relu ' , data = scale4b5_branch2b , act_type = ' relu ' ) NEW_LINE res4b5_branch2c = mx . symbol . Convolution ( name = ' res4b5 _ branch2c ' , data = res4b5_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b5_branch2c = mx . symbol . BatchNorm ( name = ' bn4b5 _ branch2c ' , data = res4b5_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b5_branch2c = bn4b5_branch2c NEW_LINE res4b5 = mx . symbol . broadcast_add ( name = ' res4b5' , * [ res4b4_relu , scale4b5_branch2c ] ) NEW_LINE res4b5_relu = mx . symbol . Activation ( name = ' res4b5 _ relu ' , data = res4b5 , act_type = ' relu ' ) NEW_LINE res4b6_branch2a = mx . symbol . Convolution ( name = ' res4b6 _ branch2a ' , data = res4b5_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2a = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2a ' , data = res4b6_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b6_branch2a = bn4b6_branch2a NEW_LINE res4b6_branch2a_relu = mx . symbol . Activation ( name = ' res4b6 _ branch2a _ relu ' , data = scale4b6_branch2a , act_type = ' relu ' ) NEW_LINE res4b6_branch2b = mx . symbol . Convolution ( name = ' res4b6 _ branch2b ' , data = res4b6_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2b = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2b ' , data = res4b6_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b6_branch2b = bn4b6_branch2b NEW_LINE res4b6_branch2b_relu = mx . symbol . Activation ( name = ' res4b6 _ branch2b _ relu ' , data = scale4b6_branch2b , act_type = ' relu ' ) NEW_LINE res4b6_branch2c = mx . symbol . Convolution ( name = ' res4b6 _ branch2c ' , data = res4b6_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b6_branch2c = mx . symbol . BatchNorm ( name = ' bn4b6 _ branch2c ' , data = res4b6_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b6_branch2c = bn4b6_branch2c NEW_LINE res4b6 = mx . symbol . broadcast_add ( name = ' res4b6' , * [ res4b5_relu , scale4b6_branch2c ] ) NEW_LINE res4b6_relu = mx . symbol . Activation ( name = ' res4b6 _ relu ' , data = res4b6 , act_type = ' relu ' ) NEW_LINE res4b7_branch2a = mx . symbol . Convolution ( name = ' res4b7 _ branch2a ' , data = res4b6_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2a = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2a ' , data = res4b7_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b7_branch2a = bn4b7_branch2a NEW_LINE res4b7_branch2a_relu = mx . symbol . Activation ( name = ' res4b7 _ branch2a _ relu ' , data = scale4b7_branch2a , act_type = ' relu ' ) NEW_LINE res4b7_branch2b = mx . symbol . Convolution ( name = ' res4b7 _ branch2b ' , data = res4b7_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2b = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2b ' , data = res4b7_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b7_branch2b = bn4b7_branch2b NEW_LINE res4b7_branch2b_relu = mx . symbol . Activation ( name = ' res4b7 _ branch2b _ relu ' , data = scale4b7_branch2b , act_type = ' relu ' ) NEW_LINE res4b7_branch2c = mx . symbol . Convolution ( name = ' res4b7 _ branch2c ' , data = res4b7_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b7_branch2c = mx . symbol . BatchNorm ( name = ' bn4b7 _ branch2c ' , data = res4b7_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b7_branch2c = bn4b7_branch2c NEW_LINE res4b7 = mx . symbol . broadcast_add ( name = ' res4b7' , * [ res4b6_relu , scale4b7_branch2c ] ) NEW_LINE res4b7_relu = mx . symbol . Activation ( name = ' res4b7 _ relu ' , data = res4b7 , act_type = ' relu ' ) NEW_LINE res4b8_branch2a = mx . symbol . Convolution ( name = ' res4b8 _ branch2a ' , data = res4b7_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2a = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2a ' , data = res4b8_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b8_branch2a = bn4b8_branch2a NEW_LINE res4b8_branch2a_relu = mx . symbol . Activation ( name = ' res4b8 _ branch2a _ relu ' , data = scale4b8_branch2a , act_type = ' relu ' ) NEW_LINE res4b8_branch2b = mx . symbol . Convolution ( name = ' res4b8 _ branch2b ' , data = res4b8_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2b = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2b ' , data = res4b8_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b8_branch2b = bn4b8_branch2b NEW_LINE res4b8_branch2b_relu = mx . symbol . Activation ( name = ' res4b8 _ branch2b _ relu ' , data = scale4b8_branch2b , act_type = ' relu ' ) NEW_LINE res4b8_branch2c = mx . symbol . Convolution ( name = ' res4b8 _ branch2c ' , data = res4b8_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b8_branch2c = mx . symbol . BatchNorm ( name = ' bn4b8 _ branch2c ' , data = res4b8_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b8_branch2c = bn4b8_branch2c NEW_LINE res4b8 = mx . symbol . broadcast_add ( name = ' res4b8' , * [ res4b7_relu , scale4b8_branch2c ] ) NEW_LINE res4b8_relu = mx . symbol . Activation ( name = ' res4b8 _ relu ' , data = res4b8 , act_type = ' relu ' ) NEW_LINE res4b9_branch2a = mx . symbol . Convolution ( name = ' res4b9 _ branch2a ' , data = res4b8_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2a = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2a ' , data = res4b9_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b9_branch2a = bn4b9_branch2a NEW_LINE res4b9_branch2a_relu = mx . symbol . Activation ( name = ' res4b9 _ branch2a _ relu ' , data = scale4b9_branch2a , act_type = ' relu ' ) NEW_LINE res4b9_branch2b = mx . symbol . Convolution ( name = ' res4b9 _ branch2b ' , data = res4b9_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2b = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2b ' , data = res4b9_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b9_branch2b = bn4b9_branch2b NEW_LINE res4b9_branch2b_relu = mx . symbol . Activation ( name = ' res4b9 _ branch2b _ relu ' , data = scale4b9_branch2b , act_type = ' relu ' ) NEW_LINE res4b9_branch2c = mx . symbol . Convolution ( name = ' res4b9 _ branch2c ' , data = res4b9_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b9_branch2c = mx . symbol . BatchNorm ( name = ' bn4b9 _ branch2c ' , data = res4b9_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b9_branch2c = bn4b9_branch2c NEW_LINE res4b9 = mx . symbol . broadcast_add ( name = ' res4b9' , * [ res4b8_relu , scale4b9_branch2c ] ) NEW_LINE res4b9_relu = mx . symbol . Activation ( name = ' res4b9 _ relu ' , data = res4b9 , act_type = ' relu ' ) NEW_LINE res4b10_branch2a = mx . symbol . Convolution ( name = ' res4b10 _ branch2a ' , data = res4b9_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2a = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2a ' , data = res4b10_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b10_branch2a = bn4b10_branch2a NEW_LINE res4b10_branch2a_relu = mx . symbol . Activation ( name = ' res4b10 _ branch2a _ relu ' , data = scale4b10_branch2a , act_type = ' relu ' ) NEW_LINE res4b10_branch2b = mx . symbol . Convolution ( name = ' res4b10 _ branch2b ' , data = res4b10_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2b = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2b ' , data = res4b10_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b10_branch2b = bn4b10_branch2b NEW_LINE res4b10_branch2b_relu = mx . symbol . Activation ( name = ' res4b10 _ branch2b _ relu ' , data = scale4b10_branch2b , act_type = ' relu ' ) NEW_LINE res4b10_branch2c = mx . symbol . Convolution ( name = ' res4b10 _ branch2c ' , data = res4b10_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b10_branch2c = mx . symbol . BatchNorm ( name = ' bn4b10 _ branch2c ' , data = res4b10_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b10_branch2c = bn4b10_branch2c NEW_LINE res4b10 = mx . symbol . broadcast_add ( name = ' res4b10' , * [ res4b9_relu , scale4b10_branch2c ] ) NEW_LINE res4b10_relu = mx . symbol . Activation ( name = ' res4b10 _ relu ' , data = res4b10 , act_type = ' relu ' ) NEW_LINE res4b11_branch2a = mx . symbol . Convolution ( name = ' res4b11 _ branch2a ' , data = res4b10_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2a = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2a ' , data = res4b11_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b11_branch2a = bn4b11_branch2a NEW_LINE res4b11_branch2a_relu = mx . symbol . Activation ( name = ' res4b11 _ branch2a _ relu ' , data = scale4b11_branch2a , act_type = ' relu ' ) NEW_LINE res4b11_branch2b = mx . symbol . Convolution ( name = ' res4b11 _ branch2b ' , data = res4b11_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2b = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2b ' , data = res4b11_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b11_branch2b = bn4b11_branch2b NEW_LINE res4b11_branch2b_relu = mx . symbol . Activation ( name = ' res4b11 _ branch2b _ relu ' , data = scale4b11_branch2b , act_type = ' relu ' ) NEW_LINE res4b11_branch2c = mx . symbol . Convolution ( name = ' res4b11 _ branch2c ' , data = res4b11_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b11_branch2c = mx . symbol . BatchNorm ( name = ' bn4b11 _ branch2c ' , data = res4b11_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b11_branch2c = bn4b11_branch2c NEW_LINE res4b11 = mx . symbol . broadcast_add ( name = ' res4b11' , * [ res4b10_relu , scale4b11_branch2c ] ) NEW_LINE res4b11_relu = mx . symbol . Activation ( name = ' res4b11 _ relu ' , data = res4b11 , act_type = ' relu ' ) NEW_LINE res4b12_branch2a = mx . symbol . Convolution ( name = ' res4b12 _ branch2a ' , data = res4b11_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2a = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2a ' , data = res4b12_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b12_branch2a = bn4b12_branch2a NEW_LINE res4b12_branch2a_relu = mx . symbol . Activation ( name = ' res4b12 _ branch2a _ relu ' , data = scale4b12_branch2a , act_type = ' relu ' ) NEW_LINE res4b12_branch2b = mx . symbol . Convolution ( name = ' res4b12 _ branch2b ' , data = res4b12_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2b = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2b ' , data = res4b12_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b12_branch2b = bn4b12_branch2b NEW_LINE res4b12_branch2b_relu = mx . symbol . Activation ( name = ' res4b12 _ branch2b _ relu ' , data = scale4b12_branch2b , act_type = ' relu ' ) NEW_LINE res4b12_branch2c = mx . symbol . Convolution ( name = ' res4b12 _ branch2c ' , data = res4b12_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b12_branch2c = mx . symbol . BatchNorm ( name = ' bn4b12 _ branch2c ' , data = res4b12_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b12_branch2c = bn4b12_branch2c NEW_LINE res4b12 = mx . symbol . broadcast_add ( name = ' res4b12' , * [ res4b11_relu , scale4b12_branch2c ] ) NEW_LINE res4b12_relu = mx . symbol . Activation ( name = ' res4b12 _ relu ' , data = res4b12 , act_type = ' relu ' ) NEW_LINE res4b13_branch2a = mx . symbol . Convolution ( name = ' res4b13 _ branch2a ' , data = res4b12_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2a = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2a ' , data = res4b13_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b13_branch2a = bn4b13_branch2a NEW_LINE res4b13_branch2a_relu = mx . symbol . Activation ( name = ' res4b13 _ branch2a _ relu ' , data = scale4b13_branch2a , act_type = ' relu ' ) NEW_LINE res4b13_branch2b = mx . symbol . Convolution ( name = ' res4b13 _ branch2b ' , data = res4b13_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2b = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2b ' , data = res4b13_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b13_branch2b = bn4b13_branch2b NEW_LINE res4b13_branch2b_relu = mx . symbol . Activation ( name = ' res4b13 _ branch2b _ relu ' , data = scale4b13_branch2b , act_type = ' relu ' ) NEW_LINE res4b13_branch2c = mx . symbol . Convolution ( name = ' res4b13 _ branch2c ' , data = res4b13_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b13_branch2c = mx . symbol . BatchNorm ( name = ' bn4b13 _ branch2c ' , data = res4b13_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b13_branch2c = bn4b13_branch2c NEW_LINE res4b13 = mx . symbol . broadcast_add ( name = ' res4b13' , * [ res4b12_relu , scale4b13_branch2c ] ) NEW_LINE res4b13_relu = mx . symbol . Activation ( name = ' res4b13 _ relu ' , data = res4b13 , act_type = ' relu ' ) NEW_LINE res4b14_branch2a = mx . symbol . Convolution ( name = ' res4b14 _ branch2a ' , data = res4b13_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2a = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2a ' , data = res4b14_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b14_branch2a = bn4b14_branch2a NEW_LINE res4b14_branch2a_relu = mx . symbol . Activation ( name = ' res4b14 _ branch2a _ relu ' , data = scale4b14_branch2a , act_type = ' relu ' ) NEW_LINE res4b14_branch2b = mx . symbol . Convolution ( name = ' res4b14 _ branch2b ' , data = res4b14_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2b = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2b ' , data = res4b14_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b14_branch2b = bn4b14_branch2b NEW_LINE res4b14_branch2b_relu = mx . symbol . Activation ( name = ' res4b14 _ branch2b _ relu ' , data = scale4b14_branch2b , act_type = ' relu ' ) NEW_LINE res4b14_branch2c = mx . symbol . Convolution ( name = ' res4b14 _ branch2c ' , data = res4b14_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b14_branch2c = mx . symbol . BatchNorm ( name = ' bn4b14 _ branch2c ' , data = res4b14_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b14_branch2c = bn4b14_branch2c NEW_LINE res4b14 = mx . symbol . broadcast_add ( name = ' res4b14' , * [ res4b13_relu , scale4b14_branch2c ] ) NEW_LINE res4b14_relu = mx . symbol . Activation ( name = ' res4b14 _ relu ' , data = res4b14 , act_type = ' relu ' ) NEW_LINE res4b15_branch2a = mx . symbol . Convolution ( name = ' res4b15 _ branch2a ' , data = res4b14_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2a = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2a ' , data = res4b15_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b15_branch2a = bn4b15_branch2a NEW_LINE res4b15_branch2a_relu = mx . symbol . Activation ( name = ' res4b15 _ branch2a _ relu ' , data = scale4b15_branch2a , act_type = ' relu ' ) NEW_LINE res4b15_branch2b = mx . symbol . Convolution ( name = ' res4b15 _ branch2b ' , data = res4b15_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2b = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2b ' , data = res4b15_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b15_branch2b = bn4b15_branch2b NEW_LINE res4b15_branch2b_relu = mx . symbol . Activation ( name = ' res4b15 _ branch2b _ relu ' , data = scale4b15_branch2b , act_type = ' relu ' ) NEW_LINE res4b15_branch2c = mx . symbol . Convolution ( name = ' res4b15 _ branch2c ' , data = res4b15_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b15_branch2c = mx . symbol . BatchNorm ( name = ' bn4b15 _ branch2c ' , data = res4b15_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b15_branch2c = bn4b15_branch2c NEW_LINE res4b15 = mx . symbol . broadcast_add ( name = ' res4b15' , * [ res4b14_relu , scale4b15_branch2c ] ) NEW_LINE res4b15_relu = mx . symbol . Activation ( name = ' res4b15 _ relu ' , data = res4b15 , act_type = ' relu ' ) NEW_LINE res4b16_branch2a = mx . symbol . Convolution ( name = ' res4b16 _ branch2a ' , data = res4b15_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2a = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2a ' , data = res4b16_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b16_branch2a = bn4b16_branch2a NEW_LINE res4b16_branch2a_relu = mx . symbol . Activation ( name = ' res4b16 _ branch2a _ relu ' , data = scale4b16_branch2a , act_type = ' relu ' ) NEW_LINE res4b16_branch2b = mx . symbol . Convolution ( name = ' res4b16 _ branch2b ' , data = res4b16_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2b = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2b ' , data = res4b16_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b16_branch2b = bn4b16_branch2b NEW_LINE res4b16_branch2b_relu = mx . symbol . Activation ( name = ' res4b16 _ branch2b _ relu ' , data = scale4b16_branch2b , act_type = ' relu ' ) NEW_LINE res4b16_branch2c = mx . symbol . Convolution ( name = ' res4b16 _ branch2c ' , data = res4b16_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b16_branch2c = mx . symbol . BatchNorm ( name = ' bn4b16 _ branch2c ' , data = res4b16_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b16_branch2c = bn4b16_branch2c NEW_LINE res4b16 = mx . symbol . broadcast_add ( name = ' res4b16' , * [ res4b15_relu , scale4b16_branch2c ] ) NEW_LINE res4b16_relu = mx . symbol . Activation ( name = ' res4b16 _ relu ' , data = res4b16 , act_type = ' relu ' ) NEW_LINE res4b17_branch2a = mx . symbol . Convolution ( name = ' res4b17 _ branch2a ' , data = res4b16_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2a = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2a ' , data = res4b17_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b17_branch2a = bn4b17_branch2a NEW_LINE res4b17_branch2a_relu = mx . symbol . Activation ( name = ' res4b17 _ branch2a _ relu ' , data = scale4b17_branch2a , act_type = ' relu ' ) NEW_LINE res4b17_branch2b = mx . symbol . Convolution ( name = ' res4b17 _ branch2b ' , data = res4b17_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2b = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2b ' , data = res4b17_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b17_branch2b = bn4b17_branch2b NEW_LINE res4b17_branch2b_relu = mx . symbol . Activation ( name = ' res4b17 _ branch2b _ relu ' , data = scale4b17_branch2b , act_type = ' relu ' ) NEW_LINE res4b17_branch2c = mx . symbol . Convolution ( name = ' res4b17 _ branch2c ' , data = res4b17_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b17_branch2c = mx . symbol . BatchNorm ( name = ' bn4b17 _ branch2c ' , data = res4b17_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b17_branch2c = bn4b17_branch2c NEW_LINE res4b17 = mx . symbol . broadcast_add ( name = ' res4b17' , * [ res4b16_relu , scale4b17_branch2c ] ) NEW_LINE res4b17_relu = mx . symbol . Activation ( name = ' res4b17 _ relu ' , data = res4b17 , act_type = ' relu ' ) NEW_LINE res4b18_branch2a = mx . symbol . Convolution ( name = ' res4b18 _ branch2a ' , data = res4b17_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2a = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2a ' , data = res4b18_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b18_branch2a = bn4b18_branch2a NEW_LINE res4b18_branch2a_relu = mx . symbol . Activation ( name = ' res4b18 _ branch2a _ relu ' , data = scale4b18_branch2a , act_type = ' relu ' ) NEW_LINE res4b18_branch2b = mx . symbol . Convolution ( name = ' res4b18 _ branch2b ' , data = res4b18_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2b = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2b ' , data = res4b18_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b18_branch2b = bn4b18_branch2b NEW_LINE res4b18_branch2b_relu = mx . symbol . Activation ( name = ' res4b18 _ branch2b _ relu ' , data = scale4b18_branch2b , act_type = ' relu ' ) NEW_LINE res4b18_branch2c = mx . symbol . Convolution ( name = ' res4b18 _ branch2c ' , data = res4b18_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b18_branch2c = mx . symbol . BatchNorm ( name = ' bn4b18 _ branch2c ' , data = res4b18_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b18_branch2c = bn4b18_branch2c NEW_LINE res4b18 = mx . symbol . broadcast_add ( name = ' res4b18' , * [ res4b17_relu , scale4b18_branch2c ] ) NEW_LINE res4b18_relu = mx . symbol . Activation ( name = ' res4b18 _ relu ' , data = res4b18 , act_type = ' relu ' ) NEW_LINE res4b19_branch2a = mx . symbol . Convolution ( name = ' res4b19 _ branch2a ' , data = res4b18_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2a = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2a ' , data = res4b19_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b19_branch2a = bn4b19_branch2a NEW_LINE res4b19_branch2a_relu = mx . symbol . Activation ( name = ' res4b19 _ branch2a _ relu ' , data = scale4b19_branch2a , act_type = ' relu ' ) NEW_LINE res4b19_branch2b = mx . symbol . Convolution ( name = ' res4b19 _ branch2b ' , data = res4b19_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2b = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2b ' , data = res4b19_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b19_branch2b = bn4b19_branch2b NEW_LINE res4b19_branch2b_relu = mx . symbol . Activation ( name = ' res4b19 _ branch2b _ relu ' , data = scale4b19_branch2b , act_type = ' relu ' ) NEW_LINE res4b19_branch2c = mx . symbol . Convolution ( name = ' res4b19 _ branch2c ' , data = res4b19_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b19_branch2c = mx . symbol . BatchNorm ( name = ' bn4b19 _ branch2c ' , data = res4b19_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b19_branch2c = bn4b19_branch2c NEW_LINE res4b19 = mx . symbol . broadcast_add ( name = ' res4b19' , * [ res4b18_relu , scale4b19_branch2c ] ) NEW_LINE res4b19_relu = mx . symbol . Activation ( name = ' res4b19 _ relu ' , data = res4b19 , act_type = ' relu ' ) NEW_LINE res4b20_branch2a = mx . symbol . Convolution ( name = ' res4b20 _ branch2a ' , data = res4b19_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2a = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2a ' , data = res4b20_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b20_branch2a = bn4b20_branch2a NEW_LINE res4b20_branch2a_relu = mx . symbol . Activation ( name = ' res4b20 _ branch2a _ relu ' , data = scale4b20_branch2a , act_type = ' relu ' ) NEW_LINE res4b20_branch2b = mx . symbol . Convolution ( name = ' res4b20 _ branch2b ' , data = res4b20_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2b = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2b ' , data = res4b20_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b20_branch2b = bn4b20_branch2b NEW_LINE res4b20_branch2b_relu = mx . symbol . Activation ( name = ' res4b20 _ branch2b _ relu ' , data = scale4b20_branch2b , act_type = ' relu ' ) NEW_LINE res4b20_branch2c = mx . symbol . Convolution ( name = ' res4b20 _ branch2c ' , data = res4b20_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b20_branch2c = mx . symbol . BatchNorm ( name = ' bn4b20 _ branch2c ' , data = res4b20_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b20_branch2c = bn4b20_branch2c NEW_LINE res4b20 = mx . symbol . broadcast_add ( name = ' res4b20' , * [ res4b19_relu , scale4b20_branch2c ] ) NEW_LINE res4b20_relu = mx . symbol . Activation ( name = ' res4b20 _ relu ' , data = res4b20 , act_type = ' relu ' ) NEW_LINE res4b21_branch2a = mx . symbol . Convolution ( name = ' res4b21 _ branch2a ' , data = res4b20_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2a = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2a ' , data = res4b21_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b21_branch2a = bn4b21_branch2a NEW_LINE res4b21_branch2a_relu = mx . symbol . Activation ( name = ' res4b21 _ branch2a _ relu ' , data = scale4b21_branch2a , act_type = ' relu ' ) NEW_LINE res4b21_branch2b = mx . symbol . Convolution ( name = ' res4b21 _ branch2b ' , data = res4b21_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2b = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2b ' , data = res4b21_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b21_branch2b = bn4b21_branch2b NEW_LINE res4b21_branch2b_relu = mx . symbol . Activation ( name = ' res4b21 _ branch2b _ relu ' , data = scale4b21_branch2b , act_type = ' relu ' ) NEW_LINE res4b21_branch2c = mx . symbol . Convolution ( name = ' res4b21 _ branch2c ' , data = res4b21_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b21_branch2c = mx . symbol . BatchNorm ( name = ' bn4b21 _ branch2c ' , data = res4b21_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b21_branch2c = bn4b21_branch2c NEW_LINE res4b21 = mx . symbol . broadcast_add ( name = ' res4b21' , * [ res4b20_relu , scale4b21_branch2c ] ) NEW_LINE res4b21_relu = mx . symbol . Activation ( name = ' res4b21 _ relu ' , data = res4b21 , act_type = ' relu ' ) NEW_LINE res4b22_branch2a = mx . symbol . Convolution ( name = ' res4b22 _ branch2a ' , data = res4b21_relu , num_filter = 256 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b22_branch2a = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2a ' , data = res4b22_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b22_branch2a = bn4b22_branch2a NEW_LINE res4b22_branch2a_relu = mx . symbol . Activation ( name = ' res4b22 _ branch2a _ relu ' , data = scale4b22_branch2a , act_type = ' relu ' ) NEW_LINE if with_dpyramid : NEW_LINE INDENT res4b22_branch2b_offset = mx . symbol . Convolution ( name = ' res4b22 _ branch2b _ offset ' , data = res4b22_branch2a_relu , num_filter = 72 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) ) NEW_LINE res4b22_branch2b = mx . contrib . symbol . DeformableConvolution ( name = ' res4b22 _ branch2b ' , data = res4b22_branch2a_relu , offset = res4b22_branch2b_offset , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , num_deformable_group = 4 , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE DEDENT else : NEW_LINE INDENT res4b22_branch2b = mx . symbol . Convolution ( name = ' res4b22 _ branch2b ' , data = res4b22_branch2a_relu , num_filter = 256 , pad = ( 1 , 1 ) , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE DEDENT bn4b22_branch2b = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2b ' , data = res4b22_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b22_branch2b = bn4b22_branch2b NEW_LINE res4b22_branch2b_relu = mx . symbol . Activation ( name = ' res4b22 _ branch2b _ relu ' , data = scale4b22_branch2b , act_type = ' relu ' ) NEW_LINE res4b22_branch2c = mx . symbol . Convolution ( name = ' res4b22 _ branch2c ' , data = res4b22_branch2b_relu , num_filter = 1024 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn4b22_branch2c = mx . symbol . BatchNorm ( name = ' bn4b22 _ branch2c ' , data = res4b22_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale4b22_branch2c = bn4b22_branch2c NEW_LINE res4b22 = mx . symbol . broadcast_add ( name = ' res4b22' , * [ res4b21_relu , scale4b22_branch2c ] ) NEW_LINE res4b22_relu = mx . symbol . Activation ( name = ' res4b22 _ relu ' , data = res4b22 , act_type = ' relu ' ) NEW_LINE if with_dilated : NEW_LINE INDENT res5_stride = ( 1 , 1 ) NEW_LINE res5_dilate = ( 2 , 2 ) NEW_LINE DEDENT else : NEW_LINE INDENT res5_stride = ( 2 , 2 ) NEW_LINE res5_dilate = ( 1 , 1 ) NEW_LINE DEDENT res5a_branch2a = mx . symbol . Convolution ( name = ' res5a _ branch2a ' , data = res4b22_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = res5_stride , no_bias = True ) NEW_LINE bn5a_branch2a = mx . symbol . BatchNorm ( name = ' bn5a _ branch2a ' , data = res5a_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5a_branch2a = bn5a_branch2a NEW_LINE res5a_branch2a_relu = mx . symbol . Activation ( name = ' res5a _ branch2a _ relu ' , data = scale5a_branch2a , act_type = ' relu ' ) NEW_LINE if with_dconv : NEW_LINE INDENT res5a_branch2b_offset = mx . symbol . Convolution ( name = ' res5a _ branch2b _ offset ' , data = res5a_branch2a_relu , num_filter = 72 , pad = res5_dilate , kernel = ( 3 , 3 ) , dilate = res5_dilate ) NEW_LINE res5a_branch2b = mx . contrib . symbol . DeformableConvolution ( name = ' res5a _ branch2b ' , data = res5a_branch2a_relu , offset = res5a_branch2b_offset , num_filter = 512 , pad = res5_dilate , kernel = ( 3 , 3 ) , num_deformable_group = 4 , stride = ( 1 , 1 ) , dilate = res5_dilate , no_bias = True ) NEW_LINE DEDENT else : NEW_LINE INDENT res5a_branch2b = mx . symbol . Convolution ( name = ' res5a _ branch2b ' , data = res5a_branch2a_relu , num_filter = 512 , pad = res5_dilate , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = res5_dilate , no_bias = True ) NEW_LINE DEDENT bn5a_branch2b = mx . symbol . BatchNorm ( name = ' bn5a _ branch2b ' , data = res5a_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5a_branch2b = bn5a_branch2b NEW_LINE res5a_branch2b_relu = mx . symbol . Activation ( name = ' res5a _ branch2b _ relu ' , data = scale5a_branch2b , act_type = ' relu ' ) NEW_LINE res5a_branch2c = mx . symbol . Convolution ( name = ' res5a _ branch2c ' , data = res5a_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5a_branch2c = mx . symbol . BatchNorm ( name = ' bn5a _ branch2c ' , data = res5a_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5a_branch2c = bn5a_branch2c NEW_LINE res5a_branch1 = mx . symbol . Convolution ( name = ' res5a _ branch1' , data = res4b22_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = res5_stride , no_bias = True ) NEW_LINE bn5a_branch1 = mx . symbol . BatchNorm ( name = ' bn5a _ branch1' , data = res5a_branch1 , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5a_branch1 = bn5a_branch1 NEW_LINE res5a = mx . symbol . broadcast_add ( name = ' res5a ' , * [ scale5a_branch1 , scale5a_branch2c ] ) NEW_LINE res5a_relu = mx . symbol . Activation ( name = ' res5a _ relu ' , data = res5a , act_type = ' relu ' ) NEW_LINE res5b_branch2a = mx . symbol . Convolution ( name = ' res5b _ branch2a ' , data = res5a_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5b_branch2a = mx . symbol . BatchNorm ( name = ' bn5b _ branch2a ' , data = res5b_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5b_branch2a = bn5b_branch2a NEW_LINE res5b_branch2a_relu = mx . symbol . Activation ( name = ' res5b _ branch2a _ relu ' , data = scale5b_branch2a , act_type = ' relu ' ) NEW_LINE if with_dconv : NEW_LINE INDENT res5b_branch2b_offset = mx . symbol . Convolution ( name = ' res5b _ branch2b _ offset ' , data = res5b_branch2a_relu , num_filter = 72 , pad = res5_dilate , kernel = ( 3 , 3 ) , dilate = res5_dilate ) NEW_LINE res5b_branch2b = mx . contrib . symbol . DeformableConvolution ( name = ' res5b _ branch2b ' , data = res5b_branch2a_relu , offset = res5b_branch2b_offset , num_filter = 512 , pad = res5_dilate , kernel = ( 3 , 3 ) , num_deformable_group = 4 , dilate = res5_dilate , no_bias = True ) NEW_LINE DEDENT else : NEW_LINE INDENT res5b_branch2b = mx . symbol . Convolution ( name = ' res5b _ branch2b ' , data = res5b_branch2a_relu , num_filter = 512 , pad = res5_dilate , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = res5_dilate , no_bias = True ) NEW_LINE DEDENT bn5b_branch2b = mx . symbol . BatchNorm ( name = ' bn5b _ branch2b ' , data = res5b_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5b_branch2b = bn5b_branch2b NEW_LINE res5b_branch2b_relu = mx . symbol . Activation ( name = ' res5b _ branch2b _ relu ' , data = scale5b_branch2b , act_type = ' relu ' ) NEW_LINE res5b_branch2c = mx . symbol . Convolution ( name = ' res5b _ branch2c ' , data = res5b_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5b_branch2c = mx . symbol . BatchNorm ( name = ' bn5b _ branch2c ' , data = res5b_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5b_branch2c = bn5b_branch2c NEW_LINE res5b = mx . symbol . broadcast_add ( name = ' res5b ' , * [ res5a_relu , scale5b_branch2c ] ) NEW_LINE res5b_relu = mx . symbol . Activation ( name = ' res5b _ relu ' , data = res5b , act_type = ' relu ' ) NEW_LINE res5c_branch2a = mx . symbol . Convolution ( name = ' res5c _ branch2a ' , data = res5b_relu , num_filter = 512 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5c_branch2a = mx . symbol . BatchNorm ( name = ' bn5c _ branch2a ' , data = res5c_branch2a , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5c_branch2a = bn5c_branch2a NEW_LINE res5c_branch2a_relu = mx . symbol . Activation ( name = ' res5c _ branch2a _ relu ' , data = scale5c_branch2a , act_type = ' relu ' ) NEW_LINE if with_dconv : NEW_LINE INDENT res5c_branch2b_offset = mx . symbol . Convolution ( name = ' res5c _ branch2b _ offset ' , data = res5c_branch2a_relu , num_filter = 72 , pad = res5_dilate , kernel = ( 3 , 3 ) , dilate = res5_dilate ) NEW_LINE res5c_branch2b = mx . contrib . symbol . DeformableConvolution ( name = ' res5c _ branch2b ' , data = res5c_branch2a_relu , offset = res5c_branch2b_offset , num_filter = 512 , pad = res5_dilate , kernel = ( 3 , 3 ) , num_deformable_group = 4 , dilate = res5_dilate , no_bias = True ) NEW_LINE DEDENT else : NEW_LINE INDENT res5c_branch2b = mx . symbol . Convolution ( name = ' res5c _ branch2b ' , data = res5c_branch2a_relu , num_filter = 512 , pad = res5_dilate , kernel = ( 3 , 3 ) , stride = ( 1 , 1 ) , dilate = res5_dilate , no_bias = True ) NEW_LINE DEDENT bn5c_branch2b = mx . symbol . BatchNorm ( name = ' bn5c _ branch2b ' , data = res5c_branch2b , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5c_branch2b = bn5c_branch2b NEW_LINE res5c_branch2b_relu = mx . symbol . Activation ( name = ' res5c _ branch2b _ relu ' , data = scale5c_branch2b , act_type = ' relu ' ) NEW_LINE res5c_branch2c = mx . symbol . Convolution ( name = ' res5c _ branch2c ' , data = res5c_branch2b_relu , num_filter = 2048 , pad = ( 0 , 0 ) , kernel = ( 1 , 1 ) , stride = ( 1 , 1 ) , no_bias = True ) NEW_LINE bn5c_branch2c = mx . symbol . BatchNorm ( name = ' bn5c _ branch2c ' , data = res5c_branch2c , use_global_stats = True , fix_gamma = False , eps = eps ) NEW_LINE scale5c_branch2c = bn5c_branch2c NEW_LINE res5c = mx . symbol . broadcast_add ( name = ' res5c ' , * [ res5b_relu , scale5c_branch2c ] ) NEW_LINE res5c_relu = mx . symbol . Activation ( name = ' res5c _ relu ' , data = res5c , act_type = ' relu ' ) NEW_LINE return res2c_relu , res3b3_relu , res4b22_relu , res5c_relu NEW_LINE DEDENT\",), (\"def get_fpn_feature ( self , c2 , c3 , c4 , c5 , feature_dim = 256 ) : NEW_LINE INDENT fpn_p5_1x1 = mx . symbol . Convolution ( data = c5 , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , stride = ( 1 , 1 ) , num_filter = feature_dim , name = ' fpn _ p5_1x1' ) NEW_LINE fpn_p4_1x1 = mx . symbol . Convolution ( data = c4 , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , stride = ( 1 , 1 ) , num_filter = feature_dim , name = ' fpn _ p4_1x1' ) NEW_LINE fpn_p3_1x1 = mx . symbol . Convolution ( data = c3 , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , stride = ( 1 , 1 ) , num_filter = feature_dim , name = ' fpn _ p3_1x1' ) NEW_LINE fpn_p2_1x1 = mx . symbol . Convolution ( data = c2 , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , stride = ( 1 , 1 ) , num_filter = feature_dim , name = ' fpn _ p2_1x1' ) NEW_LINE fpn_p5_upsample = mx . symbol . UpSampling ( fpn_p5_1x1 , scale = 2 , sample_type = ' nearest ' , name = ' fpn _ p5 _ upsample ' ) NEW_LINE fpn_p4_plus = mx . sym . ElementWiseSum ( * [ fpn_p5_upsample , fpn_p4_1x1 ] , name = ' fpn _ p4 _ sum ' ) NEW_LINE fpn_p4_upsample = mx . symbol . UpSampling ( fpn_p4_plus , scale = 2 , sample_type = ' nearest ' , name = ' fpn _ p4 _ upsample ' ) NEW_LINE fpn_p3_plus = mx . sym . ElementWiseSum ( * [ fpn_p4_upsample , fpn_p3_1x1 ] , name = ' fpn _ p3 _ sum ' ) NEW_LINE fpn_p3_upsample = mx . symbol . UpSampling ( fpn_p3_plus , scale = 2 , sample_type = ' nearest ' , name = ' fpn _ p3 _ upsample ' ) NEW_LINE fpn_p2_plus = mx . sym . ElementWiseSum ( * [ fpn_p3_upsample , fpn_p2_1x1 ] , name = ' fpn _ p2 _ sum ' ) NEW_LINE fpn_p6 = mx . sym . Convolution ( data = c5 , kernel = ( 3 , 3 ) , pad = ( 1 , 1 ) , stride = ( 2 , 2 ) , num_filter = feature_dim , name = ' fpn _ p6' ) NEW_LINE fpn_p5 = mx . symbol . Convolution ( data = fpn_p5_1x1 , kernel = ( 3 , 3 ) , pad = ( 1 , 1 ) , stride = ( 1 , 1 ) , num_filter = feature_dim , name = ' fpn _ p5' ) NEW_LINE fpn_p4 = mx . symbol . Convolution ( data = fpn_p4_plus , kernel = ( 3 , 3 ) , pad = ( 1 , 1 ) , stride = ( 1 , 1 ) , num_filter = feature_dim , name = ' fpn _ p4' ) NEW_LINE fpn_p3 = mx . symbol . Convolution ( data = fpn_p3_plus , kernel = ( 3 , 3 ) , pad = ( 1 , 1 ) , stride = ( 1 , 1 ) , num_filter = feature_dim , name = ' fpn _ p3' ) NEW_LINE fpn_p2 = mx . symbol . Convolution ( data = fpn_p2_plus , kernel = ( 3 , 3 ) , pad = ( 1 , 1 ) , stride = ( 1 , 1 ) , num_filter = feature_dim , name = ' fpn _ p2' ) NEW_LINE return fpn_p2 , fpn_p3 , fpn_p4 , fpn_p5 , fpn_p6 NEW_LINE DEDENT\",), ('def get_light_head ( self , data , suffix ) : NEW_LINE INDENT mid_num_filter = 64 NEW_LINE conv_new_1 = mx . sym . Convolution ( data = data , kernel = ( 15 , 1 ) , pad = ( 7 , 0 ) , num_filter = mid_num_filter , name = \" conv _ new _ 1\" + suffix , weight = self . shared_param_dict [ \\' conv _ new _ 1 _ weight \\' ] , bias = self . shared_param_dict [ \\' conv _ new _ 1 _ bias \\' ] , lr_mult = 3.0 ) NEW_LINE relu_new_1 = mx . sym . Activation ( data = conv_new_1 , act_type = \\' relu \\' , name = \\' relu1\\' + suffix ) NEW_LINE conv_new_2 = mx . sym . Convolution ( data = relu_new_1 , kernel = ( 1 , 15 ) , pad = ( 0 , 7 ) , num_filter = 10 * 7 * 7 , name = \" conv _ new _ 2\" + suffix , weight = self . shared_param_dict [ \\' conv _ new _ 2 _ weight \\' ] , bias = self . shared_param_dict [ \\' conv _ new _ 2 _ bias \\' ] , lr_mult = 3.0 ) NEW_LINE relu_new_2 = mx . sym . Activation ( data = conv_new_2 , act_type = \\' relu \\' , name = \\' relu2\\' + suffix ) NEW_LINE conv_new_3 = mx . sym . Convolution ( data = data , kernel = ( 1 , 15 ) , pad = ( 0 , 7 ) , num_filter = mid_num_filter , name = \" conv _ new _ 3\" + suffix , weight = self . shared_param_dict [ \\' conv _ new _ 3 _ weight \\' ] , bias = self . shared_param_dict [ \\' conv _ new _ 3 _ bias \\' ] , lr_mult = 3.0 ) NEW_LINE relu_new_3 = mx . sym . Activation ( data = conv_new_3 , act_type = \\' relu \\' , name = \\' relu3\\' + suffix ) NEW_LINE conv_new_4 = mx . sym . Convolution ( data = relu_new_3 , kernel = ( 15 , 1 ) , pad = ( 7 , 0 ) , num_filter = 10 * 7 * 7 , name = \" conv _ new _ 4\" + suffix , weight = self . shared_param_dict [ \\' conv _ new _ 4 _ weight \\' ] , bias = self . shared_param_dict [ \\' conv _ new _ 4 _ bias \\' ] , lr_mult = 3.0 ) NEW_LINE relu_new_4 = mx . sym . Activation ( data = conv_new_4 , act_type = \\' relu \\' , name = \\' relu4\\' + suffix ) NEW_LINE light_head = mx . symbol . broadcast_add ( name = \\' light _ head \\' , * [ relu_new_2 , relu_new_4 ] ) NEW_LINE return light_head NEW_LINE DEDENT',), (\"def get_rpn_subnet ( self , data , num_anchors , suffix ) : NEW_LINE INDENT rpn_conv = mx . sym . Convolution ( data = data , kernel = ( 3 , 3 ) , pad = ( 1 , 1 ) , num_filter = 512 , name = ' rpn _ conv _ ' + suffix , weight = self . shared_param_dict [ ' rpn _ conv _ weight ' ] , bias = self . shared_param_dict [ ' rpn _ conv _ bias ' ] ) NEW_LINE rpn_relu = mx . sym . Activation ( data = rpn_conv , act_type = ' relu ' , name = ' rpn _ relu _ ' + suffix ) NEW_LINE rpn_cls_score = mx . sym . Convolution ( data = rpn_relu , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , num_filter = 2 * num_anchors , name = ' rpn _ cls _ score _ ' + suffix , weight = self . shared_param_dict [ ' rpn _ cls _ score _ weight ' ] , bias = self . shared_param_dict [ ' rpn _ cls _ score _ bias ' ] ) NEW_LINE rpn_bbox_pred = mx . sym . Convolution ( data = rpn_relu , kernel = ( 1 , 1 ) , pad = ( 0 , 0 ) , num_filter = 4 * num_anchors , name = ' rpn _ bbox _ pred _ ' + suffix , weight = self . shared_param_dict [ ' rpn _ bbox _ pred _ weight ' ] , bias = self . shared_param_dict [ ' rpn _ bbox _ pred _ bias ' ] ) NEW_LINE rpn_cls_score_t1 = mx . sym . Reshape ( data = rpn_cls_score , shape = ( 0 , 2 , - 1 , 0 ) , name = ' rpn _ cls _ score _ t1 _ ' + suffix ) NEW_LINE rpn_cls_score_t2 = mx . sym . Reshape ( data = rpn_cls_score_t1 , shape = ( 0 , 2 , - 1 ) , name = ' rpn _ cls _ score _ t2 _ ' + suffix ) NEW_LINE rpn_cls_prob = mx . sym . SoftmaxActivation ( data = rpn_cls_score_t1 , mode = ' channel ' , name = ' rpn _ cls _ prob _ ' + suffix ) NEW_LINE rpn_cls_prob_t = mx . sym . Reshape ( data = rpn_cls_prob , shape = ( 0 , 2 * num_anchors , - 1 , 0 ) , name = ' rpn _ cls _ prob _ t _ ' + suffix ) NEW_LINE rpn_bbox_pred_t = mx . sym . Reshape ( data = rpn_bbox_pred , shape = ( 0 , 0 , - 1 ) , name = ' rpn _ bbox _ pred _ t _ ' + suffix ) NEW_LINE return rpn_cls_score_t2 , rpn_cls_prob_t , rpn_bbox_pred_t , rpn_bbox_pred NEW_LINE DEDENT\",), ('def get_symbol ( self , cfg , is_train = True ) : NEW_LINE INDENT num_classes = cfg . dataset . NUM_CLASSES NEW_LINE num_reg_classes = ( 2 if cfg . CLASS_AGNOSTIC else num_classes ) NEW_LINE data = mx . sym . Variable ( name = \" data \" ) NEW_LINE im_info = mx . sym . Variable ( name = \" im _ info \" ) NEW_LINE res2 , res3 , res4 , res5 = self . get_resnet_backbone ( data ) NEW_LINE fpn_p2 , fpn_p3 , fpn_p4 , fpn_p5 , fpn_p6 = self . get_fpn_feature ( res2 , res3 , res4 , res5 ) NEW_LINE fpn_p2_new = self . get_light_head ( fpn_p2 , \\' p2\\' ) NEW_LINE fpn_p3_new = self . get_light_head ( fpn_p3 , \\' p3\\' ) NEW_LINE fpn_p4_new = self . get_light_head ( fpn_p4 , \\' p4\\' ) NEW_LINE fpn_p5_new = self . get_light_head ( fpn_p5 , \\' p5\\' ) NEW_LINE rpn_cls_score_p2 , rpn_prob_p2 , rpn_bbox_loss_p2 , rpn_bbox_pred_p2 = self . get_rpn_subnet ( fpn_p2 , cfg . network . NUM_ANCHORS , \\' p2\\' ) NEW_LINE rpn_cls_score_p3 , rpn_prob_p3 , rpn_bbox_loss_p3 , rpn_bbox_pred_p3 = self . get_rpn_subnet ( fpn_p3 , cfg . network . NUM_ANCHORS , \\' p3\\' ) NEW_LINE rpn_cls_score_p4 , rpn_prob_p4 , rpn_bbox_loss_p4 , rpn_bbox_pred_p4 = self . get_rpn_subnet ( fpn_p4 , cfg . network . NUM_ANCHORS , \\' p4\\' ) NEW_LINE rpn_cls_score_p5 , rpn_prob_p5 , rpn_bbox_loss_p5 , rpn_bbox_pred_p5 = self . get_rpn_subnet ( fpn_p5 , cfg . network . NUM_ANCHORS , \\' p5\\' ) NEW_LINE rpn_cls_score_p6 , rpn_prob_p6 , rpn_bbox_loss_p6 , rpn_bbox_pred_p6 = self . get_rpn_subnet ( fpn_p6 , cfg . network . NUM_ANCHORS , \\' p6\\' ) NEW_LINE rpn_cls_prob_dict = { \\' rpn _ cls _ prob _ stride64\\' : rpn_prob_p6 , \\' rpn _ cls _ prob _ stride32\\' : rpn_prob_p5 , \\' rpn _ cls _ prob _ stride16\\' : rpn_prob_p4 , \\' rpn _ cls _ prob _ stride8\\' : rpn_prob_p3 , \\' rpn _ cls _ prob _ stride4\\' : rpn_prob_p2 , } NEW_LINE rpn_bbox_pred_dict = { \\' rpn _ bbox _ pred _ stride64\\' : rpn_bbox_pred_p6 , \\' rpn _ bbox _ pred _ stride32\\' : rpn_bbox_pred_p5 , \\' rpn _ bbox _ pred _ stride16\\' : rpn_bbox_pred_p4 , \\' rpn _ bbox _ pred _ stride8\\' : rpn_bbox_pred_p3 , \\' rpn _ bbox _ pred _ stride4\\' : rpn_bbox_pred_p2 , } NEW_LINE arg_dict = dict ( rpn_cls_prob_dict . items ( ) + rpn_bbox_pred_dict . items ( ) ) NEW_LINE if is_train : NEW_LINE INDENT rpn_label = mx . sym . Variable ( name = \\' label \\' ) NEW_LINE rpn_bbox_target = mx . sym . Variable ( name = \\' bbox _ target \\' ) NEW_LINE rpn_bbox_weight = mx . sym . Variable ( name = \\' bbox _ weight \\' ) NEW_LINE gt_boxes = mx . sym . Variable ( name = \" gt _ boxes \" ) NEW_LINE rpn_cls_score = mx . sym . Concat ( rpn_cls_score_p2 , rpn_cls_score_p3 , rpn_cls_score_p4 , rpn_cls_score_p5 , rpn_cls_score_p6 , dim = 2 ) NEW_LINE rpn_bbox_loss = mx . sym . Concat ( rpn_bbox_loss_p2 , rpn_bbox_loss_p3 , rpn_bbox_loss_p4 , rpn_bbox_loss_p5 , rpn_bbox_loss_p6 , dim = 2 ) NEW_LINE rpn_cls_output = mx . sym . SoftmaxOutput ( data = rpn_cls_score , label = rpn_label , multi_output = True , normalization = \\' valid \\' , use_ignore = True , ignore_label = - 1 , name = \\' rpn _ cls _ prob \\' ) NEW_LINE rpn_bbox_loss = rpn_bbox_weight * mx . sym . smooth_l1 ( name = \\' rpn _ bbox _ loss _ l1\\' , scalar = 3.0 , data = ( rpn_bbox_loss - rpn_bbox_target ) ) NEW_LINE rpn_bbox_loss = mx . sym . MakeLoss ( name = \\' rpn _ bbox _ loss \\' , data = rpn_bbox_loss , grad_scale = 1.0 / cfg . TRAIN . RPN_BATCH_SIZE ) NEW_LINE aux_dict = { \\' op _ type \\' : \\' pyramid _ proposal \\' , \\' name \\' : \\' rois \\' , \\' im _ info \\' : im_info , \\' feat _ stride \\' : tuple ( cfg . network . RPN_FEAT_STRIDE ) , \\' scales \\' : tuple ( cfg . network . ANCHOR_SCALES ) , \\' ratios \\' : tuple ( cfg . network . ANCHOR_RATIOS ) , \\' rpn _ pre _ nms _ top _ n \\' : cfg . TRAIN . RPN_PRE_NMS_TOP_N , \\' rpn _ post _ nms _ top _ n \\' : cfg . TRAIN . RPN_POST_NMS_TOP_N , \\' threshold \\' : cfg . TRAIN . RPN_NMS_THRESH , \\' rpn _ min _ size \\' : cfg . TRAIN . RPN_MIN_SIZE } NEW_LINE rois = mx . sym . Custom ( ** dict ( arg_dict . items ( ) + aux_dict . items ( ) ) ) NEW_LINE gt_boxes_reshape = mx . sym . Reshape ( data = gt_boxes , shape = ( - 1 , 9 ) , name = \\' gt _ boxes _ reshape \\' ) NEW_LINE rois , label , bbox_target , bbox_weight = mx . sym . Custom ( rois = rois , gt_boxes = gt_boxes_reshape , op_type = \\' proposal _ target _ rotbox \\' , num_classes = num_reg_classes , batch_images = cfg . TRAIN . BATCH_IMAGES , batch_rois = cfg . TRAIN . BATCH_ROIS , cfg = cPickle . dumps ( cfg ) , fg_fraction = cfg . TRAIN . FG_FRACTION ) NEW_LINE DEDENT else : NEW_LINE INDENT aux_dict = { \\' op _ type \\' : \\' pyramid _ proposal \\' , \\' name \\' : \\' rois \\' , \\' im _ info \\' : im_info , \\' feat _ stride \\' : tuple ( cfg . network . RPN_FEAT_STRIDE ) , \\' scales \\' : tuple ( cfg . network . ANCHOR_SCALES ) , \\' ratios \\' : tuple ( cfg . network . ANCHOR_RATIOS ) , \\' rpn _ pre _ nms _ top _ n \\' : cfg . TEST . RPN_PRE_NMS_TOP_N , \\' rpn _ post _ nms _ top _ n \\' : cfg . TEST . RPN_POST_NMS_TOP_N , \\' threshold \\' : cfg . TEST . RPN_NMS_THRESH , \\' rpn _ min _ size \\' : cfg . TEST . RPN_MIN_SIZE } NEW_LINE rois = mx . sym . Custom ( ** dict ( arg_dict . items ( ) + aux_dict . items ( ) ) ) NEW_LINE DEDENT roi_pool = mx . symbol . Custom ( data_p2 = fpn_p2_new , data_p3 = fpn_p3_new , data_p4 = fpn_p4_new , data_p5 = fpn_p5_new , rois = rois , op_type = \\' fpn _ psroi _ pooling _ v2\\' , name = \\' fpn _ psroi _ pooling _ v2\\' , pooling_mode = cfg . network . POOLING_MODE ) NEW_LINE fc_new_2 = mx . symbol . FullyConnected ( name = \\' fc _ new _ 2\\' , data = roi_pool , num_hidden = 2048 ) NEW_LINE fc_new_2_relu = mx . sym . Activation ( data = fc_new_2 , act_type = \\' relu \\' , name = \\' fc _ new _ 2 _ relu \\' ) NEW_LINE cls_score = mx . symbol . FullyConnected ( name = \\' cls _ score \\' , data = fc_new_2_relu , num_hidden = num_classes ) NEW_LINE bbox_pred = mx . symbol . FullyConnected ( name = \\' bbox _ pred \\' , data = fc_new_2_relu , num_hidden = num_reg_classes * 5 ) NEW_LINE if is_train : NEW_LINE INDENT if cfg . TRAIN . ENABLE_OHEM : NEW_LINE INDENT labels_ohem , bbox_weights_ohem = mx . sym . Custom ( op_type = \\' BoxAnnotatorOHEM \\' , num_classes = num_classes , num_reg_classes = num_reg_classes , roi_per_img = cfg . TRAIN . BATCH_ROIS_OHEM , cls_score = cls_score , bbox_pred = bbox_pred , labels = label , bbox_targets = bbox_target , bbox_weights = bbox_weight ) NEW_LINE cls_prob = mx . sym . SoftmaxOutput ( name = \\' cls _ prob \\' , data = cls_score , label = labels_ohem , normalization = \\' valid \\' , use_ignore = True , ignore_label = - 1 ) NEW_LINE bbox_loss_ = bbox_weights_ohem * mx . sym . smooth_l1 ( name = \\' bbox _ loss _ \\' , scalar = 1.0 , data = ( bbox_pred - bbox_target ) ) NEW_LINE bbox_loss = mx . sym . MakeLoss ( name = \\' bbox _ loss \\' , data = bbox_loss_ , grad_scale = 1.0 / cfg . TRAIN . BATCH_ROIS_OHEM ) NEW_LINE rcnn_label = labels_ohem NEW_LINE DEDENT else : NEW_LINE INDENT cls_prob = mx . sym . SoftmaxOutput ( name = \\' cls _ prob \\' , data = cls_score , label = label , normalization = \\' valid \\' ) NEW_LINE bbox_loss_ = bbox_weight * mx . sym . smooth_l1 ( name = \\' bbox _ loss _ \\' , scalar = 1.0 , data = ( bbox_pred - bbox_target ) ) NEW_LINE bbox_loss = mx . sym . MakeLoss ( name = \\' bbox _ loss \\' , data = bbox_loss_ , grad_scale = 1.0 / cfg . TRAIN . BATCH_ROIS ) NEW_LINE rcnn_label = label NEW_LINE DEDENT rcnn_label = mx . sym . Reshape ( data = rcnn_label , shape = ( cfg . TRAIN . BATCH_IMAGES , - 1 ) , name = \\' label _ reshape \\' ) NEW_LINE cls_prob = mx . sym . Reshape ( data = cls_prob , shape = ( cfg . TRAIN . BATCH_IMAGES , - 1 , num_classes ) , name = \\' cls _ prob _ reshape \\' ) NEW_LINE bbox_loss = mx . sym . Reshape ( data = bbox_loss , shape = ( cfg . TRAIN . BATCH_IMAGES , - 1 , 5 * num_reg_classes ) , name = \\' bbox _ loss _ reshape \\' ) NEW_LINE group = mx . sym . Group ( [ rpn_cls_output , rpn_bbox_loss , cls_prob , bbox_loss , mx . sym . BlockGrad ( rcnn_label ) ] ) NEW_LINE DEDENT else : NEW_LINE INDENT cls_prob = mx . sym . SoftmaxActivation ( name = \\' cls _ prob \\' , data = cls_score ) NEW_LINE cls_prob = mx . sym . Reshape ( data = cls_prob , shape = ( cfg . TEST . BATCH_IMAGES , - 1 , num_classes ) , name = \\' cls _ prob _ reshape \\' ) NEW_LINE bbox_pred = mx . sym . Reshape ( data = bbox_pred , shape = ( cfg . TEST . BATCH_IMAGES , - 1 , 5 * num_reg_classes ) , name = \\' bbox _ pred _ reshape \\' ) NEW_LINE group = mx . sym . Group ( [ rois , cls_prob , bbox_pred ] ) NEW_LINE DEDENT self . sym = group NEW_LINE return group NEW_LINE DEDENT',), (\"def init_weight_rcnn ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT arg_params [ ' fc _ new _ 2 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fc _ new _ 2 _ weight ' ] ) NEW_LINE arg_params [ ' fc _ new _ 2 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fc _ new _ 2 _ bias ' ] ) NEW_LINE arg_params [ ' cls _ score _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' cls _ score _ weight ' ] ) NEW_LINE arg_params [ ' cls _ score _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' cls _ score _ bias ' ] ) NEW_LINE arg_params [ ' bbox _ pred _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' bbox _ pred _ weight ' ] ) NEW_LINE arg_params [ ' bbox _ pred _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' bbox _ pred _ bias ' ] ) NEW_LINE DEDENT\",), (\"def init_weight_fpn ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT arg_params [ ' fpn _ p6 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p6 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p6 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p6 _ bias ' ] ) NEW_LINE arg_params [ ' fpn _ p5 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p5 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p5 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p5 _ bias ' ] ) NEW_LINE arg_params [ ' fpn _ p4 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p4 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p4 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p4 _ bias ' ] ) NEW_LINE arg_params [ ' fpn _ p3 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p3 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p3 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p3 _ bias ' ] ) NEW_LINE arg_params [ ' fpn _ p2 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p2 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p2 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p2 _ bias ' ] ) NEW_LINE arg_params [ ' fpn _ p5_1x1 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p5_1x1 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p5_1x1 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p5_1x1 _ bias ' ] ) NEW_LINE arg_params [ ' fpn _ p4_1x1 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p4_1x1 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p4_1x1 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p4_1x1 _ bias ' ] ) NEW_LINE arg_params [ ' fpn _ p3_1x1 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p3_1x1 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p3_1x1 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p3_1x1 _ bias ' ] ) NEW_LINE arg_params [ ' fpn _ p2_1x1 _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ ' fpn _ p2_1x1 _ weight ' ] ) NEW_LINE arg_params [ ' fpn _ p2_1x1 _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ ' fpn _ p2_1x1 _ bias ' ] ) NEW_LINE DEDENT\",), (\"def init_weight ( self , cfg , arg_params , aux_params ) : NEW_LINE INDENT for name in self . shared_param_list : NEW_LINE INDENT arg_params [ name + ' _ weight ' ] = mx . random . normal ( 0 , 0.01 , shape = self . arg_shape_dict [ name + ' _ weight ' ] ) NEW_LINE arg_params [ name + ' _ bias ' ] = mx . nd . zeros ( shape = self . arg_shape_dict [ name + ' _ bias ' ] ) NEW_LINE DEDENT self . init_weight_rcnn ( cfg , arg_params , aux_params ) NEW_LINE self . init_weight_fpn ( cfg , arg_params , aux_params ) NEW_LINE DEDENT\",), (\"def par_assign_anchor_wrapper ( cfg , iroidb , feat_sym , feat_strides , anchor_scales , anchor_ratios , allowed_border ) : NEW_LINE INDENT data , rpn_label = get_rpn_batch ( iroidb , cfg ) NEW_LINE data_shape = { k : v . shape for k , v in data . items ( ) } NEW_LINE del data_shape [ ' im _ info ' ] NEW_LINE data [ ' gt _ boxes ' ] = rpn_label [ ' gt _ boxes ' ] [ np . newaxis , : , : ] NEW_LINE feat_shape = [ y [ 1 ] for y in [ x . infer_shape ( ** data_shape ) for x in feat_sym ] ] NEW_LINE label = assign_pyramid_anchor ( feat_shape , rpn_label [ ' gt _ boxes ' ] , data [ ' im _ info ' ] , cfg , feat_strides , anchor_scales , anchor_ratios , allowed_border ) NEW_LINE return { ' data ' : data , ' label ' : label } NEW_LINE DEDENT\",), (\"def par_assign_anchor_wrapper_poly ( cfg , iroidb , feat_sym , feat_strides , anchor_scales , anchor_ratios , allowed_border ) : NEW_LINE INDENT data , rpn_label = get_rpn_batch_poly ( iroidb , cfg ) NEW_LINE data_shape = { k : v . shape for k , v in data . items ( ) } NEW_LINE del data_shape [ ' im _ info ' ] NEW_LINE data [ ' gt _ boxes ' ] = rpn_label [ ' gt _ boxes ' ] [ np . newaxis , : , : ] NEW_LINE feat_shape = [ y [ 1 ] for y in [ x . infer_shape ( ** data_shape ) for x in feat_sym ] ] NEW_LINE label = assign_pyramid_anchor_poly ( feat_shape , rpn_label [ ' gt _ boxes ' ] , data [ ' im _ info ' ] , cfg , feat_strides , anchor_scales , anchor_ratios , allowed_border ) NEW_LINE return { ' data ' : data , ' label ' : label } NEW_LINE DEDENT\",), (\"def __init__ ( self , roidb , config , batch_size = 1 , shuffle = False , has_rpn = False ) : NEW_LINE INDENT super ( TestLoader , self ) . __init__ ( ) NEW_LINE self . cfg = config NEW_LINE self . roidb = roidb NEW_LINE self . batch_size = batch_size NEW_LINE self . shuffle = shuffle NEW_LINE self . has_rpn = has_rpn NEW_LINE self . size = len ( self . roidb ) NEW_LINE self . index = np . arange ( self . size ) NEW_LINE if has_rpn : NEW_LINE INDENT self . data_name = [ ' data ' , ' im _ info ' ] NEW_LINE DEDENT else : NEW_LINE INDENT self . data_name = [ ' data ' , ' rois ' ] NEW_LINE DEDENT self . label_name = None NEW_LINE self . cur = 0 NEW_LINE self . data = None NEW_LINE self . label = [ ] NEW_LINE self . im_info = None NEW_LINE self . reset ( ) NEW_LINE self . get_batch ( ) NEW_LINE DEDENT\",), ('def provide_data ( self ) : NEW_LINE INDENT return [ [ ( k , v . shape ) for k , v in zip ( self . data_name , idata ) ] for idata in self . data ] NEW_LINE DEDENT',), ('def provide_label ( self ) : NEW_LINE INDENT return [ None for _ in range ( len ( self . data ) ) ] NEW_LINE DEDENT',), ('def provide_data_single ( self ) : NEW_LINE INDENT return [ ( k , v . shape ) for k , v in zip ( self . data_name , self . data [ 0 ] ) ] NEW_LINE DEDENT',), ('def provide_label_single ( self ) : NEW_LINE INDENT return None NEW_LINE DEDENT',), ('def reset ( self ) : NEW_LINE INDENT self . cur = 0 NEW_LINE if self . shuffle : NEW_LINE INDENT np . random . shuffle ( self . index ) NEW_LINE DEDENT DEDENT',), ('def iter_next ( self ) : NEW_LINE INDENT return self . cur < self . size NEW_LINE DEDENT',), ('def next ( self ) : NEW_LINE INDENT if self . iter_next ( ) : NEW_LINE INDENT self . get_batch ( ) NEW_LINE self . cur += self . batch_size NEW_LINE return self . im_info , mx . io . DataBatch ( data = self . data , label = self . label , pad = self . getpad ( ) , index = self . getindex ( ) , provide_data = self . provide_data , provide_label = self . provide_label ) NEW_LINE DEDENT else : NEW_LINE INDENT raise StopIteration NEW_LINE DEDENT DEDENT',), ('def getindex ( self ) : NEW_LINE INDENT return self . cur / self . batch_size NEW_LINE DEDENT',), ('def getpad ( self ) : NEW_LINE INDENT if self . cur + self . batch_size > self . size : NEW_LINE INDENT return self . cur + self . batch_size - self . size NEW_LINE DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT',), ('def get_batch ( self ) : NEW_LINE INDENT cur_from = self . cur NEW_LINE cur_to = min ( cur_from + self . batch_size , self . size ) NEW_LINE roidb = [ self . roidb [ self . index [ i ] ] for i in range ( cur_from , cur_to ) ] NEW_LINE if self . has_rpn : NEW_LINE INDENT data , label , im_info = get_rpn_testbatch ( roidb , self . cfg ) NEW_LINE DEDENT else : NEW_LINE INDENT data , label , im_info = get_rcnn_testbatch ( roidb , self . cfg ) NEW_LINE DEDENT self . data = [ [ mx . nd . array ( idata [ name ] ) for name in self . data_name ] for idata in data ] NEW_LINE self . im_info = im_info NEW_LINE DEDENT',), ('def get_batch_individual ( self ) : NEW_LINE INDENT cur_from = self . cur NEW_LINE cur_to = min ( cur_from + self . batch_size , self . size ) NEW_LINE roidb = [ self . roidb [ self . index [ i ] ] for i in range ( cur_from , cur_to ) ] NEW_LINE if self . has_rpn : NEW_LINE INDENT data , label , im_info = get_rpn_testbatch ( roidb , self . cfg ) NEW_LINE DEDENT else : NEW_LINE INDENT data , label , im_info = get_rcnn_testbatch ( roidb , self . cfg ) NEW_LINE DEDENT self . data = [ mx . nd . array ( data [ name ] ) for name in self . data_name ] NEW_LINE self . im_info = im_info NEW_LINE DEDENT',), (\"def __init__ ( self , feat_sym , roidb , cfg , batch_size = 1 , shuffle = False , ctx = None , work_load_list = None , feat_strides = ( 4 , 8 , 16 , 32 , 64 ) , anchor_scales = ( 8 , ) , anchor_ratios = ( 0.5 , 1 , 2 ) , allowed_border = 0 , aspect_grouping = False ) : NEW_LINE INDENT super ( PyramidAnchorIterator , self ) . __init__ ( ) NEW_LINE self . feat_sym = feat_sym NEW_LINE self . roidb = roidb NEW_LINE self . cfg = cfg NEW_LINE self . batch_size = batch_size NEW_LINE self . shuffle = shuffle NEW_LINE self . ctx = ctx NEW_LINE if self . ctx is None : NEW_LINE INDENT self . ctx = [ mx . cpu ( ) ] NEW_LINE DEDENT self . work_load_list = work_load_list NEW_LINE self . feat_strides = feat_strides NEW_LINE self . anchor_scales = anchor_scales NEW_LINE self . anchor_ratios = anchor_ratios NEW_LINE self . allowed_border = allowed_border NEW_LINE self . aspect_grouping = aspect_grouping NEW_LINE self . size = len ( roidb ) NEW_LINE self . index = np . arange ( self . size ) NEW_LINE if self . cfg . TRAIN . END2END : NEW_LINE INDENT self . data_name = [ ' data ' , ' im _ info ' , ' gt _ boxes ' ] NEW_LINE DEDENT else : NEW_LINE INDENT self . data_name = [ ' data ' ] NEW_LINE DEDENT self . feat_pyramid_level = np . log2 ( self . cfg . network . RPN_FEAT_STRIDE ) . astype ( int ) NEW_LINE self . label_name = [ ' label ' , ' bbox _ target ' , ' bbox _ weight ' ] NEW_LINE self . cur = 0 NEW_LINE self . batch = None NEW_LINE self . data = None NEW_LINE self . label = None NEW_LINE self . reset ( ) NEW_LINE self . get_batch_parallel ( ) NEW_LINE DEDENT\",), ('def provide_data_single ( self ) : NEW_LINE INDENT return [ ( k , v . shape ) for k , v in zip ( self . data_name , self . data [ 0 ] ) ] NEW_LINE DEDENT',), ('def provide_label_single ( self ) : NEW_LINE INDENT return [ ( k , v . shape ) for k , v in zip ( self . label_name , self . label [ 0 ] ) ] NEW_LINE DEDENT',), (\"def reset ( self ) : NEW_LINE INDENT self . cur = 0 NEW_LINE if self . shuffle : NEW_LINE INDENT if self . aspect_grouping : NEW_LINE INDENT widths = np . array ( [ r [ ' width ' ] for r in self . roidb ] ) NEW_LINE heights = np . array ( [ r [ ' height ' ] for r in self . roidb ] ) NEW_LINE horz = ( widths >= heights ) NEW_LINE vert = np . logical_not ( horz ) NEW_LINE horz_inds = np . where ( horz ) [ 0 ] NEW_LINE vert_inds = np . where ( vert ) [ 0 ] NEW_LINE inds = np . hstack ( ( np . random . permutation ( horz_inds ) , np . random . permutation ( vert_inds ) ) ) NEW_LINE extra = inds . shape [ 0 ] % self . batch_size NEW_LINE inds_ = np . reshape ( inds [ : - extra ] , ( - 1 , self . batch_size ) ) NEW_LINE row_perm = np . random . permutation ( np . arange ( inds_ . shape [ 0 ] ) ) NEW_LINE inds [ : - extra ] = np . reshape ( inds_ [ row_perm , : ] , ( - 1 , ) ) NEW_LINE self . index = inds NEW_LINE DEDENT else : NEW_LINE INDENT np . random . shuffle ( self . index ) NEW_LINE DEDENT DEDENT DEDENT\",), ('def iter_next ( self ) : NEW_LINE INDENT return self . cur + self . batch_size <= self . size NEW_LINE DEDENT',), ('def next ( self ) : NEW_LINE INDENT if self . iter_next ( ) : NEW_LINE INDENT self . get_batch_parallel ( ) NEW_LINE self . cur += self . batch_size NEW_LINE return mx . io . DataBatch ( data = self . data , label = self . label , pad = self . getpad ( ) , index = self . getindex ( ) , provide_data = self . provide_data , provide_label = self . provide_label ) NEW_LINE DEDENT else : NEW_LINE INDENT raise StopIteration NEW_LINE DEDENT DEDENT',), ('def getindex ( self ) : NEW_LINE INDENT return self . cur / self . batch_size NEW_LINE DEDENT',), ('def getpad ( self ) : NEW_LINE INDENT if self . cur + self . batch_size > self . size : NEW_LINE INDENT return self . cur + self . batch_size - self . size NEW_LINE DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT',), (\"def infer_shape ( self , max_data_shape = None , max_label_shape = None ) : NEW_LINE INDENT if max_data_shape is None : NEW_LINE INDENT max_data_shape = [ ] NEW_LINE DEDENT if max_label_shape is None : NEW_LINE INDENT max_label_shape = [ ] NEW_LINE DEDENT max_shapes = dict ( max_data_shape + max_label_shape ) NEW_LINE input_batch_size = max_shapes [ ' data ' ] [ 0 ] NEW_LINE im_info = [ [ max_shapes [ ' data ' ] [ 2 ] , max_shapes [ ' data ' ] [ 3 ] , 1.0 ] ] NEW_LINE feat_shape = [ y [ 1 ] for y in [ x . infer_shape ( ** max_shapes ) for x in self . feat_sym ] ] NEW_LINE label = assign_pyramid_anchor ( feat_shape , np . zeros ( ( 0 , 5 ) ) , im_info , self . cfg , self . feat_strides , self . anchor_scales , self . anchor_ratios , self . allowed_border ) NEW_LINE label = [ label [ k ] for k in self . label_name ] NEW_LINE label_shape = [ ( k , tuple ( [ input_batch_size ] + list ( v . shape [ 1 : ] ) ) ) for k , v in zip ( self . label_name , label ) ] NEW_LINE return max_data_shape , label_shape NEW_LINE DEDENT\",), (\"def get_batch_parallel ( self ) : NEW_LINE INDENT cur_from = self . cur NEW_LINE cur_to = min ( cur_from + self . batch_size , self . size ) NEW_LINE roidb = [ self . roidb [ self . index [ i ] ] for i in range ( cur_from , cur_to ) ] NEW_LINE work_load_list = self . work_load_list NEW_LINE ctx = self . ctx NEW_LINE if work_load_list is None : NEW_LINE INDENT work_load_list = [ 1 ] * len ( ctx ) NEW_LINE DEDENT assert isinstance ( work_load_list , list ) and len ( work_load_list ) == len ( ctx ) , slices = _split_input_slice ( self . batch_size , work_load_list ) NEW_LINE rst = [ ] NEW_LINE for idx , islice in enumerate ( slices ) : NEW_LINE INDENT iroidb = [ roidb [ i ] for i in range ( islice . start , islice . stop ) ] NEW_LINE rst . append ( par_assign_anchor_wrapper ( self . cfg , iroidb , self . feat_sym , self . feat_strides , self . anchor_scales , self . anchor_ratios , self . allowed_border ) ) NEW_LINE DEDENT all_data = [ _ [ ' data ' ] for _ in rst ] NEW_LINE all_label = [ _ [ ' label ' ] for _ in rst ] NEW_LINE self . data = [ [ mx . nd . array ( data [ key ] ) for key in self . data_name ] for data in all_data ] NEW_LINE self . label = [ [ mx . nd . array ( label [ key ] ) for key in self . label_name ] for label in all_label ] NEW_LINE DEDENT\",), (\"def __init__ ( self , feat_sym , roidb , cfg , batch_size = 1 , shuffle = False , ctx = None , work_load_list = None , feat_strides = ( 4 , 8 , 16 , 32 , 64 ) , anchor_scales = ( 8 , ) , anchor_ratios = ( 0.5 , 1 , 2 ) , allowed_border = 0 , aspect_grouping = False ) : NEW_LINE INDENT super ( PyramidAnchorIterator_poly , self ) . __init__ ( ) NEW_LINE self . feat_sym = feat_sym NEW_LINE self . roidb = roidb NEW_LINE self . cfg = cfg NEW_LINE self . batch_size = batch_size NEW_LINE self . shuffle = shuffle NEW_LINE self . ctx = ctx NEW_LINE if self . ctx is None : NEW_LINE INDENT self . ctx = [ mx . cpu ( ) ] NEW_LINE DEDENT self . work_load_list = work_load_list NEW_LINE self . feat_strides = feat_strides NEW_LINE self . anchor_scales = anchor_scales NEW_LINE self . anchor_ratios = anchor_ratios NEW_LINE self . allowed_border = allowed_border NEW_LINE self . aspect_grouping = aspect_grouping NEW_LINE self . size = len ( roidb ) NEW_LINE self . index = np . arange ( self . size ) NEW_LINE if self . cfg . TRAIN . END2END : NEW_LINE INDENT self . data_name = [ ' data ' , ' im _ info ' , ' gt _ boxes ' ] NEW_LINE DEDENT else : NEW_LINE INDENT self . data_name = [ ' data ' ] NEW_LINE DEDENT self . feat_pyramid_level = np . log2 ( self . cfg . network . RPN_FEAT_STRIDE ) . astype ( int ) NEW_LINE self . label_name = [ ' label ' , ' bbox _ target ' , ' bbox _ weight ' ] NEW_LINE self . cur = 0 NEW_LINE self . batch = None NEW_LINE self . data = None NEW_LINE self . label = None NEW_LINE self . reset ( ) NEW_LINE self . get_batch_parallel ( ) NEW_LINE DEDENT\",), ('def provide_data_single ( self ) : NEW_LINE INDENT return [ ( k , v . shape ) for k , v in zip ( self . data_name , self . data [ 0 ] ) ] NEW_LINE DEDENT',), ('def provide_label_single ( self ) : NEW_LINE INDENT return [ ( k , v . shape ) for k , v in zip ( self . label_name , self . label [ 0 ] ) ] NEW_LINE DEDENT',), (\"def reset ( self ) : NEW_LINE INDENT self . cur = 0 NEW_LINE if self . shuffle : NEW_LINE INDENT if self . aspect_grouping : NEW_LINE INDENT widths = np . array ( [ r [ ' width ' ] for r in self . roidb ] ) NEW_LINE heights = np . array ( [ r [ ' height ' ] for r in self . roidb ] ) NEW_LINE horz = ( widths >= heights ) NEW_LINE vert = np . logical_not ( horz ) NEW_LINE horz_inds = np . where ( horz ) [ 0 ] NEW_LINE vert_inds = np . where ( vert ) [ 0 ] NEW_LINE inds = np . hstack ( ( np . random . permutation ( horz_inds ) , np . random . permutation ( vert_inds ) ) ) NEW_LINE extra = inds . shape [ 0 ] % self . batch_size NEW_LINE inds_ = np . reshape ( inds [ : - extra ] , ( - 1 , self . batch_size ) ) NEW_LINE row_perm = np . random . permutation ( np . arange ( inds_ . shape [ 0 ] ) ) NEW_LINE inds [ : - extra ] = np . reshape ( inds_ [ row_perm , : ] , ( - 1 , ) ) NEW_LINE self . index = inds NEW_LINE DEDENT else : NEW_LINE INDENT np . random . shuffle ( self . index ) NEW_LINE DEDENT DEDENT DEDENT\",), ('def iter_next ( self ) : NEW_LINE INDENT return self . cur + self . batch_size <= self . size NEW_LINE DEDENT',), ('def next ( self ) : NEW_LINE INDENT if self . iter_next ( ) : NEW_LINE INDENT self . get_batch_parallel ( ) NEW_LINE self . cur += self . batch_size NEW_LINE return mx . io . DataBatch ( data = self . data , label = self . label , pad = self . getpad ( ) , index = self . getindex ( ) , provide_data = self . provide_data , provide_label = self . provide_label ) NEW_LINE DEDENT else : NEW_LINE INDENT raise StopIteration NEW_LINE DEDENT DEDENT',), ('def getindex ( self ) : NEW_LINE INDENT return self . cur / self . batch_size NEW_LINE DEDENT',), ('def getpad ( self ) : NEW_LINE INDENT if self . cur + self . batch_size > self . size : NEW_LINE INDENT return self . cur + self . batch_size - self . size NEW_LINE DEDENT else : NEW_LINE INDENT return 0 NEW_LINE DEDENT DEDENT',), (\"def infer_shape ( self , max_data_shape = None , max_label_shape = None ) : NEW_LINE INDENT if max_data_shape is None : NEW_LINE INDENT max_data_shape = [ ] NEW_LINE DEDENT if max_label_shape is None : NEW_LINE INDENT max_label_shape = [ ] NEW_LINE DEDENT max_shapes = dict ( max_data_shape + max_label_shape ) NEW_LINE input_batch_size = max_shapes [ ' data ' ] [ 0 ] NEW_LINE im_info = [ [ max_shapes [ ' data ' ] [ 2 ] , max_shapes [ ' data ' ] [ 3 ] , 1.0 ] ] NEW_LINE feat_shape = [ y [ 1 ] for y in [ x . infer_shape ( ** max_shapes ) for x in self . feat_sym ] ] NEW_LINE label = assign_pyramid_anchor_poly ( feat_shape , np . zeros ( ( 0 , 9 ) ) , im_info , self . cfg , self . feat_strides , self . anchor_scales , self . anchor_ratios , self . allowed_border ) NEW_LINE label = [ label [ k ] for k in self . label_name ] NEW_LINE label_shape = [ ( k , tuple ( [ input_batch_size ] + list ( v . shape [ 1 : ] ) ) ) for k , v in zip ( self . label_name , label ) ] NEW_LINE return max_data_shape , label_shape NEW_LINE DEDENT\",), (\"def get_batch_parallel ( self ) : NEW_LINE INDENT cur_from = self . cur NEW_LINE cur_to = min ( cur_from + self . batch_size , self . size ) NEW_LINE roidb = [ self . roidb [ self . index [ i ] ] for i in range ( cur_from , cur_to ) ] NEW_LINE work_load_list = self . work_load_list NEW_LINE ctx = self . ctx NEW_LINE if work_load_list is None : NEW_LINE INDENT work_load_list = [ 1 ] * len ( ctx ) NEW_LINE DEDENT assert isinstance ( work_load_list , list ) and len ( work_load_list ) == len ( ctx ) , slices = _split_input_slice ( self . batch_size , work_load_list ) NEW_LINE rst = [ ] NEW_LINE for idx , islice in enumerate ( slices ) : NEW_LINE INDENT iroidb = [ roidb [ i ] for i in range ( islice . start , islice . stop ) ] NEW_LINE rst . append ( par_assign_anchor_wrapper_poly ( self . cfg , iroidb , self . feat_sym , self . feat_strides , self . anchor_scales , self . anchor_ratios , self . allowed_border ) ) NEW_LINE DEDENT all_data = [ _ [ ' data ' ] for _ in rst ] NEW_LINE all_label = [ _ [ ' label ' ] for _ in rst ] NEW_LINE self . data = [ [ mx . nd . array ( data [ key ] ) for key in self . data_name ] for data in all_data ] NEW_LINE self . label = [ [ mx . nd . array ( label [ key ] ) for key in self . label_name ] for label in all_label ] NEW_LINE DEDENT\",), ('def _load_general ( data , targets , major_axis ) : NEW_LINE INDENT for d_src , d_targets in zip ( data , targets ) : NEW_LINE INDENT if isinstance ( d_targets , nd . NDArray ) : NEW_LINE INDENT d_src . copyto ( d_targets ) NEW_LINE DEDENT elif isinstance ( d_src , ( list , tuple ) ) : NEW_LINE INDENT for src , dst in zip ( d_src , d_targets ) : NEW_LINE INDENT src . copyto ( dst ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT raise NotImplementedError NEW_LINE DEDENT DEDENT DEDENT',), ('def _load_data ( batch , targets , major_axis ) : NEW_LINE INDENT _load_general ( batch . data , targets , major_axis ) NEW_LINE DEDENT',), ('def _load_label ( batch , targets , major_axis ) : NEW_LINE INDENT _load_general ( batch . label , targets , major_axis ) NEW_LINE DEDENT',), ('def _merge_multi_context ( outputs , major_axis ) : NEW_LINE INDENT rets = [ ] NEW_LINE for tensors , axis in zip ( outputs , major_axis ) : NEW_LINE INDENT if axis >= 0 : NEW_LINE INDENT rets . append ( nd . concatenate ( tensors , axis = axis , always_copy = False ) ) NEW_LINE DEDENT else : NEW_LINE INDENT rets . append ( tensors [ 0 ] ) NEW_LINE DEDENT DEDENT return rets NEW_LINE DEDENT',), ('def __init__ ( self , symbol , contexts , workload , data_shapes , label_shapes , param_names , for_training , inputs_need_grad , shared_group = None , logger = logging , fixed_param_names = None , grad_req = \\' write \\' , state_names = None ) : NEW_LINE INDENT self . param_names = param_names NEW_LINE self . arg_names = symbol . list_arguments ( ) NEW_LINE self . aux_names = symbol . list_auxiliary_states ( ) NEW_LINE self . symbol = symbol NEW_LINE self . contexts = contexts NEW_LINE self . workload = workload NEW_LINE self . for_training = for_training NEW_LINE self . inputs_need_grad = inputs_need_grad NEW_LINE self . logger = logger NEW_LINE self . fixed_param_names = fixed_param_names NEW_LINE if self . fixed_param_names is None : NEW_LINE INDENT self . fixed_param_names = [ ] NEW_LINE DEDENT self . state_names = state_names NEW_LINE if self . state_names is None : NEW_LINE INDENT self . state_names = [ ] NEW_LINE DEDENT if not for_training : NEW_LINE INDENT grad_req = \\' null \\' NEW_LINE DEDENT data_names = [ x . name for x in data_shapes [ 0 ] ] NEW_LINE if isinstance ( grad_req , str ) : NEW_LINE INDENT self . grad_req = { } NEW_LINE for k in self . arg_names : NEW_LINE INDENT if k in self . param_names : NEW_LINE INDENT self . grad_req [ k ] = \\' null \\' if k in self . fixed_param_names else grad_req NEW_LINE DEDENT elif k in data_names : NEW_LINE INDENT self . grad_req [ k ] = grad_req if self . inputs_need_grad else \\' null \\' NEW_LINE DEDENT else : NEW_LINE INDENT self . grad_req [ k ] = \\' null \\' NEW_LINE DEDENT DEDENT DEDENT elif isinstance ( grad_req , ( list , tuple ) ) : NEW_LINE INDENT assert len ( grad_req ) == len ( self . arg_names ) NEW_LINE self . grad_req = dict ( zip ( self . arg_names , grad_req ) ) NEW_LINE DEDENT elif isinstance ( grad_req , dict ) : NEW_LINE INDENT self . grad_req = { } NEW_LINE for k in self . arg_names : NEW_LINE INDENT if k in self . param_names : NEW_LINE INDENT self . grad_req [ k ] = \\' null \\' if k in self . fixed_param_names else \\' write \\' NEW_LINE DEDENT elif k in data_names : NEW_LINE INDENT self . grad_req [ k ] = \\' write \\' if self . inputs_need_grad else \\' null \\' NEW_LINE DEDENT else : NEW_LINE INDENT self . grad_req [ k ] = \\' null \\' NEW_LINE DEDENT DEDENT self . grad_req . update ( grad_req ) NEW_LINE DEDENT else : NEW_LINE INDENT raise ValueError ( \" grad _ req ▁ must ▁ be ▁ one ▁ of ▁ str , ▁ list , ▁ tuple , ▁ or ▁ dict . \" ) NEW_LINE DEDENT if shared_group is not None : NEW_LINE INDENT self . shared_data_arrays = shared_group . shared_data_arrays NEW_LINE DEDENT else : NEW_LINE INDENT self . shared_data_arrays = [ { } for _ in contexts ] NEW_LINE DEDENT self . batch_size = len ( data_shapes ) NEW_LINE self . slices = None NEW_LINE self . execs = [ ] NEW_LINE self . _default_execs = None NEW_LINE self . data_arrays = None NEW_LINE self . label_arrays = None NEW_LINE self . param_arrays = None NEW_LINE self . state_arrays = None NEW_LINE self . grad_arrays = None NEW_LINE self . aux_arrays = None NEW_LINE self . input_grad_arrays = None NEW_LINE self . data_shapes = None NEW_LINE self . label_shapes = None NEW_LINE self . data_layouts = None NEW_LINE self . label_layouts = None NEW_LINE self . output_layouts = [ DataDesc . get_batch_axis ( self . symbol [ name ] . attr ( \\' _ _ layout _ _ \\' ) ) for name in self . symbol . list_outputs ( ) ] NEW_LINE self . bind_exec ( data_shapes , label_shapes , shared_group ) NEW_LINE DEDENT',), ('def decide_slices ( self , data_shapes ) : NEW_LINE INDENT assert len ( data_shapes ) > 0 NEW_LINE major_axis = [ DataDesc . get_batch_axis ( x . layout ) for x in data_shapes ] NEW_LINE for ( name , shape ) , axis in zip ( data_shapes , major_axis ) : NEW_LINE INDENT if axis == - 1 : NEW_LINE INDENT continue NEW_LINE DEDENT batch_size = shape [ axis ] NEW_LINE if self . batch_size is not None : NEW_LINE INDENT assert batch_size == self . batch_size , ( \" all ▁ data ▁ must ▁ have ▁ the ▁ same ▁ batch ▁ size : ▁ \" + ( \" batch _ size ▁ = ▁ % d , ▁ but ▁ \" % self . batch_size ) + ( \" % s ▁ has ▁ shape ▁ % s \" % ( name , shape ) ) ) NEW_LINE DEDENT else : NEW_LINE INDENT self . batch_size = batch_size NEW_LINE self . slices = _split_input_slice ( self . batch_size , self . workload ) NEW_LINE DEDENT DEDENT return major_axis NEW_LINE DEDENT',), ('def _collect_arrays ( self ) : NEW_LINE INDENT self . data_arrays = [ [ e . arg_dict [ name ] for name , _ in self . data_shapes [ 0 ] ] for e in self . execs ] NEW_LINE self . state_arrays = [ [ e . arg_dict [ name ] for e in self . execs ] for name in self . state_names ] NEW_LINE if self . label_shapes is not None : NEW_LINE INDENT self . label_arrays = [ [ e . arg_dict [ name ] for name , _ in self . label_shapes [ 0 ] ] for e in self . execs ] NEW_LINE DEDENT else : NEW_LINE INDENT self . label_arrays = None NEW_LINE DEDENT self . param_arrays = [ [ exec_ . arg_arrays [ i ] for exec_ in self . execs ] for i , name in enumerate ( self . arg_names ) if name in self . param_names ] NEW_LINE if self . for_training : NEW_LINE INDENT self . grad_arrays = [ [ exec_ . grad_arrays [ i ] for exec_ in self . execs ] for i , name in enumerate ( self . arg_names ) if name in self . param_names ] NEW_LINE DEDENT else : NEW_LINE INDENT self . grad_arrays = None NEW_LINE DEDENT data_names = [ x [ 0 ] for x in self . data_shapes ] NEW_LINE if self . inputs_need_grad : NEW_LINE INDENT self . input_grad_arrays = [ [ exec_ . grad_arrays [ i ] for exec_ in self . execs ] for i , name in enumerate ( self . arg_names ) if name in data_names ] NEW_LINE DEDENT else : NEW_LINE INDENT self . input_grad_arrays = None NEW_LINE DEDENT self . aux_arrays = [ [ exec_ . aux_arrays [ i ] for exec_ in self . execs ] for i in range ( len ( self . aux_names ) ) ] NEW_LINE DEDENT',), ('def bind_exec ( self , data_shapes , label_shapes , shared_group = None , reshape = False ) : NEW_LINE INDENT assert reshape or not self . execs NEW_LINE for i in range ( len ( self . contexts ) ) : NEW_LINE INDENT data_shapes_i = data_shapes [ i ] NEW_LINE if label_shapes is not None : NEW_LINE INDENT label_shapes_i = label_shapes [ i ] NEW_LINE DEDENT else : NEW_LINE INDENT label_shapes_i = [ ] NEW_LINE DEDENT if reshape : NEW_LINE INDENT self . execs [ i ] = self . _default_execs [ i ] . reshape ( allow_up_sizing = True , ** dict ( data_shapes_i + label_shapes_i ) ) NEW_LINE DEDENT else : NEW_LINE INDENT self . execs . append ( self . _bind_ith_exec ( i , data_shapes_i , label_shapes_i , shared_group ) ) NEW_LINE DEDENT DEDENT self . data_shapes = data_shapes NEW_LINE self . label_shapes = label_shapes NEW_LINE self . _collect_arrays ( ) NEW_LINE DEDENT',), ('def reshape ( self , data_shapes , label_shapes ) : NEW_LINE INDENT if self . _default_execs is None : NEW_LINE INDENT self . _default_execs = [ i for i in self . execs ] NEW_LINE DEDENT for i in range ( len ( self . contexts ) ) : NEW_LINE INDENT self . execs [ i ] = self . _default_execs [ i ] . reshape ( allow_up_sizing = True , ** dict ( data_shapes [ i ] + ( label_shapes [ i ] if label_shapes is not None else [ ] ) ) ) NEW_LINE DEDENT self . data_shapes = data_shapes NEW_LINE self . label_shapes = label_shapes NEW_LINE self . _collect_arrays ( ) NEW_LINE DEDENT',), ('def set_params ( self , arg_params , aux_params ) : NEW_LINE INDENT for exec_ in self . execs : NEW_LINE INDENT exec_ . copy_params_from ( arg_params , aux_params ) NEW_LINE DEDENT DEDENT',), ('def get_params ( self , arg_params , aux_params ) : NEW_LINE INDENT for name , block in zip ( self . param_names , self . param_arrays ) : NEW_LINE INDENT weight = sum ( w . copyto ( ctx . cpu ( ) ) for w in block ) / len ( block ) NEW_LINE weight . astype ( arg_params [ name ] . dtype ) . copyto ( arg_params [ name ] ) NEW_LINE DEDENT for name , block in zip ( self . aux_names , self . aux_arrays ) : NEW_LINE INDENT weight = sum ( w . copyto ( ctx . cpu ( ) ) for w in block ) / len ( block ) NEW_LINE weight . astype ( aux_params [ name ] . dtype ) . copyto ( aux_params [ name ] ) NEW_LINE DEDENT DEDENT',), ('def forward ( self , data_batch , is_train = None ) : NEW_LINE INDENT _load_data ( data_batch , self . data_arrays , self . data_layouts ) NEW_LINE if is_train is None : NEW_LINE INDENT is_train = self . for_training NEW_LINE DEDENT if self . label_arrays is not None : NEW_LINE INDENT assert not is_train or data_batch . label NEW_LINE if data_batch . label : NEW_LINE INDENT _load_label ( data_batch , self . label_arrays , self . label_layouts ) NEW_LINE DEDENT DEDENT for exec_ in self . execs : NEW_LINE INDENT exec_ . forward ( is_train = is_train ) NEW_LINE DEDENT DEDENT',), ('def get_outputs ( self , merge_multi_context = True ) : NEW_LINE INDENT outputs = [ [ exec_ . outputs [ i ] for exec_ in self . execs ] for i in range ( len ( self . execs [ 0 ] . outputs ) ) ] NEW_LINE if merge_multi_context : NEW_LINE INDENT outputs = _merge_multi_context ( outputs , self . output_layouts ) NEW_LINE DEDENT return outputs NEW_LINE DEDENT',), ('def get_states ( self , merge_multi_context = True ) : NEW_LINE INDENT assert not merge_multi_context , return self . state_arrays NEW_LINE DEDENT',), ('def set_states ( self , states = None , value = None ) : NEW_LINE INDENT if states is not None : NEW_LINE INDENT assert value is None , \" Only ▁ one ▁ of ▁ states ▁ & ▁ value ▁ can ▁ be ▁ specified . \" NEW_LINE _load_general ( states , self . state_arrays , ( 0 , ) * len ( states ) ) NEW_LINE DEDENT else : NEW_LINE INDENT assert value is not None , \" At ▁ least ▁ one ▁ of ▁ states ▁ & ▁ value ▁ must ▁ be ▁ specified . \" NEW_LINE assert states is None , \" Only ▁ one ▁ of ▁ states ▁ & ▁ value ▁ can ▁ be ▁ specified . \" NEW_LINE for d_dst in self . state_arrays : NEW_LINE INDENT for dst in d_dst : NEW_LINE INDENT dst [ : ] = value NEW_LINE DEDENT DEDENT DEDENT DEDENT',), ('def get_input_grads ( self , merge_multi_context = True ) : NEW_LINE INDENT assert self . inputs_need_grad NEW_LINE if merge_multi_context : NEW_LINE INDENT return _merge_multi_context ( self . input_grad_arrays , self . data_layouts ) NEW_LINE DEDENT return self . input_grad_arrays NEW_LINE DEDENT',), (\"def backward ( self , out_grads = None ) : NEW_LINE INDENT assert self . for_training , ' re - bind ▁ with ▁ for _ training = True ▁ to ▁ run ▁ backward ' NEW_LINE if out_grads is None : NEW_LINE INDENT out_grads = [ ] NEW_LINE DEDENT for i , exec_ in enumerate ( self . execs ) : NEW_LINE INDENT out_grads_slice = [ ] NEW_LINE exec_ . backward ( out_grads = out_grads_slice ) NEW_LINE DEDENT DEDENT\",), ('def update_metric ( self , eval_metric , labels ) : NEW_LINE INDENT for texec , labels in zip ( self . execs , labels ) : NEW_LINE INDENT eval_metric . update ( labels , texec . outputs ) NEW_LINE DEDENT DEDENT',), ('def _bind_ith_exec ( self , i , data_shapes , label_shapes , shared_group ) : NEW_LINE INDENT shared_exec = None if shared_group is None else shared_group . execs [ i ] NEW_LINE context = self . contexts [ i ] NEW_LINE shared_data_arrays = self . shared_data_arrays [ i ] NEW_LINE input_shapes = dict ( data_shapes ) NEW_LINE if label_shapes is not None : NEW_LINE INDENT input_shapes . update ( dict ( label_shapes ) ) NEW_LINE DEDENT arg_shapes , _ , aux_shapes = self . symbol . infer_shape ( ** input_shapes ) NEW_LINE assert arg_shapes is not None , \" shape ▁ inference ▁ failed \" NEW_LINE input_types = { x . name : x . dtype for x in data_shapes } NEW_LINE if label_shapes is not None : NEW_LINE INDENT input_types . update ( { x . name : x . dtype for x in label_shapes } ) NEW_LINE DEDENT arg_types , _ , aux_types = self . symbol . infer_type ( ** input_types ) NEW_LINE assert arg_types is not None , \" type ▁ inference ▁ failed \" NEW_LINE arg_arrays = [ ] NEW_LINE grad_arrays = { } if self . for_training else None NEW_LINE def _get_or_reshape ( name , shared_data_arrays , arg_shape , arg_type , context , logger ) : NEW_LINE INDENT if name in shared_data_arrays : NEW_LINE INDENT arg_arr = shared_data_arrays [ name ] NEW_LINE if np . prod ( arg_arr . shape ) >= np . prod ( arg_shape ) : NEW_LINE INDENT assert arg_arr . dtype == arg_type NEW_LINE arg_arr = arg_arr . reshape ( arg_shape ) NEW_LINE DEDENT else : NEW_LINE INDENT logger . warning ( ( \\' bucketing : ▁ data ▁ \" % s \" ▁ has ▁ a ▁ shape ▁ % s \\' % ( name , arg_shape ) ) + ( \\' , ▁ which ▁ is ▁ larger ▁ than ▁ already ▁ allocated ▁ \\' ) + ( \\' shape ▁ % s \\' % ( arg_arr . shape , ) ) + ( \\' . ▁ Need ▁ to ▁ re - allocate . ▁ Consider ▁ putting ▁ \\' ) + ( \\' default _ bucket _ key ▁ to \\' ) + ( \\' ▁ be ▁ the ▁ bucket ▁ taking ▁ the ▁ largest ▁ input ▁ for ▁ better ▁ \\' ) + ( \\' memory ▁ sharing . \\' ) ) NEW_LINE arg_arr = nd . zeros ( arg_shape , context , dtype = arg_type ) NEW_LINE shared_data_arrays [ name ] = arg_arr NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT arg_arr = nd . zeros ( arg_shape , context , dtype = arg_type ) NEW_LINE shared_data_arrays [ name ] = arg_arr NEW_LINE DEDENT return arg_arr NEW_LINE DEDENT for j in range ( len ( self . arg_names ) ) : NEW_LINE INDENT name = self . arg_names [ j ] NEW_LINE if name in self . param_names : NEW_LINE INDENT if shared_exec is None : NEW_LINE INDENT arg_arr = nd . zeros ( arg_shapes [ j ] , context , dtype = arg_types [ j ] ) NEW_LINE if self . grad_req [ name ] != \\' null \\' : NEW_LINE INDENT grad_arr = nd . zeros ( arg_shapes [ j ] , context , dtype = arg_types [ j ] ) NEW_LINE grad_arrays [ name ] = grad_arr NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT arg_arr = shared_exec . arg_dict [ name ] NEW_LINE assert arg_arr . shape == arg_shapes [ j ] NEW_LINE assert arg_arr . dtype == arg_types [ j ] NEW_LINE if self . grad_req [ name ] != \\' null \\' : NEW_LINE INDENT grad_arrays [ name ] = shared_exec . grad_dict [ name ] NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT arg_arr = _get_or_reshape ( name , shared_data_arrays , arg_shapes [ j ] , arg_types [ j ] , context , self . logger ) NEW_LINE if self . grad_req [ name ] != \\' null \\' : NEW_LINE INDENT grad_arrays [ name ] = _get_or_reshape ( \\' grad ▁ of ▁ \\' + name , shared_data_arrays , arg_shapes [ j ] , arg_types [ j ] , context , self . logger ) NEW_LINE DEDENT DEDENT arg_arrays . append ( arg_arr ) NEW_LINE DEDENT if shared_exec is None : NEW_LINE INDENT aux_arrays = [ nd . zeros ( s , context , dtype = t ) for s , t in zip ( aux_shapes , aux_types ) ] NEW_LINE DEDENT else : NEW_LINE INDENT for j , arr in enumerate ( shared_exec . aux_arrays ) : NEW_LINE INDENT assert aux_shapes [ j ] == arr . shape NEW_LINE assert aux_types [ j ] == arr . dtype NEW_LINE DEDENT aux_arrays = shared_exec . aux_arrays [ : ] NEW_LINE DEDENT executor = self . symbol . bind ( ctx = context , args = arg_arrays , args_grad = grad_arrays , aux_states = aux_arrays , grad_req = self . grad_req , shared_exec = shared_exec ) NEW_LINE return executor NEW_LINE DEDENT',), ('def _sliced_shape ( self , shapes , i , major_axis ) : NEW_LINE INDENT sliced_shapes = [ ] NEW_LINE for desc , axis in zip ( shapes , major_axis ) : NEW_LINE INDENT shape = list ( desc . shape ) NEW_LINE if axis >= 0 : NEW_LINE INDENT shape [ axis ] = self . slices [ i ] . stop - self . slices [ i ] . start NEW_LINE DEDENT sliced_shapes . append ( DataDesc ( desc . name , tuple ( shape ) , desc . dtype , desc . layout ) ) NEW_LINE DEDENT return sliced_shapes NEW_LINE DEDENT',), ('def install_monitor ( self , mon ) : NEW_LINE INDENT for exe in self . execs : NEW_LINE INDENT mon . install ( exe ) NEW_LINE DEDENT DEDENT',), (\"def get_rpn_names ( ) : NEW_LINE INDENT pred = [ ' rpn _ cls _ prob ' , ' rpn _ bbox _ loss ' ] NEW_LINE label = [ ' rpn _ label ' , ' rpn _ bbox _ target ' , ' rpn _ bbox _ weight ' ] NEW_LINE return pred , label NEW_LINE DEDENT\",), (\"def get_rcnn_names ( cfg ) : NEW_LINE INDENT pred = [ ' rcnn _ cls _ prob ' , ' rcnn _ bbox _ loss ' ] NEW_LINE label = [ ' rcnn _ label ' , ' rcnn _ bbox _ target ' , ' rcnn _ bbox _ weight ' ] NEW_LINE if cfg . TRAIN . ENABLE_OHEM or cfg . TRAIN . END2END : NEW_LINE INDENT pred . append ( ' rcnn _ label ' ) NEW_LINE DEDENT if cfg . TRAIN . END2END : NEW_LINE INDENT rpn_pred , rpn_label = get_rpn_names ( ) NEW_LINE pred = rpn_pred + pred NEW_LINE label = rpn_label NEW_LINE DEDENT return pred , label NEW_LINE DEDENT\",), (\"def get_Rroi_names ( cfg ) : NEW_LINE INDENT pred , label = get_rcnn_names ( cfg ) NEW_LINE pred . append ( ' Rroi _ rcnn _ cls _ prob ' ) NEW_LINE pred . append ( ' Rroi _ rcnn _ bbox _ loss ' ) NEW_LINE if cfg . TRAIN . ENABLE_OHEM or cfg . TRAIN . END2END : NEW_LINE INDENT pred . append ( ' Rroi _ rcnn _ label ' ) NEW_LINE DEDENT return pred , label NEW_LINE DEDENT\",), (\"def __init__ ( self ) : NEW_LINE INDENT super ( RPNAccMetric , self ) . __init__ ( ' RPNAcc ' ) NEW_LINE self . pred , self . label = get_rpn_names ( ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT pred = preds [ self . pred . index ( ' rpn _ cls _ prob ' ) ] NEW_LINE label = labels [ self . label . index ( ' rpn _ label ' ) ] NEW_LINE pred_label = mx . ndarray . argmax_channel ( pred ) . asnumpy ( ) . astype ( ' int32' ) NEW_LINE pred_label = pred_label . reshape ( ( pred_label . shape [ 0 ] , - 1 ) ) NEW_LINE label = label . asnumpy ( ) . astype ( ' int32' ) NEW_LINE keep_inds = np . where ( label != - 1 ) NEW_LINE pred_label = pred_label [ keep_inds ] NEW_LINE label = label [ keep_inds ] NEW_LINE self . sum_metric += np . sum ( pred_label . flat == label . flat ) NEW_LINE self . num_inst += len ( pred_label . flat ) NEW_LINE DEDENT\",), (\"def __init__ ( self ) : NEW_LINE INDENT super ( RPNLogLossMetric , self ) . __init__ ( ' RPNLogLoss ' ) NEW_LINE self . pred , self . label = get_rpn_names ( ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT pred = preds [ self . pred . index ( ' rpn _ cls _ prob ' ) ] NEW_LINE label = labels [ self . label . index ( ' rpn _ label ' ) ] NEW_LINE label = label . asnumpy ( ) . astype ( ' int32' ) . reshape ( ( - 1 ) ) NEW_LINE pred = pred . asnumpy ( ) . reshape ( ( pred . shape [ 0 ] , pred . shape [ 1 ] , - 1 ) ) . transpose ( ( 0 , 2 , 1 ) ) NEW_LINE pred = pred . reshape ( ( label . shape [ 0 ] , - 1 ) ) NEW_LINE keep_inds = np . where ( label != - 1 ) [ 0 ] NEW_LINE label = label [ keep_inds ] NEW_LINE cls = pred [ keep_inds , label ] NEW_LINE cls += 1e-14 NEW_LINE cls_loss = - 1 * np . log ( cls ) NEW_LINE cls_loss = np . sum ( cls_loss ) NEW_LINE self . sum_metric += cls_loss NEW_LINE self . num_inst += label . shape [ 0 ] NEW_LINE DEDENT\",), (\"def __init__ ( self ) : NEW_LINE INDENT super ( RPNL1LossMetric , self ) . __init__ ( ' RPNL1Loss ' ) NEW_LINE self . pred , self . label = get_rpn_names ( ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT bbox_loss = preds [ self . pred . index ( ' rpn _ bbox _ loss ' ) ] . asnumpy ( ) NEW_LINE label = labels [ self . label . index ( ' rpn _ label ' ) ] . asnumpy ( ) NEW_LINE num_inst = np . sum ( label != - 1 ) NEW_LINE self . sum_metric += np . sum ( bbox_loss ) NEW_LINE self . num_inst += num_inst NEW_LINE DEDENT\",), (\"def __init__ ( self , cfg ) : NEW_LINE INDENT super ( RPNFGFraction , self ) . __init__ ( ' Proposal ▁ FG ▁ Fraction ' ) NEW_LINE self . e2e = cfg . TRAIN . END2END NEW_LINE self . ohem = cfg . TRAIN . ENABLE_OHEM NEW_LINE self . pred , self . label = get_rcnn_names ( cfg ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT pred = preds [ self . pred . index ( ' rcnn _ cls _ prob ' ) ] NEW_LINE if self . ohem or self . e2e : NEW_LINE INDENT label = preds [ self . pred . index ( ' rcnn _ label ' ) ] NEW_LINE DEDENT else : NEW_LINE INDENT label = labels [ self . label . index ( ' rcnn _ label ' ) ] NEW_LINE DEDENT num_classes = pred . shape [ - 1 ] NEW_LINE label = label . asnumpy ( ) . reshape ( - 1 , ) . astype ( ' int32' ) NEW_LINE fg_inds = np . where ( label > 0 ) [ 0 ] NEW_LINE bg_inds = np . where ( label == 0 ) [ 0 ] NEW_LINE self . sum_metric += fg_inds . shape [ 0 ] NEW_LINE self . num_inst += ( fg_inds . shape [ 0 ] + bg_inds . shape [ 0 ] ) NEW_LINE DEDENT\",), (\"def __init__ ( self , cfg ) : NEW_LINE INDENT super ( RCNNFGAccuracy , self ) . __init__ ( ' R - CNN ▁ FG ▁ Accuracy ' ) NEW_LINE self . e2e = cfg . TRAIN . END2END NEW_LINE self . ohem = cfg . TRAIN . ENABLE_OHEM NEW_LINE self . pred , self . label = get_rcnn_names ( cfg ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT pred = preds [ self . pred . index ( ' rcnn _ cls _ prob ' ) ] NEW_LINE if self . ohem or self . e2e : NEW_LINE INDENT label = preds [ self . pred . index ( ' rcnn _ label ' ) ] NEW_LINE DEDENT else : NEW_LINE INDENT label = labels [ self . label . index ( ' rcnn _ label ' ) ] NEW_LINE DEDENT num_classes = pred . shape [ - 1 ] NEW_LINE pred_label = pred . asnumpy ( ) . reshape ( - 1 , num_classes ) . argmax ( axis = 1 ) . astype ( ' int32' ) NEW_LINE label = label . asnumpy ( ) . reshape ( - 1 , ) . astype ( ' int32' ) NEW_LINE keep_inds = np . where ( label > 0 ) NEW_LINE pred_label = pred_label [ keep_inds ] NEW_LINE label = label [ keep_inds ] NEW_LINE self . sum_metric += np . sum ( np . equal ( pred_label . flat , label . flat ) ) NEW_LINE self . num_inst += pred_label . shape [ 0 ] NEW_LINE DEDENT\",), (\"def __init__ ( self , cfg ) : NEW_LINE INDENT super ( RCNNAccMetric , self ) . __init__ ( ' RCNNAcc ' ) NEW_LINE self . e2e = cfg . TRAIN . END2END NEW_LINE self . ohem = cfg . TRAIN . ENABLE_OHEM NEW_LINE self . pred , self . label = get_rcnn_names ( cfg ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT pred = preds [ self . pred . index ( ' rcnn _ cls _ prob ' ) ] NEW_LINE if self . ohem or self . e2e : NEW_LINE INDENT label = preds [ self . pred . index ( ' rcnn _ label ' ) ] NEW_LINE DEDENT else : NEW_LINE INDENT label = labels [ self . label . index ( ' rcnn _ label ' ) ] NEW_LINE DEDENT last_dim = pred . shape [ - 1 ] NEW_LINE pred_label = pred . asnumpy ( ) . reshape ( - 1 , last_dim ) . argmax ( axis = 1 ) . astype ( ' int32' ) NEW_LINE label = label . asnumpy ( ) . reshape ( - 1 , ) . astype ( ' int32' ) NEW_LINE keep_inds = np . where ( label != - 1 ) NEW_LINE pred_label = pred_label [ keep_inds ] NEW_LINE label = label [ keep_inds ] NEW_LINE self . sum_metric += np . sum ( pred_label . flat == label . flat ) NEW_LINE self . num_inst += len ( pred_label . flat ) NEW_LINE DEDENT\",), (\"def __init__ ( self , cfg ) : NEW_LINE INDENT super ( RCNNLogLossMetric , self ) . __init__ ( ' RCNNLogLoss ' ) NEW_LINE self . e2e = cfg . TRAIN . END2END NEW_LINE self . ohem = cfg . TRAIN . ENABLE_OHEM NEW_LINE self . pred , self . label = get_rcnn_names ( cfg ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT pred = preds [ self . pred . index ( ' rcnn _ cls _ prob ' ) ] NEW_LINE if self . ohem or self . e2e : NEW_LINE INDENT label = preds [ self . pred . index ( ' rcnn _ label ' ) ] NEW_LINE DEDENT else : NEW_LINE INDENT label = labels [ self . label . index ( ' rcnn _ label ' ) ] NEW_LINE DEDENT last_dim = pred . shape [ - 1 ] NEW_LINE pred = pred . asnumpy ( ) . reshape ( - 1 , last_dim ) NEW_LINE label = label . asnumpy ( ) . reshape ( - 1 , ) . astype ( ' int32' ) NEW_LINE keep_inds = np . where ( label != - 1 ) [ 0 ] NEW_LINE label = label [ keep_inds ] NEW_LINE cls = pred [ keep_inds , label ] NEW_LINE cls += 1e-14 NEW_LINE cls_loss = - 1 * np . log ( cls ) NEW_LINE cls_loss = np . sum ( cls_loss ) NEW_LINE self . sum_metric += cls_loss NEW_LINE self . num_inst += label . shape [ 0 ] NEW_LINE DEDENT\",), (\"def __init__ ( self , cfg ) : NEW_LINE INDENT super ( RCNNL1LossMetric , self ) . __init__ ( ' RCNNL1Loss ' ) NEW_LINE self . e2e = cfg . TRAIN . END2END NEW_LINE self . ohem = cfg . TRAIN . ENABLE_OHEM NEW_LINE self . pred , self . label = get_rcnn_names ( cfg ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT bbox_loss = preds [ self . pred . index ( ' rcnn _ bbox _ loss ' ) ] . asnumpy ( ) NEW_LINE if self . ohem : NEW_LINE INDENT label = preds [ self . pred . index ( ' rcnn _ label ' ) ] . asnumpy ( ) NEW_LINE DEDENT else : NEW_LINE INDENT if self . e2e : NEW_LINE INDENT label = preds [ self . pred . index ( ' rcnn _ label ' ) ] . asnumpy ( ) NEW_LINE DEDENT else : NEW_LINE INDENT label = labels [ self . label . index ( ' rcnn _ label ' ) ] . asnumpy ( ) NEW_LINE DEDENT DEDENT num_inst = np . sum ( label != - 1 ) NEW_LINE self . sum_metric += np . sum ( bbox_loss ) NEW_LINE self . num_inst += num_inst NEW_LINE DEDENT\",), (\"def __init__ ( self , cfg ) : NEW_LINE INDENT super ( RCNNFGFraction , self ) . __init__ ( ' RRoI ▁ Proposal ▁ FG ▁ Fraction ' ) NEW_LINE self . e2e = cfg . TRAIN . END2END NEW_LINE self . ohem = cfg . TRAIN . ENABLE_OHEM NEW_LINE self . pred , self . label = get_Rroi_names ( cfg ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT pred = preds [ self . pred . index ( ' Rroi _ rcnn _ cls _ prob ' ) ] NEW_LINE if self . ohem or self . e2e : NEW_LINE INDENT label = preds [ self . pred . index ( ' Rroi _ rcnn _ label ' ) ] NEW_LINE DEDENT else : NEW_LINE INDENT label = labels [ self . label . index ( ' Rroi _ rcnn _ label ' ) ] NEW_LINE DEDENT num_classes = pred . shape [ - 1 ] NEW_LINE label = label . asnumpy ( ) . reshape ( - 1 , ) . astype ( ' int32' ) NEW_LINE fg_inds = np . where ( label > 0 ) [ 0 ] NEW_LINE bg_inds = np . where ( label == 0 ) [ 0 ] NEW_LINE self . sum_metric += fg_inds . shape [ 0 ] NEW_LINE self . num_inst += ( fg_inds . shape [ 0 ] + bg_inds . shape [ 0 ] ) NEW_LINE DEDENT\",), (\"def __init__ ( self , cfg ) : NEW_LINE INDENT super ( RRoIRCNNFGAccuracy , self ) . __init__ ( ' RRoIR - CNN ▁ FG ▁ Accuracy ' ) NEW_LINE self . e2e = cfg . TRAIN . END2END NEW_LINE self . ohem = cfg . TRAIN . ENABLE_OHEM NEW_LINE self . pred , self . label = get_Rroi_names ( cfg ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT pred = preds [ self . pred . index ( ' Rroi _ rcnn _ cls _ prob ' ) ] NEW_LINE if self . ohem or self . e2e : NEW_LINE INDENT label = preds [ self . pred . index ( ' Rroi _ rcnn _ label ' ) ] NEW_LINE DEDENT else : NEW_LINE INDENT label = labels [ self . label . index ( ' Rroi _ rcnn _ label ' ) ] NEW_LINE DEDENT num_classes = pred . shape [ - 1 ] NEW_LINE pred_label = pred . asnumpy ( ) . reshape ( - 1 , num_classes ) . argmax ( axis = 1 ) . astype ( ' int32' ) NEW_LINE label = label . asnumpy ( ) . reshape ( - 1 , ) . astype ( ' int32' ) NEW_LINE keep_inds = np . where ( label > 0 ) NEW_LINE pred_label = pred_label [ keep_inds ] NEW_LINE label = label [ keep_inds ] NEW_LINE self . sum_metric += np . sum ( np . equal ( pred_label . flat , label . flat ) ) NEW_LINE self . num_inst += pred_label . shape [ 0 ] NEW_LINE DEDENT\",), (\"def __init__ ( self , cfg ) : NEW_LINE INDENT super ( RRoIAccMetric , self ) . __init__ ( ' RRoIAcc ' ) NEW_LINE self . e2e = cfg . TRAIN . END2END NEW_LINE self . ohem = cfg . TRAIN . ENABLE_OHEM NEW_LINE self . pred , self . label = get_Rroi_names ( cfg ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT pred = preds [ self . pred . index ( ' Rroi _ rcnn _ cls _ prob ' ) ] NEW_LINE if self . ohem or self . e2e : NEW_LINE INDENT label = preds [ self . pred . index ( ' Rroi _ rcnn _ label ' ) ] NEW_LINE DEDENT else : NEW_LINE INDENT label = labels [ self . label . index ( ' Rroi _ rcnn _ label ' ) ] NEW_LINE DEDENT last_dim = pred . shape [ - 1 ] NEW_LINE pred_label = pred . asnumpy ( ) . reshape ( - 1 , last_dim ) . argmax ( axis = 1 ) . astype ( ' int32' ) NEW_LINE label = label . asnumpy ( ) . reshape ( - 1 , ) . astype ( ' int32' ) NEW_LINE keep_inds = np . where ( label != - 1 ) NEW_LINE pred_label = pred_label [ keep_inds ] NEW_LINE label = label [ keep_inds ] NEW_LINE self . sum_metric += np . sum ( pred_label . flat == label . flat ) NEW_LINE self . num_inst += len ( pred_label . flat ) NEW_LINE DEDENT\",), (\"def __init__ ( self , cfg ) : NEW_LINE INDENT super ( RRoIRCNNLogLossMetric , self ) . __init__ ( ' RRoIRCNNLogLoss ' ) NEW_LINE self . e2e = cfg . TRAIN . END2END NEW_LINE self . ohem = cfg . TRAIN . ENABLE_OHEM NEW_LINE self . pred , self . label = get_Rroi_names ( cfg ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT pred = preds [ self . pred . index ( ' Rroi _ rcnn _ cls _ prob ' ) ] NEW_LINE if self . ohem or self . e2e : NEW_LINE INDENT label = preds [ self . pred . index ( ' Rroi _ rcnn _ label ' ) ] NEW_LINE DEDENT else : NEW_LINE INDENT label = labels [ self . label . index ( ' Rroi _ rcnn _ label ' ) ] NEW_LINE DEDENT last_dim = pred . shape [ - 1 ] NEW_LINE pred = pred . asnumpy ( ) . reshape ( - 1 , last_dim ) NEW_LINE label = label . asnumpy ( ) . reshape ( - 1 , ) . astype ( ' int32' ) NEW_LINE keep_inds = np . where ( label != - 1 ) [ 0 ] NEW_LINE label = label [ keep_inds ] NEW_LINE cls = pred [ keep_inds , label ] NEW_LINE cls += 1e-14 NEW_LINE cls_loss = - 1 * np . log ( cls ) NEW_LINE cls_loss = np . sum ( cls_loss ) NEW_LINE self . sum_metric += cls_loss NEW_LINE self . num_inst += label . shape [ 0 ] NEW_LINE DEDENT\",), (\"def __init__ ( self , cfg ) : NEW_LINE INDENT super ( RRoIRCNNL1LossMetric , self ) . __init__ ( ' RRoIRCNNL1Loss ' ) NEW_LINE self . e2e = cfg . TRAIN . END2END NEW_LINE self . ohem = cfg . TRAIN . ENABLE_OHEM NEW_LINE self . pred , self . label = get_Rroi_names ( cfg ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT bbox_loss = preds [ self . pred . index ( ' Rroi _ rcnn _ bbox _ loss ' ) ] . asnumpy ( ) NEW_LINE if self . ohem : NEW_LINE INDENT label = preds [ self . pred . index ( ' Rroi _ rcnn _ label ' ) ] . asnumpy ( ) NEW_LINE DEDENT else : NEW_LINE INDENT if self . e2e : NEW_LINE INDENT label = preds [ self . pred . index ( ' Rroi _ rcnn _ label ' ) ] . asnumpy ( ) NEW_LINE DEDENT else : NEW_LINE INDENT label = labels [ self . label . index ( ' Rroi _ rcnn _ label ' ) ] . asnumpy ( ) NEW_LINE DEDENT DEDENT num_inst = np . sum ( label != - 1 ) NEW_LINE self . sum_metric += np . sum ( bbox_loss ) NEW_LINE self . num_inst += num_inst NEW_LINE DEDENT\",), (\"def __init__ ( self , cfg ) : NEW_LINE INDENT super ( STLogLossMetric , self ) . __init__ ( ' STLogLoss ' ) NEW_LINE self . e2e = cfg . TRAIN . END2END NEW_LINE self . ohem = cfg . TRAIN . ENABLE_OHEM NEW_LINE self . pred , self . label = get_rcnn_names ( cfg ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT pred = preds [ - 1 ] NEW_LINE label = preds [ - 2 ] NEW_LINE last_dim = pred . shape [ - 1 ] NEW_LINE pred = pred . asnumpy ( ) . reshape ( - 1 , last_dim ) NEW_LINE label = label . asnumpy ( ) . reshape ( - 1 , ) . astype ( ' int32' ) NEW_LINE keep_inds = np . where ( label != - 1 ) [ 0 ] NEW_LINE label = label [ keep_inds ] NEW_LINE cls = pred [ keep_inds , label ] NEW_LINE cls += 1e-14 NEW_LINE cls_loss = - 1 * np . log ( cls ) NEW_LINE cls_loss = np . sum ( cls_loss ) NEW_LINE self . sum_metric += cls_loss NEW_LINE self . num_inst += label . shape [ 0 ] NEW_LINE DEDENT\",), (\"def __init__ ( self , cfg ) : NEW_LINE INDENT super ( STL1LossMetric , self ) . __init__ ( ' STL1Loss ' ) NEW_LINE self . e2e = cfg . TRAIN . END2END NEW_LINE self . ohem = cfg . TRAIN . ENABLE_OHEM NEW_LINE self . pred , self . label = get_rcnn_names ( cfg ) NEW_LINE self . pred . append ( ' st _ loss ' ) NEW_LINE DEDENT\",), (\"def update ( self , labels , preds ) : NEW_LINE INDENT st_loss = preds [ self . pred . index ( ' st _ loss ' ) ] . asnumpy ( ) NEW_LINE label = preds [ - 2 ] . asnumpy ( ) NEW_LINE num_inst = np . sum ( label != 0 ) NEW_LINE self . sum_metric += np . sum ( st_loss ) NEW_LINE self . num_inst += num_inst NEW_LINE DEDENT\",), (\"def im_detect ( predictor , data_batch , data_names , scales , cfg ) : NEW_LINE INDENT output_all = predictor . predict ( data_batch ) NEW_LINE data_dict_all = [ dict ( zip ( data_names , idata ) ) for idata in data_batch . data ] NEW_LINE scores_all = [ ] NEW_LINE pred_boxes_all = [ ] NEW_LINE for output , data_dict , scale in zip ( output_all , data_dict_all , scales ) : NEW_LINE INDENT if cfg . TEST . HAS_RPN : NEW_LINE INDENT rois = output [ ' rois _ output ' ] . asnumpy ( ) [ : , 1 : ] NEW_LINE DEDENT else : NEW_LINE INDENT rois = data_dict [ ' rois ' ] . asnumpy ( ) . reshape ( ( - 1 , 5 ) ) [ : , 1 : ] NEW_LINE DEDENT im_shape = data_dict [ ' data ' ] . shape NEW_LINE scores = output [ ' cls _ prob _ reshape _ output ' ] . asnumpy ( ) [ 0 ] NEW_LINE bbox_deltas = output [ ' bbox _ pred _ reshape _ output ' ] . asnumpy ( ) [ 0 ] NEW_LINE pred_boxes = bbox_pred ( rois , bbox_deltas ) NEW_LINE pred_boxes = clip_boxes ( pred_boxes , im_shape [ - 2 : ] ) NEW_LINE pred_boxes = pred_boxes / scale NEW_LINE scores_all . append ( scores ) NEW_LINE pred_boxes_all . append ( pred_boxes ) NEW_LINE DEDENT return scores_all , pred_boxes_all , data_dict_all NEW_LINE DEDENT\",), (\"def im_detect_poly ( predictor , data_batch , data_names , scales , cfg ) : NEW_LINE INDENT output_all = predictor . predict ( data_batch ) NEW_LINE data_dict_all = [ dict ( zip ( data_names , idata ) ) for idata in data_batch . data ] NEW_LINE scores_all = [ ] NEW_LINE pred_boxes_all = [ ] NEW_LINE for output , data_dict , scale in zip ( output_all , data_dict_all , scales ) : NEW_LINE INDENT if cfg . TEST . HAS_RPN : NEW_LINE INDENT rois = output [ ' rois _ output ' ] . asnumpy ( ) [ : , 1 : ] NEW_LINE DEDENT else : NEW_LINE INDENT rois = data_dict [ ' rois ' ] . asnumpy ( ) . reshape ( ( - 1 , 5 ) ) [ : , 1 : ] NEW_LINE DEDENT im_shape = data_dict [ ' data ' ] . shape NEW_LINE scores = output [ ' cls _ prob _ reshape _ output ' ] . asnumpy ( ) [ 0 ] NEW_LINE bbox_deltas = output [ ' bbox _ pred _ reshape _ output ' ] . asnumpy ( ) [ 0 ] NEW_LINE pred_boxes = dbbox_pred ( rois , bbox_deltas ) NEW_LINE pred_boxes = clip_polys ( pred_boxes , im_shape [ - 2 : ] ) NEW_LINE pred_boxes = pred_boxes / scale NEW_LINE scores_all . append ( scores ) NEW_LINE pred_boxes_all . append ( pred_boxes ) NEW_LINE DEDENT return scores_all , pred_boxes_all , data_dict_all NEW_LINE DEDENT\",), (\"def im_detect_rotbox ( predictor , data_batch , data_names , scales , cfg ) : NEW_LINE INDENT output_all = predictor . predict ( data_batch ) NEW_LINE data_dict_all = [ dict ( zip ( data_names , idata ) ) for idata in data_batch . data ] NEW_LINE scores_all = [ ] NEW_LINE pred_boxes_all = [ ] NEW_LINE for output , data_dict , scale in zip ( output_all , data_dict_all , scales ) : NEW_LINE INDENT if cfg . TEST . HAS_RPN : NEW_LINE INDENT rois = output [ ' rois _ output ' ] . asnumpy ( ) [ : , 1 : ] NEW_LINE DEDENT else : NEW_LINE INDENT rois = data_dict [ ' rois ' ] . asnumpy ( ) . reshape ( ( - 1 , 5 ) ) [ : , 1 : ] NEW_LINE DEDENT im_shape = data_dict [ ' data ' ] . shape NEW_LINE scores = output [ ' cls _ prob _ reshape _ output ' ] . asnumpy ( ) [ 0 ] NEW_LINE bbox_deltas = output [ ' bbox _ pred _ reshape _ output ' ] . asnumpy ( ) [ 0 ] NEW_LINE pred_boxes = dbbox_transform2_inv_warp ( rois , bbox_deltas ) NEW_LINE pred_polys = RotBox2Polys_multi_class ( pred_boxes ) NEW_LINE pred_polys = clip_polys ( pred_polys , im_shape [ - 2 : ] ) NEW_LINE pred_polys = pred_polys / scale NEW_LINE scores_all . append ( scores ) NEW_LINE pred_boxes_all . append ( pred_polys ) NEW_LINE DEDENT return scores_all , pred_boxes_all , data_dict_all NEW_LINE DEDENT\",), (\"def im_detect_rotbox_Rroi ( predictor , data_batch , data_names , scales , cfg ) : NEW_LINE INDENT output_all = predictor . predict ( data_batch ) NEW_LINE data_dict_all = [ dict ( zip ( data_names , idata ) ) for idata in data_batch . data ] NEW_LINE scores_all = [ ] NEW_LINE pred_boxes_all = [ ] NEW_LINE for output , data_dict , scale in zip ( output_all , data_dict_all , scales ) : NEW_LINE INDENT if cfg . TEST . HAS_RPN : NEW_LINE INDENT rois = output [ ' Rrois _ output ' ] . asnumpy ( ) [ : , 1 : ] NEW_LINE DEDENT else : NEW_LINE INDENT rois = data_dict [ ' rois ' ] . asnumpy ( ) . reshape ( ( - 1 , 6 ) ) [ : , 1 : ] NEW_LINE DEDENT im_shape = data_dict [ ' data ' ] . shape NEW_LINE scores = output [ ' Rroi _ cls _ prob _ reshape _ output ' ] . asnumpy ( ) [ 0 ] NEW_LINE bbox_deltas = output [ ' Rroi _ bbox _ pred _ reshape _ output ' ] . asnumpy ( ) [ 0 ] NEW_LINE if DEBUG : NEW_LINE INDENT bbox_deltas = np . zeros_like ( bbox_deltas ) NEW_LINE DEDENT pred_boxes = dbbox_transform2_inv_new ( rois , bbox_deltas , np . pi / 2. ) NEW_LINE pred_polys = RotBox2Polys_multi_class ( pred_boxes ) NEW_LINE pred_polys = clip_polys ( pred_polys , im_shape [ - 2 : ] ) NEW_LINE pred_polys = pred_polys / scale NEW_LINE scores_all . append ( scores ) NEW_LINE pred_boxes_all . append ( pred_polys ) NEW_LINE DEDENT return scores_all , pred_boxes_all , data_dict_all NEW_LINE DEDENT\",), (\"def im_detect_xyhs ( predictor , data_batch , data_names , scales , cfg ) : NEW_LINE INDENT output_all = predictor . predict ( data_batch ) NEW_LINE data_dict_all = [ dict ( zip ( data_names , idata ) ) for idata in data_batch . data ] NEW_LINE scores_all = [ ] NEW_LINE pred_boxes_all = [ ] NEW_LINE for output , data_dict , scale in zip ( output_all , data_dict_all , scales ) : NEW_LINE INDENT if cfg . TEST . HAS_RPN : NEW_LINE INDENT rois = output [ ' rois _ output ' ] . asnumpy ( ) [ : , 1 : ] NEW_LINE DEDENT else : NEW_LINE INDENT rois = data_dict [ ' rois ' ] . asnumpy ( ) . reshape ( ( - 1 , 5 ) ) [ : , 1 : ] NEW_LINE DEDENT im_shape = data_dict [ ' data ' ] . shape NEW_LINE scores = output [ ' cls _ prob _ reshape _ output ' ] . asnumpy ( ) [ 0 ] NEW_LINE bbox_deltas = output [ ' bbox _ pred _ reshape _ output ' ] . asnumpy ( ) [ 0 ] NEW_LINE pred_boxes = dbboxtransform3_inv_warp ( rois , bbox_deltas ) NEW_LINE pred_polys = xyhs2polys_muli_class ( pred_boxes ) NEW_LINE pred_polys = clip_polys ( pred_polys , im_shape [ - 2 : ] ) NEW_LINE pred_polys = pred_polys / scale NEW_LINE scores_all . append ( scores ) NEW_LINE pred_boxes_all . append ( pred_polys ) NEW_LINE DEDENT return scores_all , pred_boxes_all , data_dict_all NEW_LINE DEDENT\",), (\"def vis_all_detection ( im_array , detections , class_names , scale , cfg , threshold = 1e-3 ) : NEW_LINE INDENT import matplotlib . pyplot as plt NEW_LINE import random NEW_LINE im = image . transform_inverse ( im_array , cfg . network . PIXEL_MEANS ) NEW_LINE plt . imshow ( im ) NEW_LINE for j , name in enumerate ( class_names ) : NEW_LINE INDENT if name == ' _ _ background _ _ ' : NEW_LINE INDENT continue NEW_LINE DEDENT color = ( random . random ( ) , random . random ( ) , random . random ( ) ) NEW_LINE dets = detections [ j ] NEW_LINE for det in dets : NEW_LINE INDENT bbox = det [ : 4 ] * scale NEW_LINE score = det [ - 1 ] NEW_LINE if score < threshold : NEW_LINE INDENT continue NEW_LINE DEDENT rect = plt . Rectangle ( ( bbox [ 0 ] , bbox [ 1 ] ) , bbox [ 2 ] - bbox [ 0 ] , bbox [ 3 ] - bbox [ 1 ] , fill = False , edgecolor = color , linewidth = 3.5 ) NEW_LINE plt . gca ( ) . add_patch ( rect ) NEW_LINE plt . gca ( ) . text ( bbox [ 0 ] , bbox [ 1 ] - 2 , ' { : s } ▁ { : . 3f } ' . format ( name , score ) , bbox = dict ( facecolor = color , alpha = 0.5 ) , fontsize = 12 , color = ' white ' ) NEW_LINE DEDENT DEDENT plt . show ( ) NEW_LINE DEDENT\",), (\"def draw_all_detection ( im_array , detections , class_names , scale , cfg , threshold = 1e-1 ) : NEW_LINE INDENT import cv2 NEW_LINE import random NEW_LINE color_white = ( 255 , 255 , 255 ) NEW_LINE im = image . transform_inverse ( im_array , cfg . network . PIXEL_MEANS ) NEW_LINE im = cv2 . cvtColor ( im , cv2 . COLOR_RGB2BGR ) NEW_LINE for j , name in enumerate ( class_names ) : NEW_LINE INDENT if name == ' _ _ background _ _ ' : NEW_LINE INDENT continue NEW_LINE DEDENT color = ( random . randint ( 0 , 256 ) , random . randint ( 0 , 256 ) , random . randint ( 0 , 256 ) ) NEW_LINE dets = detections [ j ] NEW_LINE for det in dets : NEW_LINE INDENT bbox = det [ : 4 ] * scale NEW_LINE score = det [ - 1 ] NEW_LINE if score < threshold : NEW_LINE INDENT continue NEW_LINE DEDENT bbox = map ( int , bbox ) NEW_LINE cv2 . rectangle ( im , ( bbox [ 0 ] , bbox [ 1 ] ) , ( bbox [ 2 ] , bbox [ 3 ] ) , color = color , thickness = 2 ) NEW_LINE cv2 . putText ( im , ' % s ▁ % .3f ' % ( class_names [ j ] , score ) , ( bbox [ 0 ] , bbox [ 1 ] + 10 ) , color = color_white , fontFace = cv2 . FONT_HERSHEY_COMPLEX , fontScale = 0.5 ) NEW_LINE DEDENT DEDENT return im NEW_LINE DEDENT\",), (\"def draw_all_poly_detection ( im_array , detections , class_names , scale , cfg , threshold = 0.2 ) : NEW_LINE INDENT import cv2 NEW_LINE import random NEW_LINE color_white = ( 255 , 255 , 255 ) NEW_LINE im = image . transform_inverse ( im_array , cfg . network . PIXEL_MEANS ) NEW_LINE im = cv2 . cvtColor ( im , cv2 . COLOR_RGB2BGR ) NEW_LINE if DEBUG : NEW_LINE INDENT class_names = [ ' _ _ background _ _ ' , ' fg ' ] NEW_LINE DEDENT for j , name in enumerate ( class_names ) : NEW_LINE INDENT if name == ' _ _ background _ _ ' : NEW_LINE INDENT continue NEW_LINE DEDENT color = ( random . randint ( 0 , 256 ) , random . randint ( 0 , 256 ) , random . randint ( 0 , 256 ) ) NEW_LINE dets = detections [ j ] NEW_LINE for det in dets : NEW_LINE INDENT bbox = det [ : 8 ] * scale NEW_LINE score = det [ - 1 ] NEW_LINE if score < threshold : NEW_LINE INDENT continue NEW_LINE DEDENT bbox = map ( int , bbox ) NEW_LINE cv2 . circle ( im , ( bbox [ 0 ] , bbox [ 1 ] ) , 3 , ( 0 , 0 , 255 ) , - 1 ) NEW_LINE for i in range ( 3 ) : NEW_LINE INDENT cv2 . line ( im , ( bbox [ i * 2 ] , bbox [ i * 2 + 1 ] ) , ( bbox [ ( i + 1 ) * 2 ] , bbox [ ( i + 1 ) * 2 + 1 ] ) , color = color , thickness = 2 ) NEW_LINE DEDENT cv2 . line ( im , ( bbox [ 6 ] , bbox [ 7 ] ) , ( bbox [ 0 ] , bbox [ 1 ] ) , color = color , thickness = 2 ) NEW_LINE cv2 . putText ( im , ' % s ▁ % .3f ' % ( class_names [ j ] , score ) , ( bbox [ 0 ] , bbox [ 1 ] + 10 ) , color = color_white , fontFace = cv2 . FONT_HERSHEY_COMPLEX , fontScale = 0.5 ) NEW_LINE DEDENT DEDENT return im NEW_LINE DEDENT\",), ('def __init__ ( self , symbol , data_names , label_names , context = mx . cpu ( ) , max_data_shapes = None , provide_data = None , provide_label = None , arg_params = None , aux_params = None ) : NEW_LINE INDENT self . _mod = MutableModule ( symbol , data_names , label_names , context = context , max_data_shapes = max_data_shapes ) NEW_LINE self . _mod . bind ( provide_data , provide_label , for_training = False ) NEW_LINE self . _mod . init_params ( arg_params = arg_params , aux_params = aux_params ) NEW_LINE DEDENT',), ('def predict ( self , data_batch ) : NEW_LINE INDENT self . _mod . forward ( data_batch ) NEW_LINE return [ dict ( zip ( self . _mod . output_names , _ ) ) for _ in zip ( * self . _mod . get_outputs ( merge_multi_context = False ) ) ] NEW_LINE DEDENT',), (\"def do_checkpoint ( prefix , means , stds ) : NEW_LINE INDENT def _callback ( iter_no , sym , arg , aux ) : NEW_LINE INDENT arg [ ' bbox _ pred _ weight _ test ' ] = ( arg [ ' bbox _ pred _ weight ' ] . T * mx . nd . array ( stds ) ) . T NEW_LINE arg [ ' bbox _ pred _ bias _ test ' ] = arg [ ' bbox _ pred _ bias ' ] * mx . nd . array ( stds ) + mx . nd . array ( means ) NEW_LINE mx . model . save_checkpoint ( prefix , iter_no + 1 , sym , arg , aux ) NEW_LINE arg . pop ( ' bbox _ pred _ weight _ test ' ) NEW_LINE arg . pop ( ' bbox _ pred _ bias _ test ' ) NEW_LINE DEDENT return _callback NEW_LINE DEDENT\",), (\"def do_checkpoint_Rroi ( prefix , means , stds , Rroi_means , Rroi_stds ) : NEW_LINE INDENT def _callback ( iter_no , sym , arg , aux ) : NEW_LINE INDENT arg [ ' bbox _ pred _ weight _ test ' ] = ( arg [ ' bbox _ pred _ weight ' ] . T * mx . nd . array ( stds ) ) . T NEW_LINE arg [ ' bbox _ pred _ bias _ test ' ] = arg [ ' bbox _ pred _ bias ' ] * mx . nd . array ( stds ) + mx . nd . array ( means ) NEW_LINE arg [ ' Rroi _ bbox _ pred _ weight _ test ' ] = ( arg [ ' Rroi _ bbox _ pred _ weight ' ] . T * mx . nd . array ( Rroi_stds ) ) . T NEW_LINE arg [ ' Rroi _ bbox _ pred _ bias _ test ' ] = arg [ ' Rroi _ bbox _ pred _ bias ' ] * mx . nd . array ( Rroi_stds ) + mx . nd . array ( Rroi_means ) NEW_LINE mx . model . save_checkpoint ( prefix , iter_no + 1 , sym , arg , aux ) NEW_LINE arg . pop ( ' bbox _ pred _ weight _ test ' ) NEW_LINE arg . pop ( ' bbox _ pred _ bias _ test ' ) NEW_LINE arg . pop ( ' Rroi _ bbox _ pred _ weight _ test ' ) NEW_LINE arg . pop ( ' Rroi _ bbox _ pred _ bias _ test ' ) NEW_LINE DEDENT return _callback NEW_LINE DEDENT\",), ('def __init__ ( self , batch_size , frequent = 50 ) : NEW_LINE INDENT self . batch_size = batch_size NEW_LINE self . frequent = frequent NEW_LINE self . init = False NEW_LINE self . tic = 0 NEW_LINE self . last_count = 0 NEW_LINE DEDENT',), ('def __call__ ( self , param ) : NEW_LINE INDENT count = param . nbatch NEW_LINE if self . last_count > count : NEW_LINE INDENT self . init = False NEW_LINE DEDENT self . last_count = count NEW_LINE if self . init : NEW_LINE INDENT if count % self . frequent == 0 : NEW_LINE INDENT speed = self . frequent * self . batch_size / ( time . time ( ) - self . tic ) NEW_LINE s = \\' \\' NEW_LINE if param . eval_metric is not None : NEW_LINE INDENT name , value = param . eval_metric . get ( ) NEW_LINE s = \" Epoch [ % d ] ▁ Batch ▁ [ % d ] \\\\tSpeed : ▁ % .2f ▁ samples / sec\\\\tTrain - \" % ( param . epoch , count , speed ) NEW_LINE for n , v in zip ( name , value ) : NEW_LINE INDENT s += \" % s = % f , \\\\t \" % ( n , v ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT s = \" Iter [ % d ] ▁ Batch ▁ [ % d ] \\\\tSpeed : ▁ % .2f ▁ samples / sec \" % ( param . epoch , count , speed ) NEW_LINE DEDENT logging . info ( s ) NEW_LINE print ( s ) NEW_LINE self . tic = time . time ( ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT self . init = True NEW_LINE self . tic = time . time ( ) NEW_LINE DEDENT DEDENT',), (\"def load ( prefix , epoch , load_optimizer_states = False , ** kwargs ) : NEW_LINE INDENT sym , args , auxs = load_checkpoint ( prefix , epoch ) NEW_LINE mod = Module ( symbol = sym , ** kwargs ) NEW_LINE mod . _arg_params = args NEW_LINE mod . _aux_params = auxs NEW_LINE mod . params_initialized = True NEW_LINE if load_optimizer_states : NEW_LINE INDENT mod . _preload_opt_states = ' % s - %04d . states ' % ( prefix , epoch ) NEW_LINE DEDENT return mod NEW_LINE DEDENT\",), ('def __init__ ( self , symbol , data_names = ( \\' data \\' , ) , label_names = ( \\' softmax _ label \\' , ) , logger = logging , context = ctx . cpu ( ) , work_load_list = None , fixed_param_names = None , state_names = None ) : NEW_LINE INDENT super ( Module , self ) . __init__ ( logger = logger ) NEW_LINE if isinstance ( context , ctx . Context ) : NEW_LINE INDENT context = [ context ] NEW_LINE DEDENT self . _context = context NEW_LINE if work_load_list is None : NEW_LINE INDENT work_load_list = [ 1 ] * len ( self . _context ) NEW_LINE DEDENT assert len ( work_load_list ) == len ( self . _context ) NEW_LINE self . _work_load_list = work_load_list NEW_LINE self . _symbol = symbol NEW_LINE data_names = list ( data_names ) if data_names is not None else [ ] NEW_LINE label_names = list ( label_names ) if label_names is not None else [ ] NEW_LINE state_names = list ( state_names ) if state_names is not None else [ ] NEW_LINE fixed_param_names = list ( fixed_param_names ) if fixed_param_names is not None else [ ] NEW_LINE _check_input_names ( symbol , data_names , \" data \" , True ) NEW_LINE _check_input_names ( symbol , label_names , \" label \" , False ) NEW_LINE _check_input_names ( symbol , state_names , \" state \" , True ) NEW_LINE _check_input_names ( symbol , fixed_param_names , \" fixed _ param \" , True ) NEW_LINE arg_names = symbol . list_arguments ( ) NEW_LINE input_names = data_names + label_names + state_names NEW_LINE self . _param_names = [ x for x in arg_names if x not in input_names ] NEW_LINE self . _fixed_param_names = fixed_param_names NEW_LINE self . _aux_names = symbol . list_auxiliary_states ( ) NEW_LINE self . _data_names = data_names NEW_LINE self . _label_names = label_names NEW_LINE self . _state_names = state_names NEW_LINE self . _output_names = symbol . list_outputs ( ) NEW_LINE self . _arg_params = None NEW_LINE self . _aux_params = None NEW_LINE self . _params_dirty = False NEW_LINE self . _optimizer = None NEW_LINE self . _kvstore = None NEW_LINE self . _update_on_kvstore = None NEW_LINE self . _updater = None NEW_LINE self . _preload_opt_states = None NEW_LINE self . _grad_req = None NEW_LINE self . _exec_group = None NEW_LINE self . _data_shapes = None NEW_LINE self . _label_shapes = None NEW_LINE DEDENT',), ('def save_checkpoint ( self , prefix , epoch , save_optimizer_states = False ) : NEW_LINE INDENT self . _symbol . save ( \\' % s - symbol . json \\' % prefix ) NEW_LINE param_name = \\' % s - %04d . params \\' % ( prefix , epoch ) NEW_LINE self . save_params ( param_name ) NEW_LINE logging . info ( \\' Saved ▁ checkpoint ▁ to ▁ \\\\ \" % s\\\\ \" \\' , param_name ) NEW_LINE if save_optimizer_states : NEW_LINE INDENT state_name = \\' % s - %04d . states \\' % ( prefix , epoch ) NEW_LINE self . save_optimizer_states ( state_name ) NEW_LINE logging . info ( \\' Saved ▁ optimizer ▁ state ▁ to ▁ \\\\ \" % s\\\\ \" \\' , state_name ) NEW_LINE DEDENT DEDENT',), ('def _reset_bind ( self ) : NEW_LINE INDENT self . binded = False NEW_LINE self . _exec_group = None NEW_LINE self . _data_shapes = None NEW_LINE self . _label_shapes = None NEW_LINE DEDENT',), ('def data_names ( self ) : NEW_LINE INDENT return self . _data_names NEW_LINE DEDENT',), ('def label_names ( self ) : NEW_LINE INDENT return self . _label_names NEW_LINE DEDENT',), ('def output_names ( self ) : NEW_LINE INDENT return self . _output_names NEW_LINE DEDENT',), ('def data_shapes ( self ) : NEW_LINE INDENT assert self . binded NEW_LINE return self . _data_shapes NEW_LINE DEDENT',), ('def label_shapes ( self ) : NEW_LINE INDENT assert self . binded NEW_LINE return self . _label_shapes NEW_LINE DEDENT',), ('def output_shapes ( self ) : NEW_LINE INDENT assert self . binded NEW_LINE return self . _exec_group . get_output_shapes ( ) NEW_LINE DEDENT',), ('def get_params ( self ) : NEW_LINE INDENT assert self . binded and self . params_initialized NEW_LINE if self . _params_dirty : NEW_LINE INDENT self . _sync_params_from_devices ( ) NEW_LINE DEDENT return ( self . _arg_params , self . _aux_params ) NEW_LINE DEDENT',), ('def init_params ( self , initializer = Uniform ( 0.01 ) , arg_params = None , aux_params = None , allow_missing = False , force_init = False , allow_extra = False ) : NEW_LINE INDENT if self . params_initialized and not force_init : NEW_LINE INDENT warnings . warn ( \" Parameters ▁ already ▁ initialized ▁ and ▁ force _ init = False . ▁ \" \" init _ params ▁ call ▁ ignored . \" , stacklevel = 2 ) NEW_LINE return NEW_LINE DEDENT assert self . binded , \\' call ▁ bind ▁ before ▁ initializing ▁ the ▁ parameters \\' NEW_LINE def _impl ( name , arr , cache ) : NEW_LINE INDENT if cache is not None : NEW_LINE INDENT if name in cache : NEW_LINE INDENT cache_arr = cache [ name ] NEW_LINE if cache_arr is not arr : NEW_LINE INDENT cache_arr . copyto ( arr ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT if not allow_missing : NEW_LINE INDENT raise RuntimeError ( \" % s ▁ is ▁ not ▁ presented \" % name ) NEW_LINE DEDENT if initializer != None : NEW_LINE INDENT initializer ( name , arr ) NEW_LINE DEDENT DEDENT DEDENT else : NEW_LINE INDENT initializer ( name , arr ) NEW_LINE DEDENT DEDENT attrs = self . _symbol . attr_dict ( ) NEW_LINE for name , arr in self . _arg_params . items ( ) : NEW_LINE INDENT desc = InitDesc ( name , attrs . get ( name , None ) ) NEW_LINE _impl ( desc , arr , arg_params ) NEW_LINE DEDENT for name , arr in self . _aux_params . items ( ) : NEW_LINE INDENT desc = InitDesc ( name , attrs . get ( name , None ) ) NEW_LINE _impl ( desc , arr , aux_params ) NEW_LINE DEDENT self . params_initialized = True NEW_LINE self . _params_dirty = False NEW_LINE self . _exec_group . set_params ( self . _arg_params , self . _aux_params ) NEW_LINE DEDENT',), ('def set_params ( self , arg_params , aux_params , allow_missing = False , force_init = True ) : NEW_LINE INDENT if not allow_missing : NEW_LINE INDENT self . init_params ( initializer = None , arg_params = arg_params , aux_params = aux_params , allow_missing = allow_missing , force_init = force_init ) NEW_LINE return NEW_LINE DEDENT if self . params_initialized and not force_init : NEW_LINE INDENT warnings . warn ( \" Parameters ▁ already ▁ initialized ▁ and ▁ force _ init = False . ▁ \" \" set _ params ▁ call ▁ ignored . \" , stacklevel = 2 ) NEW_LINE return NEW_LINE DEDENT self . _exec_group . set_params ( arg_params , aux_params ) NEW_LINE self . _params_dirty = True NEW_LINE self . params_initialized = True NEW_LINE DEDENT',), (\"def bind ( self , data_shapes , label_shapes = None , for_training = True , inputs_need_grad = False , force_rebind = False , shared_module = None , grad_req = ' write ' ) : NEW_LINE INDENT if force_rebind : NEW_LINE INDENT self . _reset_bind ( ) NEW_LINE DEDENT if self . binded : NEW_LINE INDENT self . logger . warning ( ' Already ▁ binded , ▁ ignoring ▁ bind ( ) ' ) NEW_LINE return NEW_LINE DEDENT self . for_training = for_training NEW_LINE self . inputs_need_grad = inputs_need_grad NEW_LINE self . binded = True NEW_LINE self . _grad_req = grad_req NEW_LINE if not for_training : NEW_LINE INDENT assert not inputs_need_grad NEW_LINE DEDENT else : NEW_LINE INDENT pass NEW_LINE DEDENT self . _data_shapes , self . _label_shapes = zip ( * [ _parse_data_desc ( self . data_names , self . label_names , data_shape , label_shape ) for data_shape , label_shape in zip ( data_shapes , label_shapes ) ] ) NEW_LINE if self . _label_shapes . count ( None ) == len ( self . _label_shapes ) : NEW_LINE INDENT self . _label_shapes = None NEW_LINE DEDENT if shared_module is not None : NEW_LINE INDENT assert isinstance ( shared_module , Module ) and shared_module . binded and shared_module . params_initialized NEW_LINE shared_group = shared_module . _exec_group NEW_LINE DEDENT else : NEW_LINE INDENT shared_group = None NEW_LINE DEDENT self . _exec_group = DataParallelExecutorGroup ( self . _symbol , self . _context , self . _work_load_list , self . _data_shapes , self . _label_shapes , self . _param_names , for_training , inputs_need_grad , shared_group , logger = self . logger , fixed_param_names = self . _fixed_param_names , grad_req = grad_req , state_names = self . _state_names ) NEW_LINE if shared_module is not None : NEW_LINE INDENT self . params_initialized = True NEW_LINE self . _arg_params = shared_module . _arg_params NEW_LINE self . _aux_params = shared_module . _aux_params NEW_LINE DEDENT elif self . params_initialized : NEW_LINE INDENT self . _exec_group . set_params ( self . _arg_params , self . _aux_params ) NEW_LINE DEDENT else : NEW_LINE INDENT assert self . _arg_params is None and self . _aux_params is None NEW_LINE param_arrays = [ nd . zeros ( x [ 0 ] . shape , dtype = x [ 0 ] . dtype ) for x in self . _exec_group . param_arrays ] NEW_LINE self . _arg_params = { name : arr for name , arr in zip ( self . _param_names , param_arrays ) } NEW_LINE aux_arrays = [ nd . zeros ( x [ 0 ] . shape , dtype = x [ 0 ] . dtype ) for x in self . _exec_group . aux_arrays ] NEW_LINE self . _aux_params = { name : arr for name , arr in zip ( self . _aux_names , aux_arrays ) } NEW_LINE DEDENT if shared_module is not None and shared_module . optimizer_initialized : NEW_LINE INDENT self . borrow_optimizer ( shared_module ) NEW_LINE DEDENT DEDENT\",), ('def reshape ( self , data_shapes , label_shapes = None ) : NEW_LINE INDENT assert self . binded NEW_LINE self . _data_shapes , self . _label_shapes = zip ( * [ _parse_data_desc ( self . data_names , self . label_names , data_shape , label_shape ) for data_shape , label_shape in zip ( data_shapes , label_shapes ) ] ) NEW_LINE self . _exec_group . reshape ( self . _data_shapes , self . _label_shapes ) NEW_LINE DEDENT',), ('def init_optimizer ( self , kvstore = \\' local \\' , optimizer = \\' sgd \\' , optimizer_params = ( ( \\' learning _ rate \\' , 0.01 ) , ) , force_init = False ) : NEW_LINE INDENT assert self . binded and self . params_initialized NEW_LINE if self . optimizer_initialized and not force_init : NEW_LINE INDENT self . logger . warning ( \\' optimizer ▁ already ▁ initialized , ▁ ignoring . . . \\' ) NEW_LINE return NEW_LINE DEDENT ( kvstore , update_on_kvstore ) = _create_kvstore ( kvstore , len ( self . _context ) , self . _arg_params ) NEW_LINE batch_size = self . _exec_group . batch_size NEW_LINE if kvstore and \\' dist \\' in kvstore . type and \\' _ sync \\' in kvstore . type : NEW_LINE INDENT batch_size *= kvstore . num_workers NEW_LINE DEDENT rescale_grad = 1.0 / batch_size NEW_LINE if isinstance ( optimizer , str ) : NEW_LINE INDENT idx2name = { } NEW_LINE if update_on_kvstore : NEW_LINE INDENT idx2name . update ( enumerate ( self . _exec_group . param_names ) ) NEW_LINE DEDENT else : NEW_LINE INDENT for k in range ( len ( self . _context ) ) : NEW_LINE INDENT idx2name . update ( { i * len ( self . _context ) + k : n for i , n in enumerate ( self . _exec_group . param_names ) } ) NEW_LINE DEDENT DEDENT optimizer_params = dict ( optimizer_params ) NEW_LINE if \\' rescale _ grad \\' not in optimizer_params : NEW_LINE INDENT optimizer_params [ \\' rescale _ grad \\' ] = rescale_grad NEW_LINE DEDENT optimizer = opt . create ( optimizer , sym = self . symbol , param_idx2name = idx2name , ** optimizer_params ) NEW_LINE DEDENT else : NEW_LINE INDENT assert isinstance ( optimizer , opt . Optimizer ) NEW_LINE if optimizer . rescale_grad != rescale_grad : NEW_LINE INDENT warnings . warn ( \" Optimizer ▁ created ▁ manually ▁ outside ▁ Module ▁ but ▁ rescale _ grad ▁ \" + \" is ▁ not ▁ normalized ▁ to ▁ 1.0 / batch _ size / num _ workers ▁ ( % s ▁ vs . ▁ % s ) . ▁ \" % ( optimizer . rescale_grad , rescale_grad ) + \" Is ▁ this ▁ intended ? \" , stacklevel = 2 ) NEW_LINE DEDENT DEDENT self . _optimizer = optimizer NEW_LINE self . _kvstore = kvstore NEW_LINE self . _update_on_kvstore = update_on_kvstore NEW_LINE self . _updater = None NEW_LINE if kvstore : NEW_LINE INDENT _initialize_kvstore ( kvstore = kvstore , param_arrays = self . _exec_group . param_arrays , arg_params = self . _arg_params , param_names = self . _param_names , update_on_kvstore = update_on_kvstore ) NEW_LINE DEDENT if update_on_kvstore : NEW_LINE INDENT kvstore . set_optimizer ( self . _optimizer ) NEW_LINE DEDENT else : NEW_LINE INDENT self . _updater = opt . get_updater ( optimizer ) NEW_LINE DEDENT self . optimizer_initialized = True NEW_LINE if self . _preload_opt_states is not None : NEW_LINE INDENT self . load_optimizer_states ( self . _preload_opt_states ) NEW_LINE self . _preload_opt_states = None NEW_LINE DEDENT DEDENT',), ('def borrow_optimizer ( self , shared_module ) : NEW_LINE INDENT assert shared_module . optimizer_initialized NEW_LINE self . _optimizer = shared_module . _optimizer NEW_LINE self . _kvstore = shared_module . _kvstore NEW_LINE self . _update_on_kvstore = shared_module . _update_on_kvstore NEW_LINE self . _updater = shared_module . _updater NEW_LINE self . optimizer_initialized = True NEW_LINE DEDENT',), ('def forward ( self , data_batch , is_train = None ) : NEW_LINE INDENT assert self . binded and self . params_initialized NEW_LINE self . _exec_group . forward ( data_batch , is_train ) NEW_LINE DEDENT',), ('def backward ( self , out_grads = None ) : NEW_LINE INDENT assert self . binded and self . params_initialized NEW_LINE self . _exec_group . backward ( out_grads = out_grads ) NEW_LINE DEDENT',), ('def update ( self ) : NEW_LINE INDENT assert self . binded and self . params_initialized and self . optimizer_initialized NEW_LINE self . _params_dirty = True NEW_LINE if self . _update_on_kvstore : NEW_LINE INDENT try : NEW_LINE INDENT _update_params_on_kvstore ( self . _exec_group . param_arrays , self . _exec_group . grad_arrays , self . _kvstore ) NEW_LINE DEDENT except : NEW_LINE INDENT _update_params_on_kvstore ( self . _exec_group . param_arrays , self . _exec_group . grad_arrays , self . _kvstore , param_names = self . _exec_group . param_names ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT _update_params ( self . _exec_group . param_arrays , self . _exec_group . grad_arrays , updater = self . _updater , num_device = len ( self . _context ) , kvstore = self . _kvstore ) NEW_LINE DEDENT DEDENT',), ('def get_outputs ( self , merge_multi_context = True ) : NEW_LINE INDENT assert self . binded and self . params_initialized NEW_LINE return self . _exec_group . get_outputs ( merge_multi_context = merge_multi_context ) NEW_LINE DEDENT',), ('def get_input_grads ( self , merge_multi_context = True ) : NEW_LINE INDENT assert self . binded and self . params_initialized and self . inputs_need_grad NEW_LINE return self . _exec_group . get_input_grads ( merge_multi_context = merge_multi_context ) NEW_LINE DEDENT',), ('def get_states ( self , merge_multi_context = True ) : NEW_LINE INDENT assert self . binded and self . params_initialized NEW_LINE return self . _exec_group . get_states ( merge_multi_context = merge_multi_context ) NEW_LINE DEDENT',), ('def set_states ( self , states = None , value = None ) : NEW_LINE INDENT assert self . binded and self . params_initialized NEW_LINE self . _exec_group . set_states ( states , value ) NEW_LINE DEDENT',), ('def update_metric ( self , eval_metric , labels ) : NEW_LINE INDENT self . _exec_group . update_metric ( eval_metric , labels ) NEW_LINE DEDENT',), ('def _sync_params_from_devices ( self ) : NEW_LINE INDENT self . _exec_group . get_params ( self . _arg_params , self . _aux_params ) NEW_LINE self . _params_dirty = False NEW_LINE DEDENT',), (\"def save_optimizer_states ( self , fname ) : NEW_LINE INDENT assert self . optimizer_initialized NEW_LINE if self . _update_on_kvstore : NEW_LINE INDENT self . _kvstore . save_optimizer_states ( fname ) NEW_LINE DEDENT else : NEW_LINE INDENT with open ( fname , ' wb ' ) as fout : NEW_LINE INDENT fout . write ( self . _updater . get_states ( ) ) NEW_LINE DEDENT DEDENT DEDENT\",), (\"def load_optimizer_states ( self , fname ) : NEW_LINE INDENT assert self . optimizer_initialized NEW_LINE if self . _update_on_kvstore : NEW_LINE INDENT self . _kvstore . load_optimizer_states ( fname ) NEW_LINE DEDENT else : NEW_LINE INDENT self . _updater . set_states ( open ( fname , ' rb ' ) . read ( ) ) NEW_LINE DEDENT DEDENT\",), ('def install_monitor ( self , mon ) : NEW_LINE INDENT assert self . binded NEW_LINE self . _exec_group . install_monitor ( mon ) NEW_LINE DEDENT',), ('def __init__ ( self , symbol , data_names , label_names , logger = logging , context = ctx . cpu ( ) , work_load_list = None , max_data_shapes = None , max_label_shapes = None , fixed_param_prefix = None ) : NEW_LINE INDENT super ( MutableModule , self ) . __init__ ( logger = logger ) NEW_LINE self . _symbol = symbol NEW_LINE self . _data_names = data_names NEW_LINE self . _label_names = label_names NEW_LINE self . _context = context NEW_LINE self . _work_load_list = work_load_list NEW_LINE self . _curr_module = None NEW_LINE self . _max_data_shapes = max_data_shapes NEW_LINE self . _max_label_shapes = max_label_shapes NEW_LINE self . _fixed_param_prefix = fixed_param_prefix NEW_LINE fixed_param_names = list ( ) NEW_LINE if fixed_param_prefix is not None : NEW_LINE INDENT for name in self . _symbol . list_arguments ( ) : NEW_LINE INDENT for prefix in self . _fixed_param_prefix : NEW_LINE INDENT if prefix in name : NEW_LINE INDENT fixed_param_names . append ( name ) NEW_LINE DEDENT DEDENT DEDENT DEDENT self . _fixed_param_names = fixed_param_names NEW_LINE self . _preload_opt_states = None NEW_LINE DEDENT',), ('def _reset_bind ( self ) : NEW_LINE INDENT self . binded = False NEW_LINE self . _curr_module = None NEW_LINE DEDENT',), ('def data_names ( self ) : NEW_LINE INDENT return self . _data_names NEW_LINE DEDENT',), ('def output_names ( self ) : NEW_LINE INDENT return self . _symbol . list_outputs ( ) NEW_LINE DEDENT',), ('def data_shapes ( self ) : NEW_LINE INDENT assert self . binded NEW_LINE return self . _curr_module . data_shapes NEW_LINE DEDENT',), ('def label_shapes ( self ) : NEW_LINE INDENT assert self . binded NEW_LINE return self . _curr_module . label_shapes NEW_LINE DEDENT',), ('def output_shapes ( self ) : NEW_LINE INDENT assert self . binded NEW_LINE return self . _curr_module . output_shapes NEW_LINE DEDENT',), ('def get_params ( self ) : NEW_LINE INDENT assert self . binded and self . params_initialized NEW_LINE return self . _curr_module . get_params ( ) NEW_LINE DEDENT',), (\"def init_params ( self , initializer = Uniform ( 0.01 ) , arg_params = None , aux_params = None , allow_missing = False , force_init = False , allow_extra = False ) : NEW_LINE INDENT if self . params_initialized and not force_init : NEW_LINE INDENT return NEW_LINE DEDENT assert self . binded , ' call ▁ bind ▁ before ▁ initializing ▁ the ▁ parameters ' NEW_LINE self . _curr_module . init_params ( initializer = initializer , arg_params = arg_params , aux_params = aux_params , allow_missing = allow_missing , force_init = force_init ) NEW_LINE self . params_initialized = True NEW_LINE DEDENT\",), (\"def bind ( self , data_shapes , label_shapes = None , for_training = True , inputs_need_grad = False , force_rebind = False , shared_module = None , grad_req = ' write ' ) : NEW_LINE INDENT if self . params_initialized : NEW_LINE INDENT arg_params , aux_params = self . get_params ( ) NEW_LINE DEDENT if force_rebind : NEW_LINE INDENT self . _reset_bind ( ) NEW_LINE DEDENT if self . binded : NEW_LINE INDENT self . logger . warning ( ' Already ▁ binded , ▁ ignoring ▁ bind ( ) ' ) NEW_LINE return NEW_LINE DEDENT assert shared_module is None , ' shared _ module ▁ for ▁ MutableModule ▁ is ▁ not ▁ supported ' NEW_LINE self . for_training = for_training NEW_LINE self . inputs_need_grad = inputs_need_grad NEW_LINE self . binded = True NEW_LINE max_shapes_dict = dict ( ) NEW_LINE if self . _max_data_shapes is not None : NEW_LINE INDENT max_shapes_dict . update ( dict ( self . _max_data_shapes [ 0 ] ) ) NEW_LINE DEDENT if self . _max_label_shapes is not None : NEW_LINE INDENT max_shapes_dict . update ( dict ( self . _max_label_shapes [ 0 ] ) ) NEW_LINE DEDENT max_data_shapes = list ( ) NEW_LINE for name , shape in data_shapes [ 0 ] : NEW_LINE INDENT if name in max_shapes_dict : NEW_LINE INDENT max_data_shapes . append ( ( name , max_shapes_dict [ name ] ) ) NEW_LINE DEDENT else : NEW_LINE INDENT max_data_shapes . append ( ( name , shape ) ) NEW_LINE DEDENT DEDENT max_label_shapes = list ( ) NEW_LINE if not label_shapes . count ( None ) == len ( label_shapes ) : NEW_LINE INDENT for name , shape in label_shapes [ 0 ] : NEW_LINE INDENT if name in max_shapes_dict : NEW_LINE INDENT max_label_shapes . append ( ( name , max_shapes_dict [ name ] ) ) NEW_LINE DEDENT else : NEW_LINE INDENT max_label_shapes . append ( ( name , shape ) ) NEW_LINE DEDENT DEDENT DEDENT if len ( max_label_shapes ) == 0 : NEW_LINE INDENT max_label_shapes = None NEW_LINE DEDENT module = Module ( self . _symbol , self . _data_names , self . _label_names , logger = self . logger , context = self . _context , work_load_list = self . _work_load_list , fixed_param_names = self . _fixed_param_names ) NEW_LINE module . bind ( [ max_data_shapes for _ in range ( len ( self . _context ) ) ] , [ max_label_shapes for _ in range ( len ( self . _context ) ) ] , for_training , inputs_need_grad , force_rebind = False , shared_module = None ) NEW_LINE self . _curr_module = module NEW_LINE if self . params_initialized : NEW_LINE INDENT self . set_params ( arg_params , aux_params ) NEW_LINE DEDENT DEDENT\",), ('def save_checkpoint ( self , prefix , epoch , save_optimizer_states = False ) : NEW_LINE INDENT self . _curr_module . save_checkpoint ( prefix , epoch , save_optimizer_states ) NEW_LINE DEDENT',), (\"def init_optimizer ( self , kvstore = ' local ' , optimizer = ' sgd ' , optimizer_params = ( ( ' learning _ rate ' , 0.01 ) , ) , force_init = False ) : NEW_LINE INDENT assert self . binded and self . params_initialized NEW_LINE if self . optimizer_initialized and not force_init : NEW_LINE INDENT self . logger . warning ( ' optimizer ▁ already ▁ initialized , ▁ ignoring . ' ) NEW_LINE return NEW_LINE DEDENT self . _curr_module . _preload_opt_states = self . _preload_opt_states NEW_LINE self . _curr_module . init_optimizer ( kvstore , optimizer , optimizer_params , force_init = force_init ) NEW_LINE self . optimizer_initialized = True NEW_LINE DEDENT\",), (\"def fit ( self , train_data , eval_data = None , eval_metric = ' acc ' , epoch_end_callback = None , batch_end_callback = None , kvstore = ' local ' , optimizer = ' sgd ' , optimizer_params = ( ( ' learning _ rate ' , 0.01 ) , ) , eval_end_callback = None , eval_batch_end_callback = None , initializer = Uniform ( 0.01 ) , arg_params = None , aux_params = None , allow_missing = False , force_rebind = False , force_init = False , begin_epoch = 0 , num_epoch = None , validation_metric = None , monitor = None , prefix = None , state = None ) : NEW_LINE INDENT assert num_epoch is not None , ' please ▁ specify ▁ number ▁ of ▁ epochs ' NEW_LINE self . bind ( data_shapes = train_data . provide_data , label_shapes = train_data . provide_label , for_training = True , force_rebind = force_rebind ) NEW_LINE if monitor is not None : NEW_LINE INDENT self . install_monitor ( monitor ) NEW_LINE DEDENT self . init_params ( initializer = initializer , arg_params = arg_params , aux_params = aux_params , allow_missing = allow_missing , force_init = force_init ) NEW_LINE self . init_optimizer ( kvstore = kvstore , optimizer = optimizer , optimizer_params = optimizer_params ) NEW_LINE if state is not None : NEW_LINE INDENT self . _curr_module . load_optimizer_states ( state ) NEW_LINE DEDENT if validation_metric is None : NEW_LINE INDENT validation_metric = eval_metric NEW_LINE DEDENT if not isinstance ( eval_metric , metric . EvalMetric ) : NEW_LINE INDENT eval_metric = metric . create ( eval_metric ) NEW_LINE DEDENT for epoch in range ( begin_epoch , num_epoch ) : NEW_LINE INDENT tic = time . time ( ) NEW_LINE eval_metric . reset ( ) NEW_LINE ct = 0 NEW_LINE for nbatch , data_batch in enumerate ( train_data ) : NEW_LINE INDENT if monitor is not None : NEW_LINE INDENT monitor . tic ( ) NEW_LINE DEDENT self . forward_backward ( data_batch ) NEW_LINE self . update ( ) NEW_LINE ct = ct + 1 NEW_LINE if ct % 50 == 0 : NEW_LINE INDENT ct = 0 NEW_LINE self . update_metric ( eval_metric , data_batch . label ) NEW_LINE sys . stdout . flush ( ) NEW_LINE DEDENT if monitor is not None : NEW_LINE INDENT monitor . toc_print ( ) NEW_LINE DEDENT if batch_end_callback is not None : NEW_LINE INDENT batch_end_params = BatchEndParam ( epoch = epoch , nbatch = nbatch , eval_metric = eval_metric , locals = locals ( ) ) NEW_LINE for callback in _as_list ( batch_end_callback ) : NEW_LINE INDENT callback ( batch_end_params ) NEW_LINE DEDENT DEDENT DEDENT for name , val in eval_metric . get_name_value ( ) : NEW_LINE INDENT self . logger . info ( ' Epoch [ % d ] ▁ Train - % s = % f ' , epoch , name , val ) NEW_LINE DEDENT toc = time . time ( ) NEW_LINE self . logger . info ( ' Epoch [ % d ] ▁ Time ▁ cost = % .3f ' , epoch , ( toc - tic ) ) NEW_LINE arg_params , aux_params = self . get_params ( ) NEW_LINE self . set_params ( arg_params , aux_params ) NEW_LINE if epoch_end_callback is not None : NEW_LINE INDENT for callback in _as_list ( epoch_end_callback ) : NEW_LINE INDENT callback ( epoch , self . symbol , arg_params , aux_params ) NEW_LINE DEDENT DEDENT if eval_data : NEW_LINE INDENT res = self . score ( eval_data , validation_metric , score_end_callback = eval_end_callback , batch_end_callback = eval_batch_end_callback , epoch = epoch ) NEW_LINE for name , val in res : NEW_LINE INDENT self . logger . info ( ' Epoch [ % d ] ▁ Validation - % s = % f ' , epoch , name , val ) NEW_LINE DEDENT DEDENT train_data . reset ( ) NEW_LINE DEDENT DEDENT\",), ('def forward ( self , data_batch , is_train = None ) : NEW_LINE INDENT assert self . binded and self . params_initialized NEW_LINE if self . _curr_module . label_shapes is not None : NEW_LINE INDENT current_shapes = [ dict ( self . _curr_module . data_shapes [ i ] + self . _curr_module . label_shapes [ i ] ) for i in range ( len ( self . _context ) ) ] NEW_LINE DEDENT else : NEW_LINE INDENT current_shapes = [ dict ( self . _curr_module . data_shapes [ i ] ) for i in range ( len ( self . _context ) ) ] NEW_LINE DEDENT if is_train : NEW_LINE INDENT input_shapes = [ dict ( data_batch . provide_data [ i ] + data_batch . provide_label [ i ] ) for i in range ( len ( self . _context ) ) ] NEW_LINE DEDENT else : NEW_LINE INDENT input_shapes = [ dict ( data_batch . provide_data [ i ] ) for i in range ( len ( data_batch . provide_data ) ) ] NEW_LINE DEDENT shape_changed = len ( current_shapes ) != len ( input_shapes ) NEW_LINE for pre , cur in zip ( current_shapes , input_shapes ) : NEW_LINE INDENT for k , v in pre . items ( ) : NEW_LINE INDENT if v != cur [ k ] : NEW_LINE INDENT shape_changed = True NEW_LINE DEDENT DEDENT DEDENT if shape_changed : NEW_LINE INDENT module = Module ( self . _symbol , self . _data_names , self . _label_names , logger = self . logger , context = [ self . _context [ i ] for i in range ( len ( data_batch . provide_data ) ) ] , work_load_list = self . _work_load_list , fixed_param_names = self . _fixed_param_names ) NEW_LINE module . bind ( data_batch . provide_data , data_batch . provide_label , self . _curr_module . for_training , self . _curr_module . inputs_need_grad , force_rebind = False , shared_module = self . _curr_module ) NEW_LINE self . _curr_module = module NEW_LINE DEDENT self . _curr_module . forward ( data_batch , is_train = is_train ) NEW_LINE DEDENT',), ('def backward ( self , out_grads = None ) : NEW_LINE INDENT assert self . binded and self . params_initialized NEW_LINE self . _curr_module . backward ( out_grads = out_grads ) NEW_LINE DEDENT',), ('def update ( self ) : NEW_LINE INDENT assert self . binded and self . params_initialized and self . optimizer_initialized NEW_LINE self . _curr_module . update ( ) NEW_LINE DEDENT',), ('def get_outputs ( self , merge_multi_context = True ) : NEW_LINE INDENT assert self . binded and self . params_initialized NEW_LINE return self . _curr_module . get_outputs ( merge_multi_context = merge_multi_context ) NEW_LINE DEDENT',), ('def get_input_grads ( self , merge_multi_context = True ) : NEW_LINE INDENT assert self . binded and self . params_initialized and self . inputs_need_grad NEW_LINE return self . _curr_module . get_input_grads ( merge_multi_context = merge_multi_context ) NEW_LINE DEDENT',), ('def update_metric ( self , eval_metric , labels ) : NEW_LINE INDENT assert self . binded and self . params_initialized NEW_LINE self . _curr_module . update_metric ( eval_metric , labels ) NEW_LINE DEDENT',), ('def install_monitor ( self , mon ) : NEW_LINE INDENT assert self . binded NEW_LINE self . _curr_module . install_monitor ( mon ) NEW_LINE DEDENT',), (\"def get_rcnn_testbatch ( roidb , cfg ) : NEW_LINE INDENT imgs , roidb = get_image ( roidb , cfg ) NEW_LINE im_array = imgs NEW_LINE im_info = [ np . array ( [ roidb [ i ] [ ' im _ info ' ] ] , dtype = np . float32 ) for i in range ( len ( roidb ) ) ] NEW_LINE im_rois = [ roidb [ i ] [ ' boxes ' ] for i in range ( len ( roidb ) ) ] NEW_LINE rois = im_rois NEW_LINE rois_array = [ np . hstack ( ( 0 * np . ones ( ( rois [ i ] . shape [ 0 ] , 1 ) ) , rois [ i ] ) ) for i in range ( len ( rois ) ) ] NEW_LINE data = [ { ' data ' : im_array [ i ] , ' rois ' : rois_array [ i ] } for i in range ( len ( roidb ) ) ] NEW_LINE label = { } NEW_LINE return data , label , im_info NEW_LINE DEDENT\",), (\"def get_rcnn_batch ( roidb , cfg ) : NEW_LINE INDENT num_images = len ( roidb ) NEW_LINE imgs , roidb = get_image ( roidb , cfg ) NEW_LINE im_array = tensor_vstack ( imgs ) NEW_LINE assert cfg . TRAIN . BATCH_ROIS == - 1 or cfg . TRAIN . BATCH_ROIS % cfg . TRAIN . BATCH_IMAGES == 0 , ' BATCHIMAGES ▁ { } ▁ must ▁ divide ▁ BATCH _ ROIS ▁ { } ' . format ( cfg . TRAIN . BATCH_IMAGES , cfg . TRAIN . BATCH_ROIS ) NEW_LINE if cfg . TRAIN . BATCH_ROIS == - 1 : NEW_LINE INDENT rois_per_image = np . sum ( [ iroidb [ ' boxes ' ] . shape [ 0 ] for iroidb in roidb ] ) NEW_LINE fg_rois_per_image = rois_per_image NEW_LINE DEDENT else : NEW_LINE INDENT rois_per_image = cfg . TRAIN . BATCH_ROIS / cfg . TRAIN . BATCH_IMAGES NEW_LINE fg_rois_per_image = np . round ( cfg . TRAIN . FG_FRACTION * rois_per_image ) . astype ( int ) NEW_LINE DEDENT rois_array = list ( ) NEW_LINE labels_array = list ( ) NEW_LINE bbox_targets_array = list ( ) NEW_LINE bbox_weights_array = list ( ) NEW_LINE for im_i in range ( num_images ) : NEW_LINE INDENT roi_rec = roidb [ im_i ] NEW_LINE num_classes = roi_rec [ ' gt _ overlaps ' ] . shape [ 1 ] NEW_LINE rois = roi_rec [ ' boxes ' ] NEW_LINE labels = roi_rec [ ' max _ classes ' ] NEW_LINE overlaps = roi_rec [ ' max _ overlaps ' ] NEW_LINE bbox_targets = roi_rec [ ' bbox _ targets ' ] NEW_LINE im_rois , labels , bbox_targets , bbox_weights = sample_rois ( rois , fg_rois_per_image , rois_per_image , num_classes , cfg , labels , overlaps , bbox_targets ) NEW_LINE rois = im_rois NEW_LINE batch_index = im_i * np . ones ( ( rois . shape [ 0 ] , 1 ) ) NEW_LINE rois_array_this_image = np . hstack ( ( batch_index , rois ) ) NEW_LINE rois_array . append ( rois_array_this_image ) NEW_LINE labels_array . append ( labels ) NEW_LINE bbox_targets_array . append ( bbox_targets ) NEW_LINE bbox_weights_array . append ( bbox_weights ) NEW_LINE DEDENT rois_array = np . array ( rois_array ) NEW_LINE labels_array = np . array ( labels_array ) NEW_LINE bbox_targets_array = np . array ( bbox_targets_array ) NEW_LINE bbox_weights_array = np . array ( bbox_weights_array ) NEW_LINE data = { ' data ' : im_array , ' rois ' : rois_array } NEW_LINE label = { ' label ' : labels_array , ' bbox _ target ' : bbox_targets_array , ' bbox _ weight ' : bbox_weights_array } NEW_LINE return data , label NEW_LINE DEDENT\",), ('def sample_rois ( rois , fg_rois_per_image , rois_per_image , num_classes , cfg , labels = None , overlaps = None , bbox_targets = None , gt_boxes = None ) : NEW_LINE INDENT if labels is None : NEW_LINE INDENT overlaps = bbox_overlaps ( rois [ : , 1 : ] . astype ( np . float ) , gt_boxes [ : , : 4 ] . astype ( np . float ) ) NEW_LINE gt_assignment = overlaps . argmax ( axis = 1 ) NEW_LINE overlaps = overlaps . max ( axis = 1 ) NEW_LINE labels = gt_boxes [ gt_assignment , 4 ] NEW_LINE DEDENT fg_indexes = np . where ( overlaps >= cfg . TRAIN . FG_THRESH ) [ 0 ] NEW_LINE fg_rois_per_this_image = np . minimum ( fg_rois_per_image , fg_indexes . size ) NEW_LINE if len ( fg_indexes ) > fg_rois_per_this_image : NEW_LINE INDENT fg_indexes = npr . choice ( fg_indexes , size = fg_rois_per_this_image , replace = False ) NEW_LINE DEDENT bg_indexes = np . where ( ( overlaps < cfg . TRAIN . BG_THRESH_HI ) & ( overlaps >= cfg . TRAIN . BG_THRESH_LO ) ) [ 0 ] NEW_LINE bg_rois_per_this_image = rois_per_image - fg_rois_per_this_image NEW_LINE bg_rois_per_this_image = np . minimum ( bg_rois_per_this_image , bg_indexes . size ) NEW_LINE if len ( bg_indexes ) > bg_rois_per_this_image : NEW_LINE INDENT bg_indexes = npr . choice ( bg_indexes , size = bg_rois_per_this_image , replace = False ) NEW_LINE DEDENT keep_indexes = np . append ( fg_indexes , bg_indexes ) NEW_LINE while keep_indexes . shape [ 0 ] < rois_per_image : NEW_LINE INDENT gap = np . minimum ( len ( rois ) , rois_per_image - keep_indexes . shape [ 0 ] ) NEW_LINE gap_indexes = npr . choice ( range ( len ( rois ) ) , size = gap , replace = False ) NEW_LINE keep_indexes = np . append ( keep_indexes , gap_indexes ) NEW_LINE DEDENT labels = labels [ keep_indexes ] NEW_LINE labels [ fg_rois_per_this_image : ] = 0 NEW_LINE rois = rois [ keep_indexes ] NEW_LINE if bbox_targets is not None : NEW_LINE INDENT bbox_target_data = bbox_targets [ keep_indexes , : ] NEW_LINE DEDENT else : NEW_LINE INDENT targets = bbox_transform ( rois [ : , 1 : ] , gt_boxes [ gt_assignment [ keep_indexes ] , : 4 ] ) NEW_LINE if cfg . TRAIN . BBOX_NORMALIZATION_PRECOMPUTED : NEW_LINE INDENT targets = ( ( targets - np . array ( cfg . TRAIN . BBOX_MEANS ) ) / np . array ( cfg . TRAIN . BBOX_STDS ) ) NEW_LINE DEDENT bbox_target_data = np . hstack ( ( labels [ : , np . newaxis ] , targets ) ) NEW_LINE DEDENT bbox_targets , bbox_weights = expand_bbox_regression_targets ( bbox_target_data , num_classes , cfg ) NEW_LINE return rois , labels , bbox_targets , bbox_weights NEW_LINE DEDENT',), ('def sample_rotbox_rois ( rois , fg_rois_per_image , rois_per_image , num_classes , cfg , labels = None , overlaps = None , dbbox_targets = None , gt_boxes = None ) : NEW_LINE INDENT if labels is None : NEW_LINE INDENT hgt_boxes = bbox_poly2hbb ( gt_boxes ) NEW_LINE overlaps = bbox_overlaps ( rois [ : , 1 : ] . astype ( np . float ) , hgt_boxes [ : , : 4 ] . astype ( np . float ) ) NEW_LINE gt_assignment = overlaps . argmax ( axis = 1 ) NEW_LINE overlaps = overlaps . max ( axis = 1 ) NEW_LINE labels = hgt_boxes [ gt_assignment , 4 ] NEW_LINE DEDENT fg_indexes = np . where ( overlaps >= cfg . TRAIN . FG_THRESH ) [ 0 ] NEW_LINE fg_rois_per_this_image = np . minimum ( fg_rois_per_image , fg_indexes . size ) NEW_LINE if len ( fg_indexes ) > fg_rois_per_this_image : NEW_LINE INDENT fg_indexes = npr . choice ( fg_indexes , size = fg_rois_per_this_image , replace = False ) NEW_LINE DEDENT bg_indexes = np . where ( ( overlaps < cfg . TRAIN . BG_THRESH_HI ) & ( overlaps >= cfg . TRAIN . BG_THRESH_LO ) ) [ 0 ] NEW_LINE bg_rois_per_this_image = rois_per_image - fg_rois_per_this_image NEW_LINE bg_rois_per_this_image = np . minimum ( bg_rois_per_this_image , bg_indexes . size ) NEW_LINE if len ( bg_indexes ) > bg_rois_per_this_image : NEW_LINE INDENT bg_indexes = npr . choice ( bg_indexes , size = bg_rois_per_this_image , replace = False ) NEW_LINE DEDENT keep_indexes = np . append ( fg_indexes , bg_indexes ) NEW_LINE while keep_indexes . shape [ 0 ] < rois_per_image : NEW_LINE INDENT gap = np . minimum ( len ( rois ) , rois_per_image - keep_indexes . shape [ 0 ] ) NEW_LINE gap_indexes = npr . choice ( range ( len ( rois ) ) , size = gap , replace = False ) NEW_LINE keep_indexes = np . append ( keep_indexes , gap_indexes ) NEW_LINE DEDENT labels = labels [ keep_indexes ] NEW_LINE labels [ fg_rois_per_this_image : ] = 0 NEW_LINE rois = rois [ keep_indexes ] NEW_LINE if dbbox_targets is not None : NEW_LINE INDENT bbox_target_data = dbbox_targets [ keep_indexes , : ] NEW_LINE DEDENT else : NEW_LINE INDENT targets = dbbox_transform2_warp ( rois [ : , 1 : ] , gt_boxes [ gt_assignment [ keep_indexes ] , : 8 ] ) NEW_LINE if cfg . TRAIN . BBOX_NORMALIZATION_PRECOMPUTED : NEW_LINE INDENT targets = ( ( targets - np . array ( cfg . TRAIN . BBOX_MEANS ) ) / np . array ( cfg . TRAIN . BBOX_STDS ) ) NEW_LINE DEDENT bbox_target_data = np . hstack ( ( labels [ : , np . newaxis ] , targets ) ) NEW_LINE DEDENT bbox_targets , bbox_weights = expand_bbox_regression_targets_base ( bbox_target_data , num_classes , cfg ) NEW_LINE return rois , labels , bbox_targets , bbox_weights NEW_LINE DEDENT',), ('def sample_Rrois ( Rrois , fg_rois_per_image , rois_per_image , num_classes , cfg , labels = None , overlaps = None , dbbox_targets = None , gt_boxes = None , device_id = 0 ) : NEW_LINE INDENT if labels is None : NEW_LINE INDENT overlaps = poly_overlaps ( Rrois [ : , 1 : ] . astype ( np . float32 ) , gt_boxes [ : , : 5 ] . astype ( np . float32 ) , device_id ) NEW_LINE gt_assignment = overlaps . argmax ( axis = 1 ) NEW_LINE overlaps = overlaps . max ( axis = 1 ) NEW_LINE labels = gt_boxes [ gt_assignment , 5 ] NEW_LINE DEDENT fg_indexes = np . where ( overlaps >= cfg . TRAIN . RRoI_FG_THRESH ) [ 0 ] NEW_LINE fg_rois_per_this_image = np . minimum ( fg_rois_per_image , fg_indexes . size ) NEW_LINE if len ( fg_indexes ) > fg_rois_per_this_image : NEW_LINE INDENT fg_indexes = npr . choice ( fg_indexes , size = fg_rois_per_this_image , replace = False ) NEW_LINE DEDENT bg_indexes = np . where ( ( overlaps < cfg . TRAIN . BG_THRESH_HI ) & ( overlaps >= cfg . TRAIN . BG_THRESH_LO ) ) [ 0 ] NEW_LINE bg_rois_per_this_image = rois_per_image - fg_rois_per_this_image NEW_LINE bg_rois_per_this_image = np . minimum ( bg_rois_per_this_image , bg_indexes . size ) NEW_LINE if len ( bg_indexes ) > bg_rois_per_this_image : NEW_LINE INDENT bg_indexes = npr . choice ( bg_indexes , size = bg_rois_per_this_image , replace = False ) NEW_LINE DEDENT keep_indexes = np . append ( fg_indexes , bg_indexes ) NEW_LINE while keep_indexes . shape [ 0 ] < rois_per_image : NEW_LINE INDENT gap = np . minimum ( len ( Rrois ) , rois_per_image - keep_indexes . shape [ 0 ] ) NEW_LINE gap_indexes = npr . choice ( range ( len ( Rrois ) ) , size = gap , replace = False ) NEW_LINE keep_indexes = np . append ( keep_indexes , gap_indexes ) NEW_LINE DEDENT labels = labels [ keep_indexes ] NEW_LINE labels [ fg_rois_per_this_image : ] = 0 NEW_LINE Rrois = Rrois [ keep_indexes ] NEW_LINE if dbbox_targets is not None : NEW_LINE INDENT bbox_target_data = dbbox_targets [ keep_indexes , : ] NEW_LINE DEDENT else : NEW_LINE INDENT targets = dbbox_transform2_best_match_warp ( Rrois [ : , 1 : ] , gt_boxes [ gt_assignment [ keep_indexes ] , : 5 ] ) NEW_LINE if cfg . TRAIN . BBOX_NORMALIZATION_PRECOMPUTED : NEW_LINE INDENT targets = ( ( targets - np . array ( cfg . TRAIN . RRoI_BBOX_STDS ) ) / np . array ( cfg . TRAIN . RRoI_BBOX_STDS ) ) NEW_LINE DEDENT bbox_target_data = np . hstack ( ( labels [ : , np . newaxis ] , targets ) ) NEW_LINE DEDENT bbox_targets , bbox_weights = expand_bbox_regression_targets_base_new ( bbox_target_data , num_classes , cfg . network . RRoI_CLASS_AGNOSTIC ) NEW_LINE return Rrois , labels , bbox_targets , bbox_weights NEW_LINE DEDENT',), ('def sample_poly_rois ( rois , fg_rois_per_image , rois_per_image , num_classes , cfg , labels = None , overlaps = None , dbbox_targets = None , gt_boxes = None ) : NEW_LINE INDENT if labels is None : NEW_LINE INDENT hgt_boxes = bbox_poly2hbb ( gt_boxes ) NEW_LINE overlaps = bbox_overlaps ( rois [ : , 1 : ] . astype ( np . float ) , hgt_boxes [ : , : 4 ] . astype ( np . float ) ) NEW_LINE gt_assignment = overlaps . argmax ( axis = 1 ) NEW_LINE overlaps = overlaps . max ( axis = 1 ) NEW_LINE labels = hgt_boxes [ gt_assignment , 4 ] NEW_LINE DEDENT fg_indexes = np . where ( overlaps >= cfg . TRAIN . FG_THRESH ) [ 0 ] NEW_LINE fg_rois_per_this_image = np . minimum ( fg_rois_per_image , fg_indexes . size ) NEW_LINE if len ( fg_indexes ) > fg_rois_per_this_image : NEW_LINE INDENT fg_indexes = npr . choice ( fg_indexes , size = fg_rois_per_this_image , replace = False ) NEW_LINE DEDENT bg_indexes = np . where ( ( overlaps < cfg . TRAIN . BG_THRESH_HI ) & ( overlaps >= cfg . TRAIN . BG_THRESH_LO ) ) [ 0 ] NEW_LINE bg_rois_per_this_image = rois_per_image - fg_rois_per_this_image NEW_LINE bg_rois_per_this_image = np . minimum ( bg_rois_per_this_image , bg_indexes . size ) NEW_LINE if len ( bg_indexes ) > bg_rois_per_this_image : NEW_LINE INDENT bg_indexes = npr . choice ( bg_indexes , size = bg_rois_per_this_image , replace = False ) NEW_LINE DEDENT keep_indexes = np . append ( fg_indexes , bg_indexes ) NEW_LINE while keep_indexes . shape [ 0 ] < rois_per_image : NEW_LINE INDENT gap = np . minimum ( len ( rois ) , rois_per_image - keep_indexes . shape [ 0 ] ) NEW_LINE gap_indexes = npr . choice ( range ( len ( rois ) ) , size = gap , replace = False ) NEW_LINE keep_indexes = np . append ( keep_indexes , gap_indexes ) NEW_LINE DEDENT labels = labels [ keep_indexes ] NEW_LINE labels [ fg_rois_per_this_image : ] = 0 NEW_LINE rois = rois [ keep_indexes ] NEW_LINE if dbbox_targets is not None : NEW_LINE INDENT bbox_target_data = dbbox_targets [ keep_indexes , : ] NEW_LINE DEDENT else : NEW_LINE INDENT targets = dbbox_transform ( rois [ : , 1 : ] , gt_boxes [ gt_assignment [ keep_indexes ] , : 8 ] ) NEW_LINE if cfg . TRAIN . BBOX_NORMALIZATION_PRECOMPUTED : NEW_LINE INDENT targets = ( ( targets - np . array ( cfg . TRAIN . BBOX_MEANS ) ) / np . array ( cfg . TRAIN . BBOX_STDS ) ) NEW_LINE DEDENT bbox_target_data = np . hstack ( ( labels [ : , np . newaxis ] , targets ) ) NEW_LINE DEDENT bbox_targets , bbox_weights = expand_bbox_regression_targets_base ( bbox_target_data , num_classes , cfg ) NEW_LINE return rois , labels , bbox_targets , bbox_weights NEW_LINE DEDENT',), ('def sample_rotbox_rois_region_pred ( rois , fg_rois_per_image , rois_per_image , num_classes , cfg , labels = None , overlaps = None , dbbox_targets = None , gt_boxes = None ) : NEW_LINE INDENT if labels is None : NEW_LINE INDENT hgt_boxes = bbox_poly2hbb ( gt_boxes ) NEW_LINE overlaps = bbox_overlaps ( rois [ : , 1 : ] . astype ( np . float ) , hgt_boxes [ : , : 4 ] . astype ( np . float ) ) NEW_LINE gt_assignment = overlaps . argmax ( axis = 1 ) NEW_LINE overlaps = overlaps . max ( axis = 1 ) NEW_LINE labels = hgt_boxes [ gt_assignment , 4 ] NEW_LINE DEDENT fg_indexes = np . where ( overlaps >= cfg . TRAIN . FG_THRESH ) [ 0 ] NEW_LINE fg_rois_per_this_image = np . minimum ( fg_rois_per_image , fg_indexes . size ) NEW_LINE if len ( fg_indexes ) > fg_rois_per_this_image : NEW_LINE INDENT fg_indexes = npr . choice ( fg_indexes , size = fg_rois_per_this_image , replace = False ) NEW_LINE DEDENT bg_indexes = np . where ( ( overlaps < cfg . TRAIN . BG_THRESH_HI ) & ( overlaps >= cfg . TRAIN . BG_THRESH_LO ) ) [ 0 ] NEW_LINE bg_rois_per_this_image = rois_per_image - fg_rois_per_this_image NEW_LINE bg_rois_per_this_image = np . minimum ( bg_rois_per_this_image , bg_indexes . size ) NEW_LINE if len ( bg_indexes ) > bg_rois_per_this_image : NEW_LINE INDENT bg_indexes = npr . choice ( bg_indexes , size = bg_rois_per_this_image , replace = False ) NEW_LINE DEDENT keep_indexes = np . append ( fg_indexes , bg_indexes ) NEW_LINE while keep_indexes . shape [ 0 ] < rois_per_image : NEW_LINE INDENT gap = np . minimum ( len ( rois ) , rois_per_image - keep_indexes . shape [ 0 ] ) NEW_LINE gap_indexes = npr . choice ( range ( len ( rois ) ) , size = gap , replace = False ) NEW_LINE keep_indexes = np . append ( keep_indexes , gap_indexes ) NEW_LINE DEDENT labels = labels [ keep_indexes ] NEW_LINE labels [ fg_rois_per_this_image : ] = 0 NEW_LINE rois = rois [ keep_indexes ] NEW_LINE if dbbox_targets is not None : NEW_LINE INDENT bbox_target_data = dbbox_targets [ keep_indexes , : ] NEW_LINE DEDENT else : NEW_LINE INDENT targets = dbbox_transform2_warp ( rois [ : , 1 : ] , gt_boxes [ gt_assignment [ keep_indexes ] , : 8 ] ) NEW_LINE if cfg . TRAIN . BBOX_NORMALIZATION_PRECOMPUTED : NEW_LINE INDENT targets = ( ( targets - np . array ( cfg . TRAIN . BBOX_MEANS ) ) / np . array ( cfg . TRAIN . BBOX_STDS ) ) NEW_LINE DEDENT bbox_target_data = np . hstack ( ( labels [ : , np . newaxis ] , targets ) ) NEW_LINE DEDENT bbox_targets , bbox_weights = expand_bbox_regression_targets_base ( bbox_target_data , num_classes , cfg ) NEW_LINE return rois , labels , bbox_targets , bbox_weights NEW_LINE DEDENT',), ('def sample_rotbox_rois_nd ( rois , fg_rois_per_image , rois_per_image , num_classes , cfg , labels = None , overlaps = None , dbbox_targets = None , gt_boxes = None ) : NEW_LINE INDENT if labels is None : NEW_LINE INDENT hgt_boxes = bbox_poly2hbb_nd ( gt_boxes ) NEW_LINE overlaps = mx . nd . contrib . box_iou ( rois [ : , 1 : ] . astype ( np . float ) , hgt_boxes [ : , : 4 ] . astype ( np . float ) ) NEW_LINE gt_assignment = overlaps . argmax ( axis = 1 ) NEW_LINE overlaps = overlaps . max ( axis = 1 ) NEW_LINE labels = hgt_boxes [ gt_assignment , 4 ] NEW_LINE DEDENT overlaps = overlaps . asnumpy ( ) NEW_LINE fg_indexes = np . where ( overlaps >= cfg . TRAIN . FG_THRESH ) [ 0 ] NEW_LINE fg_rois_per_this_image = np . minimum ( fg_rois_per_image , fg_indexes . size ) NEW_LINE if len ( fg_indexes ) > fg_rois_per_this_image : NEW_LINE INDENT fg_indexes = npr . choice ( fg_indexes , size = fg_rois_per_this_image , replace = False ) NEW_LINE DEDENT bg_indexes = np . where ( ( overlaps < cfg . TRAIN . BG_THRESH_HI ) & ( overlaps >= cfg . TRAIN . BG_THRESH_LO ) ) [ 0 ] NEW_LINE bg_rois_per_this_image = rois_per_image - fg_rois_per_this_image NEW_LINE bg_rois_per_this_image = np . minimum ( bg_rois_per_this_image , bg_indexes . size ) NEW_LINE if len ( bg_indexes ) > bg_rois_per_this_image : NEW_LINE INDENT bg_indexes = npr . choice ( bg_indexes , size = bg_rois_per_this_image , replace = False ) NEW_LINE DEDENT keep_indexes = np . append ( fg_indexes , bg_indexes ) NEW_LINE while keep_indexes . shape [ 0 ] < rois_per_image : NEW_LINE INDENT gap = np . minimum ( len ( rois ) , rois_per_image - keep_indexes . shape [ 0 ] ) NEW_LINE gap_indexes = npr . choice ( range ( len ( rois ) ) , size = gap , replace = False ) NEW_LINE keep_indexes = np . append ( keep_indexes , gap_indexes ) NEW_LINE DEDENT keep_indexes = mx . nd . array ( keep_indexes ) NEW_LINE labels = labels [ keep_indexes ] NEW_LINE if ( fg_rois_per_this_image < labels . size ) : NEW_LINE INDENT labels [ fg_rois_per_this_image : ] = 0 NEW_LINE DEDENT rois = rois [ keep_indexes ] NEW_LINE if dbbox_targets is not None : NEW_LINE INDENT bbox_target_data = dbbox_targets [ keep_indexes , : ] NEW_LINE DEDENT else : NEW_LINE INDENT targets = dbbox_transform2_warp_nd ( rois [ : , 1 : ] , gt_boxes [ gt_assignment [ keep_indexes ] , : 8 ] ) NEW_LINE if cfg . TRAIN . BBOX_NORMALIZATION_PRECOMPUTED : NEW_LINE INDENT targets = ( ( targets - mx . nd . array ( cfg . TRAIN . BBOX_MEANS ) ) / mx . nd . array ( cfg . TRAIN . BBOX_STDS ) ) NEW_LINE DEDENT bbox_target_data = mx . nd . concat ( labels . expand_dims ( 1 ) , targets , dim = 1 ) NEW_LINE DEDENT bbox_targets , bbox_weights = expand_bbox_regression_targets_base ( bbox_target_data . asnumpy ( ) , num_classes , cfg ) NEW_LINE return rois , labels , bbox_targets , bbox_weights NEW_LINE DEDENT',), ('def sample_xyhs_rois ( rois , fg_rois_per_image , rois_per_image , num_classes , cfg , labels = None , overlaps = None , dbbox_targets = None , gt_boxes = None ) : NEW_LINE INDENT if labels is None : NEW_LINE INDENT hgt_boxes = bbox_poly2hbb ( gt_boxes ) NEW_LINE overlaps = bbox_overlaps ( rois [ : , 1 : ] . astype ( np . float ) , hgt_boxes [ : , : 4 ] . astype ( np . float ) ) NEW_LINE gt_assignment = overlaps . argmax ( axis = 1 ) NEW_LINE overlaps = overlaps . max ( axis = 1 ) NEW_LINE labels = hgt_boxes [ gt_assignment , 4 ] NEW_LINE DEDENT fg_indexes = np . where ( overlaps >= cfg . TRAIN . FG_THRESH ) [ 0 ] NEW_LINE fg_rois_per_this_image = np . minimum ( fg_rois_per_image , fg_indexes . size ) NEW_LINE if len ( fg_indexes ) > fg_rois_per_this_image : NEW_LINE INDENT fg_indexes = npr . choice ( fg_indexes , size = fg_rois_per_this_image , replace = False ) NEW_LINE DEDENT bg_indexes = np . where ( ( overlaps < cfg . TRAIN . BG_THRESH_HI ) & ( overlaps >= cfg . TRAIN . BG_THRESH_LO ) ) [ 0 ] NEW_LINE bg_rois_per_this_image = rois_per_image - fg_rois_per_this_image NEW_LINE bg_rois_per_this_image = np . minimum ( bg_rois_per_this_image , bg_indexes . size ) NEW_LINE if len ( bg_indexes ) > bg_rois_per_this_image : NEW_LINE INDENT bg_indexes = npr . choice ( bg_indexes , size = bg_rois_per_this_image , replace = False ) NEW_LINE DEDENT keep_indexes = np . append ( fg_indexes , bg_indexes ) NEW_LINE while keep_indexes . shape [ 0 ] < rois_per_image : NEW_LINE INDENT gap = np . minimum ( len ( rois ) , rois_per_image - keep_indexes . shape [ 0 ] ) NEW_LINE gap_indexes = npr . choice ( range ( len ( rois ) ) , size = gap , replace = False ) NEW_LINE keep_indexes = np . append ( keep_indexes , gap_indexes ) NEW_LINE DEDENT labels = labels [ keep_indexes ] NEW_LINE labels [ fg_rois_per_this_image : ] = 0 NEW_LINE rois = rois [ keep_indexes ] NEW_LINE if dbbox_targets is not None : NEW_LINE INDENT bbox_target_data = dbbox_targets [ keep_indexes , : ] NEW_LINE DEDENT else : NEW_LINE INDENT targets = dbboxtransform3_warp ( rois [ : , 1 : ] , gt_boxes [ gt_assignment [ keep_indexes ] , : 8 ] ) NEW_LINE if cfg . TRAIN . BBOX_NORMALIZATION_PRECOMPUTED : NEW_LINE INDENT targets = ( ( targets - np . array ( cfg . TRAIN . BBOX_MEANS ) ) / np . array ( cfg . TRAIN . BBOX_STDS ) ) NEW_LINE DEDENT bbox_target_data = np . hstack ( ( labels [ : , np . newaxis ] , targets ) ) NEW_LINE DEDENT bbox_targets , bbox_weights = expand_bbox_regression_targets_base ( bbox_target_data , num_classes , cfg ) NEW_LINE return rois , labels , bbox_targets , bbox_weights NEW_LINE DEDENT',), (\"def sample_xyhs_rois_nd ( rois , fg_rois_per_image , rois_per_image , num_classes , cfg , labels = None , overlaps = None , dbbox_targets = None , gt_boxes = None ) : NEW_LINE INDENT if labels is None : NEW_LINE INDENT hgt_boxes = bbox_poly2hbb_nd ( gt_boxes ) NEW_LINE overlaps = mx . nd . contrib . box_iou ( rois [ : , 1 : ] . astype ( ' float32' ) , hgt_boxes [ : , : 4 ] . astype ( ' float32' ) ) NEW_LINE gt_assignment = overlaps . argmax ( axis = 1 ) NEW_LINE overlaps = overlaps . max ( axis = 1 ) NEW_LINE labels = hgt_boxes [ gt_assignment , 4 ] NEW_LINE DEDENT overlaps = overlaps . asnumpy ( ) NEW_LINE fg_indexes = np . where ( overlaps >= cfg . TRAIN . FG_THRESH ) [ 0 ] NEW_LINE fg_rois_per_this_image = np . minimum ( fg_rois_per_image , fg_indexes . size ) NEW_LINE if len ( fg_indexes ) > fg_rois_per_this_image : NEW_LINE INDENT fg_indexes = npr . choice ( fg_indexes , size = fg_rois_per_this_image , replace = False ) NEW_LINE DEDENT bg_indexes = np . where ( ( overlaps < cfg . TRAIN . BG_THRESH_HI ) & ( overlaps >= cfg . TRAIN . BG_THRESH_LO ) ) [ 0 ] NEW_LINE bg_rois_per_this_image = rois_per_image - fg_rois_per_this_image NEW_LINE bg_rois_per_this_image = np . minimum ( bg_rois_per_this_image , bg_indexes . size ) NEW_LINE if len ( bg_indexes ) > bg_rois_per_this_image : NEW_LINE INDENT bg_indexes = npr . choice ( bg_indexes , size = bg_rois_per_this_image , replace = False ) NEW_LINE DEDENT keep_indexes = np . append ( fg_indexes , bg_indexes ) NEW_LINE while keep_indexes . shape [ 0 ] < rois_per_image : NEW_LINE INDENT gap = np . minimum ( len ( rois ) , rois_per_image - keep_indexes . shape [ 0 ] ) NEW_LINE gap_indexes = npr . choice ( range ( len ( rois ) ) , size = gap , replace = False ) NEW_LINE keep_indexes = np . append ( keep_indexes , gap_indexes ) NEW_LINE DEDENT labels = labels [ keep_indexes ] NEW_LINE labels [ fg_rois_per_this_image : ] = 0 NEW_LINE rois = rois [ keep_indexes ] NEW_LINE if dbbox_targets is not None : NEW_LINE INDENT bbox_target_data = dbbox_targets [ keep_indexes , : ] NEW_LINE DEDENT else : NEW_LINE INDENT targets = dbboxtransform3_warp ( rois [ : , 1 : ] , gt_boxes [ gt_assignment [ keep_indexes ] , : 8 ] ) NEW_LINE if cfg . TRAIN . BBOX_NORMALIZATION_PRECOMPUTED : NEW_LINE INDENT targets = ( ( targets - np . array ( cfg . TRAIN . BBOX_MEANS ) ) / np . array ( cfg . TRAIN . BBOX_STDS ) ) NEW_LINE DEDENT bbox_target_data = np . hstack ( ( labels [ : , np . newaxis ] , targets ) ) NEW_LINE DEDENT bbox_targets , bbox_weights = expand_bbox_regression_targets_base ( bbox_target_data , num_classes , cfg ) NEW_LINE return rois , labels , bbox_targets , bbox_weights NEW_LINE DEDENT\",)]\n",
            "1.5044640712440014\n",
            "On batch 511\n",
            "tensor([0.0254, 0.0254, 0.0253, 0.0254, 0.0248, 0.0251, 0.0250, 0.0250, 0.0246,\n",
            "        0.0252, 0.0250, 0.0249, 0.0255, 0.0253, 0.0252, 0.0254, 0.0248, 0.0251,\n",
            "        0.0250, 0.0248, 0.0246, 0.0248, 0.0249, 0.0252, 0.0256, 0.0247, 0.0246,\n",
            "        0.0252, 0.0246, 0.0251, 0.0246, 0.0247, 0.0246, 0.0248, 0.0252, 0.0247,\n",
            "        0.0254, 0.0249, 0.0248, 0.0247], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "('\\\\label{eq:GIN}\\n    \\\\mathbf{X}^{G_i, k + 1} = \\\\text{MLP}^k((\\\\mathbf{A}^{G_i} + (1 + \\\\epsilon)\\\\mathbf{I})\\\\mathbf{X}^{G_i, k}),\\n',)\n",
            "[(\"def train ( epoch , encoder , classifier , data_loader , dataset , optimizer_e , optimizer_c , args ) : NEW_LINE INDENT encoder . train ( ) NEW_LINE classifier . train ( ) NEW_LINE total_loss = 0 NEW_LINE for data in data_loader : NEW_LINE INDENT if ( args . setting in [ ' no ' , ' upsampling ' ] or args . min_num_graph == 0 ) : NEW_LINE INDENT data = data . to ( args . device ) NEW_LINE H = encoder ( data . x , data . edge_index , data . batch ) NEW_LINE logits = classifier ( H ) NEW_LINE loss = F . nll_loss ( logits , data . y ) NEW_LINE DEDENT elif ( args . setting == ' reweight ' ) : NEW_LINE INDENT data = data . to ( args . device ) NEW_LINE H = encoder ( data . x , data . edge_index , data . batch ) NEW_LINE logits = classifier ( H ) NEW_LINE args . weight = torch . zeros_like ( args . class_train_num_graph , dtype = torch . float ) NEW_LINE for i in range ( len ( torch . unique ( data . y ) ) ) : NEW_LINE INDENT args . weight [ i ] = 1 / ( ( data . y == torch . unique ( data . y ) [ i ] ) . sum ( ) ) NEW_LINE DEDENT loss = F . nll_loss ( logits , data . y , weight = args . weight ) NEW_LINE DEDENT elif ( args . setting == ' smote ' ) : NEW_LINE INDENT data = data . to ( args . device ) NEW_LINE H = encoder ( data . x , data . edge_index , data . batch ) NEW_LINE logits = classifier ( H ) NEW_LINE H_aug , y_aug = embed_smote ( H , args . class_train_num_graph , data . y , args . k ) NEW_LINE logits_aug = classifier ( H_aug ) NEW_LINE loss = F . nll_loss ( logits , data . y ) + F . nll_loss ( logits_aug , y_aug ) NEW_LINE DEDENT elif ( args . setting == ' mix ' ) : NEW_LINE INDENT data = data . to ( args . device ) NEW_LINE H = encoder ( data . x , data . edge_index , data . batch ) NEW_LINE logits = classifier ( H ) NEW_LINE mixed_H , y_a , y_b , lam = mixup ( H , data . y , args , alpha = 1.0 ) NEW_LINE logits_mix = classifier ( mixed_H ) NEW_LINE loss = lam * F . nll_loss ( logits_mix , y_a ) + ( 1 - lam ) * F . nll_loss ( logits_mix , y_b ) NEW_LINE DEDENT elif ( args . setting == ' remix ' ) : NEW_LINE INDENT data = data . to ( args . device ) NEW_LINE H = encoder ( data . x , data . edge_index , data . batch ) NEW_LINE mixed_H , y_a , y_b , lam = remixup ( H , data . y , args . class_train_num_graph , alpha = 1.0 , tau = 0.5 , kappa = 3 ) NEW_LINE logits_mix = classifier ( mixed_H ) NEW_LINE loss = F . nll_loss ( lam . view ( - 1 , 1 ) * logits_mix , y_a ) + F . nll_loss ( ( 1 - lam ) . view ( - 1 , 1 ) * logits_mix , y_b ) NEW_LINE DEDENT elif ( args . setting == ' knn ' ) : NEW_LINE INDENT idx = len ( data . id ) NEW_LINE extra_id = id_pad ( data . id , args . kernel_idx ) NEW_LINE if ( len ( extra_id ) != 0 ) : NEW_LINE INDENT data = data_pad ( data , extra_id , dataset , args . mapping ) . to ( args . device ) NEW_LINE DEDENT else : NEW_LINE INDENT data = data . to ( args . device ) NEW_LINE DEDENT H = encoder ( data . x , data . edge_index , data . batch ) NEW_LINE logits = classifier ( H ) [ : idx ] NEW_LINE knn_edge_index , _ = subgraph ( data . id , args . knn_edge_index , relabel_nodes = True ) NEW_LINE y_data = data . y [ : idx ] NEW_LINE H_knn = H NEW_LINE for i in range ( args . prop_epochs ) : NEW_LINE INDENT H_knn = propagate ( knn_edge_index , H_knn ) NEW_LINE DEDENT logits_knn = classifier ( H_knn ) [ : idx ] NEW_LINE loss = F . nll_loss ( logits_knn , y_data ) NEW_LINE DEDENT elif ( args . setting == ' aug ' ) : NEW_LINE INDENT data = data . to ( args . device ) NEW_LINE H_augs , logit_augs = [ ] , [ ] NEW_LINE for i in range ( args . aug_num ) : NEW_LINE INDENT if ( args . aug == ' RE ' ) : NEW_LINE INDENT edge_index_aug = remove_edge ( data . edge_index , args . aug_ratio ) NEW_LINE H_augs . append ( encoder ( data . x , edge_index_aug , data . batch ) ) NEW_LINE logit_augs . append ( classifier ( H_augs [ - 1 ] ) ) NEW_LINE DEDENT elif ( args . aug == ' DN ' ) : NEW_LINE INDENT x_aug = drop_node ( data . x , args . aug_ratio ) NEW_LINE H_augs . append ( encoder ( x_aug , data . edge_index , data . batch ) ) NEW_LINE logit_augs . append ( classifier ( H_augs [ - 1 ] ) ) NEW_LINE DEDENT DEDENT loss = 0 NEW_LINE for i in range ( len ( logit_augs ) ) : NEW_LINE INDENT loss += F . nll_loss ( logit_augs [ i ] , data . y ) NEW_LINE DEDENT loss = loss / len ( logit_augs ) NEW_LINE loss = loss + consis_loss ( logit_augs , temp = args . temp ) NEW_LINE DEDENT elif ( args . setting == ' knn _ aug ' ) : NEW_LINE INDENT idx = len ( data . id ) NEW_LINE extra_id = id_pad ( data . id , args . kernel_idx ) NEW_LINE if ( len ( extra_id ) != 0 ) : NEW_LINE INDENT data = data_pad ( data , extra_id , dataset , args . mapping ) . to ( args . device ) NEW_LINE DEDENT else : NEW_LINE INDENT data = data . to ( args . device ) NEW_LINE DEDENT H_augs , logit_augs = [ ] , [ ] NEW_LINE for i in range ( args . aug_num ) : NEW_LINE INDENT if ( args . aug == ' RE ' ) : NEW_LINE INDENT edge_index_aug = remove_edge ( data . edge_index , args . aug_ratio ) NEW_LINE H_augs . append ( encoder ( data . x , edge_index_aug , data . batch ) ) NEW_LINE DEDENT elif ( args . aug == ' DN ' ) : NEW_LINE INDENT x_aug = drop_node ( data . x , args . aug_ratio ) NEW_LINE H_augs . append ( encoder ( x_aug , data . edge_index , data . batch ) ) NEW_LINE DEDENT DEDENT knn_edge_index , _ = subgraph ( data . id , args . knn_edge_index , relabel_nodes = True ) NEW_LINE logit_aug_props = [ ] NEW_LINE for k in range ( args . aug_num ) : NEW_LINE INDENT H_aug_knn = H_augs [ k ] NEW_LINE for i in range ( args . prop_epochs ) : NEW_LINE INDENT H_aug_knn = propagate ( knn_edge_index , H_aug_knn ) NEW_LINE DEDENT logit_aug_props . append ( classifier ( H_aug_knn [ : idx ] ) ) NEW_LINE DEDENT y_data = data . y [ : idx ] NEW_LINE loss = 0 NEW_LINE for i in range ( len ( logit_aug_props ) ) : NEW_LINE INDENT loss += F . nll_loss ( logit_aug_props [ i ] , y_data ) NEW_LINE DEDENT loss = loss / len ( logit_aug_props ) NEW_LINE loss = loss + consis_loss ( logit_aug_props ) NEW_LINE DEDENT optimizer_e . zero_grad ( ) NEW_LINE optimizer_c . zero_grad ( ) NEW_LINE loss . backward ( ) NEW_LINE optimizer_e . step ( ) NEW_LINE optimizer_c . step ( ) NEW_LINE total_loss += float ( loss ) * data . num_graphs NEW_LINE DEDENT return total_loss / len ( data_loader . dataset ) NEW_LINE DEDENT\",), (\"def eval ( encoder , classifier , data_loader , dataset , optimizer_e , optimizer_c , args ) : NEW_LINE INDENT encoder . eval ( ) NEW_LINE classifier . eval ( ) NEW_LINE pred , truth = [ ] , [ ] NEW_LINE total_loss = 0 NEW_LINE for data in data_loader : NEW_LINE INDENT if ( args . setting in [ ' no ' , ' upsampling ' ] or args . min_num_graph == 0 ) : NEW_LINE INDENT data = data . to ( args . device ) NEW_LINE H = encoder ( data . x , data . edge_index , data . batch ) NEW_LINE logits = classifier ( H ) NEW_LINE loss = F . nll_loss ( logits , data . y ) NEW_LINE pred . extend ( logits . argmax ( - 1 ) . tolist ( ) ) NEW_LINE truth . extend ( data . y . tolist ( ) ) NEW_LINE DEDENT elif ( args . setting == ' reweight ' ) : NEW_LINE INDENT data = data . to ( args . device ) NEW_LINE H = encoder ( data . x , data . edge_index , data . batch ) NEW_LINE logits = classifier ( H ) NEW_LINE args . weight = max ( args . class_train_num_graph ) / args . class_train_num_graph NEW_LINE loss = F . nll_loss ( logits , data . y , weight = args . weight ) NEW_LINE pred . extend ( logits . argmax ( - 1 ) . tolist ( ) ) NEW_LINE truth . extend ( data . y . tolist ( ) ) NEW_LINE DEDENT elif ( args . setting == ' smote ' ) : NEW_LINE INDENT data = data . to ( args . device ) NEW_LINE H = encoder ( data . x , data . edge_index , data . batch ) NEW_LINE logits = classifier ( H ) NEW_LINE H_aug , y_aug = embed_smote ( H , args . class_train_num_graph , data . y , args . k ) NEW_LINE logits_aug = classifier ( H_aug ) NEW_LINE loss = F . nll_loss ( logits , data . y ) + F . nll_loss ( logits_aug , y_aug ) NEW_LINE pred . extend ( logits . argmax ( - 1 ) . tolist ( ) ) NEW_LINE truth . extend ( data . y . tolist ( ) ) NEW_LINE DEDENT elif ( args . setting == ' mix ' ) : NEW_LINE INDENT data = data . to ( args . device ) NEW_LINE H = encoder ( data . x , data . edge_index , data . batch ) NEW_LINE logits = classifier ( H ) NEW_LINE mixed_H , y_a , y_b , lam = mixup ( H , data . y , args , alpha = 1.0 ) NEW_LINE logits_mix = classifier ( mixed_H ) NEW_LINE loss = lam * F . nll_loss ( logits_mix , y_a ) + ( 1 - lam ) * F . nll_loss ( logits_mix , y_b ) NEW_LINE pred . extend ( logits . argmax ( - 1 ) . tolist ( ) ) NEW_LINE truth . extend ( data . y . tolist ( ) ) NEW_LINE DEDENT elif ( args . setting == ' remix ' ) : NEW_LINE INDENT data = data . to ( args . device ) NEW_LINE H = encoder ( data . x , data . edge_index , data . batch ) NEW_LINE mixed_H , y_a , y_b , lam = remixup ( H , data . y , args . class_train_num_graph , alpha = 1.0 , tau = 0.5 , kappa = 3 ) NEW_LINE logits_mix = classifier ( mixed_H ) NEW_LINE loss = F . nll_loss ( lam . view ( - 1 , 1 ) * logits_mix , y_a ) + F . nll_loss ( ( 1 - lam ) . view ( - 1 , 1 ) * logits_mix , y_b ) NEW_LINE pred . extend ( logits_mix . argmax ( - 1 ) . tolist ( ) ) NEW_LINE truth . extend ( data . y . tolist ( ) ) NEW_LINE DEDENT elif ( args . setting == ' knn ' ) : NEW_LINE INDENT idx = len ( data . id ) NEW_LINE extra_id = id_pad ( data . id , args . kernel_idx ) NEW_LINE if ( len ( extra_id ) != 0 ) : NEW_LINE INDENT data = data_pad ( data , extra_id , dataset , args . mapping ) . to ( args . device ) NEW_LINE DEDENT else : NEW_LINE INDENT data = data . to ( args . device ) NEW_LINE DEDENT H = encoder ( data . x , data . edge_index , data . batch ) NEW_LINE logits = classifier ( H ) [ : idx ] NEW_LINE knn_edge_index , _ = subgraph ( data . id , args . knn_edge_index , relabel_nodes = True ) NEW_LINE y_data = data . y [ : idx ] NEW_LINE H_knn = H NEW_LINE for i in range ( args . prop_epochs ) : NEW_LINE INDENT H_knn = propagate ( knn_edge_index , H_knn ) NEW_LINE DEDENT logits_knn = classifier ( H_knn ) [ : idx ] NEW_LINE loss = F . nll_loss ( logits_knn , y_data ) NEW_LINE pred . extend ( logits_knn . argmax ( - 1 ) . tolist ( ) ) NEW_LINE truth . extend ( y_data . tolist ( ) ) NEW_LINE DEDENT elif ( args . setting == ' aug ' ) : NEW_LINE INDENT data = data . to ( args . device ) NEW_LINE H_augs , logit_augs = [ ] , [ ] NEW_LINE for i in range ( args . aug_num ) : NEW_LINE INDENT if ( args . aug == ' RE ' ) : NEW_LINE INDENT edge_index_aug = remove_edge ( data . edge_index , args . aug_ratio ) NEW_LINE H_augs . append ( encoder ( data . x , edge_index_aug , data . batch ) ) NEW_LINE logit_augs . append ( classifier ( H_augs [ - 1 ] ) ) NEW_LINE DEDENT elif ( args . aug == ' DN ' ) : NEW_LINE INDENT x_aug = drop_node ( data . x , args . aug_ratio ) NEW_LINE H_augs . append ( encoder ( x_aug , data . edge_index , data . batch ) ) NEW_LINE logit_augs . append ( classifier ( H_augs [ - 1 ] ) ) NEW_LINE DEDENT DEDENT loss = 0 NEW_LINE for i in range ( len ( logit_augs ) ) : NEW_LINE INDENT loss += F . nll_loss ( logit_augs [ i ] , data . y ) NEW_LINE DEDENT loss = loss / len ( logit_augs ) NEW_LINE loss = loss + consis_loss ( logit_augs ) NEW_LINE logit_aug = torch . stack ( logit_augs ) . mean ( dim = 0 ) NEW_LINE pred . extend ( logit_aug . argmax ( - 1 ) . tolist ( ) ) NEW_LINE truth . extend ( data . y . tolist ( ) ) NEW_LINE DEDENT elif ( args . setting == ' knn _ aug ' ) : NEW_LINE INDENT idx = len ( data . id ) NEW_LINE extra_id = id_pad ( data . id , args . kernel_idx ) NEW_LINE if ( len ( extra_id ) != 0 ) : NEW_LINE INDENT data = data_pad ( data , extra_id , dataset , args . mapping ) . to ( args . device ) NEW_LINE DEDENT else : NEW_LINE INDENT data = data . to ( args . device ) NEW_LINE DEDENT H_augs , logit_augs = [ ] , [ ] NEW_LINE for i in range ( args . aug_num ) : NEW_LINE INDENT if ( args . aug == ' RE ' ) : NEW_LINE INDENT edge_index_aug = remove_edge ( data . edge_index , args . aug_ratio ) NEW_LINE H_augs . append ( encoder ( data . x , edge_index_aug , data . batch ) ) NEW_LINE DEDENT elif ( args . aug == ' DN ' ) : NEW_LINE INDENT x_aug = drop_node ( data . x , args . aug_ratio ) NEW_LINE H_augs . append ( encoder ( x_aug , data . edge_index , data . batch ) ) NEW_LINE DEDENT DEDENT knn_edge_index , _ = subgraph ( data . id , args . knn_edge_index , relabel_nodes = True ) NEW_LINE logit_aug_props = [ ] NEW_LINE for k in range ( args . aug_num ) : NEW_LINE INDENT H_aug_knn = H_augs [ k ] NEW_LINE for i in range ( args . prop_epochs ) : NEW_LINE INDENT H_aug_knn = propagate ( knn_edge_index , H_aug_knn ) NEW_LINE DEDENT logit_aug_props . append ( classifier ( H_aug_knn [ : idx ] ) ) NEW_LINE DEDENT y_data = data . y [ : idx ] NEW_LINE loss = 0 NEW_LINE for i in range ( len ( logit_aug_props ) ) : NEW_LINE INDENT loss += F . nll_loss ( logit_aug_props [ i ] , y_data ) NEW_LINE DEDENT loss = loss / len ( logit_aug_props ) NEW_LINE loss = loss + consis_loss ( logit_aug_props ) NEW_LINE logit_aug_prop = torch . stack ( logit_aug_props ) . mean ( dim = 0 ) NEW_LINE pred . extend ( logit_aug_prop . argmax ( - 1 ) . tolist ( ) ) NEW_LINE truth . extend ( y_data . tolist ( ) ) NEW_LINE DEDENT total_loss += float ( loss ) * data . num_graphs NEW_LINE DEDENT acc_c = f1_score ( truth , pred , labels = np . arange ( 0 , 2 ) , average = None , zero_division = 0 ) NEW_LINE acc = ( np . array ( pred ) == np . array ( truth ) ) . sum ( ) / len ( truth ) NEW_LINE return { ' loss ' : total_loss / len ( data_loader . dataset ) , ' F1 - macro ' : np . mean ( acc_c ) , ' F1 - micro ' : acc } NEW_LINE DEDENT\",), ('def upsample ( dataset ) : NEW_LINE INDENT y = torch . tensor ( [ dataset [ i ] . y for i in range ( len ( dataset ) ) ] ) NEW_LINE classes = torch . unique ( y ) NEW_LINE num_class_graph = [ ( y == i . item ( ) ) . sum ( ) for i in classes ] NEW_LINE max_num_class_graph = max ( num_class_graph ) NEW_LINE chosen = [ ] NEW_LINE for i in range ( len ( classes ) ) : NEW_LINE INDENT train_idx = torch . where ( ( y == classes [ i ] ) == True ) [ 0 ] . tolist ( ) NEW_LINE up_sample_ratio = max_num_class_graph / num_class_graph [ i ] NEW_LINE up_sample_num = int ( num_class_graph [ i ] * up_sample_ratio - num_class_graph [ i ] ) NEW_LINE if ( up_sample_num <= len ( train_idx ) ) : NEW_LINE INDENT up_sample = random . sample ( train_idx , up_sample_num ) NEW_LINE DEDENT else : NEW_LINE INDENT tmp = int ( up_sample_num / len ( train_idx ) ) NEW_LINE up_sample = train_idx * tmp NEW_LINE tmp = up_sample_num - len ( train_idx ) * tmp NEW_LINE up_sample . extend ( random . sample ( train_idx , tmp ) ) NEW_LINE DEDENT chosen . extend ( up_sample ) NEW_LINE DEDENT chosen = torch . tensor ( chosen ) NEW_LINE extend_data = dataset [ chosen ] NEW_LINE data = list ( dataset ) + list ( extend_data ) NEW_LINE return data NEW_LINE DEDENT',), ('def embed_smote ( embed , num_training_graph , y , k ) : NEW_LINE INDENT max_num_training_graph = max ( num_training_graph ) NEW_LINE classes = torch . unique ( y ) NEW_LINE embed_aug = [ ] NEW_LINE y_aug = [ ] NEW_LINE for i in range ( len ( classes ) ) : NEW_LINE INDENT train_idx = torch . where ( ( y == classes [ i ] ) == True ) [ 0 ] . tolist ( ) NEW_LINE c_embed = embed [ train_idx ] NEW_LINE c_dist = torch . cdist ( c_embed , c_embed , p = 2 ) NEW_LINE c_min_idx = torch . topk ( c_dist , min ( k , c_dist . size ( 0 ) ) , largest = False ) [ 1 ] [ : , : ] . tolist ( ) NEW_LINE up_sample_ratio = max_num_training_graph / num_training_graph [ i ] NEW_LINE up_sample_num = int ( num_training_graph [ i ] * up_sample_ratio - num_training_graph [ i ] ) NEW_LINE tmp = 1 NEW_LINE head_list = list ( np . arange ( 0 , len ( train_idx ) ) ) NEW_LINE while ( tmp <= up_sample_num ) : NEW_LINE INDENT head_id = random . choice ( head_list ) NEW_LINE tail_id = random . choice ( c_min_idx [ head_id ] ) NEW_LINE delta = torch . rand ( 1 ) . to ( c_embed . device ) NEW_LINE new_embed = torch . lerp ( c_embed [ head_id ] , c_embed [ tail_id ] , delta ) NEW_LINE embed_aug . append ( new_embed ) NEW_LINE y_aug . append ( classes [ i ] ) NEW_LINE tmp += 1 NEW_LINE DEDENT DEDENT if ( embed_aug == [ ] ) : NEW_LINE INDENT return embed , y NEW_LINE DEDENT return torch . stack ( embed_aug ) , torch . stack ( y_aug ) . to ( embed . device ) NEW_LINE DEDENT',), ('def mixup ( x , y , args , alpha = 1.0 ) : NEW_LINE INDENT if alpha > 0 : NEW_LINE INDENT lam = np . random . beta ( alpha , alpha ) NEW_LINE DEDENT else : NEW_LINE INDENT lam = 1 NEW_LINE DEDENT batch_size = x . size ( ) [ 0 ] NEW_LINE index = torch . randperm ( batch_size ) . cuda ( ) NEW_LINE mixed_x = lam * x + ( 1 - lam ) * x [ index , : ] NEW_LINE y_a , y_b = y , y [ index ] NEW_LINE return mixed_x , y_a , y_b , lam NEW_LINE DEDENT',), ('def remixup ( x , y , num_training_graph , alpha = 1.0 , tau = 3 , kappa = 3 ) : NEW_LINE INDENT if alpha > 0 : NEW_LINE INDENT lam = np . random . beta ( alpha , alpha ) NEW_LINE DEDENT else : NEW_LINE INDENT lam = 1 NEW_LINE DEDENT batch_size = x . size ( ) [ 0 ] NEW_LINE index = torch . randperm ( batch_size ) . cuda ( ) NEW_LINE mixed_x = lam * x + ( 1 - lam ) * x [ index , : ] NEW_LINE y_a , y_b = y , y [ index ] NEW_LINE num_class_a , num_class_b = num_training_graph [ y_a ] , num_training_graph [ y_b ] NEW_LINE num_ratio = num_class_a / num_class_b NEW_LINE cond_ratio1 , cond_ratio2 = num_ratio >= kappa , num_ratio <= 1 / kappa NEW_LINE lamb_list = mixed_x . new ( batch_size ) . fill_ ( lam ) NEW_LINE cond_lamb1 = lamb_list < tau NEW_LINE cond_lamb2 = ( 1 - lamb_list ) < tau NEW_LINE lamb_list [ cond_lamb1 & cond_ratio1 ] = 0 NEW_LINE lamb_list [ cond_lamb2 & cond_ratio2 ] = 1 NEW_LINE return mixed_x , y_a , y_b , lamb_list NEW_LINE DEDENT',), ('def construct_knn ( kernel_idx ) : NEW_LINE INDENT edge_index = [ [ ] , [ ] ] NEW_LINE for i in range ( len ( kernel_idx ) ) : NEW_LINE INDENT for j in range ( len ( kernel_idx [ i ] ) ) : NEW_LINE INDENT edge_index [ 0 ] . append ( i ) NEW_LINE edge_index [ 1 ] . append ( kernel_idx [ i , j ] . item ( ) ) NEW_LINE edge_index [ 0 ] . append ( kernel_idx [ i , j ] . item ( ) ) NEW_LINE edge_index [ 1 ] . append ( i ) NEW_LINE DEDENT DEDENT return torch . tensor ( edge_index , dtype = torch . long ) NEW_LINE DEDENT',), (\"def propagate ( edge_index , x , deg = None ) : NEW_LINE INDENT edge_index , _ = add_remaining_self_loops ( edge_index ) NEW_LINE if ( deg == None ) : NEW_LINE INDENT row , col = edge_index NEW_LINE deg = degree ( col , x . size ( 0 ) , dtype = x . dtype ) NEW_LINE deg_inv_sqrt = deg . pow ( - 0.5 ) NEW_LINE edge_weight = deg_inv_sqrt [ col ] * deg_inv_sqrt [ col ] NEW_LINE DEDENT else : NEW_LINE INDENT row , col = edge_index NEW_LINE deg_inv_sqrt = deg . pow ( - 0.5 ) . to ( edge_index . device ) NEW_LINE edge_weight = deg_inv_sqrt [ col ] * deg_inv_sqrt [ col ] NEW_LINE DEDENT out = edge_weight . view ( - 1 , 1 ) * x [ row ] NEW_LINE return scatter ( out , edge_index [ - 1 ] , dim = 0 , dim_size = x . size ( 0 ) , reduce = ' add ' ) NEW_LINE DEDENT\",), ('def id_pad ( data_id , kernel_id ) : NEW_LINE INDENT pad_id = set ( kernel_id [ data_id ] . view ( - 1 ) . tolist ( ) ) NEW_LINE repeat_id = pad_id . intersection ( set ( data_id . tolist ( ) ) ) NEW_LINE extra_id = pad_id - repeat_id NEW_LINE return torch . tensor ( list ( extra_id ) , dtype = torch . long ) NEW_LINE DEDENT',), ('def data_pad ( data , extra_id , dataset , mapping ) : NEW_LINE INDENT extra_id = [ mapping [ extra_id [ i ] . item ( ) ] for i in range ( len ( extra_id ) ) ] NEW_LINE extra_dataset = dataset [ extra_id ] NEW_LINE extra_dataloader = DataLoader ( extra_dataset , batch_size = len ( extra_dataset ) ) NEW_LINE for extra_data in extra_dataloader : NEW_LINE INDENT if ( extra_data . x is None ) : NEW_LINE INDENT extra_data . x = torch . ones ( ( extra_data . batch . size ( 0 ) , 1 ) ) NEW_LINE DEDENT data . edge_index = torch . cat ( [ data . edge_index , extra_data . edge_index + data . x . size ( 0 ) ] , dim = 1 ) NEW_LINE data . x = torch . cat ( [ data . x , extra_data . x ] , dim = 0 ) NEW_LINE data . id = torch . cat ( [ data . id , extra_data . id ] , dim = 0 ) NEW_LINE data . y = torch . cat ( [ data . y , extra_data . y ] , dim = 0 ) NEW_LINE data . batch = torch . cat ( [ data . batch , extra_data . batch + max ( data . batch ) + 1 ] ) NEW_LINE DEDENT return data NEW_LINE DEDENT',), ('def consis_loss ( logps , temp = 0.5 ) : NEW_LINE INDENT ps = [ torch . exp ( p ) for p in logps ] NEW_LINE sum_p = 0. NEW_LINE for p in ps : NEW_LINE INDENT sum_p = sum_p + p NEW_LINE DEDENT avg_p = sum_p / len ( ps ) NEW_LINE sharp_p = ( torch . pow ( avg_p , 1. / temp ) / torch . sum ( torch . pow ( avg_p , 1. / temp ) , dim = 1 , keepdim = True ) ) . detach ( ) NEW_LINE loss = 0. NEW_LINE for p in ps : NEW_LINE INDENT loss += torch . mean ( ( p - sharp_p ) . pow ( 2 ) . sum ( 1 ) ) NEW_LINE DEDENT loss = loss / len ( ps ) NEW_LINE return 1 * loss NEW_LINE DEDENT',), (\"def homophily ( edge_index , y ) : NEW_LINE INDENT degree_cal = degree ( edge_index [ 1 ] , num_nodes = y . size ( 0 ) ) NEW_LINE edge_homo = ( y [ edge_index [ 0 ] ] == y [ edge_index [ 1 ] ] ) . sum ( ) . item ( ) / edge_index . size ( 1 ) NEW_LINE tmp = y [ edge_index [ 0 ] ] == y [ edge_index [ 1 ] ] NEW_LINE node_homo = scatter ( tmp , edge_index [ 1 ] , dim = 0 , dim_size = y . size ( 0 ) , reduce = ' add ' ) / degree_cal NEW_LINE return edge_homo , node_homo . mean ( ) NEW_LINE DEDENT\",), (\"def tsne_visual ( encoder , classifier , dataset , args ) : NEW_LINE INDENT x , y , pred = [ ] , [ ] , [ ] NEW_LINE data_loader = DataLoader ( dataset , batch_size = args . batch_size ) NEW_LINE mapping = { } NEW_LINE inverse_mapping = { } NEW_LINE count = 0 NEW_LINE for data in data_loader : NEW_LINE INDENT data = data . to ( args . device ) NEW_LINE H = encoder ( data . x , data . edge_index , data . batch ) NEW_LINE x . append ( H ) NEW_LINE y . append ( data . y ) NEW_LINE pred . append ( classifier ( H ) . argmax ( - 1 ) ) NEW_LINE for idd in data . id : NEW_LINE INDENT mapping [ idd . item ( ) ] = count NEW_LINE inverse_mapping [ count ] = idd . item ( ) NEW_LINE count += 1 NEW_LINE DEDENT DEDENT x = torch . cat ( x , dim = 0 ) . detach ( ) . cpu ( ) . numpy ( ) NEW_LINE y = torch . cat ( y , dim = 0 ) . detach ( ) . cpu ( ) . numpy ( ) NEW_LINE pred = torch . cat ( pred , dim = 0 ) . detach ( ) . cpu ( ) . numpy ( ) NEW_LINE pred_mask = ( pred == y ) NEW_LINE print ( x . shape ) NEW_LINE x = TSNE ( n_components = 2 , learning_rate = ' auto ' , init = ' random ' , random_state = 0 ) . fit_transform ( x ) NEW_LINE plt . subplot ( 1 , 1 , 1 ) NEW_LINE print ( y . shape , pred . shape , ( y == 0 ) & ( pred == 1 ) ) NEW_LINE plt . scatter ( x [ y == 1 , 0 ] , x [ y == 1 , 1 ] , c = ' grey ' , s = 5 ) NEW_LINE plt . scatter ( x [ ( y == 0 ) & ( pred == 0 ) , 0 ] , x [ ( y == 0 ) & ( pred == 0 ) , 1 ] , c = ' red ' , s = 5 ) NEW_LINE plt . scatter ( x [ ( y == 0 ) & ( pred == 1 ) , 0 ] , x [ ( y == 0 ) & ( pred == 1 ) , 1 ] , c = ' red ' , s = 30 ) NEW_LINE for edge in args . knn_edge_index . t ( ) : NEW_LINE INDENT if ( y [ mapping [ edge [ 0 ] . item ( ) ] ] == 0 or y [ mapping [ edge [ 1 ] . item ( ) ] ] == 0 ) : NEW_LINE INDENT if ( pred_mask [ mapping [ edge [ 0 ] . item ( ) ] ] == False or pred_mask [ mapping [ edge [ 1 ] . item ( ) ] ] == False ) : NEW_LINE INDENT if ( y [ mapping [ edge [ 0 ] . item ( ) ] ] == 0 and y [ mapping [ edge [ 1 ] . item ( ) ] ] == 0 ) : NEW_LINE INDENT c = ' red ' NEW_LINE DEDENT if ( y [ mapping [ edge [ 0 ] . item ( ) ] ] == 1 and y [ mapping [ edge [ 1 ] . item ( ) ] ] == 1 ) : NEW_LINE INDENT c = ' grey ' NEW_LINE DEDENT if ( y [ mapping [ edge [ 0 ] . item ( ) ] ] != y [ mapping [ edge [ 1 ] . item ( ) ] ] ) : NEW_LINE INDENT c = ' orange ' NEW_LINE DEDENT plt . plot ( ( x [ mapping [ edge [ 0 ] . item ( ) ] , 0 ] , x [ mapping [ edge [ 1 ] . item ( ) ] , 0 ] ) , ( x [ mapping [ edge [ 0 ] . item ( ) ] , 1 ] , x [ mapping [ edge [ 1 ] . item ( ) ] , 1 ] ) , linewidth = 0.2 , c = c ) NEW_LINE DEDENT DEDENT DEDENT plt . savefig ( ' . / result / visual ' + args . setting + ' . pdf ' , dpi = 1000 ) NEW_LINE DEDENT\",), (\"def pca_visual ( encoder , classifier , dataset , args ) : NEW_LINE INDENT import numpy as np NEW_LINE from sklearn . model_selection import train_test_split NEW_LINE from sklearn . preprocessing import StandardScaler NEW_LINE from sklearn . decomposition import IncrementalPCA NEW_LINE from sklearn . model_selection import GridSearchCV NEW_LINE from sklearn . linear_model import LogisticRegression NEW_LINE from sklearn import metrics NEW_LINE import matplotlib . pyplot as plt NEW_LINE import seaborn as sns NEW_LINE x = [ ] NEW_LINE y = [ ] NEW_LINE data_loader = DataLoader ( dataset , batch_size = args . batch_size ) NEW_LINE y_pred = [ ] NEW_LINE mapping = { } NEW_LINE inverse_mapping = { } NEW_LINE count = 0 NEW_LINE for data in data_loader : NEW_LINE INDENT data = data . to ( args . device ) NEW_LINE H = encoder ( data . x , data . edge_index , data . batch ) NEW_LINE x . append ( H ) NEW_LINE y . append ( data . y ) NEW_LINE y_pred . append ( classifier ( H ) . argmax ( - 1 ) ) NEW_LINE for idd in data . id : NEW_LINE INDENT mapping [ idd . item ( ) ] = count NEW_LINE inverse_mapping [ count ] = idd . item ( ) NEW_LINE count += 1 NEW_LINE DEDENT DEDENT y_pred = torch . cat ( y_pred ) . detach ( ) . cpu ( ) . numpy ( ) NEW_LINE x = torch . cat ( x , dim = 0 ) . detach ( ) . cpu ( ) . numpy ( ) NEW_LINE y = torch . cat ( y , dim = 0 ) . detach ( ) . cpu ( ) . numpy ( ) NEW_LINE print ( len ( y ) , ( y_pred == y ) . sum ( ) / len ( y ) ) NEW_LINE scalerx = StandardScaler ( ) NEW_LINE X_scaled = scalerx . fit_transform ( x ) NEW_LINE pca = IncrementalPCA ( n_components = 2 ) NEW_LINE X_pca = pca . fit_transform ( X_scaled ) NEW_LINE params = { ' C ' : [ 1e-5 , 1e-4 , 1e-3 , 1e-2 , 1e-1 , 1 , 10 , 100 ] } NEW_LINE clf = LogisticRegression ( ) NEW_LINE folds = 5 NEW_LINE model = GridSearchCV ( estimator = clf , param_grid = params , scoring = ' accuracy ' , cv = folds , return_train_score = True , verbose = 3 ) NEW_LINE model . fit ( X_pca , y ) NEW_LINE pred_mask = ( y_pred == y ) NEW_LINE print ( 111 , pred_mask . sum ( ) , len ( pred_mask ) ) NEW_LINE x_min , x_max = X_pca [ : , 0 ] . min ( ) - 1 , X_pca [ : , 0 ] . max ( ) + 1 NEW_LINE y_min , y_max = X_pca [ : , 1 ] . min ( ) - 1 , X_pca [ : , 1 ] . max ( ) + 1 NEW_LINE xx , yy = np . meshgrid ( np . arange ( x_min , x_max , 0.1 ) , np . arange ( y_min , y_max , 0.1 ) ) NEW_LINE Z = model . predict ( np . c_ [ xx . ravel ( ) , yy . ravel ( ) ] ) NEW_LINE Z = Z . reshape ( xx . shape ) NEW_LINE plt . figure ( ) NEW_LINE plt . subplot ( 1 , 1 , 1 ) NEW_LINE plt . contourf ( xx , yy , Z , cmap = ' Pastel1' ) NEW_LINE plt . scatter ( X_pca [ y == 0 , 0 ] , X_pca [ y == 0 , 1 ] , c = ' red ' , s = 30 , edgecolor = ' k ' ) NEW_LINE plt . scatter ( X_pca [ y == 1 , 0 ] , X_pca [ y == 1 , 1 ] , c = ' grey ' , s = 30 , edgecolor = ' k ' ) NEW_LINE for edge in args . knn_edge_index . t ( ) : NEW_LINE INDENT if ( pred_mask [ mapping [ edge [ 0 ] . item ( ) ] ] == False or pred_mask [ mapping [ edge [ 1 ] . item ( ) ] ] == False ) : NEW_LINE INDENT if ( y [ mapping [ edge [ 0 ] . item ( ) ] ] == 0 and y [ mapping [ edge [ 1 ] . item ( ) ] ] == 0 ) : NEW_LINE INDENT c = ' red ' NEW_LINE DEDENT if ( y [ mapping [ edge [ 0 ] . item ( ) ] ] == 1 and y [ mapping [ edge [ 1 ] . item ( ) ] ] == 1 ) : NEW_LINE INDENT c = ' grey ' NEW_LINE DEDENT if ( y [ mapping [ edge [ 0 ] . item ( ) ] ] != y [ mapping [ edge [ 1 ] . item ( ) ] ] ) : NEW_LINE INDENT c = ' orange ' NEW_LINE DEDENT plt . plot ( ( X_pca [ mapping [ edge [ 0 ] . item ( ) ] , 0 ] , X_pca [ mapping [ edge [ 1 ] . item ( ) ] , 0 ] ) , ( X_pca [ mapping [ edge [ 0 ] . item ( ) ] , 1 ] , X_pca [ mapping [ edge [ 1 ] . item ( ) ] , 1 ] ) , linewidth = 0.2 , c = c ) NEW_LINE DEDENT DEDENT plt . xlabel ( '1st ▁ Principal ▁ Component ' , fontweight = ' bold ' , fontsize = 20 ) NEW_LINE plt . ylabel ( '2nd ▁ Principal ▁ Component ' , fontweight = ' bold ' , fontsize = 20 ) NEW_LINE plt . savefig ( ' db _ visual ' + args . setting + ' . pdf ' , dpi = 1000 ) NEW_LINE DEDENT\",), ('def upsample ( H , y , num_training_graph ) : NEW_LINE INDENT max_num_training_graph = max ( num_training_graph ) NEW_LINE classes = torch . unique ( y ) NEW_LINE chosen = [ ] NEW_LINE for i in range ( len ( classes ) ) : NEW_LINE INDENT train_idx = torch . where ( ( y == classes [ i ] ) == True ) [ 0 ] . tolist ( ) NEW_LINE up_sample_ratio = max_num_training_graph / num_training_graph [ i ] NEW_LINE up_sample_num = int ( num_training_graph [ i ] * up_sample_ratio - num_training_graph [ i ] ) NEW_LINE if ( up_sample_num <= len ( train_idx ) ) : NEW_LINE INDENT up_sample = random . sample ( train_idx , up_sample_num ) NEW_LINE DEDENT else : NEW_LINE INDENT tmp = int ( up_sample_num / len ( train_idx ) ) NEW_LINE up_sample = train_idx * tmp NEW_LINE tmp = up_sample_num - len ( train_idx ) * tmp NEW_LINE up_sample . extend ( random . sample ( train_idx , tmp ) ) NEW_LINE DEDENT chosen . extend ( up_sample ) NEW_LINE DEDENT chosen = torch . tensor ( chosen ) NEW_LINE H = torch . cat ( [ H , H [ chosen ] ] , dim = 0 ) NEW_LINE y = torch . cat ( [ y , y [ chosen ] ] , dim = 0 ) NEW_LINE return H , y NEW_LINE DEDENT',), ('def embed_smote ( embed , num_training_graph , y , k ) : NEW_LINE INDENT max_num_training_graph = max ( num_training_graph ) NEW_LINE classes = torch . unique ( y ) NEW_LINE embed_aug = [ ] NEW_LINE y_aug = [ ] NEW_LINE for i in range ( len ( classes ) ) : NEW_LINE INDENT train_idx = torch . where ( ( y == classes [ i ] ) == True ) [ 0 ] . tolist ( ) NEW_LINE c_embed = embed [ train_idx ] NEW_LINE c_dist = torch . cdist ( c_embed , c_embed , p = 2 ) NEW_LINE c_min_idx = torch . topk ( c_dist , min ( k , c_dist . size ( 0 ) ) , largest = False ) [ 1 ] [ : , 1 : ] . tolist ( ) NEW_LINE up_sample_ratio = max_num_training_graph / num_training_graph [ i ] NEW_LINE up_sample_num = int ( num_training_graph [ i ] * up_sample_ratio - num_training_graph [ i ] ) NEW_LINE tmp = 1 NEW_LINE head_list = list ( np . arange ( 0 , len ( train_idx ) ) ) NEW_LINE while ( tmp <= up_sample_num ) : NEW_LINE INDENT head_id = random . choice ( head_list ) NEW_LINE tail_id = random . choice ( c_min_idx [ head_id ] ) NEW_LINE delta = torch . rand ( 1 ) . to ( c_embed . device ) NEW_LINE new_embed = torch . lerp ( c_embed [ head_id ] , c_embed [ tail_id ] , delta ) NEW_LINE embed_aug . append ( new_embed ) NEW_LINE y_aug . append ( classes [ i ] ) NEW_LINE tmp += 1 NEW_LINE DEDENT DEDENT return torch . stack ( embed_aug ) , torch . stack ( y_aug ) . to ( embed . device ) NEW_LINE DEDENT',), ('def mixup ( x , y , args , alpha = 1.0 ) : NEW_LINE INDENT if alpha > 0 : NEW_LINE INDENT lam = np . random . beta ( alpha , alpha ) NEW_LINE DEDENT else : NEW_LINE INDENT lam = 1 NEW_LINE DEDENT batch_size = x . size ( ) [ 0 ] NEW_LINE index = torch . randperm ( batch_size ) . cuda ( ) NEW_LINE mixed_x = lam * x + ( 1 - lam ) * x [ index , : ] NEW_LINE y_a , y_b = y , y [ index ] NEW_LINE return mixed_x , y_a , y_b , lam NEW_LINE DEDENT',), ('def remixup ( x , y , num_training_graph , alpha = 1.0 , tau = 3 , kappa = 3 ) : NEW_LINE INDENT if alpha > 0 : NEW_LINE INDENT lam = np . random . beta ( alpha , alpha ) NEW_LINE DEDENT else : NEW_LINE INDENT lam = 1 NEW_LINE DEDENT batch_size = x . size ( ) [ 0 ] NEW_LINE index = torch . randperm ( batch_size ) . cuda ( ) NEW_LINE mixed_x = lam * x + ( 1 - lam ) * x [ index , : ] NEW_LINE y_a , y_b = y , y [ index ] NEW_LINE num_class_a , num_class_b = num_training_graph [ y_a ] , num_training_graph [ y_b ] NEW_LINE num_ratio = num_class_a / num_class_b NEW_LINE cond_ratio1 , cond_ratio2 = num_ratio >= kappa , num_ratio <= 1 / kappa NEW_LINE lamb_list = mixed_x . new ( batch_size ) . fill_ ( lam ) NEW_LINE cond_lamb1 = lamb_list < tau NEW_LINE cond_lamb2 = ( 1 - lamb_list ) < tau NEW_LINE lamb_list [ cond_lamb1 & cond_ratio1 ] = 0 NEW_LINE lamb_list [ cond_lamb2 & cond_ratio2 ] = 1 NEW_LINE return mixed_x , y_a , y_b , lamb_list NEW_LINE DEDENT',), ('def construct_knn ( kernel_idx ) : NEW_LINE INDENT edge_index = [ [ ] , [ ] ] NEW_LINE for i in range ( len ( kernel_idx ) ) : NEW_LINE INDENT for j in range ( len ( kernel_idx [ i ] ) ) : NEW_LINE INDENT edge_index [ 0 ] . append ( i ) NEW_LINE edge_index [ 1 ] . append ( kernel_idx [ i , j ] . item ( ) ) NEW_LINE edge_index [ 0 ] . append ( kernel_idx [ i , j ] . item ( ) ) NEW_LINE edge_index [ 1 ] . append ( i ) NEW_LINE DEDENT DEDENT return torch . tensor ( edge_index , dtype = torch . long ) NEW_LINE DEDENT',), (\"def propagate ( edge_index , x ) : NEW_LINE INDENT row , col = edge_index NEW_LINE deg = degree ( col , x . size ( 0 ) , dtype = x . dtype ) NEW_LINE deg_inv_sqrt = deg . pow ( - 0.5 ) NEW_LINE edge_weight = deg_inv_sqrt [ row ] * deg_inv_sqrt [ row ] NEW_LINE out = edge_weight . view ( - 1 , 1 ) * x [ row ] NEW_LINE return scatter ( out , edge_index [ - 1 ] , dim = 0 , dim_size = x . size ( 0 ) , reduce = ' add ' ) NEW_LINE DEDENT\",), ('def remove_edge ( edge_index , drop_ratio ) : NEW_LINE INDENT edge_index , _ = dropout_adj ( edge_index , p = drop_ratio ) NEW_LINE return edge_index NEW_LINE DEDENT',), ('def drop_node ( x , drop_ratio ) : NEW_LINE INDENT node_num , _ = x . size ( ) NEW_LINE drop_num = int ( node_num * drop_ratio ) NEW_LINE idx_mask = np . random . choice ( node_num , drop_num , replace = False ) . tolist ( ) NEW_LINE x [ idx_mask ] = 0 NEW_LINE return x NEW_LINE DEDENT',), (\"def get_TUDataset ( dataset ) : NEW_LINE INDENT path = osp . join ( osp . dirname ( osp . realpath ( __file__ ) ) , ' . . ' , ' data ' , ' TU ' ) NEW_LINE dataset = TUDataset ( path , name = dataset ) . shuffle ( ) NEW_LINE n_feat , n_class = max ( dataset . num_features , 1 ) , dataset . num_classes NEW_LINE mapping = { } NEW_LINE for i in range ( len ( dataset ) ) : NEW_LINE INDENT mapping [ dataset [ i ] . id . item ( ) ] = i NEW_LINE DEDENT return dataset , n_feat , n_class , mapping NEW_LINE DEDENT\",), ('def shuffle ( dataname , dataset , imb_ratio , num_train , num_val ) : NEW_LINE INDENT class_train_num_graph = [ int ( imb_ratio * num_train ) , num_train - int ( imb_ratio * num_train ) ] NEW_LINE class_val_num_graph = [ int ( imb_ratio * num_val ) , num_val - int ( imb_ratio * num_val ) ] NEW_LINE y = torch . tensor ( [ data . y . item ( ) for data in dataset ] ) NEW_LINE classes = torch . unique ( y ) NEW_LINE indices = [ ] NEW_LINE for i in range ( len ( classes ) ) : NEW_LINE INDENT index = torch . nonzero ( y == classes [ i ] ) . view ( - 1 ) NEW_LINE index = index [ torch . randperm ( index . size ( 0 ) ) ] NEW_LINE indices . append ( index ) NEW_LINE DEDENT train_index , val_index , test_index = [ ] , [ ] , [ ] NEW_LINE for i in range ( len ( classes ) ) : NEW_LINE INDENT train_index . append ( indices [ classes [ i ] ] [ : class_train_num_graph [ classes [ i ] ] ] ) NEW_LINE val_index . append ( indices [ classes [ i ] ] [ class_train_num_graph [ classes [ i ] ] : ( class_train_num_graph [ classes [ i ] ] + class_val_num_graph [ classes [ i ] ] ) ] ) NEW_LINE test_index . append ( indices [ classes [ i ] ] [ ( class_train_num_graph [ classes [ i ] ] + class_val_num_graph [ classes [ i ] ] ) : ] ) NEW_LINE DEDENT train_index = torch . cat ( train_index , dim = 0 ) NEW_LINE val_index = torch . cat ( val_index , dim = 0 ) NEW_LINE test_index = torch . cat ( test_index , dim = 0 ) NEW_LINE train_dataset = dataset [ train_index ] NEW_LINE val_dataset = dataset [ val_index ] NEW_LINE test_dataset = dataset [ test_index ] NEW_LINE return train_dataset , val_dataset , test_dataset , torch . tensor ( class_train_num_graph ) , torch . tensor ( class_val_num_graph ) NEW_LINE DEDENT',), (\"def __init__ ( self , root : str , name : str , transform : Optional [ Callable ] = None , pre_transform : Optional [ Callable ] = None , pre_filter : Optional [ Callable ] = None , use_node_attr : bool = False , use_edge_attr : bool = False , cleaned : bool = False ) : NEW_LINE INDENT self . name = name NEW_LINE self . cleaned = cleaned NEW_LINE super ( ) . __init__ ( root , transform , pre_transform , pre_filter ) NEW_LINE self . data , self . slices = torch . load ( self . processed_paths [ 0 ] ) NEW_LINE if self . data . x is not None and not use_node_attr : NEW_LINE INDENT num_node_attributes = self . num_node_attributes NEW_LINE self . data . x = self . data . x [ : , num_node_attributes : ] NEW_LINE DEDENT if self . data . edge_attr is not None and not use_edge_attr : NEW_LINE INDENT num_edge_attributes = self . num_edge_attributes NEW_LINE self . data . edge_attr = self . data . edge_attr [ : , num_edge_attributes : ] NEW_LINE DEDENT if not ( self . name == ' MUTAG ' or self . name == ' PTC _ MR ' or self . name == ' DD ' or self . name == ' PROTEINS ' or self . name == ' NCI1' or self . name == ' NCI109' or self . name == ' Mutagenicity ' ) : NEW_LINE INDENT edge_index = self . data . edge_index [ 0 , : ] . numpy ( ) NEW_LINE _ , num_edge = self . data . edge_index . size ( ) NEW_LINE nlist = [ edge_index [ n ] + 1 for n in range ( num_edge - 1 ) if edge_index [ n ] > edge_index [ n + 1 ] ] NEW_LINE nlist . append ( edge_index [ - 1 ] + 1 ) NEW_LINE num_node = np . array ( nlist ) . sum ( ) NEW_LINE self . data . x = torch . ones ( ( num_node , 1 ) ) NEW_LINE edge_slice = [ 0 ] NEW_LINE k = 0 NEW_LINE for n in nlist : NEW_LINE INDENT k = k + n NEW_LINE edge_slice . append ( k ) NEW_LINE DEDENT self . slices [ ' x ' ] = torch . tensor ( edge_slice ) NEW_LINE DEDENT self . data . id = torch . arange ( 0 , self . data . y . size ( 0 ) ) NEW_LINE self . slices [ ' id ' ] = self . slices [ ' y ' ] . clone ( ) NEW_LINE DEDENT\",), ('def raw_dir ( self ) -> str : NEW_LINE INDENT name = f\\' raw { \" _ cleaned \" ▁ if▁ self. cleaned ▁ else ▁ \" \" } \\' NEW_LINE return osp . join ( self . root , self . name , name ) NEW_LINE DEDENT',), ('def processed_dir ( self ) -> str : NEW_LINE INDENT name = f\\' processed { \" _ cleaned \" ▁ if▁ self. cleaned ▁ else ▁ \" \" } \\' NEW_LINE return osp . join ( self . root , self . name , name ) NEW_LINE DEDENT',), ('def num_node_labels ( self ) -> int : NEW_LINE INDENT if self . data . x is None : NEW_LINE INDENT return 0 NEW_LINE DEDENT for i in range ( self . data . x . size ( 1 ) ) : NEW_LINE INDENT x = self . data . x [ : , i : ] NEW_LINE if ( ( x == 0 ) | ( x == 1 ) ) . all ( ) and ( x . sum ( dim = 1 ) == 1 ) . all ( ) : NEW_LINE INDENT return self . data . x . size ( 1 ) - i NEW_LINE DEDENT DEDENT return 0 NEW_LINE DEDENT',), ('def num_node_attributes ( self ) -> int : NEW_LINE INDENT if self . data . x is None : NEW_LINE INDENT return 0 NEW_LINE DEDENT return self . data . x . size ( 1 ) - self . num_node_labels NEW_LINE DEDENT',), ('def num_edge_labels ( self ) -> int : NEW_LINE INDENT if self . data . edge_attr is None : NEW_LINE INDENT return 0 NEW_LINE DEDENT for i in range ( self . data . edge_attr . size ( 1 ) ) : NEW_LINE INDENT if self . data . edge_attr [ : , i : ] . sum ( ) == self . data . edge_attr . size ( 0 ) : NEW_LINE INDENT return self . data . edge_attr . size ( 1 ) - i NEW_LINE DEDENT DEDENT return 0 NEW_LINE DEDENT',), ('def num_edge_attributes ( self ) -> int : NEW_LINE INDENT if self . data . edge_attr is None : NEW_LINE INDENT return 0 NEW_LINE DEDENT return self . data . edge_attr . size ( 1 ) - self . num_edge_labels NEW_LINE DEDENT',), (\"def raw_file_names ( self ) -> List [ str ] : NEW_LINE INDENT names = [ ' A ' , ' graph _ indicator ' ] NEW_LINE return [ f' { self. name } _ { name } . txt ' for name in names ] NEW_LINE DEDENT\",), (\"def processed_file_names ( self ) -> str : NEW_LINE INDENT return ' data . pt ' NEW_LINE DEDENT\",), (\"def download ( self ) : NEW_LINE INDENT url = self . cleaned_url if self . cleaned else self . url NEW_LINE folder = osp . join ( self . root , self . name ) NEW_LINE path = download_url ( f' { url } / { self. name } . zip ' , folder ) NEW_LINE extract_zip ( path , folder ) NEW_LINE os . unlink ( path ) NEW_LINE shutil . rmtree ( self . raw_dir ) NEW_LINE os . rename ( osp . join ( folder , self . name ) , self . raw_dir ) NEW_LINE DEDENT\",), ('def process ( self ) : NEW_LINE INDENT self . data , self . slices = read_tu_data ( self . raw_dir , self . name ) NEW_LINE if self . pre_filter is not None : NEW_LINE INDENT data_list = [ self . get ( idx ) for idx in range ( len ( self ) ) ] NEW_LINE data_list = [ data for data in data_list if self . pre_filter ( data ) ] NEW_LINE self . data , self . slices = self . collate ( data_list ) NEW_LINE DEDENT if self . pre_transform is not None : NEW_LINE INDENT data_list = [ self . get ( idx ) for idx in range ( len ( self ) ) ] NEW_LINE data_list = [ self . pre_transform ( data ) for data in data_list ] NEW_LINE self . data , self . slices = self . collate ( data_list ) NEW_LINE DEDENT torch . save ( ( self . data , self . slices ) , self . processed_paths [ 0 ] ) NEW_LINE DEDENT',), (\"def __repr__ ( self ) -> str : NEW_LINE INDENT return f' { self. name } ( { len ( self) } ) ' NEW_LINE DEDENT\",), ('def __init__ ( self , args ) : NEW_LINE INDENT super ( GIN , self ) . __init__ ( ) NEW_LINE self . conv1 = GINConv ( Sequential ( Linear ( args . n_feat , args . n_hidden ) , BatchNorm1d ( args . n_hidden ) , ReLU ( ) , Linear ( args . n_hidden , args . n_hidden ) , ReLU ( ) ) ) NEW_LINE self . conv2 = GINConv ( Sequential ( Linear ( args . n_hidden , args . n_hidden ) , BatchNorm1d ( args . n_hidden ) , ReLU ( ) , Linear ( args . n_hidden , args . n_hidden ) , ReLU ( ) ) ) NEW_LINE self . conv3 = GINConv ( Sequential ( Linear ( args . n_hidden , args . n_hidden ) , BatchNorm1d ( args . n_hidden ) , ReLU ( ) , Linear ( args . n_hidden , args . n_hidden ) , ReLU ( ) ) ) NEW_LINE self . conv4 = GINConv ( Sequential ( Linear ( args . n_hidden , args . n_hidden ) , BatchNorm1d ( args . n_hidden ) , ReLU ( ) , Linear ( args . n_hidden , args . n_hidden ) , ReLU ( ) ) ) NEW_LINE self . conv5 = GINConv ( Sequential ( Linear ( args . n_hidden , args . n_hidden ) , BatchNorm1d ( args . n_hidden ) , ReLU ( ) , Linear ( args . n_hidden , args . n_hidden ) , ReLU ( ) ) ) NEW_LINE DEDENT',), ('def forward ( self , x , edge_index , batch ) : NEW_LINE INDENT x = self . conv1 ( x , edge_index ) NEW_LINE x = self . conv2 ( x , edge_index ) NEW_LINE x = self . conv3 ( x , edge_index ) NEW_LINE x = self . conv4 ( x , edge_index ) NEW_LINE x = self . conv5 ( x , edge_index ) NEW_LINE x = global_add_pool ( x , batch ) NEW_LINE return x NEW_LINE DEDENT',), ('def __init__ ( self , args ) : NEW_LINE INDENT super ( MLP_Classifier , self ) . __init__ ( ) NEW_LINE self . lin1 = Linear ( args . n_hidden , args . n_hidden ) NEW_LINE self . lin2 = Linear ( args . n_hidden , args . n_class ) NEW_LINE DEDENT',), ('def forward ( self , x ) : NEW_LINE INDENT x = self . lin1 ( x ) . relu ( ) NEW_LINE x = F . dropout ( x , p = 0.5 , training = self . training ) NEW_LINE x = self . lin2 ( x ) NEW_LINE return F . log_softmax ( x , dim = 1 ) NEW_LINE DEDENT',)]\n",
            "1.3472238630056381\n",
            "On batch 767\n",
            "tensor([0.0083, 0.0084, 0.0084, 0.0084, 0.0085, 0.0084, 0.0084, 0.0084, 0.0084,\n",
            "        0.0084, 0.0085, 0.0083, 0.0082, 0.0082, 0.0082, 0.0082, 0.0082, 0.0084,\n",
            "        0.0086, 0.0081, 0.0083, 0.0082, 0.0084, 0.0084, 0.0084, 0.0085, 0.0086,\n",
            "        0.0083, 0.0084, 0.0084, 0.0084, 0.0084, 0.0083, 0.0085, 0.0084, 0.0085,\n",
            "        0.0084, 0.0085, 0.0085, 0.0084, 0.0085, 0.0085, 0.0084, 0.0083, 0.0083,\n",
            "        0.0084, 0.0085, 0.0084, 0.0084, 0.0085, 0.0082, 0.0085, 0.0082, 0.0086,\n",
            "        0.0083, 0.0085, 0.0085, 0.0086, 0.0084, 0.0085, 0.0084, 0.0082, 0.0085,\n",
            "        0.0082, 0.0086, 0.0083, 0.0085, 0.0085, 0.0085, 0.0084, 0.0085, 0.0084,\n",
            "        0.0084, 0.0082, 0.0085, 0.0082, 0.0086, 0.0083, 0.0085, 0.0085, 0.0086,\n",
            "        0.0084, 0.0085, 0.0084, 0.0084, 0.0085, 0.0086, 0.0083, 0.0083, 0.0086,\n",
            "        0.0084, 0.0084, 0.0084, 0.0084, 0.0085, 0.0084, 0.0085, 0.0084, 0.0085,\n",
            "        0.0085, 0.0085, 0.0084, 0.0083, 0.0085, 0.0084, 0.0084, 0.0083, 0.0085,\n",
            "        0.0084, 0.0083, 0.0085, 0.0084, 0.0083, 0.0083, 0.0085, 0.0083, 0.0085,\n",
            "        0.0085, 0.0084], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "('\\n    \\\\mathbf{y}_k=\\\\lambda_{k1} F_k (\\\\mathbf{x}_k )+\\\\lambda_{k2} \\\\mathbf{x}_k\\n    \\\\label{eq:2}\\n',)\n",
            "[(\"def print_network ( net ) : NEW_LINE INDENT num_params = 0 NEW_LINE for param in net . parameters ( ) : NEW_LINE INDENT num_params += param . numel ( ) NEW_LINE DEDENT print ( net ) NEW_LINE print ( ' Total ▁ number ▁ of ▁ parameters : ▁ % d ' % num_params ) NEW_LINE DEDENT\",), (\"def print_setting ( net , args ) : NEW_LINE INDENT print ( ' init ▁ this ▁ train : ' ) NEW_LINE print_network ( net ) NEW_LINE print ( ' training ▁ model : ' , args . model ) NEW_LINE print ( ' scale : ' , args . scale ) NEW_LINE print ( ' resume ▁ from ▁ ' , args . resume ) NEW_LINE print ( ' output ▁ patch ▁ size ' , args . patch_size ) NEW_LINE print ( ' model ▁ setting : ▁ n _ resblocks : ' , args . n_resblocks , ' n _ feats : ' , args . n_feats , ' block _ feats : ' , args . block_feats ) NEW_LINE print ( ' optimization ▁ setting : ▁ ' , args . optimizer ) NEW_LINE print ( ' total ▁ epochs : ' , args . epochs ) NEW_LINE print ( ' lr : ' , args . lr , ' lr _ decay ▁ at : ' , args . decay_type , ' decay ▁ gamma : ' , args . gamma ) NEW_LINE print ( ' train ▁ loss : ' , args . loss ) NEW_LINE print ( ' save _ name : ' , args . save ) NEW_LINE DEDENT\",), (\"def set_template ( args ) : NEW_LINE INDENT if args . template . find ( ' jpeg ' ) >= 0 : NEW_LINE INDENT args . data_train = ' DIV2K _ jpeg ' NEW_LINE args . data_test = ' DIV2K _ jpeg ' NEW_LINE args . epochs = 200 NEW_LINE args . lr_decay = 100 NEW_LINE DEDENT if args . template . find ( ' EDSR _ paper ' ) >= 0 : NEW_LINE INDENT args . model = ' EDSR ' NEW_LINE args . n_resblocks = 32 NEW_LINE args . n_feats = 256 NEW_LINE args . res_scale = 0.1 NEW_LINE DEDENT if args . template . find ( ' MDSR ' ) >= 0 : NEW_LINE INDENT args . model = ' MDSR ' NEW_LINE args . patch_size = 48 NEW_LINE args . epochs = 650 NEW_LINE DEDENT if args . template . find ( ' DDBPN ' ) >= 0 : NEW_LINE INDENT args . model = ' DDBPN ' NEW_LINE args . patch_size = 128 NEW_LINE args . scale = '4' NEW_LINE args . data_test = ' Set5' NEW_LINE args . batch_size = 20 NEW_LINE args . epochs = 1000 NEW_LINE args . lr_decay = 500 NEW_LINE args . gamma = 0.1 NEW_LINE args . weight_decay = 1e-4 NEW_LINE args . loss = '1 * MSE ' NEW_LINE DEDENT if args . template . find ( ' GAN ' ) >= 0 : NEW_LINE INDENT args . epochs = 200 NEW_LINE args . lr = 5e-5 NEW_LINE args . lr_decay = 150 NEW_LINE DEDENT if args . template . find ( ' RCAN ' ) >= 0 : NEW_LINE INDENT args . model = ' RCAN ' NEW_LINE args . n_resgroups = 10 NEW_LINE args . n_resblocks = 20 NEW_LINE args . n_feats = 64 NEW_LINE args . chop = True NEW_LINE DEDENT DEDENT\",), ('def cosine_restart ( T_max , epoch ) : NEW_LINE INDENT epoch = float ( epoch ) NEW_LINE restart_period = T_max NEW_LINE while epoch / restart_period > 1.0 : NEW_LINE INDENT epoch = epoch - restart_period NEW_LINE DEDENT radians = math . pi * ( epoch / restart_period ) NEW_LINE return 0.5 * ( 1.0 + math . cos ( radians ) ) NEW_LINE DEDENT',), ('def multistep_restart ( T_max , epoch ) : NEW_LINE INDENT epoch = float ( epoch ) NEW_LINE restart_period = T_max NEW_LINE while epoch / restart_period > 1.0 : NEW_LINE INDENT epoch = epoch - restart_period NEW_LINE DEDENT if epoch < 200 : NEW_LINE INDENT return 1 NEW_LINE DEDENT if epoch < 400 : NEW_LINE INDENT return 0.5 NEW_LINE DEDENT if epoch < 600 : NEW_LINE INDENT return 0.25 NEW_LINE DEDENT if epoch < 800 : NEW_LINE INDENT return 0.125 NEW_LINE DEDENT return 0.125 * 0.5 NEW_LINE DEDENT',), ('def quantize ( img , rgb_range ) : NEW_LINE INDENT pixel_range = 255 / rgb_range NEW_LINE return img . mul ( pixel_range ) . clamp ( 0 , 255 ) . round ( ) . div ( pixel_range ) NEW_LINE DEDENT',), ('def calc_psnr ( sr , hr , scale , rgb_range , benchmark = False ) : NEW_LINE INDENT diff = ( sr - hr ) . data . div ( rgb_range ) NEW_LINE if benchmark : NEW_LINE INDENT shave = scale NEW_LINE if diff . size ( 1 ) > 1 : NEW_LINE INDENT convert = diff . new ( 1 , 3 , 1 , 1 ) NEW_LINE convert [ 0 , 0 , 0 , 0 ] = 65.738 NEW_LINE convert [ 0 , 1 , 0 , 0 ] = 129.057 NEW_LINE convert [ 0 , 2 , 0 , 0 ] = 25.064 NEW_LINE diff . mul_ ( convert ) . div_ ( 256 ) NEW_LINE diff = diff . sum ( dim = 1 , keepdim = True ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT shave = scale + 6 NEW_LINE DEDENT valid = diff [ : , : , shave : - shave , shave : - shave ] NEW_LINE mse = valid . pow ( 2 ) . mean ( ) NEW_LINE return - 10 * math . log10 ( mse ) NEW_LINE DEDENT',), ('def matlab_style_gauss2D ( shape = ( 3 , 3 ) , sigma = 0.5 ) : NEW_LINE INDENT m , n = [ ( ss - 1. ) / 2. for ss in shape ] NEW_LINE y , x = np . ogrid [ - m : m + 1 , - n : n + 1 ] NEW_LINE h = np . exp ( - ( x * x + y * y ) / ( 2. * sigma * sigma ) ) NEW_LINE h [ h < np . finfo ( h . dtype ) . eps * h . max ( ) ] = 0 NEW_LINE sumh = h . sum ( ) NEW_LINE if sumh != 0 : NEW_LINE INDENT h /= sumh NEW_LINE DEDENT return h NEW_LINE DEDENT',), ('def get_y_channel ( x , rgb_range = 255 ) : NEW_LINE INDENT x = x . squeeze ( ) NEW_LINE normalized = x . data . mul ( 255 / rgb_range ) NEW_LINE ndarr = normalized . byte ( ) . permute ( 1 , 2 , 0 ) . cpu ( ) . numpy ( ) NEW_LINE im_h_ycbcr = np . array ( Image . fromarray ( ndarr , \" RGB \" ) . convert ( \" YCbCr \" ) ) NEW_LINE return im_h_ycbcr [ 0 , : , : ] NEW_LINE DEDENT',), (\"def make_optimizer ( args , my_model ) : NEW_LINE INDENT trainable = filter ( lambda x : x . requires_grad , my_model . parameters ( ) ) NEW_LINE if args . optimizer == ' SGD ' : NEW_LINE INDENT optimizer_function = optim . SGD NEW_LINE kwargs = { ' momentum ' : args . momentum } NEW_LINE DEDENT elif args . optimizer == ' ADAM ' : NEW_LINE INDENT optimizer_function = optim . Adam NEW_LINE kwargs = { ' betas ' : ( args . beta1 , args . beta2 ) , ' eps ' : args . epsilon } NEW_LINE DEDENT elif args . optimizer == ' RMSprop ' : NEW_LINE INDENT optimizer_function = optim . RMSprop NEW_LINE kwargs = { ' eps ' : args . epsilon } NEW_LINE DEDENT kwargs [ ' lr ' ] = args . lr NEW_LINE kwargs [ ' weight _ decay ' ] = args . weight_decay NEW_LINE return optimizer_function ( trainable , ** kwargs ) NEW_LINE DEDENT\",), (\"def make_scheduler ( args , my_optimizer ) : NEW_LINE INDENT if args . decay_type == ' step ' : NEW_LINE INDENT scheduler = lrs . StepLR ( my_optimizer , step_size = args . lr_decay , gamma = args . gamma ) NEW_LINE DEDENT if args . decay_type . find ( ' step ' ) >= 0 : NEW_LINE INDENT milestones = args . decay_type . split ( ' _ ' ) NEW_LINE milestones . pop ( 0 ) NEW_LINE milestones = list ( map ( lambda x : int ( x ) , milestones ) ) NEW_LINE print ( milestones ) NEW_LINE scheduler = lrs . MultiStepLR ( my_optimizer , milestones = milestones , gamma = args . gamma ) NEW_LINE DEDENT if args . decay_type == ' restart ' : NEW_LINE INDENT scheduler = lrs . LambdaLR ( my_optimizer , lambda epoch : multistep_restart ( args . period , epoch ) ) NEW_LINE DEDENT return scheduler NEW_LINE DEDENT\",), ('def __init__ ( self ) : NEW_LINE INDENT self . acc = 0 NEW_LINE self . tic ( ) NEW_LINE DEDENT',), ('def tic ( self ) : NEW_LINE INDENT self . t0 = time . time ( ) NEW_LINE DEDENT',), ('def toc ( self ) : NEW_LINE INDENT return time . time ( ) - self . t0 NEW_LINE DEDENT',), ('def hold ( self ) : NEW_LINE INDENT self . acc += self . toc ( ) NEW_LINE DEDENT',), ('def release ( self ) : NEW_LINE INDENT ret = self . acc NEW_LINE self . acc = 0 NEW_LINE return ret NEW_LINE DEDENT',), ('def reset ( self ) : NEW_LINE INDENT self . acc = 0 NEW_LINE DEDENT',), (\"def __init__ ( self , args ) : NEW_LINE INDENT self . args = args NEW_LINE self . ok = True NEW_LINE self . log = torch . Tensor ( ) NEW_LINE now = datetime . datetime . now ( ) . strftime ( ' % Y - % m - % d - % H : % M : % S ' ) NEW_LINE if args . load == ' . ' : NEW_LINE INDENT if args . save == ' . ' : args . save = now NEW_LINE self . dir = ' . . / experiment / ' + args . save NEW_LINE DEDENT else : NEW_LINE INDENT self . dir = ' . . / experiment / ' + args . load NEW_LINE if not os . path . exists ( self . dir ) : NEW_LINE INDENT args . load = ' . ' NEW_LINE DEDENT else : NEW_LINE INDENT self . log = torch . load ( self . dir + ' / psnr _ log . pt ' ) NEW_LINE print ( ' Continue ▁ from ▁ epoch ▁ { } . . . ' . format ( len ( self . log ) ) ) NEW_LINE DEDENT DEDENT if args . reset : NEW_LINE INDENT os . system ( ' rm ▁ - rf ▁ ' + self . dir ) NEW_LINE args . load = ' . ' NEW_LINE DEDENT def _make_dir ( path ) : NEW_LINE INDENT if not os . path . exists ( path ) : os . makedirs ( path ) NEW_LINE DEDENT _make_dir ( self . dir ) NEW_LINE _make_dir ( self . dir + ' / model ' ) NEW_LINE _make_dir ( self . dir + ' / results ' ) NEW_LINE open_type = ' a ' if os . path . exists ( self . dir + ' / log . txt ' ) else ' w ' NEW_LINE self . log_file = open ( self . dir + ' / log . txt ' , open_type ) NEW_LINE with open ( self . dir + ' / config . txt ' , open_type ) as f : NEW_LINE INDENT f . write ( now + ' \\\\n \\\\n ' ) NEW_LINE for arg in vars ( args ) : NEW_LINE INDENT f . write ( ' { } : ▁ { } \\\\n ' . format ( arg , getattr ( args , arg ) ) ) NEW_LINE DEDENT f . write ( ' \\\\n ' ) NEW_LINE DEDENT DEDENT\",), (\"def save ( self , trainer , epoch , is_best = False ) : NEW_LINE INDENT trainer . model . save ( self . dir , epoch , is_best = is_best ) NEW_LINE trainer . loss . save ( self . dir ) NEW_LINE trainer . loss . plot_loss ( self . dir , epoch ) NEW_LINE self . plot_psnr ( epoch ) NEW_LINE torch . save ( self . log , os . path . join ( self . dir , ' psnr _ log . pt ' ) ) NEW_LINE torch . save ( trainer . optimizer . state_dict ( ) , os . path . join ( self . dir , ' optimizer . pt ' ) ) NEW_LINE DEDENT\",), ('def add_log ( self , log ) : NEW_LINE INDENT self . log = torch . cat ( [ self . log , log ] ) NEW_LINE DEDENT',), (\"def write_log ( self , log , refresh = False ) : NEW_LINE INDENT print ( log ) NEW_LINE self . log_file . write ( log + ' \\\\n ' ) NEW_LINE if refresh : NEW_LINE INDENT self . log_file . close ( ) NEW_LINE self . log_file = open ( self . dir + ' / log . txt ' , ' a ' ) NEW_LINE DEDENT DEDENT\",), ('def done ( self ) : NEW_LINE INDENT self . log_file . close ( ) NEW_LINE DEDENT',), (\"def plot_psnr ( self , epoch ) : NEW_LINE INDENT axis = np . linspace ( 1 , epoch , epoch ) NEW_LINE label = ' SR ▁ on ▁ { } ' . format ( self . args . data_test ) NEW_LINE fig = plt . figure ( ) NEW_LINE plt . title ( label ) NEW_LINE for idx_scale , scale in enumerate ( self . args . scale ) : NEW_LINE INDENT plt . plot ( axis , self . log [ : , idx_scale ] . numpy ( ) , label = ' Scale ▁ { } ' . format ( scale ) ) NEW_LINE DEDENT plt . legend ( ) NEW_LINE plt . xlabel ( ' Epochs ' ) NEW_LINE plt . ylabel ( ' PSNR ' ) NEW_LINE plt . grid ( True ) NEW_LINE plt . savefig ( ' { } / test _ { } . pdf ' . format ( self . dir , self . args . data_test ) ) NEW_LINE plt . close ( fig ) NEW_LINE DEDENT\",), (\"def save_results ( self , filename , save_list , scale ) : NEW_LINE INDENT filename = ' { } / results / { } _ x { } _ ' . format ( self . dir , filename , scale ) NEW_LINE postfix = ( ' SR ' , ' HR ' ) NEW_LINE for v , p in zip ( save_list , postfix ) : NEW_LINE INDENT normalized = v [ 0 ] . data . mul ( 255 / self . args . rgb_range ) NEW_LINE ndarr = normalized . byte ( ) . permute ( 1 , 2 , 0 ) . cpu ( ) . numpy ( ) NEW_LINE misc . imsave ( ' { } { } . png ' . format ( filename , p ) , ndarr ) NEW_LINE DEDENT DEDENT\",), ('def _ms_loop ( dataset , index_queue , data_queue , collate_fn , scale , seed , init_fn , worker_id ) : NEW_LINE INDENT global _use_shared_memory NEW_LINE _use_shared_memory = True NEW_LINE _set_worker_signal_handlers ( ) NEW_LINE torch . set_num_threads ( 1 ) NEW_LINE torch . manual_seed ( seed ) NEW_LINE while True : NEW_LINE INDENT r = index_queue . get ( ) NEW_LINE if r is None : NEW_LINE INDENT break NEW_LINE DEDENT idx , batch_indices = r NEW_LINE try : NEW_LINE INDENT idx_scale = 0 NEW_LINE if len ( scale ) > 1 and dataset . train : NEW_LINE INDENT idx_scale = random . randrange ( 0 , len ( scale ) ) NEW_LINE dataset . set_scale ( idx_scale ) NEW_LINE DEDENT samples = collate_fn ( [ dataset [ i ] for i in batch_indices ] ) NEW_LINE samples . append ( idx_scale ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT data_queue . put ( ( idx , ExceptionWrapper ( sys . exc_info ( ) ) ) ) NEW_LINE DEDENT else : NEW_LINE INDENT data_queue . put ( ( idx , samples ) ) NEW_LINE DEDENT DEDENT DEDENT',), ('def __init__ ( self , loader ) : NEW_LINE INDENT self . dataset = loader . dataset NEW_LINE self . scale = loader . scale NEW_LINE self . collate_fn = loader . collate_fn NEW_LINE self . batch_sampler = loader . batch_sampler NEW_LINE self . num_workers = loader . num_workers NEW_LINE self . pin_memory = loader . pin_memory and torch . cuda . is_available ( ) NEW_LINE self . timeout = loader . timeout NEW_LINE self . done_event = threading . Event ( ) NEW_LINE self . sample_iter = iter ( self . batch_sampler ) NEW_LINE if self . num_workers > 0 : NEW_LINE INDENT self . worker_init_fn = loader . worker_init_fn NEW_LINE self . index_queues = [ multiprocessing . Queue ( ) for _ in range ( self . num_workers ) ] NEW_LINE self . worker_queue_idx = 0 NEW_LINE self . worker_result_queue = multiprocessing . SimpleQueue ( ) NEW_LINE self . batches_outstanding = 0 NEW_LINE self . worker_pids_set = False NEW_LINE self . shutdown = False NEW_LINE self . send_idx = 0 NEW_LINE self . rcvd_idx = 0 NEW_LINE self . reorder_dict = { } NEW_LINE base_seed = torch . LongTensor ( 1 ) . random_ ( ) [ 0 ] NEW_LINE self . workers = [ multiprocessing . Process ( target = _ms_loop , args = ( self . dataset , self . index_queues [ i ] , self . worker_result_queue , self . collate_fn , self . scale , base_seed + i , self . worker_init_fn , i ) ) for i in range ( self . num_workers ) ] NEW_LINE if self . pin_memory or self . timeout > 0 : NEW_LINE INDENT self . data_queue = queue . Queue ( ) NEW_LINE if self . pin_memory : NEW_LINE INDENT maybe_device_id = torch . cuda . current_device ( ) NEW_LINE DEDENT else : NEW_LINE INDENT maybe_device_id = None NEW_LINE DEDENT self . worker_manager_thread = threading . Thread ( target = _worker_manager_loop , args = ( self . worker_result_queue , self . data_queue , self . done_event , self . pin_memory , maybe_device_id ) ) NEW_LINE self . worker_manager_thread . daemon = True NEW_LINE self . worker_manager_thread . start ( ) NEW_LINE DEDENT else : NEW_LINE INDENT self . data_queue = self . worker_result_queue NEW_LINE DEDENT for w in self . workers : NEW_LINE INDENT w . daemon = True NEW_LINE w . start ( ) NEW_LINE DEDENT _update_worker_pids ( id ( self ) , tuple ( w . pid for w in self . workers ) ) NEW_LINE _set_SIGCHLD_handler ( ) NEW_LINE self . worker_pids_set = True NEW_LINE for _ in range ( 2 * self . num_workers ) : NEW_LINE INDENT self . _put_indices ( ) NEW_LINE DEDENT DEDENT DEDENT',), ('def __init__ ( self , args , dataset , batch_size = 1 , shuffle = False , sampler = None , batch_sampler = None , collate_fn = default_collate , pin_memory = False , drop_last = False , timeout = 0 , worker_init_fn = None ) : NEW_LINE INDENT super ( MSDataLoader , self ) . __init__ ( dataset , batch_size = batch_size , shuffle = shuffle , sampler = sampler , batch_sampler = batch_sampler , num_workers = args . n_threads , collate_fn = collate_fn , pin_memory = pin_memory , drop_last = drop_last , timeout = timeout , worker_init_fn = worker_init_fn ) NEW_LINE self . scale = args . scale NEW_LINE DEDENT',), ('def __iter__ ( self ) : NEW_LINE INDENT return _MSDataLoaderIter ( self ) NEW_LINE DEDENT',), (\"def __init__ ( self , args , loader , my_model , my_loss , ckp ) : NEW_LINE INDENT self . args = args NEW_LINE self . scale = args . scale NEW_LINE self . ckp = ckp NEW_LINE self . loader_train = loader . loader_train NEW_LINE self . loader_test = loader . loader_test NEW_LINE self . model = my_model NEW_LINE self . loss = my_loss NEW_LINE self . optimizer = utility . make_optimizer ( args , self . model ) NEW_LINE self . scheduler = utility . make_scheduler ( args , self . optimizer ) NEW_LINE if self . args . load != ' . ' : NEW_LINE INDENT self . optimizer . load_state_dict ( torch . load ( os . path . join ( ckp . dir , ' optimizer . pt ' ) ) ) NEW_LINE for _ in range ( len ( ckp . log ) ) : self . scheduler . step ( ) NEW_LINE DEDENT self . error_last = 1e8 NEW_LINE DEDENT\",), (\"def train ( self ) : NEW_LINE INDENT self . scheduler . step ( ) NEW_LINE self . loss . step ( ) NEW_LINE epoch = self . scheduler . last_epoch + 1 NEW_LINE lr = self . scheduler . get_lr ( ) [ 0 ] NEW_LINE self . ckp . write_log ( ' [ Epoch ▁ { } ] \\\\tLearning ▁ rate : ▁ { : . 6e } ' . format ( epoch , Decimal ( lr ) ) ) NEW_LINE self . loss . start_log ( ) NEW_LINE self . model . train ( ) NEW_LINE timer_data , timer_model = utility . timer ( ) , utility . timer ( ) NEW_LINE for batch , ( lr , hr , _ , idx_scale ) in enumerate ( self . loader_train ) : NEW_LINE INDENT lr , hr = self . prepare ( lr , hr ) NEW_LINE timer_data . hold ( ) NEW_LINE timer_model . tic ( ) NEW_LINE self . optimizer . zero_grad ( ) NEW_LINE sr = self . model ( lr , idx_scale ) NEW_LINE loss = self . loss ( sr , hr ) NEW_LINE loss . backward ( ) NEW_LINE if self . args . gclip > 0 : NEW_LINE INDENT utils . clip_grad_value_ ( self . model . parameters ( ) , self . args . gclip ) NEW_LINE DEDENT self . optimizer . step ( ) NEW_LINE timer_model . hold ( ) NEW_LINE if ( batch + 1 ) % self . args . print_every == 0 : NEW_LINE INDENT self . ckp . write_log ( ' [ { } / { } ] \\\\t { } \\\\t { : . 1f } + { : . 1f } s ' . format ( ( batch + 1 ) * self . args . batch_size , len ( self . loader_train . dataset ) , self . loss . display_loss ( batch ) , timer_model . release ( ) , timer_data . release ( ) ) ) NEW_LINE DEDENT timer_data . tic ( ) NEW_LINE DEDENT self . loss . end_log ( len ( self . loader_train ) ) NEW_LINE self . error_last = self . loss . log [ - 1 , - 1 ] NEW_LINE DEDENT\",), (\"def test ( self ) : NEW_LINE INDENT epoch = self . scheduler . last_epoch + 1 NEW_LINE self . ckp . write_log ( ' \\\\n Evaluation : ' ) NEW_LINE self . ckp . add_log ( torch . zeros ( 1 , len ( self . scale ) ) ) NEW_LINE self . model . eval ( ) NEW_LINE timer_test = utility . timer ( ) NEW_LINE with torch . no_grad ( ) : NEW_LINE INDENT for idx_scale , scale in enumerate ( self . scale ) : NEW_LINE INDENT eval_psnr = 0 NEW_LINE self . loader_test . dataset . set_scale ( idx_scale ) NEW_LINE tqdm_test = tqdm ( self . loader_test , ncols = 80 ) NEW_LINE for idx_img , ( lr , hr , filename , _ ) in enumerate ( tqdm_test ) : NEW_LINE INDENT filename = filename [ 0 ] NEW_LINE no_eval = ( hr . nelement ( ) == 1 ) NEW_LINE if not no_eval : NEW_LINE INDENT lr , hr = self . prepare ( lr , hr ) NEW_LINE DEDENT else : NEW_LINE INDENT lr , = self . prepare ( lr ) NEW_LINE DEDENT sr = self . model ( lr , idx_scale ) NEW_LINE sr = utility . quantize ( sr , self . args . rgb_range ) NEW_LINE save_list = [ sr ] NEW_LINE if not no_eval : NEW_LINE INDENT eval_psnr += utility . calc_psnr ( sr , hr , scale , self . args . rgb_range , benchmark = self . loader_test . dataset . benchmark ) NEW_LINE save_list . extend ( [ hr ] ) NEW_LINE DEDENT if self . args . save_results : NEW_LINE INDENT self . ckp . save_results ( filename , save_list , scale ) NEW_LINE DEDENT DEDENT self . ckp . log [ - 1 , idx_scale ] = eval_psnr / len ( self . loader_test ) NEW_LINE best = self . ckp . log . max ( 0 ) NEW_LINE self . ckp . write_log ( ' [ { } ▁ x { } ] \\\\tPSNR : ▁ { : . 3f } ▁ ( Best ▁ PSNR : ▁ { : . 3f } ▁ @ epoch ▁ { } ) ' . format ( self . args . data_test , scale , self . ckp . log [ - 1 , idx_scale ] , best [ 0 ] [ idx_scale ] , best [ 1 ] [ idx_scale ] + 1 ) ) NEW_LINE DEDENT DEDENT self . ckp . write_log ( ' Total ▁ time : ▁ { : . 2f } s \\\\n ' . format ( timer_test . toc ( ) ) , refresh = True ) NEW_LINE if not self . args . test_only : NEW_LINE INDENT self . ckp . save ( self , epoch , is_best = ( best [ 1 ] [ 0 ] + 1 == epoch ) ) NEW_LINE DEDENT DEDENT\",), (\"def prepare ( self , * args ) : NEW_LINE INDENT device = torch . device ( ' cpu ' if self . args . cpu else ' cuda ' ) NEW_LINE def _prepare ( tensor ) : NEW_LINE INDENT if self . args . precision == ' half ' : tensor = tensor . half ( ) NEW_LINE return tensor . to ( device ) NEW_LINE DEDENT return [ _prepare ( a ) for a in args ] NEW_LINE DEDENT\",), ('def terminate ( self ) : NEW_LINE INDENT if self . args . test_only : NEW_LINE INDENT self . test ( ) NEW_LINE return True NEW_LINE DEDENT else : NEW_LINE INDENT epoch = self . scheduler . last_epoch + 1 NEW_LINE return epoch >= self . args . epochs NEW_LINE DEDENT DEDENT',), (\"def __init__ ( self , args , gan_type = ' GAN ' ) : NEW_LINE INDENT super ( Discriminator , self ) . __init__ ( ) NEW_LINE in_channels = 3 NEW_LINE out_channels = 64 NEW_LINE depth = 7 NEW_LINE bn = True NEW_LINE act = nn . LeakyReLU ( negative_slope = 0.2 , inplace = True ) NEW_LINE m_features = [ common . BasicBlock ( args . n_colors , out_channels , 3 , bn = bn , act = act ) ] NEW_LINE for i in range ( depth ) : NEW_LINE INDENT in_channels = out_channels NEW_LINE if i % 2 == 1 : NEW_LINE INDENT stride = 1 NEW_LINE out_channels *= 2 NEW_LINE DEDENT else : NEW_LINE INDENT stride = 2 NEW_LINE DEDENT m_features . append ( common . BasicBlock ( in_channels , out_channels , 3 , stride = stride , bn = bn , act = act ) ) NEW_LINE DEDENT self . features = nn . Sequential ( * m_features ) NEW_LINE patch_size = args . patch_size // ( 2 ** ( ( depth + 1 ) // 2 ) ) NEW_LINE m_classifier = [ nn . Linear ( out_channels * patch_size ** 2 , 1024 ) , act , nn . Linear ( 1024 , 1 ) ] NEW_LINE self . classifier = nn . Sequential ( * m_classifier ) NEW_LINE DEDENT\",), ('def forward ( self , x ) : NEW_LINE INDENT features = self . features ( x ) NEW_LINE output = self . classifier ( features . view ( features . size ( 0 ) , - 1 ) ) NEW_LINE return output NEW_LINE DEDENT',), (\"def __init__ ( self , conv_index , rgb_range = 1 ) : NEW_LINE INDENT super ( VGG , self ) . __init__ ( ) NEW_LINE vgg_features = models . vgg19 ( pretrained = True ) . features NEW_LINE modules = [ m for m in vgg_features ] NEW_LINE if conv_index == '22' : NEW_LINE INDENT self . vgg = nn . Sequential ( * modules [ : 8 ] ) NEW_LINE DEDENT elif conv_index == '54' : NEW_LINE INDENT self . vgg = nn . Sequential ( * modules [ : 35 ] ) NEW_LINE DEDENT vgg_mean = ( 0.485 , 0.456 , 0.406 ) NEW_LINE vgg_std = ( 0.229 * rgb_range , 0.224 * rgb_range , 0.225 * rgb_range ) NEW_LINE self . sub_mean = common . MeanShift ( rgb_range , vgg_mean , vgg_std ) NEW_LINE self . vgg . requires_grad = False NEW_LINE DEDENT\",), ('def forward ( self , sr , hr ) : NEW_LINE INDENT def _forward ( x ) : NEW_LINE INDENT x = self . sub_mean ( x ) NEW_LINE x = self . vgg ( x ) NEW_LINE return x NEW_LINE DEDENT vgg_sr = _forward ( sr ) NEW_LINE with torch . no_grad ( ) : NEW_LINE INDENT vgg_hr = _forward ( hr . detach ( ) ) NEW_LINE DEDENT loss = F . mse_loss ( vgg_sr , vgg_hr ) NEW_LINE return loss NEW_LINE DEDENT',), (\"def __init__ ( self , args , gan_type ) : NEW_LINE INDENT super ( Adversarial , self ) . __init__ ( ) NEW_LINE self . gan_type = gan_type NEW_LINE self . gan_k = args . gan_k NEW_LINE self . discriminator = discriminator . Discriminator ( args , gan_type ) NEW_LINE if gan_type != ' WGAN _ GP ' : NEW_LINE INDENT self . optimizer = utility . make_optimizer ( args , self . discriminator ) NEW_LINE DEDENT else : NEW_LINE INDENT self . optimizer = optim . Adam ( self . discriminator . parameters ( ) , betas = ( 0 , 0.9 ) , eps = 1e-8 , lr = 1e-5 ) NEW_LINE DEDENT self . scheduler = utility . make_scheduler ( args , self . optimizer ) NEW_LINE DEDENT\",), (\"def forward ( self , fake , real ) : NEW_LINE INDENT fake_detach = fake . detach ( ) NEW_LINE self . loss = 0 NEW_LINE for _ in range ( self . gan_k ) : NEW_LINE INDENT self . optimizer . zero_grad ( ) NEW_LINE d_fake = self . discriminator ( fake_detach ) NEW_LINE d_real = self . discriminator ( real ) NEW_LINE if self . gan_type == ' GAN ' : NEW_LINE INDENT label_fake = torch . zeros_like ( d_fake ) NEW_LINE label_real = torch . ones_like ( d_real ) NEW_LINE loss_d = F . binary_cross_entropy_with_logits ( d_fake , label_fake ) + F . binary_cross_entropy_with_logits ( d_real , label_real ) NEW_LINE DEDENT elif self . gan_type . find ( ' WGAN ' ) >= 0 : NEW_LINE INDENT loss_d = ( d_fake - d_real ) . mean ( ) NEW_LINE if self . gan_type . find ( ' GP ' ) >= 0 : NEW_LINE INDENT epsilon = torch . rand_like ( fake ) . view ( - 1 , 1 , 1 , 1 ) NEW_LINE hat = fake_detach . mul ( 1 - epsilon ) + real . mul ( epsilon ) NEW_LINE hat . requires_grad = True NEW_LINE d_hat = self . discriminator ( hat ) NEW_LINE gradients = torch . autograd . grad ( outputs = d_hat . sum ( ) , inputs = hat , retain_graph = True , create_graph = True , only_inputs = True ) [ 0 ] NEW_LINE gradients = gradients . view ( gradients . size ( 0 ) , - 1 ) NEW_LINE gradient_norm = gradients . norm ( 2 , dim = 1 ) NEW_LINE gradient_penalty = 10 * gradient_norm . sub ( 1 ) . pow ( 2 ) . mean ( ) NEW_LINE loss_d += gradient_penalty NEW_LINE DEDENT DEDENT self . loss += loss_d . item ( ) NEW_LINE loss_d . backward ( ) NEW_LINE self . optimizer . step ( ) NEW_LINE if self . gan_type == ' WGAN ' : NEW_LINE INDENT for p in self . discriminator . parameters ( ) : NEW_LINE INDENT p . data . clamp_ ( - 1 , 1 ) NEW_LINE DEDENT DEDENT DEDENT self . loss /= self . gan_k NEW_LINE d_fake_for_g = self . discriminator ( fake ) NEW_LINE if self . gan_type == ' GAN ' : NEW_LINE INDENT loss_g = F . binary_cross_entropy_with_logits ( d_fake_for_g , label_real ) NEW_LINE DEDENT elif self . gan_type . find ( ' WGAN ' ) >= 0 : NEW_LINE INDENT loss_g = - d_fake_for_g . mean ( ) NEW_LINE DEDENT return loss_g NEW_LINE DEDENT\",), ('def state_dict ( self , * args , ** kwargs ) : NEW_LINE INDENT state_discriminator = self . discriminator . state_dict ( * args , ** kwargs ) NEW_LINE state_optimizer = self . optimizer . state_dict ( ) NEW_LINE return dict ( ** state_discriminator , ** state_optimizer ) NEW_LINE DEDENT',), (\"def __init__ ( self , args , ckp ) : NEW_LINE INDENT super ( Loss , self ) . __init__ ( ) NEW_LINE print ( ' Preparing ▁ loss ▁ function : ' ) NEW_LINE self . n_GPUs = args . n_GPUs NEW_LINE self . loss = [ ] NEW_LINE self . loss_module = nn . ModuleList ( ) NEW_LINE for loss in args . loss . split ( ' + ' ) : NEW_LINE INDENT weight , loss_type = loss . split ( ' * ' ) NEW_LINE if loss_type == ' MSE ' : NEW_LINE INDENT loss_function = nn . MSELoss ( ) NEW_LINE DEDENT elif loss_type == ' L1' : NEW_LINE INDENT loss_function = nn . L1Loss ( ) NEW_LINE DEDENT elif loss_type . find ( ' VGG ' ) >= 0 : NEW_LINE INDENT module = import_module ( ' loss . vgg ' ) NEW_LINE loss_function = getattr ( module , ' VGG ' ) ( loss_type [ 3 : ] , rgb_range = args . rgb_range ) NEW_LINE DEDENT elif loss_type . find ( ' GAN ' ) >= 0 : NEW_LINE INDENT module = import_module ( ' loss . adversarial ' ) NEW_LINE loss_function = getattr ( module , ' Adversarial ' ) ( args , loss_type ) NEW_LINE DEDENT self . loss . append ( { ' type ' : loss_type , ' weight ' : float ( weight ) , ' function ' : loss_function } ) NEW_LINE if loss_type . find ( ' GAN ' ) >= 0 : NEW_LINE INDENT self . loss . append ( { ' type ' : ' DIS ' , ' weight ' : 1 , ' function ' : None } ) NEW_LINE DEDENT DEDENT if len ( self . loss ) > 1 : NEW_LINE INDENT self . loss . append ( { ' type ' : ' Total ' , ' weight ' : 0 , ' function ' : None } ) NEW_LINE DEDENT for l in self . loss : NEW_LINE INDENT if l [ ' function ' ] is not None : NEW_LINE INDENT print ( ' { : . 3f } ▁ * ▁ { } ' . format ( l [ ' weight ' ] , l [ ' type ' ] ) ) NEW_LINE self . loss_module . append ( l [ ' function ' ] ) NEW_LINE DEDENT DEDENT self . log = torch . Tensor ( ) NEW_LINE device = torch . device ( ' cpu ' if args . cpu else ' cuda ' ) NEW_LINE self . loss_module . to ( device ) NEW_LINE if args . precision == ' half ' : self . loss_module . half ( ) NEW_LINE if not args . cpu and args . n_GPUs > 1 : NEW_LINE INDENT self . loss_module = nn . DataParallel ( self . loss_module , range ( args . n_GPUs ) ) NEW_LINE DEDENT if args . load != ' . ' : self . load ( ckp . dir , cpu = args . cpu ) NEW_LINE DEDENT\",), (\"def forward ( self , sr , hr ) : NEW_LINE INDENT losses = [ ] NEW_LINE for i , l in enumerate ( self . loss ) : NEW_LINE INDENT if l [ ' function ' ] is not None : NEW_LINE INDENT loss = l [ ' function ' ] ( sr , hr ) NEW_LINE effective_loss = l [ ' weight ' ] * loss NEW_LINE losses . append ( effective_loss ) NEW_LINE self . log [ - 1 , i ] += effective_loss . item ( ) NEW_LINE DEDENT elif l [ ' type ' ] == ' DIS ' : NEW_LINE INDENT self . log [ - 1 , i ] += self . loss [ i - 1 ] [ ' function ' ] . loss NEW_LINE DEDENT DEDENT loss_sum = sum ( losses ) NEW_LINE if len ( self . loss ) > 1 : NEW_LINE INDENT self . log [ - 1 , - 1 ] += loss_sum . item ( ) NEW_LINE DEDENT return loss_sum NEW_LINE DEDENT\",), (\"def step ( self ) : NEW_LINE INDENT for l in self . get_loss_module ( ) : NEW_LINE INDENT if hasattr ( l , ' scheduler ' ) : NEW_LINE INDENT l . scheduler . step ( ) NEW_LINE DEDENT DEDENT DEDENT\",), ('def start_log ( self ) : NEW_LINE INDENT self . log = torch . cat ( ( self . log , torch . zeros ( 1 , len ( self . loss ) ) ) ) NEW_LINE DEDENT',), ('def end_log ( self , n_batches ) : NEW_LINE INDENT self . log [ - 1 ] . div_ ( n_batches ) NEW_LINE DEDENT',), (\"def display_loss ( self , batch ) : NEW_LINE INDENT n_samples = batch + 1 NEW_LINE log = [ ] NEW_LINE for l , c in zip ( self . loss , self . log [ - 1 ] ) : NEW_LINE INDENT log . append ( ' [ { } : ▁ { : . 4f } ] ' . format ( l [ ' type ' ] , c / n_samples ) ) NEW_LINE DEDENT return ' ' . join ( log ) NEW_LINE DEDENT\",), (\"def plot_loss ( self , apath , epoch ) : NEW_LINE INDENT axis = np . linspace ( 1 , epoch , epoch ) NEW_LINE for i , l in enumerate ( self . loss ) : NEW_LINE INDENT label = ' { } ▁ Loss ' . format ( l [ ' type ' ] ) NEW_LINE fig = plt . figure ( ) NEW_LINE plt . title ( label ) NEW_LINE plt . plot ( axis , self . log [ : , i ] . numpy ( ) , label = label ) NEW_LINE plt . legend ( ) NEW_LINE plt . xlabel ( ' Epochs ' ) NEW_LINE plt . ylabel ( ' Loss ' ) NEW_LINE plt . grid ( True ) NEW_LINE plt . savefig ( ' { } / loss _ { } . pdf ' . format ( apath , l [ ' type ' ] ) ) NEW_LINE plt . close ( fig ) NEW_LINE DEDENT DEDENT\",), ('def get_loss_module ( self ) : NEW_LINE INDENT if self . n_GPUs == 1 : NEW_LINE INDENT return self . loss_module NEW_LINE DEDENT else : NEW_LINE INDENT return self . loss_module . module NEW_LINE DEDENT DEDENT',), (\"def save ( self , apath ) : NEW_LINE INDENT torch . save ( self . state_dict ( ) , os . path . join ( apath , ' loss . pt ' ) ) NEW_LINE torch . save ( self . log , os . path . join ( apath , ' loss _ log . pt ' ) ) NEW_LINE DEDENT\",), (\"def load ( self , apath , cpu = False ) : NEW_LINE INDENT if cpu : NEW_LINE INDENT kwargs = { ' map _ location ' : lambda storage , loc : storage } NEW_LINE DEDENT else : NEW_LINE INDENT kwargs = { } NEW_LINE DEDENT self . load_state_dict ( torch . load ( os . path . join ( apath , ' loss . pt ' ) , ** kwargs ) ) NEW_LINE self . log = torch . load ( os . path . join ( apath , ' loss _ log . pt ' ) ) NEW_LINE for l in self . loss_module : NEW_LINE INDENT if hasattr ( l , ' scheduler ' ) : NEW_LINE INDENT for _ in range ( len ( self . log ) ) : l . scheduler . step ( ) NEW_LINE DEDENT DEDENT DEDENT\",), ('def make_model ( args , parent = False ) : NEW_LINE INDENT return MODEL ( args ) NEW_LINE DEDENT',), ('def __init__ ( self , init_value = 1e-3 ) : NEW_LINE INDENT super ( ) . __init__ ( ) NEW_LINE self . scale = nn . Parameter ( torch . FloatTensor ( [ init_value ] ) ) NEW_LINE DEDENT',), ('def forward ( self , input ) : NEW_LINE INDENT return input * self . scale NEW_LINE DEDENT',), ('def __init__ ( self , n_feats , kernel_size , block_feats , wn , res_scale = 1 , act = nn . ReLU ( True ) ) : NEW_LINE INDENT super ( AWRU , self ) . __init__ ( ) NEW_LINE self . res_scale = Scale ( res_scale ) NEW_LINE self . x_scale = Scale ( 1 ) NEW_LINE body = [ ] NEW_LINE body . append ( wn ( nn . Conv2d ( n_feats , block_feats , kernel_size , padding = kernel_size // 2 ) ) ) NEW_LINE body . append ( act ) NEW_LINE body . append ( wn ( nn . Conv2d ( block_feats , n_feats , kernel_size , padding = kernel_size // 2 ) ) ) NEW_LINE self . body = nn . Sequential ( * body ) NEW_LINE DEDENT',), ('def forward ( self , x ) : NEW_LINE INDENT res = self . res_scale ( self . body ( x ) ) + self . x_scale ( x ) NEW_LINE return res NEW_LINE DEDENT',), ('def __init__ ( self , args , scale , n_feats , kernel_size , wn ) : NEW_LINE INDENT super ( AWMS , self ) . __init__ ( ) NEW_LINE out_feats = scale * scale * args . n_colors NEW_LINE self . tail_k3 = wn ( nn . Conv2d ( n_feats , out_feats , 3 , padding = 3 // 2 , dilation = 1 ) ) NEW_LINE self . tail_k5 = wn ( nn . Conv2d ( n_feats , out_feats , 5 , padding = 5 // 2 , dilation = 1 ) ) NEW_LINE self . tail_k7 = wn ( nn . Conv2d ( n_feats , out_feats , 7 , padding = 7 // 2 , dilation = 1 ) ) NEW_LINE self . tail_k9 = wn ( nn . Conv2d ( n_feats , out_feats , 9 , padding = 9 // 2 , dilation = 1 ) ) NEW_LINE self . pixelshuffle = nn . PixelShuffle ( scale ) NEW_LINE self . scale_k3 = Scale ( 0.25 ) NEW_LINE self . scale_k5 = Scale ( 0.25 ) NEW_LINE self . scale_k7 = Scale ( 0.25 ) NEW_LINE self . scale_k9 = Scale ( 0.25 ) NEW_LINE DEDENT',), ('def forward ( self , x ) : NEW_LINE INDENT x0 = self . pixelshuffle ( self . scale_k3 ( self . tail_k3 ( x ) ) ) NEW_LINE x1 = self . pixelshuffle ( self . scale_k5 ( self . tail_k5 ( x ) ) ) NEW_LINE x2 = self . pixelshuffle ( self . scale_k7 ( self . tail_k7 ( x ) ) ) NEW_LINE x3 = self . pixelshuffle ( self . scale_k9 ( self . tail_k9 ( x ) ) ) NEW_LINE return x0 + x1 + x2 + x3 NEW_LINE DEDENT',), ('def __init__ ( self , n_feats , kernel_size , block_feats , n_awru , wn , res_scale , act = nn . ReLU ( True ) ) : NEW_LINE INDENT super ( LFB , self ) . __init__ ( ) NEW_LINE self . n = n_awru NEW_LINE self . lfl = nn . ModuleList ( [ AWRU ( n_feats , kernel_size , block_feats , wn = wn , res_scale = res_scale , act = act ) for i in range ( self . n ) ] ) NEW_LINE self . reduction = wn ( nn . Conv2d ( n_feats * self . n , n_feats , kernel_size , padding = kernel_size // 2 ) ) NEW_LINE self . res_scale = Scale ( res_scale ) NEW_LINE self . x_scale = Scale ( 1 ) NEW_LINE DEDENT',), ('def forward ( self , x ) : NEW_LINE INDENT s = x NEW_LINE out = [ ] NEW_LINE for i in range ( self . n ) : NEW_LINE INDENT x = self . lfl [ i ] ( x ) NEW_LINE out . append ( x ) NEW_LINE DEDENT res = self . reduction ( torch . cat ( out , dim = 1 ) ) NEW_LINE return self . res_scale ( res ) + self . x_scale ( s ) NEW_LINE DEDENT',), ('def __init__ ( self , args ) : NEW_LINE INDENT super ( MODEL , self ) . __init__ ( ) NEW_LINE self . args = args NEW_LINE scale = args . scale [ 0 ] NEW_LINE n_resblocks = args . n_resblocks NEW_LINE n_feats = args . n_feats NEW_LINE kernel_size = 3 NEW_LINE res_scale = args . res_scale NEW_LINE n_awru = args . n_awru NEW_LINE act = nn . ReLU ( True ) NEW_LINE wn = lambda x : torch . nn . utils . weight_norm ( x ) NEW_LINE self . rgb_mean = torch . autograd . Variable ( torch . FloatTensor ( [ 0.4488 , 0.4371 , 0.4040 ] ) ) . view ( [ 1 , 3 , 1 , 1 ] ) NEW_LINE head = [ ] NEW_LINE head . append ( wn ( nn . Conv2d ( args . n_colors , n_feats , 3 , padding = 3 // 2 ) ) ) NEW_LINE body = [ ] NEW_LINE for i in range ( n_resblocks ) : NEW_LINE INDENT body . append ( LFB ( n_feats , kernel_size , args . block_feats , n_awru , wn = wn , res_scale = res_scale , act = act ) ) NEW_LINE DEDENT out_feats = scale * scale * args . n_colors NEW_LINE tail = AWMS ( args , scale , n_feats , kernel_size , wn ) NEW_LINE skip = [ ] NEW_LINE skip . append ( wn ( nn . Conv2d ( args . n_colors , out_feats , 3 , padding = 3 // 2 ) ) ) NEW_LINE skip . append ( nn . PixelShuffle ( scale ) ) NEW_LINE self . head = nn . Sequential ( * head ) NEW_LINE self . body = nn . Sequential ( * body ) NEW_LINE self . tail = tail NEW_LINE self . skip = nn . Sequential ( * skip ) NEW_LINE DEDENT',), ('def forward ( self , x ) : NEW_LINE INDENT x = ( x - self . rgb_mean . cuda ( ) * 255 ) / 127.5 NEW_LINE s = self . skip ( x ) NEW_LINE x = self . head ( x ) NEW_LINE x = self . body ( x ) NEW_LINE x = self . tail ( x ) NEW_LINE x += s NEW_LINE x = x * 127.5 + self . rgb_mean . cuda ( ) * 255 NEW_LINE return x NEW_LINE DEDENT',), ('def make_model ( args , parent = False ) : NEW_LINE INDENT return MODEL ( args ) NEW_LINE DEDENT',), ('def __init__ ( self , init_value = 1e-3 ) : NEW_LINE INDENT super ( ) . __init__ ( ) NEW_LINE self . scale = nn . Parameter ( torch . FloatTensor ( [ init_value ] ) ) NEW_LINE DEDENT',), ('def forward ( self , input ) : NEW_LINE INDENT return input * self . scale NEW_LINE DEDENT',), ('def __init__ ( self , n_feats , kernel_size , block_feats , wn , res_scale = 1 , act = nn . ReLU ( True ) ) : NEW_LINE INDENT super ( AWRU , self ) . __init__ ( ) NEW_LINE self . res_scale = Scale ( 1 ) NEW_LINE self . x_scale = Scale ( 1 ) NEW_LINE body = [ ] NEW_LINE body . append ( wn ( nn . Conv2d ( n_feats , block_feats , kernel_size , padding = kernel_size // 2 ) ) ) NEW_LINE body . append ( act ) NEW_LINE body . append ( wn ( nn . Conv2d ( block_feats , n_feats , kernel_size , padding = kernel_size // 2 ) ) ) NEW_LINE self . body = nn . Sequential ( * body ) NEW_LINE DEDENT',), ('def forward ( self , x ) : NEW_LINE INDENT res = self . res_scale ( self . body ( x ) ) + self . x_scale ( x ) NEW_LINE return res NEW_LINE DEDENT',), ('def __init__ ( self , args , scale , n_feats , kernel_size , wn ) : NEW_LINE INDENT super ( AWMS , self ) . __init__ ( ) NEW_LINE out_feats = scale * scale * args . n_colors NEW_LINE self . tail_k3 = wn ( nn . Conv2d ( n_feats , out_feats , 3 , padding = 3 // 2 , dilation = 1 ) ) NEW_LINE self . tail_k5 = wn ( nn . Conv2d ( n_feats , out_feats , 5 , padding = 5 // 2 , dilation = 1 ) ) NEW_LINE self . tail_k7 = wn ( nn . Conv2d ( n_feats , out_feats , 7 , padding = 7 // 2 , dilation = 1 ) ) NEW_LINE self . tail_k9 = wn ( nn . Conv2d ( n_feats , out_feats , 9 , padding = 9 // 2 , dilation = 1 ) ) NEW_LINE self . pixelshuffle = nn . PixelShuffle ( scale ) NEW_LINE self . scale_k3 = Scale ( 0.25 ) NEW_LINE self . scale_k5 = Scale ( 0.25 ) NEW_LINE self . scale_k7 = Scale ( 0.25 ) NEW_LINE self . scale_k9 = Scale ( 0.25 ) NEW_LINE DEDENT',), ('def forward ( self , x ) : NEW_LINE INDENT x0 = self . pixelshuffle ( self . scale_k3 ( self . tail_k3 ( x ) ) ) NEW_LINE x1 = self . pixelshuffle ( self . scale_k5 ( self . tail_k5 ( x ) ) ) NEW_LINE x2 = self . pixelshuffle ( self . scale_k7 ( self . tail_k7 ( x ) ) ) NEW_LINE x3 = self . pixelshuffle ( self . scale_k9 ( self . tail_k9 ( x ) ) ) NEW_LINE return x0 + x1 + x2 + x3 NEW_LINE DEDENT',), ('def __init__ ( self , n_feats , kernel_size , block_feats , wn , act = nn . ReLU ( True ) ) : NEW_LINE INDENT super ( LFB , self ) . __init__ ( ) NEW_LINE self . b0 = AWRU ( n_feats , kernel_size , block_feats , wn = wn , act = act ) NEW_LINE self . b1 = AWRU ( n_feats , kernel_size , block_feats , wn = wn , act = act ) NEW_LINE self . b2 = AWRU ( n_feats , kernel_size , block_feats , wn = wn , act = act ) NEW_LINE self . b3 = AWRU ( n_feats , kernel_size , block_feats , wn = wn , act = act ) NEW_LINE self . reduction = wn ( nn . Conv2d ( n_feats * 4 , n_feats , 3 , padding = 3 // 2 ) ) NEW_LINE self . res_scale = Scale ( 1 ) NEW_LINE self . x_scale = Scale ( 1 ) NEW_LINE DEDENT',), ('def forward ( self , x ) : NEW_LINE INDENT x0 = self . b0 ( x ) NEW_LINE x1 = self . b1 ( x0 ) NEW_LINE x2 = self . b2 ( x1 ) NEW_LINE x3 = self . b3 ( x2 ) NEW_LINE res = self . reduction ( torch . cat ( [ x0 , x1 , x2 , x3 ] , dim = 1 ) ) NEW_LINE return self . res_scale ( res ) + self . x_scale ( x ) NEW_LINE DEDENT',), ('def __init__ ( self , args ) : NEW_LINE INDENT super ( MODEL , self ) . __init__ ( ) NEW_LINE self . args = args NEW_LINE scale = args . scale [ 0 ] NEW_LINE n_resblocks = args . n_resblocks NEW_LINE n_feats = args . n_feats NEW_LINE kernel_size = 3 NEW_LINE act = nn . ReLU ( True ) NEW_LINE wn = lambda x : torch . nn . utils . weight_norm ( x ) NEW_LINE self . rgb_mean = torch . autograd . Variable ( torch . FloatTensor ( [ 0.4488 , 0.4371 , 0.4040 ] ) ) . view ( [ 1 , 3 , 1 , 1 ] ) NEW_LINE head = [ ] NEW_LINE head . append ( wn ( nn . Conv2d ( args . n_colors , n_feats , 3 , padding = 3 // 2 ) ) ) NEW_LINE body = [ ] NEW_LINE for i in range ( n_resblocks ) : NEW_LINE INDENT body . append ( LFB ( n_feats , kernel_size , args . block_feats , wn = wn , act = act ) ) NEW_LINE DEDENT out_feats = scale * scale * args . n_colors NEW_LINE tail = AWMS ( args , scale , n_feats , kernel_size , wn ) NEW_LINE skip = [ ] NEW_LINE skip . append ( wn ( nn . Conv2d ( args . n_colors , out_feats , 3 , padding = 3 // 2 ) ) ) NEW_LINE skip . append ( nn . PixelShuffle ( scale ) ) NEW_LINE self . head = nn . Sequential ( * head ) NEW_LINE self . body = nn . Sequential ( * body ) NEW_LINE self . tail = tail NEW_LINE self . skip = nn . Sequential ( * skip ) NEW_LINE DEDENT',), ('def forward ( self , x ) : NEW_LINE INDENT x = ( x - self . rgb_mean . cuda ( ) * 255 ) / 127.5 NEW_LINE s = self . skip ( x ) NEW_LINE x = self . head ( x ) NEW_LINE x = self . body ( x ) NEW_LINE x = self . tail ( x ) NEW_LINE x += s NEW_LINE x = x * 127.5 + self . rgb_mean . cuda ( ) * 255 NEW_LINE return x NEW_LINE DEDENT',), ('def load_state_dict ( self , state_dict , strict = True ) : NEW_LINE INDENT own_state = self . state_dict ( ) NEW_LINE for name , param in state_dict . items ( ) : NEW_LINE INDENT if name in own_state : NEW_LINE INDENT if isinstance ( param , nn . Parameter ) : NEW_LINE INDENT param = param . data NEW_LINE DEDENT try : NEW_LINE INDENT own_state [ name ] . copy_ ( param ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT if name . find ( \\' tail \\' ) >= 0 or name . find ( \\' skip \\' ) >= 0 : NEW_LINE INDENT print ( \\' Replace ▁ pre - trained ▁ upsampler ▁ to ▁ new ▁ one . . . \\' ) NEW_LINE DEDENT else : NEW_LINE INDENT raise RuntimeError ( \\' While ▁ copying ▁ the ▁ parameter ▁ named ▁ { } , ▁ \\' . format ( name , own_state [ name ] . size ( ) , param . size ( ) ) ) DEDENT DEDENT DEDENT elif strict : NEW_LINE INDENT if name . find ( \\' tail \\' ) == - 1 : NEW_LINE INDENT raise KeyError ( \\' unexpected ▁ key ▁ \" { } \" ▁ in ▁ state _ dict \\' . format ( name ) ) NEW_LINE DEDENT DEDENT DEDENT if strict : NEW_LINE INDENT missing = set ( own_state . keys ( ) ) - set ( state_dict . keys ( ) ) NEW_LINE if len ( missing ) > 0 : NEW_LINE INDENT raise KeyError ( \\' missing ▁ keys ▁ in ▁ state _ dict : ▁ \" { } \" \\' . format ( missing ) ) NEW_LINE DEDENT DEDENT DEDENT',), ('def make_model ( args , parent = False ) : NEW_LINE INDENT return MODEL ( args ) NEW_LINE DEDENT',), ('def __init__ ( self , init_value = 1e-3 ) : NEW_LINE INDENT super ( ) . __init__ ( ) NEW_LINE self . scale = nn . Parameter ( torch . FloatTensor ( [ init_value ] ) ) NEW_LINE DEDENT',), ('def forward ( self , input ) : NEW_LINE INDENT return input * self . scale NEW_LINE DEDENT',), ('def __init__ ( self , n_feats , kernel_size , block_feats , wn , res_scale = 1 , act = nn . ReLU ( True ) ) : NEW_LINE INDENT super ( AWRU , self ) . __init__ ( ) NEW_LINE self . res_scale = Scale ( 1 ) NEW_LINE self . x_scale = Scale ( 1 ) NEW_LINE body = [ ] NEW_LINE body . append ( wn ( nn . Conv2d ( n_feats , block_feats , kernel_size , padding = kernel_size // 2 ) ) ) NEW_LINE body . append ( act ) NEW_LINE body . append ( wn ( nn . Conv2d ( block_feats , n_feats , kernel_size , padding = kernel_size // 2 ) ) ) NEW_LINE self . body = nn . Sequential ( * body ) NEW_LINE DEDENT',), ('def forward ( self , x ) : NEW_LINE INDENT res = self . res_scale ( self . body ( x ) ) + self . x_scale ( x ) NEW_LINE return res NEW_LINE DEDENT',), ('def __init__ ( self , args , scale , n_feats , kernel_size , wn ) : NEW_LINE INDENT super ( AWMS , self ) . __init__ ( ) NEW_LINE out_feats = scale * scale * args . n_colors NEW_LINE self . tail_k3 = wn ( nn . Conv2d ( n_feats , out_feats , 3 , padding = 3 // 2 , dilation = 1 ) ) NEW_LINE self . tail_k5 = wn ( nn . Conv2d ( n_feats , out_feats , 5 , padding = 5 // 2 , dilation = 1 ) ) NEW_LINE self . tail_k7 = wn ( nn . Conv2d ( n_feats , out_feats , 7 , padding = 7 // 2 , dilation = 1 ) ) NEW_LINE self . tail_k9 = wn ( nn . Conv2d ( n_feats , out_feats , 9 , padding = 9 // 2 , dilation = 1 ) ) NEW_LINE self . pixelshuffle = nn . PixelShuffle ( scale ) NEW_LINE self . scale_k3 = Scale ( 0.25 ) NEW_LINE self . scale_k5 = Scale ( 0.25 ) NEW_LINE self . scale_k7 = Scale ( 0.25 ) NEW_LINE self . scale_k9 = Scale ( 0.25 ) NEW_LINE DEDENT',), ('def forward ( self , x ) : NEW_LINE INDENT x0 = self . pixelshuffle ( self . scale_k3 ( self . tail_k3 ( x ) ) ) NEW_LINE x1 = self . pixelshuffle ( self . scale_k5 ( self . tail_k5 ( x ) ) ) NEW_LINE x2 = self . pixelshuffle ( self . scale_k7 ( self . tail_k7 ( x ) ) ) NEW_LINE x3 = self . pixelshuffle ( self . scale_k9 ( self . tail_k9 ( x ) ) ) NEW_LINE return x0 + x1 + x2 + x3 NEW_LINE DEDENT',), ('def __init__ ( self , n_feats , kernel_size , block_feats , wn , act = nn . ReLU ( True ) ) : NEW_LINE INDENT super ( LFB , self ) . __init__ ( ) NEW_LINE self . b0 = AWRU ( n_feats , kernel_size , block_feats , wn = wn , act = act ) NEW_LINE self . b1 = AWRU ( n_feats , kernel_size , block_feats , wn = wn , act = act ) NEW_LINE self . b2 = AWRU ( n_feats , kernel_size , block_feats , wn = wn , act = act ) NEW_LINE self . b3 = AWRU ( n_feats , kernel_size , block_feats , wn = wn , act = act ) NEW_LINE self . b4 = AWRU ( n_feats , kernel_size , block_feats , wn = wn , act = act ) NEW_LINE self . b5 = AWRU ( n_feats , kernel_size , block_feats , wn = wn , act = act ) NEW_LINE self . b6 = AWRU ( n_feats , kernel_size , block_feats , wn = wn , act = act ) NEW_LINE self . b7 = AWRU ( n_feats , kernel_size , block_feats , wn = wn , act = act ) NEW_LINE self . reduction = wn ( nn . Conv2d ( n_feats * 8 , n_feats , 3 , padding = 3 // 2 ) ) NEW_LINE self . res_scale = Scale ( 1 ) NEW_LINE self . x_scale = Scale ( 1 ) NEW_LINE DEDENT',), ('def forward ( self , x ) : NEW_LINE INDENT x0 = self . b0 ( x ) NEW_LINE x1 = self . b1 ( x0 ) NEW_LINE x2 = self . b2 ( x1 ) NEW_LINE x3 = self . b3 ( x2 ) NEW_LINE x4 = self . b4 ( x3 ) NEW_LINE x5 = self . b5 ( x4 ) NEW_LINE x6 = self . b6 ( x5 ) NEW_LINE x7 = self . b7 ( x6 ) NEW_LINE res = self . reduction ( torch . cat ( [ x0 , x1 , x2 , x3 , x4 , x5 , x6 , x7 ] , dim = 1 ) ) NEW_LINE return self . res_scale ( res ) + self . x_scale ( x ) NEW_LINE DEDENT',), ('def __init__ ( self , args ) : NEW_LINE INDENT super ( MODEL , self ) . __init__ ( ) NEW_LINE self . args = args NEW_LINE scale = args . scale [ 0 ] NEW_LINE n_resblocks = args . n_resblocks NEW_LINE n_feats = args . n_feats NEW_LINE kernel_size = 3 NEW_LINE act = nn . ReLU ( True ) NEW_LINE wn = lambda x : torch . nn . utils . weight_norm ( x ) NEW_LINE self . rgb_mean = torch . autograd . Variable ( torch . FloatTensor ( [ 0.4488 , 0.4371 , 0.4040 ] ) ) . view ( [ 1 , 3 , 1 , 1 ] ) NEW_LINE head = [ ] NEW_LINE head . append ( wn ( nn . Conv2d ( args . n_colors , n_feats , 3 , padding = 3 // 2 ) ) ) NEW_LINE body = [ ] NEW_LINE for i in range ( n_resblocks ) : NEW_LINE INDENT body . append ( LFB ( n_feats , kernel_size , args . block_feats , wn = wn , act = act ) ) NEW_LINE DEDENT out_feats = scale * scale * args . n_colors NEW_LINE tail = AWMS ( args , scale , n_feats , kernel_size , wn ) NEW_LINE skip = [ ] NEW_LINE skip . append ( wn ( nn . Conv2d ( args . n_colors , out_feats , 3 , padding = 3 // 2 ) ) ) NEW_LINE skip . append ( nn . PixelShuffle ( scale ) ) NEW_LINE self . head = nn . Sequential ( * head ) NEW_LINE self . body = nn . Sequential ( * body ) NEW_LINE self . tail = tail NEW_LINE self . skip = nn . Sequential ( * skip ) NEW_LINE DEDENT',), ('def forward ( self , x ) : NEW_LINE INDENT x = ( x - self . rgb_mean . cuda ( ) * 255 ) / 127.5 NEW_LINE s = self . skip ( x ) NEW_LINE x = self . head ( x ) NEW_LINE x = self . body ( x ) NEW_LINE x = self . tail ( x ) NEW_LINE x += s NEW_LINE x = x * 127.5 + self . rgb_mean . cuda ( ) * 255 NEW_LINE return x NEW_LINE DEDENT',), ('def load_state_dict ( self , state_dict , strict = False ) : NEW_LINE INDENT own_state = self . state_dict ( ) NEW_LINE for name , param in state_dict . items ( ) : NEW_LINE INDENT if name in own_state : NEW_LINE INDENT if isinstance ( param , nn . Parameter ) : NEW_LINE INDENT param = param . data NEW_LINE DEDENT try : NEW_LINE INDENT own_state [ name ] . copy_ ( param ) NEW_LINE DEDENT except Exception : NEW_LINE INDENT if name . find ( \\' tail \\' ) >= 0 or name . find ( \\' skip \\' ) >= 0 : NEW_LINE INDENT print ( \\' Replace ▁ pre - trained ▁ upsampler ▁ to ▁ new ▁ one . . . \\' ) NEW_LINE DEDENT else : NEW_LINE INDENT raise RuntimeError ( \\' While ▁ copying ▁ the ▁ parameter ▁ named ▁ { } , ▁ \\' . format ( name , own_state [ name ] . size ( ) , param . size ( ) ) ) DEDENT DEDENT DEDENT elif strict : NEW_LINE INDENT if name . find ( \\' tail \\' ) == - 1 : NEW_LINE INDENT raise KeyError ( \\' unexpected ▁ key ▁ \" { } \" ▁ in ▁ state _ dict \\' . format ( name ) ) NEW_LINE DEDENT DEDENT DEDENT if strict : NEW_LINE INDENT missing = set ( own_state . keys ( ) ) - set ( state_dict . keys ( ) ) NEW_LINE if len ( missing ) > 0 : NEW_LINE INDENT raise KeyError ( \\' missing ▁ keys ▁ in ▁ state _ dict : ▁ \" { } \" \\' . format ( missing ) ) NEW_LINE DEDENT DEDENT DEDENT',), (\"def __init__ ( self , args , ckp ) : NEW_LINE INDENT super ( Model , self ) . __init__ ( ) NEW_LINE print ( ' Making ▁ model . . . ' ) NEW_LINE self . scale = args . scale NEW_LINE self . idx_scale = 0 NEW_LINE self . self_ensemble = args . self_ensemble NEW_LINE self . chop = args . chop NEW_LINE self . precision = args . precision NEW_LINE self . cpu = args . cpu NEW_LINE self . device = torch . device ( ' cpu ' if args . cpu else ' cuda ' ) NEW_LINE self . n_GPUs = args . n_GPUs NEW_LINE self . save_models = args . save_models NEW_LINE self . test_only = args . test_only NEW_LINE module = import_module ( ' model . ' + args . model . lower ( ) ) NEW_LINE self . model = module . make_model ( args ) . to ( self . device ) NEW_LINE if args . precision == ' half ' : self . model . half ( ) NEW_LINE if not args . cpu and args . n_GPUs > 1 : NEW_LINE INDENT self . model = nn . DataParallel ( self . model , range ( args . n_GPUs ) ) NEW_LINE DEDENT self . load ( ckp . dir , pre_train = args . pre_train , resume = args . resume , cpu = args . cpu ) NEW_LINE print ( self . model , file = ckp . log_file ) NEW_LINE DEDENT\",), (\"def forward ( self , x , idx_scale ) : NEW_LINE INDENT self . idx_scale = idx_scale NEW_LINE target = self . get_model ( ) NEW_LINE if hasattr ( target , ' set _ scale ' ) : NEW_LINE INDENT target . set_scale ( idx_scale ) NEW_LINE DEDENT if self . self_ensemble and not self . training : NEW_LINE INDENT if self . chop : NEW_LINE INDENT forward_function = self . forward_chop NEW_LINE DEDENT else : NEW_LINE INDENT forward_function = self . model . forward NEW_LINE DEDENT return self . forward_x8 ( x , forward_function ) NEW_LINE DEDENT elif self . chop and not self . training : NEW_LINE INDENT return self . forward_chop ( x ) NEW_LINE DEDENT else : NEW_LINE INDENT return self . model ( x ) NEW_LINE DEDENT DEDENT\",), ('def get_model ( self ) : NEW_LINE INDENT if self . n_GPUs == 1 : NEW_LINE INDENT return self . model NEW_LINE DEDENT else : NEW_LINE INDENT return self . model . module NEW_LINE DEDENT DEDENT',), ('def state_dict ( self , ** kwargs ) : NEW_LINE INDENT target = self . get_model ( ) NEW_LINE return target . state_dict ( ** kwargs ) NEW_LINE DEDENT',), (\"def save ( self , apath , epoch , is_best = False ) : NEW_LINE INDENT target = self . get_model ( ) NEW_LINE torch . save ( target . state_dict ( ) , os . path . join ( apath , ' model ' , ' model _ latest . pt ' ) ) NEW_LINE if is_best : NEW_LINE INDENT torch . save ( target . state_dict ( ) , os . path . join ( apath , ' model ' , ' model _ best . pt ' ) ) NEW_LINE DEDENT if self . save_models : NEW_LINE INDENT torch . save ( target . state_dict ( ) , os . path . join ( apath , ' model ' , ' model _ { } . pt ' . format ( epoch ) ) ) NEW_LINE DEDENT DEDENT\",), (\"def load ( self , apath , pre_train = ' . ' , resume = - 1 , cpu = False ) : NEW_LINE INDENT if cpu : NEW_LINE INDENT kwargs = { ' map _ location ' : lambda storage , loc : storage } NEW_LINE DEDENT else : NEW_LINE INDENT if self . test_only and self . n_GPUs == 1 : NEW_LINE INDENT kwargs = { ' map _ location ' : ' cuda : 0' } NEW_LINE DEDENT else : NEW_LINE INDENT kwargs = { } NEW_LINE DEDENT DEDENT if resume == - 1 : NEW_LINE INDENT self . get_model ( ) . load_state_dict ( torch . load ( os . path . join ( apath , ' model ' , ' model _ latest . pt ' ) , ** kwargs ) , strict = False ) NEW_LINE DEDENT elif resume == 0 : NEW_LINE INDENT if pre_train != ' . ' : NEW_LINE INDENT print ( ' Loading ▁ model ▁ from ▁ { } ' . format ( pre_train ) ) NEW_LINE self . get_model ( ) . load_state_dict ( torch . load ( pre_train , ** kwargs ) , strict = False ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT self . get_model ( ) . load_state_dict ( torch . load ( os . path . join ( apath , ' model ' , ' model _ { } . pt ' . format ( resume ) ) , ** kwargs ) , strict = False ) NEW_LINE DEDENT DEDENT\",), ('def forward_chop ( self , x , shave = 10 , min_size = 160000 ) : NEW_LINE INDENT scale = self . scale [ self . idx_scale ] NEW_LINE n_GPUs = min ( self . n_GPUs , 4 ) NEW_LINE b , c , h , w = x . size ( ) NEW_LINE h_half , w_half = h // 2 , w // 2 NEW_LINE h_size , w_size = h_half + shave , w_half + shave NEW_LINE lr_list = [ x [ : , : , 0 : h_size , 0 : w_size ] , x [ : , : , 0 : h_size , ( w - w_size ) : w ] , x [ : , : , ( h - h_size ) : h , 0 : w_size ] , x [ : , : , ( h - h_size ) : h , ( w - w_size ) : w ] ] NEW_LINE if w_size * h_size < min_size : NEW_LINE INDENT sr_list = [ ] NEW_LINE for i in range ( 0 , 4 , n_GPUs ) : NEW_LINE INDENT lr_batch = torch . cat ( lr_list [ i : ( i + n_GPUs ) ] , dim = 0 ) NEW_LINE sr_batch = self . model ( lr_batch ) NEW_LINE sr_list . extend ( sr_batch . chunk ( n_GPUs , dim = 0 ) ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT sr_list = [ self . forward_chop ( patch , shave = shave , min_size = min_size ) for patch in lr_list ] NEW_LINE DEDENT h , w = scale * h , scale * w NEW_LINE h_half , w_half = scale * h_half , scale * w_half NEW_LINE h_size , w_size = scale * h_size , scale * w_size NEW_LINE shave *= scale NEW_LINE output = x . new ( b , c , h , w ) NEW_LINE output [ : , : , 0 : h_half , 0 : w_half ] = sr_list [ 0 ] [ : , : , 0 : h_half , 0 : w_half ] NEW_LINE output [ : , : , 0 : h_half , w_half : w ] = sr_list [ 1 ] [ : , : , 0 : h_half , ( w_size - w + w_half ) : w_size ] NEW_LINE output [ : , : , h_half : h , 0 : w_half ] = sr_list [ 2 ] [ : , : , ( h_size - h + h_half ) : h_size , 0 : w_half ] NEW_LINE output [ : , : , h_half : h , w_half : w ] = sr_list [ 3 ] [ : , : , ( h_size - h + h_half ) : h_size , ( w_size - w + w_half ) : w_size ] NEW_LINE return output NEW_LINE DEDENT',), (\"def forward_x8 ( self , x , forward_function ) : NEW_LINE INDENT def _transform ( v , op ) : NEW_LINE INDENT if self . precision != ' single ' : v = v . float ( ) NEW_LINE v2np = v . data . cpu ( ) . numpy ( ) NEW_LINE if op == ' v ' : NEW_LINE INDENT tfnp = v2np [ : , : , : , : : - 1 ] . copy ( ) NEW_LINE DEDENT elif op == ' h ' : NEW_LINE INDENT tfnp = v2np [ : , : , : : - 1 , : ] . copy ( ) NEW_LINE DEDENT elif op == ' t ' : NEW_LINE INDENT tfnp = v2np . transpose ( ( 0 , 1 , 3 , 2 ) ) . copy ( ) NEW_LINE DEDENT ret = torch . Tensor ( tfnp ) . to ( self . device ) NEW_LINE if self . precision == ' half ' : ret = ret . half ( ) NEW_LINE return ret NEW_LINE DEDENT lr_list = [ x ] NEW_LINE for tf in ' v ' , ' h ' , ' t ' : NEW_LINE INDENT lr_list . extend ( [ _transform ( t , tf ) for t in lr_list ] ) NEW_LINE DEDENT sr_list = [ forward_function ( aug ) for aug in lr_list ] NEW_LINE for i in range ( len ( sr_list ) ) : NEW_LINE INDENT if i > 3 : NEW_LINE INDENT sr_list [ i ] = _transform ( sr_list [ i ] , ' t ' ) NEW_LINE DEDENT if i % 4 > 1 : NEW_LINE INDENT sr_list [ i ] = _transform ( sr_list [ i ] , ' h ' ) NEW_LINE DEDENT if ( i % 4 ) % 2 == 1 : NEW_LINE INDENT sr_list [ i ] = _transform ( sr_list [ i ] , ' v ' ) NEW_LINE DEDENT DEDENT output_cat = torch . cat ( sr_list , dim = 0 ) NEW_LINE output = output_cat . mean ( dim = 0 , keepdim = True ) NEW_LINE return output NEW_LINE DEDENT\",), (\"def __init__ ( self , args , name = ' ' , train = True , benchmark = True ) : NEW_LINE INDENT super ( Benchmark , self ) . __init__ ( args , name = name , train = train , benchmark = True ) NEW_LINE DEDENT\",), (\"def _set_filesystem ( self , dir_data ) : NEW_LINE INDENT self . apath = os . path . join ( dir_data , ' benchmark ' , self . name ) NEW_LINE self . dir_hr = os . path . join ( self . apath , ' HR ' ) NEW_LINE self . dir_lr = os . path . join ( self . apath , self . args . lr_type ) NEW_LINE self . ext = ( ' ' , ' . png ' ) NEW_LINE print ( self . dir_lr ) NEW_LINE print ( self . dir_hr ) NEW_LINE DEDENT\",), (\"def __init__ ( self , args , name = ' DIV2K ' , train = True , benchmark = False ) : NEW_LINE INDENT super ( DIV2K , self ) . __init__ ( args , name = name , train = train , benchmark = benchmark ) NEW_LINE DEDENT\",), ('def _scan ( self ) : NEW_LINE INDENT names_hr , names_lr = super ( DIV2K , self ) . _scan ( ) NEW_LINE names_hr = names_hr [ self . begin - 1 : self . end ] NEW_LINE names_lr = [ n [ self . begin - 1 : self . end ] for n in names_lr ] NEW_LINE return names_hr , names_lr NEW_LINE DEDENT',), (\"def _set_filesystem ( self , dir_data ) : NEW_LINE INDENT super ( DIV2K , self ) . _set_filesystem ( dir_data ) NEW_LINE self . dir_hr = os . path . join ( self . apath , ' DIV2K _ train _ HR ' ) NEW_LINE self . dir_lr = os . path . join ( self . apath , ' DIV2K _ train _ ' + self . args . lr_type ) NEW_LINE DEDENT\",), (\"def __init__ ( self , args , name = ' ' , train = True , benchmark = False ) : NEW_LINE INDENT self . args = args NEW_LINE self . name = name NEW_LINE self . train = train NEW_LINE self . split = ' train ' if train else ' test ' NEW_LINE self . do_eval = True NEW_LINE self . benchmark = benchmark NEW_LINE self . scale = args . scale NEW_LINE self . idx_scale = 0 NEW_LINE data_range = [ r . split ( ' - ' ) for r in args . data_range . split ( ' / ' ) ] NEW_LINE if train : NEW_LINE INDENT data_range = data_range [ 0 ] NEW_LINE DEDENT else : NEW_LINE INDENT if args . test_only and len ( data_range ) == 1 : NEW_LINE INDENT data_range = data_range [ 0 ] NEW_LINE DEDENT else : NEW_LINE INDENT data_range = data_range [ 1 ] NEW_LINE DEDENT DEDENT self . begin , self . end = list ( map ( lambda x : int ( x ) , data_range ) ) NEW_LINE self . _set_filesystem ( args . dir_data ) NEW_LINE if args . ext . find ( ' img ' ) < 0 : NEW_LINE INDENT path_bin = os . path . join ( self . apath , ' bin ' ) NEW_LINE os . makedirs ( path_bin , exist_ok = True ) NEW_LINE DEDENT list_hr , list_lr = self . _scan ( ) NEW_LINE if args . ext . find ( ' bin ' ) >= 0 : NEW_LINE INDENT list_hr , list_lr = self . _scan ( ) NEW_LINE self . images_hr = self . _check_and_load ( args . ext , list_hr , self . _name_hrbin ( ) ) NEW_LINE self . images_lr = [ self . _check_and_load ( args . ext , l , self . _name_lrbin ( s ) ) for s , l in zip ( self . scale , list_lr ) ] NEW_LINE DEDENT else : NEW_LINE INDENT if args . ext . find ( ' img ' ) >= 0 or benchmark : NEW_LINE INDENT self . images_hr , self . images_lr = list_hr , list_lr NEW_LINE DEDENT elif args . ext . find ( ' sep ' ) >= 0 : NEW_LINE INDENT os . makedirs ( self . dir_hr . replace ( self . apath , path_bin ) , exist_ok = True ) NEW_LINE for s in self . scale : NEW_LINE INDENT os . makedirs ( os . path . join ( self . dir_lr . replace ( self . apath , path_bin ) , ' X { } ' . format ( s ) ) , exist_ok = True ) NEW_LINE DEDENT self . images_hr , self . images_lr = [ ] , [ [ ] for _ in self . scale ] NEW_LINE for h in list_hr : NEW_LINE INDENT b = h . replace ( self . apath , path_bin ) NEW_LINE b = b . replace ( self . ext [ 0 ] , ' . pt ' ) NEW_LINE self . images_hr . append ( b ) NEW_LINE self . _check_and_load ( args . ext , [ h ] , b , verbose = True , load = False ) NEW_LINE DEDENT for i , ll in enumerate ( list_lr ) : NEW_LINE INDENT for l in ll : NEW_LINE INDENT b = l . replace ( self . apath , path_bin ) NEW_LINE b = b . replace ( self . ext [ 1 ] , ' . pt ' ) NEW_LINE self . images_lr [ i ] . append ( b ) NEW_LINE self . _check_and_load ( args . ext , [ l ] , b , verbose = True , load = False ) NEW_LINE DEDENT DEDENT DEDENT DEDENT if train : NEW_LINE INDENT self . repeat = args . test_every // ( len ( self . images_hr ) // args . batch_size ) NEW_LINE DEDENT DEDENT\",), (\"def _scan ( self ) : NEW_LINE INDENT names_hr = sorted ( glob . glob ( os . path . join ( self . dir_hr , ' * ' + self . ext [ 0 ] ) ) ) NEW_LINE names_lr = [ [ ] for _ in self . scale ] NEW_LINE for f in names_hr : NEW_LINE INDENT filename , _ = os . path . splitext ( os . path . basename ( f ) ) NEW_LINE for si , s in enumerate ( self . scale ) : NEW_LINE INDENT names_lr [ si ] . append ( os . path . join ( self . dir_lr , ' X { } / { } x { } { } ' . format ( s , filename , s , self . ext [ 1 ] ) ) ) NEW_LINE DEDENT DEDENT return names_hr , names_lr NEW_LINE DEDENT\",), (\"def _set_filesystem ( self , dir_data ) : NEW_LINE INDENT self . apath = os . path . join ( dir_data , self . name ) NEW_LINE self . dir_hr = os . path . join ( self . apath , ' HR ' ) NEW_LINE self . dir_lr = os . path . join ( self . apath , ' LR _ bicubic ' ) NEW_LINE self . ext = ( ' . png ' , ' . png ' ) NEW_LINE DEDENT\",), (\"def _name_hrbin ( self ) : NEW_LINE INDENT return os . path . join ( self . apath , ' bin ' , ' { } _ bin _ HR . pt ' . format ( self . split ) ) NEW_LINE DEDENT\",), (\"def _name_lrbin ( self , scale ) : NEW_LINE INDENT return os . path . join ( self . apath , ' bin ' , ' { } _ bin _ LR _ X { } . pt ' . format ( self . split , scale ) ) NEW_LINE DEDENT\",), (\"def _check_and_load ( self , ext , l , f , verbose = True , load = True ) : NEW_LINE INDENT if os . path . isfile ( f ) and ext . find ( ' reset ' ) < 0 : NEW_LINE INDENT if load : NEW_LINE INDENT if verbose : print ( ' Loading ▁ { } . . . ' . format ( f ) ) NEW_LINE with open ( f , ' rb ' ) as _f : ret = pickle . load ( _f ) NEW_LINE return ret NEW_LINE DEDENT else : NEW_LINE INDENT return None NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT if verbose : NEW_LINE INDENT if ext . find ( ' reset ' ) >= 0 : NEW_LINE INDENT print ( ' Making ▁ a ▁ new ▁ binary : ▁ { } ' . format ( f ) ) NEW_LINE DEDENT else : NEW_LINE INDENT print ( ' { } ▁ does ▁ not ▁ exist . ▁ Now ▁ making ▁ binary . . . ' . format ( f ) ) NEW_LINE DEDENT DEDENT b = [ { ' name ' : os . path . splitext ( os . path . basename ( _l ) ) [ 0 ] , ' image ' : imageio . imread ( _l ) } for _l in l ] NEW_LINE with open ( f , ' wb ' ) as _f : pickle . dump ( b , _f ) NEW_LINE return b NEW_LINE DEDENT DEDENT\",), ('def __getitem__ ( self , idx ) : NEW_LINE INDENT lr , hr , filename = self . _load_file ( idx ) NEW_LINE lr , hr = self . get_patch ( lr , hr ) NEW_LINE lr , hr = common . set_channel ( lr , hr , n_channels = self . args . n_colors ) NEW_LINE lr_tensor , hr_tensor = common . np2Tensor ( lr , hr , rgb_range = self . args . rgb_range ) NEW_LINE return lr_tensor , hr_tensor , filename NEW_LINE DEDENT',), ('def __len__ ( self ) : NEW_LINE INDENT if self . train : NEW_LINE INDENT return len ( self . images_hr ) * self . repeat NEW_LINE DEDENT else : NEW_LINE INDENT return len ( self . images_hr ) NEW_LINE DEDENT DEDENT',), ('def _get_index ( self , idx ) : NEW_LINE INDENT if self . train : NEW_LINE INDENT return idx % len ( self . images_hr ) NEW_LINE DEDENT else : NEW_LINE INDENT return idx NEW_LINE DEDENT DEDENT',), (\"def _load_file ( self , idx ) : NEW_LINE INDENT idx = self . _get_index ( idx ) NEW_LINE f_hr = self . images_hr [ idx ] NEW_LINE f_lr = self . images_lr [ self . idx_scale ] [ idx ] NEW_LINE if self . args . ext . find ( ' bin ' ) >= 0 : NEW_LINE INDENT filename = f_hr [ ' name ' ] NEW_LINE hr = f_hr [ ' image ' ] NEW_LINE lr = f_lr [ ' image ' ] NEW_LINE DEDENT else : NEW_LINE INDENT filename , _ = os . path . splitext ( os . path . basename ( f_hr ) ) NEW_LINE if self . args . ext == ' img ' or self . benchmark : NEW_LINE INDENT hr = imageio . imread ( f_hr ) NEW_LINE lr = imageio . imread ( f_lr ) NEW_LINE DEDENT elif self . args . ext . find ( ' sep ' ) >= 0 : NEW_LINE INDENT with open ( f_hr , ' rb ' ) as _f : hr = np . load ( _f ) [ 0 ] [ ' image ' ] NEW_LINE with open ( f_lr , ' rb ' ) as _f : lr = np . load ( _f ) [ 0 ] [ ' image ' ] NEW_LINE DEDENT DEDENT return lr , hr , filename NEW_LINE DEDENT\",), ('def get_patch ( self , lr , hr ) : NEW_LINE INDENT scale = self . scale [ self . idx_scale ] NEW_LINE multi_scale = len ( self . scale ) > 1 NEW_LINE if self . train : NEW_LINE INDENT lr , hr = common . get_patch ( lr , hr , patch_size = self . args . patch_size , scale = scale , multi_scale = multi_scale ) NEW_LINE if not self . args . no_augment : NEW_LINE INDENT lr , hr = common . augment ( lr , hr ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT ih , iw = lr . shape [ : 2 ] NEW_LINE hr = hr [ 0 : ih * scale , 0 : iw * scale ] NEW_LINE DEDENT return lr , hr NEW_LINE DEDENT',), ('def set_scale ( self , idx_scale ) : NEW_LINE INDENT self . idx_scale = idx_scale NEW_LINE DEDENT',), (\"def __init__ ( self , args , name = ' Demo ' , train = False , benchmark = False ) : NEW_LINE INDENT self . args = args NEW_LINE self . name = name NEW_LINE self . scale = args . scale NEW_LINE self . idx_scale = 0 NEW_LINE self . train = False NEW_LINE self . do_eval = False NEW_LINE self . benchmark = benchmark NEW_LINE self . filelist = [ ] NEW_LINE for f in os . listdir ( args . dir_demo ) : NEW_LINE INDENT if f . find ( ' . png ' ) >= 0 or f . find ( ' . jp ' ) >= 0 : NEW_LINE INDENT self . filelist . append ( os . path . join ( args . dir_demo , f ) ) NEW_LINE DEDENT DEDENT self . filelist . sort ( ) NEW_LINE DEDENT\",), ('def __getitem__ ( self , idx ) : NEW_LINE INDENT filename = os . path . split ( self . filelist [ idx ] ) [ - 1 ] NEW_LINE filename , _ = os . path . splitext ( filename ) NEW_LINE lr = imageio . imread ( self . filelist [ idx ] ) NEW_LINE lr , = common . set_channel ( lr , n_channels = self . args . n_colors ) NEW_LINE lr_t , = common . np2Tensor ( lr , rgb_range = self . args . rgb_range ) NEW_LINE return lr_t , - 1 , filename NEW_LINE DEDENT',), ('def __len__ ( self ) : NEW_LINE INDENT return len ( self . filelist ) NEW_LINE DEDENT',), ('def set_scale ( self , idx_scale ) : NEW_LINE INDENT self . idx_scale = idx_scale NEW_LINE DEDENT',), (\"def __init__ ( self , args ) : NEW_LINE INDENT self . loader_train = None NEW_LINE if not args . test_only : NEW_LINE INDENT module_train = import_module ( ' data . ' + args . data_train . lower ( ) ) NEW_LINE trainset = getattr ( module_train , args . data_train ) ( args ) NEW_LINE self . loader_train = MSDataLoader ( args , trainset , batch_size = args . batch_size , shuffle = True , pin_memory = not args . cpu ) NEW_LINE DEDENT if args . data_test in [ ' Set5' , ' Set14' , ' B100' , ' Urban100' , ' Manga109' ] : NEW_LINE INDENT module_test = import_module ( ' data . benchmark ' ) NEW_LINE testset = getattr ( module_test , ' Benchmark ' ) ( args , name = args . data_test , train = False ) NEW_LINE DEDENT else : NEW_LINE INDENT module_test = import_module ( ' data . ' + args . data_test . lower ( ) ) NEW_LINE testset = getattr ( module_test , args . data_test ) ( args , train = False ) NEW_LINE DEDENT self . loader_test = MSDataLoader ( args , testset , batch_size = 1 , shuffle = False , pin_memory = not args . cpu ) NEW_LINE DEDENT\",), ('def get_patch ( * args , patch_size = 96 , scale = 1 , multi_scale = False ) : NEW_LINE INDENT ih , iw = args [ 0 ] . shape [ : 2 ] NEW_LINE p = scale if multi_scale else 1 NEW_LINE tp = p * patch_size NEW_LINE ip = tp // scale NEW_LINE ix = random . randrange ( 0 , iw - ip + 1 ) NEW_LINE iy = random . randrange ( 0 , ih - ip + 1 ) NEW_LINE tx , ty = scale * ix , scale * iy NEW_LINE ret = [ args [ 0 ] [ iy : iy + ip , ix : ix + ip , : ] , * [ a [ ty : ty + tp , tx : tx + tp , : ] for a in args [ 1 : ] ] ] NEW_LINE return ret NEW_LINE DEDENT',), ('def set_channel ( * args , n_channels = 3 ) : NEW_LINE INDENT def _set_channel ( img ) : NEW_LINE INDENT if img . ndim == 2 : NEW_LINE INDENT img = np . expand_dims ( img , axis = 2 ) NEW_LINE DEDENT c = img . shape [ 2 ] NEW_LINE if n_channels == 1 and c == 3 : NEW_LINE INDENT img = np . expand_dims ( sc . rgb2ycbcr ( img ) [ : , : , 0 ] , 2 ) NEW_LINE DEDENT elif n_channels == 3 and c == 1 : NEW_LINE INDENT img = np . concatenate ( [ img ] * n_channels , 2 ) NEW_LINE DEDENT return img NEW_LINE DEDENT return [ _set_channel ( a ) for a in args ] NEW_LINE DEDENT',), ('def np2Tensor ( * args , rgb_range = 255 ) : NEW_LINE INDENT def _np2Tensor ( img ) : NEW_LINE INDENT np_transpose = np . ascontiguousarray ( img . transpose ( ( 2 , 0 , 1 ) ) ) NEW_LINE np_transpose = np_transpose . astype ( np . float32 ) NEW_LINE tensor = torch . from_numpy ( np_transpose ) . float ( ) NEW_LINE tensor . mul_ ( rgb_range / 255 ) NEW_LINE return tensor NEW_LINE DEDENT return [ _np2Tensor ( a ) for a in args ] NEW_LINE DEDENT',), ('def augment ( * args , hflip = True , rot = True ) : NEW_LINE INDENT hflip = hflip and random . random ( ) < 0.5 NEW_LINE vflip = rot and random . random ( ) < 0.5 NEW_LINE rot90 = rot and random . random ( ) < 0.5 NEW_LINE def _augment ( img ) : NEW_LINE INDENT if hflip : img = img [ : , : : - 1 , : ] NEW_LINE if vflip : img = img [ : : - 1 , : , : ] NEW_LINE if rot90 : img = img . transpose ( 1 , 0 , 2 ) NEW_LINE return img NEW_LINE DEDENT return [ _augment ( a ) for a in args ] NEW_LINE DEDENT',)]\n",
            "1.2839103117585182\n",
            "On batch 1023\n",
            "tensor([0.0056, 0.0056, 0.0055, 0.0055, 0.0055, 0.0055, 0.0056, 0.0055, 0.0054,\n",
            "        0.0055, 0.0054, 0.0055, 0.0055, 0.0055, 0.0055, 0.0055, 0.0055, 0.0055,\n",
            "        0.0055, 0.0054, 0.0054, 0.0055, 0.0056, 0.0055, 0.0055, 0.0055, 0.0055,\n",
            "        0.0055, 0.0054, 0.0054, 0.0055, 0.0055, 0.0054, 0.0055, 0.0055, 0.0055,\n",
            "        0.0055, 0.0055, 0.0055, 0.0055, 0.0054, 0.0055, 0.0055, 0.0055, 0.0055,\n",
            "        0.0055, 0.0055, 0.0055, 0.0056, 0.0056, 0.0055, 0.0055, 0.0055, 0.0055,\n",
            "        0.0055, 0.0054, 0.0055, 0.0055, 0.0055, 0.0055, 0.0055, 0.0055, 0.0055,\n",
            "        0.0055, 0.0055, 0.0055, 0.0055, 0.0055, 0.0055, 0.0054, 0.0055, 0.0056,\n",
            "        0.0055, 0.0055, 0.0054, 0.0054, 0.0054, 0.0055, 0.0055, 0.0055, 0.0055,\n",
            "        0.0055, 0.0055, 0.0055, 0.0055, 0.0055, 0.0055, 0.0055, 0.0054, 0.0056,\n",
            "        0.0055, 0.0056, 0.0055, 0.0056, 0.0054, 0.0055, 0.0055, 0.0055, 0.0055,\n",
            "        0.0055, 0.0055, 0.0055, 0.0055, 0.0056, 0.0055, 0.0054, 0.0056, 0.0055,\n",
            "        0.0055, 0.0054, 0.0055, 0.0056, 0.0055, 0.0055, 0.0055, 0.0055, 0.0055,\n",
            "        0.0055, 0.0055, 0.0054, 0.0054, 0.0055, 0.0055, 0.0055, 0.0055, 0.0055,\n",
            "        0.0055, 0.0055, 0.0056, 0.0056, 0.0056, 0.0055, 0.0055, 0.0055, 0.0054,\n",
            "        0.0055, 0.0056, 0.0055, 0.0054, 0.0055, 0.0055, 0.0055, 0.0055, 0.0054,\n",
            "        0.0054, 0.0056, 0.0055, 0.0054, 0.0055, 0.0055, 0.0054, 0.0054, 0.0055,\n",
            "        0.0054, 0.0055, 0.0054, 0.0055, 0.0055, 0.0055, 0.0055, 0.0055, 0.0055,\n",
            "        0.0054, 0.0054, 0.0055, 0.0055, 0.0055, 0.0055, 0.0056, 0.0055, 0.0055,\n",
            "        0.0054, 0.0054, 0.0055, 0.0055, 0.0056, 0.0055, 0.0055, 0.0054, 0.0056,\n",
            "        0.0055, 0.0056], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "('\\n\\\\label{equ:alignerror}\\n    \\\\text{error}(T) = \\\\frac{1}{M} \\\\Sigma_{i=1}^{M} |(T - T_{\\\\text{gt}}) x_{i\\\\_\\\\text{reference}}|_2\\n',)\n",
            "[('def _check_for_openmp ( ) : NEW_LINE INDENT import distutils . sysconfig NEW_LINE import tempfile NEW_LINE import shutil NEW_LINE tmpdir = tempfile . mkdtemp ( prefix = \\' probreg \\' ) NEW_LINE compiler = os . environ . get ( \\' CC \\' , distutils . sysconfig . get_config_var ( \\' CC \\' ) ) NEW_LINE if compiler is None : NEW_LINE INDENT return False NEW_LINE DEDENT compiler = compiler . split ( ) [ 0 ] NEW_LINE tmpfile = os . path . join ( tmpdir , \\' check _ openmp . c \\' ) NEW_LINE with open ( tmpfile , \\' w \\' ) as f : NEW_LINE INDENT f . write ( \\'\\'\\' STRNEWLINE # include ▁ < omp . h > STRNEWLINE # include ▁ < stdio . h > STRNEWLINE int ▁ main ( ) ▁ { STRNEWLINE ▁ ▁ ▁ ▁ # pragma ▁ omp ▁ parallel STRNEWLINE ▁ ▁ ▁ ▁ printf ( \" Hello ▁ from ▁ thread ▁ % d \" , ▁ omp _ get _ thread _ num ( ) ) ; STRNEWLINE } STRNEWLINE \\'\\'\\' ) NEW_LINE DEDENT try : NEW_LINE INDENT with open ( os . devnull , \\' w \\' ) as fnull : NEW_LINE INDENT exit_code = subprocess . call ( [ compiler , \\' - fopenmp \\' , \\' - o % s \\' % os . path . join ( tmpdir , \\' check _ openmp \\' ) , tmpfile ] , stdout = fnull , stderr = fnull ) NEW_LINE DEDENT DEDENT except OSError : NEW_LINE INDENT exit_code = 1 NEW_LINE DEDENT finally : NEW_LINE INDENT shutil . rmtree ( tmpdir ) NEW_LINE DEDENT if exit_code == 0 : NEW_LINE INDENT print ( \\' Continuing ▁ your ▁ build ▁ using ▁ OpenMP . . . \\\\n \\' ) NEW_LINE return True NEW_LINE DEDENT return False NEW_LINE DEDENT',), ('def find_eigen ( hint = [ ] ) : NEW_LINE INDENT search_dirs = hint + [ \" / usr / local / include / eigen3\" , \" / usr / local / homebrew / include / eigen3\" , \" / opt / local / var / macports / software / eigen3\" , \" / opt / local / include / eigen3\" , \" / usr / include / eigen3\" , \" / usr / include / local \" , \" / usr / include \" , ] NEW_LINE for d in search_dirs : NEW_LINE INDENT path = os . path . join ( d , \" Eigen \" , \" Dense \" ) NEW_LINE if os . path . exists ( path ) : NEW_LINE INDENT vf = os . path . join ( d , \" Eigen \" , \" src \" , \" Core \" , \" util \" , \" Macros . h \" ) NEW_LINE if not os . path . exists ( vf ) : NEW_LINE INDENT continue NEW_LINE DEDENT src = open ( vf , \" r \" ) . read ( ) NEW_LINE v1 = re . findall ( \" # define ▁ EIGEN _ WORLD _ VERSION ▁ ( . + ) \" , src ) NEW_LINE v2 = re . findall ( \" # define ▁ EIGEN _ MAJOR _ VERSION ▁ ( . + ) \" , src ) NEW_LINE v3 = re . findall ( \" # define ▁ EIGEN _ MINOR _ VERSION ▁ ( . + ) \" , src ) NEW_LINE if not len ( v1 ) or not len ( v2 ) or not len ( v3 ) : NEW_LINE INDENT continue NEW_LINE DEDENT v = \" { 0 } . {1 } . {2 } \" . format ( v1 [ 0 ] , v2 [ 0 ] , v3 [ 0 ] ) NEW_LINE print ( \" Found ▁ Eigen ▁ version ▁ { 0 } ▁ in : ▁ { 1 } \" . format ( v , d ) ) NEW_LINE return d NEW_LINE DEDENT DEDENT return None NEW_LINE DEDENT',), (\"def has_flag ( compiler , flagname ) : NEW_LINE INDENT import tempfile NEW_LINE with tempfile . NamedTemporaryFile ( ' w ' , suffix = ' . cpp ' ) as f : NEW_LINE INDENT f . write ( ' int ▁ main ▁ ( int ▁ argc , ▁ char ▁ * * argv ) ▁ { ▁ return ▁ 0 ; ▁ } ' ) NEW_LINE try : NEW_LINE INDENT compiler . compile ( [ f . name ] , extra_postargs = [ flagname ] ) NEW_LINE DEDENT except setuptools . distutils . errors . CompileError : NEW_LINE INDENT return False NEW_LINE DEDENT DEDENT return True NEW_LINE DEDENT\",), (\"def cpp_flag ( compiler ) : NEW_LINE INDENT if has_flag ( compiler , ' - std = c + + 14' ) : NEW_LINE INDENT return ' - std = c + + 14' NEW_LINE DEDENT elif has_flag ( compiler , ' - std = c + + 11' ) : NEW_LINE INDENT return ' - std = c + + 11' NEW_LINE DEDENT else : NEW_LINE INDENT raise RuntimeError ( ' Unsupported ▁ compiler ▁ - - ▁ at ▁ least ▁ C + + 11 ▁ support ▁ ' ' is ▁ needed ! ' ) NEW_LINE DEDENT DEDENT\",), (\"def __init__ ( self , user = False ) : NEW_LINE INDENT try : NEW_LINE INDENT import pybind11 NEW_LINE DEDENT except ImportError : NEW_LINE INDENT if subprocess . call ( [ sys . executable , ' - m ' , ' pip ' , ' install ' , ' pybind11' ] ) : NEW_LINE INDENT raise RuntimeError ( ' pybind11 ▁ install ▁ failed . ' ) NEW_LINE DEDENT DEDENT self . user = user NEW_LINE DEDENT\",), ('def __str__ ( self ) : NEW_LINE INDENT import pybind11 NEW_LINE return pybind11 . get_include ( self . user ) NEW_LINE DEDENT',), (\"def build_extensions ( self ) : NEW_LINE INDENT ct = self . compiler . compiler_type NEW_LINE opts = self . c_opts . get ( ct , [ ] ) NEW_LINE if ct == ' unix ' : NEW_LINE INDENT opts . append ( cpp_flag ( self . compiler ) ) NEW_LINE if use_omp : NEW_LINE INDENT opts . append ( ' - fopenmp ' ) NEW_LINE DEDENT if has_flag ( self . compiler , ' - fvisibility = hidden ' ) : NEW_LINE INDENT opts . append ( ' - fvisibility = hidden ' ) NEW_LINE DEDENT DEDENT for ext in self . extensions : NEW_LINE INDENT ext . extra_compile_args = opts NEW_LINE DEDENT build_ext . build_extensions ( self ) NEW_LINE DEDENT\",), ('def test_gaussian_filtering ( self ) : NEW_LINE INDENT x = np . random . rand ( 10 , 1 ) NEW_LINE v0 = np . r_ [ np . zeros ( ( 5 , 1 ) ) , np . ones ( ( 5 , 1 ) ) ] NEW_LINE v1 = np . r_ [ np . zeros ( ( 5 , 1 ) ) , np . random . rand ( 5 , 1 ) ] NEW_LINE ph = gf . Permutohedral ( x ) NEW_LINE out0 = ph . filter ( v0 ) . flatten ( ) [ : 5 ] NEW_LINE out1 = ph . filter ( v1 ) . flatten ( ) [ : 5 ] NEW_LINE out2 = gt . _gauss_transform_direct ( x [ 5 : , : ] , x [ : 5 , : ] , v0 . flatten ( ) [ 5 : ] , np . sqrt ( 2.0 ) ) NEW_LINE out3 = gt . _gauss_transform_direct ( x [ 5 : , : ] , x [ : 5 , : ] , v1 . flatten ( ) [ 5 : ] , np . sqrt ( 2.0 ) ) NEW_LINE self . assertTrue ( np . allclose ( ( out0 / out1 ) , ( out2 / out3 ) , atol = 0 , rtol = 3.0e-1 ) ) NEW_LINE DEDENT',), ('def estimate_normals ( pcd , params ) : NEW_LINE INDENT pcd . estimate_normals ( search_param = params ) NEW_LINE pcd . orient_normals_to_align_with_direction ( ) NEW_LINE DEDENT',), (\"def setUp ( self ) : NEW_LINE INDENT pcd = o3 . io . read_point_cloud ( ' data / horse . ply ' ) NEW_LINE pcd = pcd . voxel_down_sample ( voxel_size = 0.01 ) NEW_LINE estimate_normals ( pcd , o3 . geometry . KDTreeSearchParamHybrid ( radius = 0.01 , max_nn = 10 ) ) NEW_LINE self . _source = np . asarray ( pcd . points ) NEW_LINE rot = t3d . euler . euler2mat ( * np . random . uniform ( 0.0 , np . pi / 4 , 3 ) ) NEW_LINE self . _tf = tf . RigidTransformation ( rot , np . zeros ( 3 ) ) NEW_LINE self . _target = self . _tf . transform ( self . _source ) NEW_LINE self . _target_normals = np . asarray ( np . dot ( pcd . normals , self . _tf . rot . T ) ) NEW_LINE DEDENT\",), ('def test_filterreg_registration_pt2pt ( self ) : NEW_LINE INDENT res = filterreg . registration_filterreg ( self . _source , self . _target ) NEW_LINE self . assertTrue ( np . allclose ( t3d . euler . mat2euler ( res . transformation . rot ) , t3d . euler . mat2euler ( self . _tf . rot ) , atol = 2.0e-1 , rtol = 1.0e-1 ) ) NEW_LINE self . assertTrue ( np . allclose ( res . transformation . t , self . _tf . t , atol = 1.0e-2 , rtol = 1.0e-3 ) ) NEW_LINE DEDENT',), ('def test_filterreg_registration_pt2pl ( self ) : NEW_LINE INDENT res = filterreg . registration_filterreg ( self . _source , self . _target , self . _target_normals ) NEW_LINE self . assertTrue ( np . allclose ( t3d . euler . mat2euler ( res . transformation . rot ) , t3d . euler . mat2euler ( self . _tf . rot ) , atol = 2.0e-1 , rtol = 1.0e-1 ) ) NEW_LINE self . assertTrue ( np . allclose ( res . transformation . t , self . _tf . t , atol = 1.0e-2 , rtol = 1.0e-3 ) ) NEW_LINE DEDENT',), ('def test_k_center_clustering ( self ) : NEW_LINE INDENT k1 = np . array ( [ 0.0 , 0.0 ] ) NEW_LINE k2 = np . array ( [ 10.0 , 10.0 ] ) NEW_LINE n = 10 NEW_LINE k1s = k1 + np . random . rand ( n , 2 ) NEW_LINE k2s = k2 + np . random . rand ( n , 2 ) NEW_LINE x = np . r_ [ k1s , k2s ] NEW_LINE idxs = _ifgt . _kcenter_clustering ( x , 2 ) NEW_LINE self . assertTrue ( ( idxs [ : n ] != idxs [ n : ] ) . all ( ) ) NEW_LINE DEDENT',), ('def test_gauss_transform ( self ) : NEW_LINE INDENT x = np . random . rand ( 10 , 3 ) NEW_LINE y = np . random . rand ( 5 , 3 ) NEW_LINE w = np . random . rand ( 10 ) NEW_LINE h = 1.0 NEW_LINE ans = gt . _gauss_transform_direct ( x , y , w , h ) NEW_LINE trans = gt . GaussTransform ( x , h , sw_h = 0.0 ) NEW_LINE self . assertTrue ( np . allclose ( ans , trans . compute ( y , w ) , atol = 1.0e-4 , rtol = 1.0e-4 ) ) NEW_LINE h = 0.5 NEW_LINE ans = gt . _gauss_transform_direct ( x , y , w , h ) NEW_LINE trans = gt . GaussTransform ( x , h , sw_h = 0.0 ) NEW_LINE self . assertTrue ( np . allclose ( ans , trans . compute ( y , w ) , atol = 1.0e-4 , rtol = 1.0e-4 ) ) NEW_LINE DEDENT',), (\"def setUp ( self ) : NEW_LINE INDENT pcd = o3 . io . read_point_cloud ( ' data / horse . ply ' ) NEW_LINE pcd = pcd . voxel_down_sample ( voxel_size = 0.01 ) NEW_LINE self . _source = np . asarray ( pcd . points ) NEW_LINE rot = t3d . euler . euler2mat ( * np . random . uniform ( 0.0 , np . pi / 4 , 3 ) ) NEW_LINE self . _tf = tf . RigidTransformation ( rot , np . zeros ( 3 ) ) NEW_LINE self . _target = self . _tf . transform ( self . _source ) NEW_LINE DEDENT\",), ('def test_cpd_registration ( self ) : NEW_LINE INDENT res = cpd . registration_cpd ( self . _source , self . _target ) NEW_LINE self . assertTrue ( np . allclose ( t3d . euler . mat2euler ( res . transformation . rot ) , t3d . euler . mat2euler ( self . _tf . rot ) , atol = 1.0e-2 , rtol = 1.0e-2 ) ) NEW_LINE self . assertTrue ( np . allclose ( res . transformation . t , self . _tf . t , atol = 1.0e-4 , rtol = 1.0e-4 ) ) NEW_LINE DEDENT',), ('def setUp ( self ) : NEW_LINE INDENT points = [ ] NEW_LINE normals = [ ] NEW_LINE resolution = 0.2 NEW_LINE for i in range ( 5 ) : NEW_LINE INDENT for j in range ( 5 ) : NEW_LINE INDENT points . append ( np . array ( [ - 0.5 + i * resolution , - 0.5 + j * resolution , - 0.5 ] ) ) NEW_LINE normals . append ( np . array ( [ 0.0 , 0.0 , 1.0 ] ) ) NEW_LINE DEDENT DEDENT self . _source = np . array ( points ) NEW_LINE rot = t3d . euler . euler2mat ( np . deg2rad ( 10.0 ) , 0.0 , 0.0 ) NEW_LINE self . _tf = tf . RigidTransformation ( rot , np . zeros ( 3 ) ) NEW_LINE self . _target = self . _tf . transform ( self . _source ) NEW_LINE self . _target_normals = np . dot ( np . array ( normals ) , self . _tf . rot . T ) NEW_LINE DEDENT',), ('def test_point_to_plane ( self ) : NEW_LINE INDENT tw , q = pt2pl . compute_twist_for_pt2pl ( self . _source , self . _target , self . _target_normals , np . ones ( self . _source . shape [ 0 ] ) ) NEW_LINE r , t = so . twist_mul ( tw , np . identity ( 3 ) , np . zeros ( 3 ) ) NEW_LINE r0 = np . identity ( 4 ) NEW_LINE r0 [ : 3 , : 3 ] = r NEW_LINE r1 = np . identity ( 4 ) NEW_LINE r1 [ : 3 , : 3 ] = self . _tf . rot NEW_LINE self . assertTrue ( np . allclose ( r0 * r1 . transpose ( ) , np . identity ( 4 ) , atol = 5.0e-2 , rtol = 1.0e-2 ) ) NEW_LINE self . assertTrue ( np . allclose ( t , self . _tf . t , atol = 5.0e-1 , rtol = 1.0e-2 ) ) NEW_LINE DEDENT',), (\"def setUp ( self ) : NEW_LINE INDENT pcd = o3 . io . read_point_cloud ( ' data / horse . ply ' ) NEW_LINE pcd = pcd . voxel_down_sample ( voxel_size = 0.01 ) NEW_LINE self . _source = np . asarray ( pcd . points ) NEW_LINE rot = t3d . euler . euler2mat ( * np . random . uniform ( 0.0 , np . pi / 4 , 3 ) ) NEW_LINE self . _tf = tf . RigidTransformation ( rot , np . zeros ( 3 ) ) NEW_LINE self . _target = self . _tf . transform ( self . _source ) NEW_LINE DEDENT\",), ('def test_svr_registration ( self ) : NEW_LINE INDENT res = l2dist_regs . registration_svr ( self . _source , self . _target ) NEW_LINE self . assertTrue ( np . allclose ( t3d . euler . mat2euler ( res . rot ) , t3d . euler . mat2euler ( self . _tf . rot ) , atol = 1.0e-1 , rtol = 1.0e-1 ) ) NEW_LINE self . assertTrue ( np . allclose ( res . t , self . _tf . t , atol = 1.0e-2 , rtol = 1.0e-3 ) ) NEW_LINE DEDENT',), ('def test_pairwise_squared_sum ( self ) : NEW_LINE INDENT n = 5 NEW_LINE dim = 3 NEW_LINE x = np . arange ( n * dim ) . reshape ( ( n , dim ) ) NEW_LINE ans = np . sum ( [ np . sum ( ( x [ i ] - x ) ** 2 ) for i in range ( n ) ] ) / ( n * n * dim ) NEW_LINE self . assertAlmostEqual ( mu . squared_kernel_sum ( x , x ) , ans ) NEW_LINE DEDENT',), ('def test_rbf_kernel ( self ) : NEW_LINE INDENT x = np . random . rand ( 5 , 3 ) NEW_LINE g = mu . rbf_kernel ( x , x , 1.0 ) NEW_LINE self . assertTrue ( np . allclose ( g , g . T ) ) NEW_LINE DEDENT',), ('def __new__ ( cls , n_points ) : NEW_LINE INDENT return super ( DeformableKinematicModel . SkinningWeight , cls ) . __new__ ( cls , n_points , dtype = [ ( \" pair \" , \" i4\" , 2 ) , ( \" val \" , \" f4\" , 2 ) ] ) NEW_LINE DEDENT',), ('def make_weight ( cls , pairs , vals ) : NEW_LINE INDENT weights = cls . SkinningWeight ( pairs . shape [ 0 ] ) NEW_LINE weights [ \" pair \" ] = pairs NEW_LINE weights [ \" val \" ] = vals NEW_LINE return weights NEW_LINE DEDENT',), ('def __init__ ( self , xp = np ) : NEW_LINE INDENT self . xp = xp NEW_LINE DEDENT',), ('def transform ( self , points , array_type = o3 . utility . Vector3dVector ) : NEW_LINE INDENT if isinstance ( points , array_type ) : NEW_LINE INDENT return array_type ( self . _transform ( self . xp . asarray ( points ) ) ) NEW_LINE DEDENT return self . _transform ( points ) NEW_LINE DEDENT',), ('def _transform ( self , points ) : NEW_LINE INDENT return points NEW_LINE DEDENT',), ('def __init__ ( self , rot = np . identity ( 3 ) , t = np . zeros ( 3 ) , scale = 1.0 , xp = np ) : NEW_LINE INDENT super ( RigidTransformation , self ) . __init__ ( xp ) NEW_LINE self . rot = rot NEW_LINE self . t = t NEW_LINE self . scale = scale NEW_LINE DEDENT',), ('def _transform ( self , points ) : NEW_LINE INDENT return self . scale * self . xp . dot ( points , self . rot . T ) + self . t NEW_LINE DEDENT',), ('def inverse ( self ) : NEW_LINE INDENT return RigidTransformation ( self . rot . T , - self . xp . dot ( self . rot . T , self . t ) / self . scale , 1.0 / self . scale ) NEW_LINE DEDENT',), ('def __mul__ ( self , other ) : NEW_LINE INDENT return RigidTransformation ( self . xp . dot ( self . rot , other . rot ) , self . t + self . scale * self . xp . dot ( self . rot , other . t ) , self . scale * other . scale , ) NEW_LINE DEDENT',), ('def __init__ ( self , b = np . identity ( 3 ) , t = np . zeros ( 3 ) , xp = np ) : NEW_LINE INDENT super ( AffineTransformation , self ) . __init__ ( xp ) NEW_LINE self . b = b NEW_LINE self . t = t NEW_LINE DEDENT',), ('def _transform ( self , points ) : NEW_LINE INDENT return self . xp . dot ( points , self . b . T ) + self . t NEW_LINE DEDENT',), ('def __init__ ( self , w , points , beta = 2.0 , xp = np ) : NEW_LINE INDENT super ( NonRigidTransformation , self ) . __init__ ( xp ) NEW_LINE if xp == np : NEW_LINE INDENT self . g = mu . rbf_kernel ( points , points , beta ) NEW_LINE DEDENT else : NEW_LINE INDENT from . import cupy_utils NEW_LINE self . g = cupy_utils . rbf_kernel ( points , points , beta ) NEW_LINE DEDENT self . w = w NEW_LINE DEDENT',), ('def _transform ( self , points ) : NEW_LINE INDENT return points + self . xp . dot ( self . g , self . w ) NEW_LINE DEDENT',), ('def __init__ ( self , rot = np . identity ( 3 ) , t = np . zeros ( 3 ) , scale = 1.0 , v = 0.0 ) : NEW_LINE INDENT super ( CombinedTransformation , self ) . __init__ ( ) NEW_LINE self . rigid_trans = RigidTransformation ( rot , t , scale ) NEW_LINE self . v = v NEW_LINE DEDENT',), ('def _transform ( self , points ) : NEW_LINE INDENT return self . rigid_trans . _transform ( points + self . v ) NEW_LINE DEDENT',), ('def __init__ ( self , a , v , control_pts , kernel = mu . tps_kernel ) : NEW_LINE INDENT super ( TPSTransformation , self ) . __init__ ( ) NEW_LINE self . a = a NEW_LINE self . v = v NEW_LINE self . control_pts = control_pts NEW_LINE self . _kernel = kernel NEW_LINE DEDENT',), ('def prepare ( self , landmarks ) : NEW_LINE INDENT control_pts = self . control_pts NEW_LINE m , d = landmarks . shape NEW_LINE n , _ = control_pts . shape NEW_LINE pm = np . c_ [ np . ones ( ( m , 1 ) ) , landmarks ] NEW_LINE pn = np . c_ [ np . ones ( ( n , 1 ) ) , control_pts ] NEW_LINE u , _ , _ = np . linalg . svd ( pn ) NEW_LINE pp = u [ : , d + 1 : ] NEW_LINE kk = self . _kernel ( control_pts , control_pts ) NEW_LINE uu = self . _kernel ( landmarks , control_pts ) NEW_LINE basis = np . c_ [ pm , np . dot ( uu , pp ) ] NEW_LINE kernel = np . dot ( pp . T , np . dot ( kk , pp ) ) NEW_LINE return basis , kernel NEW_LINE DEDENT',), ('def transform_basis ( self , basis ) : NEW_LINE INDENT return np . dot ( basis , np . r_ [ self . a , self . v ] ) NEW_LINE DEDENT',), ('def _transform ( self , points ) : NEW_LINE INDENT basis , _ = self . prepare ( points ) NEW_LINE return self . transform_basis ( basis ) NEW_LINE DEDENT',), ('def n_nodes ( self ) : NEW_LINE INDENT return self [ \" pair \" ] . max ( ) + 1 NEW_LINE DEDENT',), ('def pairs_set ( self ) : NEW_LINE INDENT return itertools . permutations ( range ( self . n_nodes ) , 2 ) NEW_LINE DEDENT',), ('def in_pair ( self , pair ) : NEW_LINE INDENT return np . argwhere ( ( self [ \" pair \" ] == pair ) . all ( 1 ) ) . flatten ( ) NEW_LINE DEDENT',), ('def __init__ ( self , dualquats , weights ) : NEW_LINE INDENT if not _imp_dq : NEW_LINE INDENT raise RuntimeError ( \" No ▁ dq3d ▁ python ▁ package , ▁ deformable ▁ kinematic ▁ model ▁ not ▁ available . \" ) NEW_LINE DEDENT super ( DeformableKinematicModel , self ) . __init__ ( ) NEW_LINE self . weights = weights NEW_LINE self . dualquats = dualquats NEW_LINE self . trans = [ op . dlb ( w [ 1 ] , [ self . dualquats [ i ] for i in w [ 0 ] ] ) for w in self . weights ] NEW_LINE DEDENT',), ('def _transform ( self , points ) : NEW_LINE INDENT return np . array ( [ t . transform_point ( p ) for t , p in zip ( self . trans , points ) ] ) NEW_LINE DEDENT',), ('def squared_kernel_sum ( x , y ) : NEW_LINE INDENT xc = cp . asarray ( x , dtype = cp . float32 , order = \" C \" ) NEW_LINE yc = cp . asarray ( y , dtype = cp . float32 , order = \" C \" ) NEW_LINE nx = xc . shape [ 0 ] NEW_LINE ny = yc . shape [ 0 ] NEW_LINE dim = xc . shape [ 1 ] NEW_LINE res = cp . zeros ( ( nx , ny ) , dtype = cp . float32 , order = \" C \" ) NEW_LINE grid = ( ( nx + _BLOCK_SIZE - 1 ) // _BLOCK_SIZE , ( ny + _BLOCK_SIZE - 1 ) // _BLOCK_SIZE , 1 ) NEW_LINE squard_norm_outer_kernel ( grid , ( _BLOCK_SIZE , _BLOCK_SIZE , 1 ) , ( xc , yc , dim , nx , ny , res ) ) NEW_LINE return res . sum ( ) / ( nx * ny * dim ) NEW_LINE DEDENT',), ('def rbf_kernel ( x , y , beta ) : NEW_LINE INDENT xc = cp . asarray ( x , dtype = cp . float32 , order = \" C \" ) NEW_LINE yc = cp . asarray ( y , dtype = cp . float32 , order = \" C \" ) NEW_LINE nx = xc . shape [ 0 ] NEW_LINE ny = yc . shape [ 0 ] NEW_LINE dim = xc . shape [ 1 ] NEW_LINE res = cp . zeros ( ( nx , ny ) , dtype = cp . float32 , order = \" C \" ) NEW_LINE grid = ( ( nx + _BLOCK_SIZE - 1 ) // _BLOCK_SIZE , ( ny + _BLOCK_SIZE - 1 ) // _BLOCK_SIZE , 1 ) NEW_LINE squard_norm_outer_kernel ( grid , ( _BLOCK_SIZE , _BLOCK_SIZE , 1 ) , ( xc , yc , dim , nx , ny , res ) ) NEW_LINE return cp . exp ( ( - res / ( 2.0 * beta ) ) ) NEW_LINE DEDENT',), ('def registration_gmmreg ( source , target , tf_type_name = \" rigid \" , callbacks = [ ] , ** kargs ) : NEW_LINE INDENT cv = lambda x : np . asarray ( x . points if isinstance ( x , o3 . geometry . PointCloud ) else x ) NEW_LINE if tf_type_name == \" rigid \" : NEW_LINE INDENT gmmreg = RigidGMMReg ( cv ( source ) , ** kargs ) NEW_LINE DEDENT elif tf_type_name == \" nonrigid \" : NEW_LINE INDENT gmmreg = TPSGMMReg ( cv ( source ) , ** kargs ) NEW_LINE DEDENT else : NEW_LINE INDENT raise ValueError ( \" Unknown ▁ transform ▁ type ▁ % s \" % tf_type_name ) NEW_LINE DEDENT gmmreg . set_callbacks ( callbacks ) NEW_LINE return gmmreg . registration ( cv ( target ) ) NEW_LINE DEDENT',), ('def registration_svr ( source : Union [ np . ndarray , o3 . geometry . PointCloud ] , target : Union [ np . ndarray , o3 . geometry . PointCloud ] , tf_type_name : str = \" rigid \" , maxiter : int = 1 , tol : float = 1.0e-3 , opt_maxiter : int = 50 , opt_tol : float = 1.0e-3 , callbacks : List [ Callable ] = [ ] , ** kwargs : Any , ) : NEW_LINE INDENT cv = lambda x : np . asarray ( x . points if isinstance ( x , o3 . geometry . PointCloud ) else x ) NEW_LINE if tf_type_name == \" rigid \" : NEW_LINE INDENT svr = RigidSVR ( cv ( source ) , ** kwargs ) NEW_LINE DEDENT elif tf_type_name == \" nonrigid \" : NEW_LINE INDENT svr = TPSSVR ( cv ( source ) , ** kwargs ) NEW_LINE DEDENT else : NEW_LINE INDENT raise ValueError ( \" Unknown ▁ transform ▁ type ▁ % s \" % tf_type_name ) NEW_LINE DEDENT svr . set_callbacks ( callbacks ) NEW_LINE return svr . registration ( cv ( target ) , maxiter , tol , opt_maxiter , opt_tol ) NEW_LINE DEDENT',), ('def __init__ ( self , source , feature_gen , cost_fn , sigma = 1.0 , delta = 0.9 , use_estimated_sigma = True ) : NEW_LINE INDENT self . _source = source NEW_LINE self . _feature_gen = feature_gen NEW_LINE self . _cost_fn = cost_fn NEW_LINE self . _sigma = sigma NEW_LINE self . _delta = delta NEW_LINE self . _use_estimated_sigma = use_estimated_sigma NEW_LINE self . _callbacks = [ ] NEW_LINE if not self . _source is None and self . _use_estimated_sigma : NEW_LINE INDENT self . _estimate_sigma ( self . _source ) NEW_LINE DEDENT DEDENT',), ('def set_source ( self , source ) : NEW_LINE INDENT self . _source = source NEW_LINE if self . _use_estimated_sigma : NEW_LINE INDENT self . _estimate_sigma ( self . _source ) NEW_LINE DEDENT DEDENT',), ('def set_callbacks ( self , callbacks ) : NEW_LINE INDENT self . _callbacks . extend ( callbacks ) NEW_LINE DEDENT',), ('def _estimate_sigma ( self , data ) : NEW_LINE INDENT ndata , dim = data . shape NEW_LINE data_hat = data - np . mean ( data , axis = 0 ) NEW_LINE self . _sigma = np . power ( np . linalg . det ( np . dot ( data_hat . T , data_hat ) / ( ndata - 1 ) ) , 1.0 / ( 2.0 * dim ) ) NEW_LINE DEDENT',), ('def _annealing ( self ) : NEW_LINE INDENT self . _sigma *= self . _delta NEW_LINE DEDENT',), ('def optimization_cb ( self , x ) : NEW_LINE INDENT tf_result = self . _cost_fn . to_transformation ( x ) NEW_LINE for c in self . _callbacks : NEW_LINE INDENT c ( tf_result ) NEW_LINE DEDENT DEDENT',), ('def registration ( self , target , maxiter = 1 , tol = 1.0e-3 , opt_maxiter = 50 , opt_tol = 1.0e-3 ) : NEW_LINE INDENT f = None NEW_LINE x_ini = self . _cost_fn . initial ( ) NEW_LINE for _ in range ( maxiter ) : NEW_LINE INDENT self . _feature_gen . init ( ) NEW_LINE mu_source , phi_source = self . _feature_gen . compute ( self . _source ) NEW_LINE mu_target , phi_target = self . _feature_gen . compute ( target ) NEW_LINE args = ( mu_source , phi_source , mu_target , phi_target , self . _sigma ) NEW_LINE res = minimize ( self . _cost_fn , x_ini , args = args , method = \" BFGS \" , jac = True , tol = opt_tol , options = { \" maxiter \" : opt_maxiter , \" disp \" : log . level == logging . DEBUG } , callback = self . optimization_cb , ) NEW_LINE self . _annealing ( ) NEW_LINE self . _feature_gen . annealing ( ) NEW_LINE if not f is None and abs ( res . fun - f ) < tol : NEW_LINE INDENT break NEW_LINE DEDENT f = res . fun NEW_LINE x_ini = res . x NEW_LINE DEDENT return self . _cost_fn . to_transformation ( res . x ) NEW_LINE DEDENT',), ('def __init__ ( self , source , sigma = 1.0 , delta = 0.9 , n_gmm_components = 800 , use_estimated_sigma = True ) : NEW_LINE INDENT n_gmm_components = min ( n_gmm_components , int ( source . shape [ 0 ] * 0.8 ) ) NEW_LINE super ( RigidGMMReg , self ) . __init__ ( source , ft . GMM ( n_gmm_components ) , cf . RigidCostFunction ( ) , sigma , delta , use_estimated_sigma ) NEW_LINE DEDENT',), ('def __init__ ( self , source , sigma = 1.0 , delta = 0.9 , n_gmm_components = 800 , alpha = 1.0 , beta = 0.1 , use_estimated_sigma = True ) : NEW_LINE INDENT n_gmm_components = min ( n_gmm_components , int ( source . shape [ 0 ] * 0.8 ) ) NEW_LINE super ( TPSGMMReg , self ) . __init__ ( source , ft . GMM ( n_gmm_components ) , cf . TPSCostFunction ( [ ] , alpha , beta ) , sigma , delta , use_estimated_sigma ) NEW_LINE self . _feature_gen . init ( ) NEW_LINE control_pts , _ = self . _feature_gen . compute ( source ) NEW_LINE self . _cost_fn . _control_pts = control_pts NEW_LINE DEDENT',), ('def __init__ ( self , source , sigma = 1.0 , delta = 0.9 , gamma = 0.5 , nu = 0.1 , use_estimated_sigma = True ) : NEW_LINE INDENT super ( RigidSVR , self ) . __init__ ( source , ft . OneClassSVM ( source . shape [ 1 ] , sigma , gamma , nu ) , cf . RigidCostFunction ( ) , sigma , delta , use_estimated_sigma , ) NEW_LINE DEDENT',), ('def _estimate_sigma ( self , data ) : NEW_LINE INDENT super ( RigidSVR , self ) . _estimate_sigma ( data ) NEW_LINE self . _feature_gen . _sigma = self . _sigma NEW_LINE self . _feature_gen . _gamma = 1.0 / ( 2.0 * np . square ( self . _sigma ) ) NEW_LINE DEDENT',), ('def __init__ ( self , source , sigma = 1.0 , delta = 0.9 , gamma = 0.5 , nu = 0.1 , alpha = 1.0 , beta = 0.1 , use_estimated_sigma = True ) : NEW_LINE INDENT super ( TPSSVR , self ) . __init__ ( source , ft . OneClassSVM ( source . shape [ 1 ] , sigma , gamma , nu ) , cf . TPSCostFunction ( [ ] , alpha , beta ) , sigma , delta , use_estimated_sigma , ) NEW_LINE self . _feature_gen . init ( ) NEW_LINE control_pts , _ = self . _feature_gen . compute ( source ) NEW_LINE self . _cost_fn . _control_pts = control_pts NEW_LINE DEDENT',), ('def _estimate_sigma ( self , data ) : NEW_LINE INDENT super ( TPSSVR , self ) . _estimate_sigma ( data ) NEW_LINE self . _feature_gen . _sigma = self . _sigma NEW_LINE self . _feature_gen . _gamma = 1.0 / ( 2.0 * np . square ( self . _sigma ) ) NEW_LINE DEDENT',), ('def init ( self ) : NEW_LINE INDENT pass NEW_LINE DEDENT',), ('def compute ( self , data ) : NEW_LINE INDENT return None NEW_LINE DEDENT',), ('def annealing ( self ) : NEW_LINE INDENT pass NEW_LINE DEDENT',), ('def __call__ ( self , data ) : NEW_LINE INDENT return self . compute ( data ) NEW_LINE DEDENT',), ('def __init__ ( self , radius_normal = 0.1 , radius_feature = 0.5 ) : NEW_LINE INDENT self . _param_normal = o3 . geometry . KDTreeSearchParamHybrid ( radius = radius_normal , max_nn = 30 ) NEW_LINE self . _param_feature = o3 . geometry . KDTreeSearchParamHybrid ( radius = radius_feature , max_nn = 100 ) NEW_LINE DEDENT',), ('def init ( self ) : NEW_LINE INDENT pass NEW_LINE DEDENT',), ('def estimate_normals ( self , pcd ) : NEW_LINE INDENT pcd . estimate_normals ( search_param = self . _param_normal ) NEW_LINE DEDENT',), ('def compute ( self , data ) : NEW_LINE INDENT pcd = o3 . geometry . PointCloud ( ) NEW_LINE pcd . points = o3 . utility . Vector3dVector ( data ) NEW_LINE self . estimate_normals ( pcd ) NEW_LINE fpfh = o3 . pipelines . registration . compute_fpfh_feature ( pcd , self . _param_feature ) NEW_LINE return fpfh . data . T NEW_LINE DEDENT',), ('def __init__ ( self , n_gmm_components = 800 ) : NEW_LINE INDENT self . _n_gmm_components = n_gmm_components NEW_LINE DEDENT',), ('def init ( self ) : NEW_LINE INDENT self . _clf = mixture . GaussianMixture ( n_components = self . _n_gmm_components , covariance_type = \" spherical \" ) NEW_LINE DEDENT',), ('def compute ( self , data ) : NEW_LINE INDENT self . _clf . fit ( data ) NEW_LINE return self . _clf . means_ , self . _clf . weights_ NEW_LINE DEDENT',), ('def __init__ ( self , dim , sigma , gamma = 0.5 , nu = 0.05 , delta = 10.0 ) : NEW_LINE INDENT self . _dim = dim NEW_LINE self . _sigma = sigma NEW_LINE self . _gamma = gamma NEW_LINE self . _nu = nu NEW_LINE self . _delta = delta NEW_LINE DEDENT',), ('def init ( self ) : NEW_LINE INDENT self . _clf = svm . OneClassSVM ( nu = self . _nu , kernel = \" rbf \" , gamma = self . _gamma ) NEW_LINE DEDENT',), ('def compute ( self , data ) : NEW_LINE INDENT self . _clf . fit ( data ) NEW_LINE z = np . power ( 2.0 * np . pi * self . _sigma ** 2 , self . _dim * 0.5 ) NEW_LINE return self . _clf . support_vectors_ , self . _clf . dual_coef_ [ 0 ] * z NEW_LINE DEDENT',), ('def annealing ( self ) : NEW_LINE INDENT self . _gamma *= self . _delta NEW_LINE DEDENT',), ('def dualquat_from_twist ( tw ) : NEW_LINE INDENT ang = np . linalg . norm ( tw [ : 3 ] ) NEW_LINE if ang < np . finfo ( np . float32 ) . eps : NEW_LINE INDENT return dualquat ( quat . identity ( ) , tw [ 3 : ] ) NEW_LINE DEDENT return dualquat ( quat ( ang , tw [ : 3 ] / ang ) , tw [ 3 : ] ) NEW_LINE DEDENT',), ('def _maximization_step ( t_source , target , estep_res , trans_p , sigma2 , w = 0.0 , objective_type = \" pt2pt \" ) : NEW_LINE INDENT return None NEW_LINE DEDENT',), ('def _maximization_step ( t_source , target , estep_res , trans_p , sigma2 , w = 0.0 , objective_type = \" pt2pt \" ) : NEW_LINE INDENT m , dim = t_source . shape NEW_LINE n = target . shape [ 0 ] NEW_LINE assert dim == 2 or dim == 3 , \" dim ▁ must ▁ be ▁ 2 ▁ or ▁ 3 . \" NEW_LINE m0 , m1 , m2 , nx = estep_res NEW_LINE tw = np . zeros ( dim * 2 ) NEW_LINE c = w / ( 1.0 - w ) * n / m * ( 2.0 * sigma2 * np . pi ) ** ( dim / 2.0 ) NEW_LINE nonzero_idx = m0 != 0 NEW_LINE if not nonzero_idx . any ( ) : NEW_LINE INDENT return MstepResult ( trans_p , sigma2 , None ) NEW_LINE DEDENT m0 = m0 [ nonzero_idx ] NEW_LINE m1 = m1 [ nonzero_idx ] NEW_LINE t_source_e = t_source [ nonzero_idx ] NEW_LINE m1m0 = np . divide ( m1 . T , m0 ) . T NEW_LINE m0m0 = m0 / ( m0 + c ) NEW_LINE drxdx = np . sqrt ( m0m0 * 1.0 / sigma2 ) NEW_LINE if objective_type == \" pt2pt \" : NEW_LINE INDENT if dim == 2 : NEW_LINE INDENT dr , dt = kabsch . kabsch2d ( t_source_e , m1m0 , drxdx ) NEW_LINE DEDENT else : NEW_LINE INDENT dr , dt = kabsch . kabsch ( t_source_e , m1m0 , drxdx ) NEW_LINE DEDENT rx = np . multiply ( drxdx , ( t_source_e - m1m0 ) . T ) . T NEW_LINE rot , t = np . dot ( dr , trans_p . rot ) , np . dot ( trans_p . t , dr . T ) + dt NEW_LINE q = np . linalg . norm ( rx , ord = 2 , axis = 1 ) . sum ( ) NEW_LINE DEDENT elif objective_type == \" pt2pl \" : NEW_LINE INDENT nxm0 = ( nx [ nonzero_idx ] . T / m0 ) . T NEW_LINE tw , q = pt2pl . compute_twist_for_pt2pl ( t_source_e , m1m0 , nxm0 , drxdx ) NEW_LINE rot , t = so . twist_mul ( tw , trans_p . rot , trans_p . t ) NEW_LINE DEDENT else : NEW_LINE INDENT raise ValueError ( \" Unknown ▁ objective _ type : ▁ % s . \" % objective_type ) NEW_LINE DEDENT if not m2 is None : NEW_LINE INDENT m2 = m2 [ nonzero_idx ] NEW_LINE sigma2 = ( ( m0 * np . square ( t_source_e ) . sum ( axis = 1 ) - 2.0 * ( t_source_e * m1 ) . sum ( axis = 1 ) + m2 ) / ( m0 + c ) ) . sum ( ) NEW_LINE sigma2 /= 3.0 * m0m0 . sum ( ) NEW_LINE DEDENT return MstepResult ( tf . RigidTransformation ( rot , t ) , sigma2 , q ) NEW_LINE DEDENT',), ('def _maximization_step ( t_source , target , estep_res , trans_p , sigma2 , w = 0.0 , objective_type = \" \" , maxiter = 50 , tol = 1.0e-4 ) : NEW_LINE INDENT m , dim = t_source . shape NEW_LINE n6d = dim * 2 NEW_LINE idx_6d = lambda i : slice ( i * n6d , ( i + 1 ) * n6d ) NEW_LINE n = target . shape [ 0 ] NEW_LINE n_nodes = trans_p . weights . n_nodes NEW_LINE assert dim == 3 , \" dim ▁ must ▁ be ▁ 3 . \" NEW_LINE m0 , m1 , m2 , _ = estep_res NEW_LINE tw = np . zeros ( n_nodes * dim * 2 ) NEW_LINE c = w / ( 1.0 - w ) * n / m NEW_LINE m0 [ m0 == 0 ] = np . finfo ( np . float32 ) . eps NEW_LINE m1m0 = np . divide ( m1 . T , m0 ) . T NEW_LINE m0m0 = m0 / ( m0 + c ) NEW_LINE drxdx = np . sqrt ( m0m0 * 1.0 / sigma2 ) NEW_LINE dxdz = np . apply_along_axis ( so . diff_x_from_twist , 1 , t_source ) NEW_LINE a = np . zeros ( ( n_nodes * n6d , n_nodes * n6d ) ) NEW_LINE for pair in trans_p . weights . pairs_set ( ) : NEW_LINE INDENT jtj_tw = np . zeros ( [ n6d , n6d ] ) NEW_LINE for idx in trans_p . weights . in_pair ( pair ) : NEW_LINE INDENT drxdz = drxdx [ idx ] * dxdz [ idx ] NEW_LINE w = trans_p . weights [ idx ] [ \" val \" ] NEW_LINE jtj_tw += w [ 0 ] * w [ 1 ] * np . dot ( drxdz . T , drxdz ) NEW_LINE DEDENT a [ idx_6d ( pair [ 0 ] ) , idx_6d ( pair [ 1 ] ) ] += jtj_tw NEW_LINE a [ idx_6d ( pair [ 1 ] ) , idx_6d ( pair [ 0 ] ) ] += jtj_tw NEW_LINE DEDENT for _ in range ( maxiter ) : NEW_LINE INDENT x = np . zeros_like ( t_source ) NEW_LINE for pair in trans_p . weights . pairs_set ( ) : NEW_LINE INDENT for idx in trans_p . weights . in_pair ( pair ) : NEW_LINE INDENT w = trans_p . weights [ idx ] [ \" val \" ] NEW_LINE q0 = dualquat_from_twist ( tw [ idx_6d ( pair [ 0 ] ) ] ) NEW_LINE q1 = dualquat_from_twist ( tw [ idx_6d ( pair [ 1 ] ) ] ) NEW_LINE x [ idx ] = ( w [ 0 ] * q0 + w [ 1 ] * q1 ) . transform_point ( t_source [ idx ] ) NEW_LINE DEDENT DEDENT rx = np . multiply ( drxdx , ( x - m1m0 ) . T ) . T NEW_LINE b = np . zeros ( n_nodes * n6d ) NEW_LINE for pair in trans_p . weights . pairs_set ( ) : NEW_LINE INDENT j_tw = np . zeros ( n6d ) NEW_LINE for idx in trans_p . weights . in_pair ( pair ) : NEW_LINE INDENT drxdz = drxdx [ idx ] * dxdz [ idx ] NEW_LINE w = trans_p . weights [ idx ] [ \" val \" ] NEW_LINE j_tw += w [ 0 ] * np . dot ( drxdz . T , rx [ idx ] ) NEW_LINE DEDENT b [ idx_6d ( pair [ 0 ] ) ] += j_tw NEW_LINE DEDENT dtw = np . linalg . lstsq ( a , b , rcond = None ) [ 0 ] NEW_LINE tw -= dtw NEW_LINE if np . linalg . norm ( dtw ) < tol : NEW_LINE INDENT break NEW_LINE DEDENT DEDENT dualquats = [ dualquat_from_twist ( tw [ idx_6d ( i ) ] ) * dq for i , dq in enumerate ( trans_p . dualquats ) ] NEW_LINE if not m2 is None : NEW_LINE INDENT sigma2 = ( ( m0 * np . square ( t_source ) . sum ( axis = 1 ) - 2.0 * ( t_source * m1 ) . sum ( axis = 1 ) + m2 ) / ( m0 + c ) ) . sum ( ) NEW_LINE sigma2 /= 3.0 * m0m0 . sum ( ) NEW_LINE DEDENT q = np . dot ( rx . T , rx ) . sum ( ) NEW_LINE return MstepResult ( tf . DeformableKinematicModel ( dualquats , trans_p . weights ) , sigma2 , q ) NEW_LINE DEDENT',), ('def registration_filterreg ( source : Union [ np . ndarray , o3 . geometry . PointCloud ] , target : Union [ np . ndarray , o3 . geometry . PointCloud ] , target_normals : Optional [ np . ndarray ] = None , sigma2 : Optional [ float ] = None , update_sigma2 : bool = False , w : float = 0 , objective_type : str = \" pt2pt \" , maxiter : int = 50 , tol : float = 0.001 , min_sigma2 : float = 1.0e-4 , feature_fn : Callable = lambda x : x , callbacks : List [ Callable ] = [ ] , ** kwargs : Any , ) : NEW_LINE INDENT cv = lambda x : np . asarray ( x . points if isinstance ( x , o3 . geometry . PointCloud ) else x ) NEW_LINE frg = RigidFilterReg ( cv ( source ) , cv ( target_normals ) , sigma2 , update_sigma2 , ** kwargs ) NEW_LINE frg . set_callbacks ( callbacks ) NEW_LINE return frg . registration ( cv ( target ) , w = w , objective_type = objective_type , maxiter = maxiter , tol = tol , min_sigma2 = min_sigma2 , feature_fn = feature_fn , ) NEW_LINE DEDENT',), ('def __init__ ( self , source = None , target_normals = None , sigma2 = None , update_sigma2 = False ) : NEW_LINE INDENT self . _source = source NEW_LINE self . _target_normals = target_normals NEW_LINE self . _sigma2 = sigma2 NEW_LINE self . _update_sigma2 = update_sigma2 NEW_LINE self . _tf_type = None NEW_LINE self . _tf_result = None NEW_LINE self . _callbacks = [ ] NEW_LINE DEDENT',), ('def set_source ( self , source ) : NEW_LINE INDENT self . _source = source NEW_LINE DEDENT',), ('def set_target_normals ( self , target_normals ) : NEW_LINE INDENT self . _target_normals = target_normals NEW_LINE DEDENT',), ('def set_callbacks ( self , callbacks ) : NEW_LINE INDENT self . _callbacks = callbacks NEW_LINE DEDENT',), ('def expectation_step ( self , t_source , target , y , sigma2 , update_sigma2 , objective_type = \" pt2pt \" , alpha = 0.015 ) : NEW_LINE INDENT assert t_source . ndim == 2 and target . ndim == 2 , \" source ▁ and ▁ target ▁ must ▁ have ▁ 2 ▁ dimensions . \" NEW_LINE m , _ = t_source . shape NEW_LINE n = target . shape [ 0 ] NEW_LINE sigma = np . sqrt ( sigma2 ) NEW_LINE fx = t_source / sigma NEW_LINE fy = target / sigma NEW_LINE zero_m1 = np . zeros ( ( m , 1 ) ) NEW_LINE zeros_md = np . zeros ( ( m , y . shape [ 1 ] ) ) NEW_LINE fin = np . r_ [ fx , fy ] NEW_LINE ph = gf . Permutohedral ( fin ) NEW_LINE if ph . get_lattice_size ( ) > n * alpha : NEW_LINE INDENT ph = gf . Permutohedral ( fin , False ) NEW_LINE DEDENT vin0 = np . r_ [ zero_m1 , np . ones ( ( n , 1 ) ) ] NEW_LINE vin1 = np . r_ [ zeros_md , y ] NEW_LINE m0 = ph . filter ( vin0 , m ) . flatten ( ) [ : m ] NEW_LINE m1 = ph . filter ( vin1 , m ) [ : m ] NEW_LINE if update_sigma2 : NEW_LINE INDENT vin2 = np . r_ [ zero_m1 , np . expand_dims ( np . square ( y ) . sum ( axis = 1 ) , axis = 1 ) ] NEW_LINE m2 = ph . filter ( vin2 , m ) . flatten ( ) [ : m ] NEW_LINE DEDENT else : NEW_LINE INDENT m2 = None NEW_LINE DEDENT if objective_type == \" pt2pt \" : NEW_LINE INDENT nx = None NEW_LINE DEDENT elif objective_type == \" pt2pl \" : NEW_LINE INDENT vin = np . r_ [ zeros_md , self . _target_normals ] NEW_LINE nx = ph . filter ( vin , m ) [ : m ] NEW_LINE DEDENT else : NEW_LINE INDENT raise ValueError ( \" Unknown ▁ objective _ type : ▁ % s . \" % objective_type ) NEW_LINE DEDENT return EstepResult ( m0 , m1 , m2 , nx ) NEW_LINE DEDENT',), ('def maximization_step ( self , t_source , target , estep_res , w = 0.0 , objective_type = \" pt2pt \" ) : NEW_LINE INDENT return self . _maximization_step ( t_source , target , estep_res , self . _tf_result , self . _sigma2 , w , objective_type = objective_type ) NEW_LINE DEDENT',), ('def registration ( self , target , w = 0.0 , objective_type = \" pt2pt \" , maxiter = 50 , tol = 0.001 , min_sigma2 = 1.0e-4 , feature_fn = lambda x : x ) : NEW_LINE INDENT assert not self . _tf_type is None , \" transformation ▁ type ▁ is ▁ None . \" NEW_LINE q = None NEW_LINE ftarget = feature_fn ( target ) NEW_LINE if self . _sigma2 is None : NEW_LINE INDENT fsource = feature_fn ( self . _source ) NEW_LINE self . _sigma2 = max ( mu . squared_kernel_sum ( fsource , ftarget ) , min_sigma2 ) NEW_LINE DEDENT for i in range ( maxiter ) : NEW_LINE INDENT t_source = self . _tf_result . transform ( self . _source ) NEW_LINE fsource = feature_fn ( t_source ) NEW_LINE estep_res = self . expectation_step ( fsource , ftarget , target , self . _sigma2 , self . _update_sigma2 , objective_type ) NEW_LINE res = self . maximization_step ( t_source , target , estep_res , w = w , objective_type = objective_type ) NEW_LINE if res . q is None : NEW_LINE INDENT res = res . _replace ( q = q ) NEW_LINE break NEW_LINE DEDENT self . _tf_result = res . transformation NEW_LINE self . _sigma2 = max ( res . sigma2 , min_sigma2 ) NEW_LINE for c in self . _callbacks : NEW_LINE INDENT c ( self . _tf_result ) NEW_LINE DEDENT log . debug ( \" Iteration : ▁ { } , ▁ Criteria : ▁ { } \" . format ( i , res . q ) ) NEW_LINE if not q is None and abs ( res . q - q ) < tol : NEW_LINE INDENT break NEW_LINE DEDENT q = res . q NEW_LINE DEDENT return res NEW_LINE DEDENT',), ('def __init__ ( self , source = None , target_normals = None , sigma2 = None , update_sigma2 = False , tf_init_params = { } ) : NEW_LINE INDENT super ( RigidFilterReg , self ) . __init__ ( source = source , target_normals = target_normals , sigma2 = sigma2 , update_sigma2 = update_sigma2 ) NEW_LINE self . _tf_type = tf . RigidTransformation NEW_LINE self . _tf_result = self . _tf_type ( ** tf_init_params ) NEW_LINE DEDENT',), ('def __init__ ( self , source = None , skinning_weight = None , sigma2 = None ) : NEW_LINE INDENT if not _imp_dq : NEW_LINE INDENT raise RuntimeError ( \" No ▁ dq3d ▁ python ▁ package , ▁ filterreg ▁ deformation ▁ model ▁ not ▁ available . \" ) NEW_LINE DEDENT super ( DeformableKinematicFilterReg , self ) . __init__ ( source , sigma2 = sigma2 ) NEW_LINE self . _tf_type = tf . DeformableKinematicModel NEW_LINE self . _skinning_weight = skinning_weight NEW_LINE self . _tf_result = self . _tf_type ( [ dualquat . identity ( ) for _ in range ( self . _skinning_weight . n_nodes ) ] , self . _skinning_weight ) NEW_LINE DEDENT',), ('def _gauss_transform_direct ( source , target , weights , h ) : NEW_LINE INDENT h2 = h * h NEW_LINE fn = lambda t : np . dot ( weights , np . exp ( - np . sum ( np . square ( t - source ) , axis = 1 ) / h2 ) ) NEW_LINE return np . apply_along_axis ( fn , 1 , target ) NEW_LINE DEDENT',), ('def __init__ ( self , source , h ) : NEW_LINE INDENT self . _source = source NEW_LINE self . _h = h NEW_LINE DEDENT',), ('def compute ( self , target , weights ) : NEW_LINE INDENT return _gauss_transform_direct ( self . _source , target , weights , self . _h ) NEW_LINE DEDENT',), ('def __init__ ( self , source , h , eps = 1.0e-4 , sw_h = 0.01 ) : NEW_LINE INDENT self . _m = source . shape [ 0 ] NEW_LINE if h < sw_h : NEW_LINE INDENT self . _impl = Direct ( source , h ) NEW_LINE DEDENT else : NEW_LINE INDENT self . _impl = _ifgt . Ifgt ( source , h , eps ) NEW_LINE DEDENT DEDENT',), ('def compute ( self , target , weights = None ) : NEW_LINE INDENT if weights is None : NEW_LINE INDENT weights = np . ones ( self . _m ) NEW_LINE DEDENT if weights . ndim == 1 : NEW_LINE INDENT return self . _impl . compute ( target , weights ) NEW_LINE DEDENT elif weights . ndim == 2 : NEW_LINE INDENT return np . r_ [ [ self . _impl . compute ( target , w ) for w in weights ] ] NEW_LINE DEDENT else : NEW_LINE INDENT raise ValueError ( \" weights . ndim ▁ must ▁ be ▁ 1 ▁ or ▁ 2 . \" ) NEW_LINE DEDENT DEDENT',), ('def _maximization_step ( source , target , estep_res , sigma2_p = None ) : NEW_LINE INDENT return None NEW_LINE DEDENT',), ('def _maximization_step ( source , target , rigid_trans , estep_res , gmat_inv , lmd , k , sigma2_p = None ) : NEW_LINE INDENT nu_d , nu , n_p , px , x_hat = estep_res NEW_LINE dim = source . shape [ 1 ] NEW_LINE m = source . shape [ 0 ] NEW_LINE s2s2 = rigid_trans . scale ** 2 / ( sigma2_p ** 2 ) NEW_LINE sigma_mat_inv = lmd * gmat_inv + s2s2 * np . diag ( nu ) NEW_LINE sigma_mat = np . linalg . inv ( sigma_mat_inv ) NEW_LINE residual = rigid_trans . inverse ( ) . transform ( x_hat ) - source NEW_LINE v_hat = s2s2 * np . matmul ( np . multiply ( np . kron ( sigma_mat , np . identity ( dim ) ) , np . kron ( nu , np . ones ( dim ) ) ) , residual . ravel ( ) ) . reshape ( - 1 , dim ) NEW_LINE u_hat = source + v_hat NEW_LINE alpha = np . exp ( spsp . psi ( k + nu ) - spsp . psi ( k * m + n_p ) ) NEW_LINE x_m = np . sum ( nu * x_hat . T , axis = 1 ) / n_p NEW_LINE sigma2_m = np . sum ( nu * np . diag ( sigma_mat ) , axis = 0 ) / n_p NEW_LINE u_m = np . sum ( nu * u_hat . T , axis = 1 ) / n_p NEW_LINE u_hm = u_hat - u_m NEW_LINE s_xu = np . matmul ( np . multiply ( nu , ( x_hat - x_m ) . T ) , u_hm ) / n_p NEW_LINE s_uu = np . matmul ( np . multiply ( nu , u_hm . T ) , u_hm ) / n_p + sigma2_m * np . identity ( dim ) NEW_LINE phi , s_xu_d , psih = np . linalg . svd ( s_xu , full_matrices = True ) NEW_LINE c = np . ones ( dim ) NEW_LINE c [ - 1 ] = np . linalg . det ( np . dot ( phi , psih ) ) NEW_LINE rot = np . matmul ( phi * c , psih ) NEW_LINE tr_rsxu = np . trace ( np . matmul ( rot , s_xu ) ) NEW_LINE scale = tr_rsxu / np . trace ( s_uu ) NEW_LINE t = x_m - scale * np . dot ( rot , u_m ) NEW_LINE y_hat = rigid_trans . transform ( source + v_hat ) NEW_LINE s1 = np . dot ( target . ravel ( ) , np . kron ( nu_d , np . ones ( dim ) ) * target . ravel ( ) ) NEW_LINE s2 = np . dot ( px . ravel ( ) , y_hat . ravel ( ) ) NEW_LINE s3 = np . dot ( y_hat . ravel ( ) , np . kron ( nu , np . ones ( dim ) ) * y_hat . ravel ( ) ) NEW_LINE sigma2 = ( s1 - 2.0 * s2 + s3 ) / ( n_p * dim ) + scale ** 2 * sigma2_m NEW_LINE return MstepResult ( tf . CombinedTransformation ( rot , t , scale , v_hat ) , u_hat , sigma_mat , alpha , sigma2 ) NEW_LINE DEDENT',), ('def registration_bcpd ( source : Union [ np . ndarray , o3 . geometry . PointCloud ] , target : Union [ np . ndarray , o3 . geometry . PointCloud ] , w : float = 0.0 , maxiter : int = 50 , tol : float = 0.001 , callbacks : List [ Callable ] = [ ] , ** kwargs : Any , ) : NEW_LINE INDENT cv = lambda x : np . asarray ( x . points if isinstance ( x , o3 . geometry . PointCloud ) else x ) NEW_LINE bcpd = CombinedBCPD ( cv ( source ) , ** kwargs ) NEW_LINE bcpd . set_callbacks ( callbacks ) NEW_LINE return bcpd . registration ( cv ( target ) , w , maxiter ) NEW_LINE DEDENT',), ('def __init__ ( self , source = None ) : NEW_LINE INDENT self . _source = source NEW_LINE self . _tf_type = None NEW_LINE self . _callbacks = [ ] NEW_LINE DEDENT',), ('def set_source ( self , source ) : NEW_LINE INDENT self . _source = source NEW_LINE DEDENT',), ('def set_callbacks ( self , callbacks ) : NEW_LINE INDENT self . _callbacks . extend ( callbacks ) NEW_LINE DEDENT',), ('def _initialize ( self , target ) : NEW_LINE INDENT return MstepResult ( None , None , None , None , None ) NEW_LINE DEDENT',), ('def expectation_step ( self , t_source , target , scale , alpha , sigma_mat , sigma2 , w = 0.0 ) : NEW_LINE INDENT assert t_source . ndim == 2 and target . ndim == 2 , \" source ▁ and ▁ target ▁ must ▁ have ▁ 2 ▁ dimensions . \" NEW_LINE dim = t_source . shape [ 1 ] NEW_LINE pmat = np . stack ( [ np . sum ( np . square ( target - ts ) , axis = 1 ) for ts in t_source ] ) NEW_LINE pmat = np . exp ( - pmat / ( 2.0 * sigma2 ) ) NEW_LINE pmat /= ( 2.0 * np . pi * sigma2 ) ** ( dim * 0.5 ) NEW_LINE pmat = pmat . T NEW_LINE pmat *= np . exp ( - ( scale ** 2 ) / ( 2 * sigma2 ) * np . diag ( sigma_mat ) * dim ) NEW_LINE pmat *= ( 1.0 - w ) * alpha NEW_LINE den = w / target . shape [ 0 ] + np . sum ( pmat , axis = 1 ) NEW_LINE den [ den == 0 ] = np . finfo ( np . float32 ) . eps NEW_LINE pmat = np . divide ( pmat . T , den ) NEW_LINE nu_d = np . sum ( pmat , axis = 0 ) NEW_LINE nu = np . sum ( pmat , axis = 1 ) NEW_LINE nu_inv = 1.0 / np . kron ( nu , np . ones ( dim ) ) NEW_LINE px = np . dot ( np . kron ( pmat , np . identity ( dim ) ) , target . ravel ( ) ) NEW_LINE x_hat = np . multiply ( px , nu_inv ) . reshape ( - 1 , dim ) NEW_LINE return EstepResult ( nu_d , nu , np . sum ( nu ) , px . reshape ( - 1 , dim ) , x_hat ) NEW_LINE DEDENT',), ('def maximization_step ( self , target , estep_res , sigma2_p = None ) : NEW_LINE INDENT return self . _maximization_step ( self . _source , target , estep_res , sigma2_p ) NEW_LINE DEDENT',), ('def registration ( self , target , w = 0.0 , maxiter = 50 , tol = 0.001 ) : NEW_LINE INDENT assert not self . _tf_type is None , \" transformation ▁ type ▁ is ▁ None . \" NEW_LINE res = self . _initialize ( target ) NEW_LINE target_tree = cKDTree ( target , leafsize = 10 ) NEW_LINE rmse = None NEW_LINE for i in range ( maxiter ) : NEW_LINE INDENT t_source = res . transformation . transform ( self . _source ) NEW_LINE estep_res = self . expectation_step ( t_source , target , res . transformation . rigid_trans . scale , res . alpha , res . sigma_mat , res . sigma2 , w ) NEW_LINE res = self . maximization_step ( target , res . transformation . rigid_trans , estep_res , res . sigma2 ) NEW_LINE for c in self . _callbacks : NEW_LINE INDENT c ( res . transformation ) NEW_LINE DEDENT tmp_rmse = mu . compute_rmse ( t_source , target_tree ) NEW_LINE log . debug ( \" Iteration : ▁ { } , ▁ Criteria : ▁ { } \" . format ( i , tmp_rmse ) ) NEW_LINE if not rmse is None and abs ( rmse - tmp_rmse ) < tol : NEW_LINE INDENT break NEW_LINE DEDENT rmse = tmp_rmse NEW_LINE DEDENT return res . transformation NEW_LINE DEDENT',), ('def __init__ ( self , source = None , lmd = 2.0 , k = 1.0e20 , gamma = 1.0 ) : NEW_LINE INDENT super ( CombinedBCPD , self ) . __init__ ( source ) NEW_LINE self . _tf_type = tf . CombinedTransformation NEW_LINE self . lmd = lmd NEW_LINE self . k = k NEW_LINE self . gamma = gamma NEW_LINE DEDENT',), ('def _initialize ( self , target ) : NEW_LINE INDENT m , dim = self . _source . shape NEW_LINE self . gmat = mu . inverse_multiquadric_kernel ( self . _source , self . _source ) NEW_LINE self . gmat_inv = np . linalg . inv ( self . gmat ) NEW_LINE sigma2 = self . gamma * mu . squared_kernel_sum ( self . _source , target ) NEW_LINE q = 1.0 + target . shape [ 0 ] * dim * 0.5 * np . log ( sigma2 ) NEW_LINE return MstepResult ( self . _tf_type ( np . identity ( dim ) , np . zeros ( dim ) ) , None , np . identity ( m ) , 1.0 / m , sigma2 ) NEW_LINE DEDENT',), ('def maximization_step ( self , target , rigid_trans , estep_res , sigma2_p = None ) : NEW_LINE INDENT return self . _maximization_step ( self . _source , target , rigid_trans , estep_res , self . gmat_inv , self . lmd , self . k , sigma2_p ) NEW_LINE DEDENT',), ('def compute_l2_dist ( mu_source , phi_source , mu_target , phi_target , sigma ) : NEW_LINE INDENT z = np . power ( 2.0 * np . pi * sigma ** 2 , mu_source . shape [ 1 ] * 0.5 ) NEW_LINE gtrans = gt . GaussTransform ( mu_target , np . sqrt ( 2.0 ) * sigma ) NEW_LINE phi_j_e = gtrans . compute ( mu_source , phi_target / z ) NEW_LINE phi_mu_j_e = gtrans . compute ( mu_source , phi_target * mu_target . T / z ) . T NEW_LINE g = ( phi_source * phi_j_e * mu_source . T - phi_source * phi_mu_j_e . T ) . T / ( 2.0 * sigma ** 2 ) NEW_LINE return - np . dot ( phi_source , phi_j_e ) , g NEW_LINE DEDENT',), ('def __init__ ( self , tf_type ) : NEW_LINE INDENT self . _tf_type = tf_type NEW_LINE DEDENT',), ('def to_transformation ( self , theta ) : NEW_LINE INDENT return None NEW_LINE DEDENT',), ('def initial ( self ) : NEW_LINE INDENT return None NEW_LINE DEDENT',), ('def __call__ ( self , theta , * args ) : NEW_LINE INDENT return None , None NEW_LINE DEDENT',), ('def __init__ ( self ) : NEW_LINE INDENT self . _tf_type = tf . RigidTransformation NEW_LINE DEDENT',), ('def to_transformation ( self , theta ) : NEW_LINE INDENT rot = t3d . quaternions . quat2mat ( theta [ : 4 ] ) NEW_LINE return self . _tf_type ( rot , theta [ 4 : 7 ] ) NEW_LINE DEDENT',), ('def initial ( self ) : NEW_LINE INDENT x0 = np . zeros ( 7 ) NEW_LINE x0 [ 0 ] = 1.0 NEW_LINE return x0 NEW_LINE DEDENT',), ('def __call__ ( self , theta , * args ) : NEW_LINE INDENT mu_source , phi_source , mu_target , phi_target , sigma = args NEW_LINE tf_obj = self . to_transformation ( theta ) NEW_LINE t_mu_source = tf_obj . transform ( mu_source ) NEW_LINE f , g = compute_l2_dist ( t_mu_source , phi_source , mu_target , phi_target , sigma ) NEW_LINE d_rot = so . diff_rot_from_quaternion ( theta [ : 4 ] ) NEW_LINE gtm0 = np . dot ( g . T , mu_source ) NEW_LINE grad = np . concatenate ( [ ( gtm0 * d_rot ) . sum ( axis = ( 1 , 2 ) ) , g . sum ( axis = 0 ) ] ) NEW_LINE return f , grad NEW_LINE DEDENT',), ('def __init__ ( self , control_pts , alpha = 1.0 , beta = 0.1 ) : NEW_LINE INDENT self . _tf_type = tf . TPSTransformation NEW_LINE self . _alpha = alpha NEW_LINE self . _beta = beta NEW_LINE self . _control_pts = control_pts NEW_LINE DEDENT',), ('def to_transformation ( self , theta ) : NEW_LINE INDENT dim = self . _control_pts . shape [ 1 ] NEW_LINE n_data = theta . shape [ 0 ] // dim NEW_LINE n_a = dim * ( dim + 1 ) NEW_LINE a = theta [ : n_a ] . reshape ( dim + 1 , dim ) NEW_LINE v = theta [ n_a : ] . reshape ( n_data - dim - 1 , dim ) NEW_LINE return self . _tf_type ( a , v , self . _control_pts ) NEW_LINE DEDENT',), ('def initial ( self ) : NEW_LINE INDENT dim = self . _control_pts . shape [ 1 ] NEW_LINE a = np . r_ [ np . zeros ( ( 1 , dim ) ) , np . identity ( dim ) ] NEW_LINE v = np . zeros ( ( self . _control_pts . shape [ 0 ] - dim - 1 , dim ) ) NEW_LINE return np . r_ [ a , v ] . flatten ( ) NEW_LINE DEDENT',), ('def __call__ ( self , theta , * args ) : NEW_LINE INDENT dim = self . _control_pts . shape [ 1 ] NEW_LINE mu_source , phi_source , mu_target , phi_target , sigma = args NEW_LINE tf_obj = self . to_transformation ( theta ) NEW_LINE basis , kernel = tf_obj . prepare ( mu_source ) NEW_LINE t_mu_source = tf_obj . transform_basis ( basis ) NEW_LINE bending = np . trace ( np . dot ( tf_obj . v . T , np . dot ( kernel , tf_obj . v ) ) ) NEW_LINE f1 , g1 = compute_l2_dist ( t_mu_source , phi_source , t_mu_source , phi_source , sigma ) NEW_LINE f2 , g2 = compute_l2_dist ( t_mu_source , phi_source , mu_target , phi_target , sigma ) NEW_LINE f = - f1 + 2.0 * f2 NEW_LINE g = - 2.0 * g1 + 2.0 * g2 NEW_LINE grad = self . _alpha * np . dot ( basis . T , g ) NEW_LINE grad [ dim + 1 : , : ] += 2.0 * self . _beta * np . dot ( kernel , tf_obj . v ) NEW_LINE return self . _alpha * f + self . _beta * bending , grad . flatten ( ) NEW_LINE DEDENT',), ('def _maximization_step ( source : np . ndarray , target : np . ndarray , estep_res : EstepResult , sigma2_p : Optional [ float ] = None , xp : ModuleType = np ) -> Optional [ MstepResult ] : NEW_LINE INDENT return None NEW_LINE DEDENT',), ('def _maximization_step ( source : np . ndarray , target : np . ndarray , estep_res : EstepResult , sigma2_p : Optional [ float ] = None , update_scale : bool = True , xp : ModuleType = np ) -> MstepResult : NEW_LINE INDENT pt1 , p1 , px , n_p = estep_res NEW_LINE dim = source . shape [ 1 ] NEW_LINE mu_x = xp . sum ( px , axis = 0 ) / n_p NEW_LINE mu_y = xp . dot ( source . T , p1 ) / n_p NEW_LINE target_hat = target - mu_x NEW_LINE source_hat = source - mu_y NEW_LINE a = xp . dot ( px . T , source_hat ) - xp . outer ( mu_x , xp . dot ( p1 . T , source_hat ) ) NEW_LINE u , _ , vh = np . linalg . svd ( a , full_matrices = True ) NEW_LINE c = xp . ones ( dim ) NEW_LINE c [ - 1 ] = xp . linalg . det ( xp . dot ( u , vh ) ) NEW_LINE rot = xp . dot ( u * c , vh ) NEW_LINE tr_atr = np . trace ( xp . dot ( a . T , rot ) ) NEW_LINE tr_yp1y = np . trace ( xp . dot ( source_hat . T * p1 , source_hat ) ) NEW_LINE scale = tr_atr / tr_yp1y if update_scale else 1.0 NEW_LINE t = mu_x - scale * xp . dot ( rot , mu_y ) NEW_LINE tr_xp1x = xp . trace ( xp . dot ( target_hat . T * pt1 , target_hat ) ) NEW_LINE if update_scale : NEW_LINE INDENT sigma2 = ( tr_xp1x - scale * tr_atr ) / ( n_p * dim ) NEW_LINE DEDENT else : NEW_LINE INDENT sigma2 = ( tr_xp1x + tr_yp1y - scale * tr_atr ) / ( n_p * dim ) NEW_LINE DEDENT sigma2 = max ( sigma2 , np . finfo ( np . float32 ) . eps ) NEW_LINE q = ( tr_xp1x - 2.0 * scale * tr_atr + ( scale ** 2 ) * tr_yp1y ) / ( 2.0 * sigma2 ) NEW_LINE q += dim * n_p * 0.5 * np . log ( sigma2 ) NEW_LINE return MstepResult ( tf . RigidTransformation ( rot , t , scale , xp = xp ) , sigma2 , q ) NEW_LINE DEDENT',), ('def _maximization_step ( source : np . ndarray , target : np . ndarray , estep_res : EstepResult , sigma2_p : Optional [ float ] = None , xp : ModuleType = np ) -> MstepResult : NEW_LINE INDENT pt1 , p1 , px , n_p = estep_res NEW_LINE dim = source . shape [ 1 ] NEW_LINE mu_x = xp . sum ( px , axis = 0 ) / n_p NEW_LINE mu_y = xp . dot ( source . T , p1 ) / n_p NEW_LINE target_hat = target - mu_x NEW_LINE source_hat = source - mu_y NEW_LINE a = xp . dot ( px . T , source_hat ) - xp . outer ( mu_x , xp . dot ( p1 . T , source_hat ) ) NEW_LINE yp1y = xp . dot ( source_hat . T * p1 , source_hat ) NEW_LINE b = xp . linalg . solve ( yp1y . T , a . T ) . T NEW_LINE t = mu_x - xp . dot ( b , mu_y ) NEW_LINE tr_xp1x = xp . trace ( xp . dot ( target_hat . T * pt1 , target_hat ) ) NEW_LINE tr_xpyb = xp . trace ( xp . dot ( a , b . T ) ) NEW_LINE sigma2 = ( tr_xp1x - tr_xpyb ) / ( n_p * dim ) NEW_LINE tr_ab = xp . trace ( xp . dot ( a , b . T ) ) NEW_LINE sigma2 = max ( sigma2 , np . finfo ( np . float32 ) . eps ) NEW_LINE q = ( tr_xp1x - 2 * tr_ab + tr_xpyb ) / ( 2.0 * sigma2 ) NEW_LINE q += dim * n_p * 0.5 * np . log ( sigma2 ) NEW_LINE return MstepResult ( tf . AffineTransformation ( b , t ) , sigma2 , q ) NEW_LINE DEDENT',), ('def _maximization_step ( source : np . ndarray , target : np . ndarray , estep_res : EstepResult , sigma2_p : float , tf_obj : tf . NonRigidTransformation , lmd : float , xp : ModuleType = np ) -> MstepResult : NEW_LINE INDENT pt1 , p1 , px , n_p = estep_res NEW_LINE dim = source . shape [ 1 ] NEW_LINE w = xp . linalg . solve ( ( p1 * tf_obj . g ) . T + lmd * sigma2_p * xp . identity ( source . shape [ 0 ] ) , px - ( source . T * p1 ) . T ) NEW_LINE t = source + xp . dot ( tf_obj . g , w ) NEW_LINE tr_xp1x = xp . trace ( xp . dot ( target . T * pt1 , target ) ) NEW_LINE tr_pxt = xp . trace ( xp . dot ( px . T , t ) ) NEW_LINE tr_tpt = xp . trace ( xp . dot ( t . T * p1 , t ) ) NEW_LINE sigma2 = ( tr_xp1x - 2.0 * tr_pxt + tr_tpt ) / ( n_p * dim ) NEW_LINE tf_obj . w = w NEW_LINE return MstepResult ( tf_obj , sigma2 , sigma2 ) NEW_LINE DEDENT',), ('def _maximization_step ( source : np . ndarray , target : np . ndarray , estep_res : EstepResult , sigma2_p : float , tf_obj : tf . NonRigidTransformation , lmd : float , alpha : float , p1_tilde : float , px_tilde : float , xp : ModuleType = np ) -> MstepResult : NEW_LINE INDENT pt1 , p1 , px , n_p = estep_res NEW_LINE dim = source . shape [ 1 ] NEW_LINE w = xp . linalg . solve ( ( p1 * tf_obj . g ) . T + sigma2_p / alpha * ( p1_tilde * tf_obj . g ) . T + lmd * sigma2_p * xp . identity ( source . shape [ 0 ] ) , px - ( source . T * p1 ) . T + sigma2_p / alpha * ( px_tilde - ( source . T * p1_tilde ) . T ) ) NEW_LINE t = source + xp . dot ( tf_obj . g , w ) NEW_LINE tr_xp1x = xp . trace ( xp . dot ( target . T * pt1 , target ) ) NEW_LINE tr_pxt = xp . trace ( xp . dot ( px . T , t ) ) NEW_LINE tr_tpt = xp . trace ( xp . dot ( t . T * p1 , t ) ) NEW_LINE sigma2 = ( tr_xp1x - 2.0 * tr_pxt + tr_tpt ) / ( n_p * dim ) NEW_LINE tf_obj . w = w NEW_LINE return MstepResult ( tf_obj , sigma2 , sigma2 ) NEW_LINE DEDENT',), ('def registration_cpd ( source : Union [ np . ndarray , o3 . geometry . PointCloud ] , target : Union [ np . ndarray , o3 . geometry . PointCloud ] , tf_type_name : str = \" rigid \" , w : float = 0.0 , maxiter : int = 50 , tol : float = 0.001 , callbacks : List [ Callable ] = [ ] , use_cuda : bool = False , ** kwargs : Any , ) : NEW_LINE INDENT xp = np NEW_LINE if use_cuda : NEW_LINE INDENT import cupy as cp NEW_LINE xp = cp NEW_LINE DEDENT cv = lambda x : xp . asarray ( x . points if isinstance ( x , o3 . geometry . PointCloud ) else x ) NEW_LINE if tf_type_name == \" rigid \" : NEW_LINE INDENT cpd = RigidCPD ( cv ( source ) , use_cuda = use_cuda , ** kwargs ) NEW_LINE DEDENT elif tf_type_name == \" affine \" : NEW_LINE INDENT cpd = AffineCPD ( cv ( source ) , use_cuda = use_cuda , ** kwargs ) NEW_LINE DEDENT elif tf_type_name == \" nonrigid \" : NEW_LINE INDENT cpd = NonRigidCPD ( cv ( source ) , use_cuda = use_cuda , ** kwargs ) NEW_LINE DEDENT elif tf_type_name == \\' nonrigid _ constrained \\' : NEW_LINE INDENT cpd = ConstrainedNonRigidCPD ( cv ( source ) , use_cuda = use_cuda , ** kwargs ) NEW_LINE DEDENT else : NEW_LINE INDENT raise ValueError ( \" Unknown ▁ transformation ▁ type ▁ % s \" % tf_type_name ) NEW_LINE DEDENT cpd . set_callbacks ( callbacks ) NEW_LINE return cpd . registration ( cv ( target ) , w , maxiter , tol ) NEW_LINE DEDENT',), ('def __init__ ( self , source : Optional [ np . ndarray ] = None , use_cuda : bool = False ) -> None : NEW_LINE INDENT self . _source = source NEW_LINE self . _tf_type = None NEW_LINE self . _callbacks = [ ] NEW_LINE if use_cuda : NEW_LINE INDENT import cupy as cp NEW_LINE from . import cupy_utils NEW_LINE self . xp = cp NEW_LINE self . cupy_utils = cupy_utils NEW_LINE self . _squared_kernel_sum = cupy_utils . squared_kernel_sum NEW_LINE DEDENT else : NEW_LINE INDENT self . xp = np NEW_LINE self . _squared_kernel_sum = mu . squared_kernel_sum NEW_LINE DEDENT DEDENT',), ('def set_source ( self , source : np . ndarray ) -> None : NEW_LINE INDENT self . _source = source NEW_LINE DEDENT',), ('def set_callbacks ( self , callbacks : List [ Callable ] ) -> None : NEW_LINE INDENT self . _callbacks . extend ( callbacks ) NEW_LINE DEDENT',), ('def _initialize ( self , target : np . ndarray ) -> MstepResult : NEW_LINE INDENT return MstepResult ( None , None , None ) NEW_LINE DEDENT',), ('def expectation_step ( self , t_source : np . ndarray , target : np . ndarray , sigma2 : float , w : float = 0.0 ) -> EstepResult : NEW_LINE INDENT assert t_source . ndim == 2 and target . ndim == 2 , \" source ▁ and ▁ target ▁ must ▁ have ▁ 2 ▁ dimensions . \" NEW_LINE pmat = self . xp . stack ( [ self . xp . sum ( self . xp . square ( target - ts ) , axis = 1 ) for ts in t_source ] ) NEW_LINE pmat = self . xp . exp ( - pmat / ( 2.0 * sigma2 ) ) NEW_LINE c = ( 2.0 * np . pi * sigma2 ) ** ( t_source . shape [ 1 ] * 0.5 ) NEW_LINE c *= w / ( 1.0 - w ) * t_source . shape [ 0 ] / target . shape [ 0 ] NEW_LINE den = self . xp . sum ( pmat , axis = 0 ) NEW_LINE den [ den == 0 ] = self . xp . finfo ( np . float32 ) . eps NEW_LINE den += c NEW_LINE pmat = self . xp . divide ( pmat , den ) NEW_LINE pt1 = self . xp . sum ( pmat , axis = 0 ) NEW_LINE p1 = self . xp . sum ( pmat , axis = 1 ) NEW_LINE px = self . xp . dot ( pmat , target ) NEW_LINE return EstepResult ( pt1 , p1 , px , np . sum ( p1 ) ) NEW_LINE DEDENT',), ('def maximization_step ( self , target : np . ndarray , estep_res : EstepResult , sigma2_p : Optional [ float ] = None ) -> Optional [ MstepResult ] : NEW_LINE INDENT return self . _maximization_step ( self . _source , target , estep_res , sigma2_p , xp = self . xp ) NEW_LINE DEDENT',), ('def registration ( self , target : np . ndarray , w : float = 0.0 , maxiter : int = 50 , tol : float = 0.001 ) -> MstepResult : NEW_LINE INDENT assert not self . _tf_type is None , \" transformation ▁ type ▁ is ▁ None . \" NEW_LINE res = self . _initialize ( target ) NEW_LINE q = res . q NEW_LINE for i in range ( maxiter ) : NEW_LINE INDENT t_source = res . transformation . transform ( self . _source ) NEW_LINE estep_res = self . expectation_step ( t_source , target , res . sigma2 , w ) NEW_LINE res = self . maximization_step ( target , estep_res , res . sigma2 ) NEW_LINE for c in self . _callbacks : NEW_LINE INDENT c ( res . transformation ) NEW_LINE DEDENT log . debug ( \" Iteration : ▁ { } , ▁ Criteria : ▁ { } \" . format ( i , res . q ) ) NEW_LINE if abs ( res . q - q ) < tol : NEW_LINE INDENT break NEW_LINE DEDENT q = res . q NEW_LINE DEDENT return res NEW_LINE DEDENT',), ('def __init__ ( self , source : Optional [ np . ndarray ] = None , update_scale : bool = True , tf_init_params : Dict = { } , use_cuda : bool = False ) -> None : NEW_LINE INDENT super ( RigidCPD , self ) . __init__ ( source , use_cuda ) NEW_LINE self . _tf_type = tf . RigidTransformation NEW_LINE self . _update_scale = update_scale NEW_LINE self . _tf_init_params = tf_init_params NEW_LINE DEDENT',), ('def _initialize ( self , target : np . ndarray ) -> MstepResult : NEW_LINE INDENT dim = self . _source . shape [ 1 ] NEW_LINE sigma2 = self . _squared_kernel_sum ( self . _source , target ) NEW_LINE q = 1.0 + target . shape [ 0 ] * dim * 0.5 * np . log ( sigma2 ) NEW_LINE if len ( self . _tf_init_params ) == 0 : NEW_LINE INDENT self . _tf_init_params = { \" rot \" : self . xp . identity ( dim ) , \" t \" : self . xp . zeros ( dim ) } NEW_LINE DEDENT if not \" xp \" in self . _tf_init_params : NEW_LINE INDENT self . _tf_init_params [ \" xp \" ] = self . xp NEW_LINE DEDENT return MstepResult ( self . _tf_type ( ** self . _tf_init_params ) , sigma2 , q ) NEW_LINE DEDENT',), ('def maximization_step ( self , target : np . ndarray , estep_res : EstepResult , sigma2_p : Optional [ float ] = None ) -> MstepResult : NEW_LINE INDENT return self . _maximization_step ( self . _source , target , estep_res , sigma2_p , self . _update_scale , self . xp ) NEW_LINE DEDENT',), ('def __init__ ( self , source : Optional [ np . ndarray ] = None , tf_init_params : Dict = { } , use_cuda : bool = False ) -> None : NEW_LINE INDENT super ( AffineCPD , self ) . __init__ ( source , use_cuda ) NEW_LINE self . _tf_type = tf . AffineTransformation NEW_LINE self . _tf_init_params = tf_init_params NEW_LINE DEDENT',), ('def _initialize ( self , target : np . ndarray ) -> MstepResult : NEW_LINE INDENT dim = self . _source . shape [ 1 ] NEW_LINE sigma2 = self . _squared_kernel_sum ( self . _source , target ) NEW_LINE q = 1.0 + target . shape [ 0 ] * dim * 0.5 * np . log ( sigma2 ) NEW_LINE if len ( self . _tf_init_params ) == 0 : NEW_LINE INDENT self . _tf_init_params = { \" b \" : self . xp . identity ( dim ) , \" t \" : self . xp . zeros ( dim ) } NEW_LINE DEDENT if not \" xp \" in self . _tf_init_params : NEW_LINE INDENT self . _tf_init_params [ \" xp \" ] = self . xp NEW_LINE DEDENT return MstepResult ( self . _tf_type ( ** self . _tf_init_params ) , sigma2 , q ) NEW_LINE DEDENT',), ('def __init__ ( self , source : Optional [ np . ndarray ] = None , beta : float = 2.0 , lmd : float = 2.0 , use_cuda : bool = False ) -> None : NEW_LINE INDENT super ( NonRigidCPD , self ) . __init__ ( source , use_cuda ) NEW_LINE self . _tf_type = tf . NonRigidTransformation NEW_LINE self . _beta = beta NEW_LINE self . _lmd = lmd NEW_LINE self . _tf_obj = None NEW_LINE if not self . _source is None : NEW_LINE INDENT self . _tf_obj = self . _tf_type ( None , self . _source , self . _beta , self . xp ) NEW_LINE DEDENT DEDENT',), ('def set_source ( self , source : np . ndarray ) -> None : NEW_LINE INDENT self . _source = source NEW_LINE self . _tf_obj = self . _tf_type ( None , self . _source , self . _beta ) NEW_LINE DEDENT',), ('def maximization_step ( self , target : np . ndarray , estep_res : EstepResult , sigma2_p : Optional [ float ] = None ) -> MstepResult : NEW_LINE INDENT return self . _maximization_step ( self . _source , target , estep_res , sigma2_p , self . _tf_obj , self . _lmd , self . xp ) NEW_LINE DEDENT',), ('def _initialize ( self , target : np . ndarray ) -> MstepResult : NEW_LINE INDENT dim = self . _source . shape [ 1 ] NEW_LINE sigma2 = self . _squared_kernel_sum ( self . _source , target ) NEW_LINE q = 1.0 + target . shape [ 0 ] * dim * 0.5 * np . log ( sigma2 ) NEW_LINE self . _tf_obj . w = self . xp . zeros_like ( self . _source ) NEW_LINE return MstepResult ( self . _tf_obj , sigma2 , q ) NEW_LINE DEDENT',), ('def __init__ ( self , source : Optional [ np . ndarray ] = None , beta : float = 2.0 , lmd : float = 2.0 , alpha : float = 1e-8 , use_cuda : bool = False , idx_source : Optional [ np . ndarray ] = None , idx_target : Optional [ np . ndarray ] = None ) : NEW_LINE INDENT super ( ConstrainedNonRigidCPD , self ) . __init__ ( source , use_cuda ) NEW_LINE self . _tf_type = tf . NonRigidTransformation NEW_LINE self . _beta = beta NEW_LINE self . _lmd = lmd NEW_LINE self . alpha = alpha NEW_LINE self . _tf_obj = None NEW_LINE self . idx_source , self . idx_target = idx_source , idx_target NEW_LINE if not self . _source is None : NEW_LINE INDENT self . _tf_obj = self . _tf_type ( None , self . _source , self . _beta , self . xp ) NEW_LINE DEDENT DEDENT',), ('def set_source ( self , source : np . ndarray ) -> None : NEW_LINE INDENT self . _source = source NEW_LINE self . _tf_obj = self . _tf_type ( None , self . _source , self . _beta ) NEW_LINE DEDENT',), ('def maximization_step ( self , target : np . ndarray , estep_res : EstepResult , sigma2_p : Optional [ float ] = None ) -> MstepResult : NEW_LINE INDENT return self . _maximization_step ( self . _source , target , estep_res , sigma2_p , self . _tf_obj , self . _lmd , self . alpha , self . p1_tilde , self . px_tilde , self . xp ) NEW_LINE DEDENT',), ('def _initialize ( self , target : np . ndarray ) -> MstepResult : NEW_LINE INDENT dim = self . _source . shape [ 1 ] NEW_LINE sigma2 = self . _squared_kernel_sum ( self . _source , target ) NEW_LINE q = 1.0 + target . shape [ 0 ] * dim * 0.5 * np . log ( sigma2 ) NEW_LINE self . _tf_obj . w = self . xp . zeros_like ( self . _source ) NEW_LINE self . p_tilde = self . xp . zeros ( ( self . _source . shape [ 0 ] , target . shape [ 0 ] ) ) NEW_LINE if self . idx_source is not None and self . idx_target is not None : NEW_LINE INDENT self . p_tilde [ self . idx_source , self . idx_target ] = 1 NEW_LINE DEDENT self . p1_tilde = self . xp . sum ( self . p_tilde , axis = 1 ) NEW_LINE self . px_tilde = self . xp . dot ( self . p_tilde , target ) NEW_LINE return MstepResult ( self . _tf_obj , sigma2 , q ) NEW_LINE DEDENT',), ('def registration_gmmtree ( source : Union [ np . ndarray , o3 . geometry . PointCloud ] , target : Union [ np . ndarray , o3 . geometry . PointCloud ] , maxiter : int = 20 , tol : float = 1.0e-4 , callbacks : List [ Callable ] = [ ] , ** kwargs : Any , ) : NEW_LINE INDENT cv = lambda x : np . asarray ( x . points if isinstance ( x , o3 . geometry . PointCloud ) else x ) NEW_LINE gt = GMMTree ( cv ( source ) , ** kwargs ) NEW_LINE gt . set_callbacks ( callbacks ) NEW_LINE return gt . registration ( cv ( target ) , maxiter , tol ) NEW_LINE DEDENT',), ('def __init__ ( self , source = None , tree_level = 2 , lambda_c = 0.01 , lambda_s = 0.001 , tf_init_params = { } ) : NEW_LINE INDENT self . _source = source NEW_LINE self . _tree_level = tree_level NEW_LINE self . _lambda_c = lambda_c NEW_LINE self . _lambda_s = lambda_s NEW_LINE self . _tf_type = tf . RigidTransformation NEW_LINE self . _tf_result = self . _tf_type ( ** tf_init_params ) NEW_LINE self . _callbacks = [ ] NEW_LINE if not self . _source is None : NEW_LINE INDENT self . _nodes = _gmmtree . build_gmmtree ( self . _source , self . _tree_level , self . _lambda_s , 1.0e-4 ) NEW_LINE DEDENT DEDENT',), ('def set_source ( self , source ) : NEW_LINE INDENT self . _source = source NEW_LINE self . _nodes = _gmmtree . build_gmmtree ( self . _source , self . _tree_level , self . _lambda_s , 1.0e-4 ) NEW_LINE DEDENT',), ('def set_callbacks ( self , callbacks ) : NEW_LINE INDENT self . _callbacks = callbacks NEW_LINE DEDENT',), ('def expectation_step ( self , target ) : NEW_LINE INDENT res = _gmmtree . gmmtree_reg_estep ( target , self . _nodes , self . _tree_level , self . _lambda_c ) NEW_LINE return EstepResult ( res ) NEW_LINE DEDENT',), ('def maximization_step ( self , estep_res , trans_p ) : NEW_LINE INDENT moments = estep_res . moments NEW_LINE n = len ( moments ) NEW_LINE amat = np . zeros ( ( n * 3 , 6 ) ) NEW_LINE bmat = np . zeros ( n * 3 ) NEW_LINE for i , m in enumerate ( moments ) : NEW_LINE INDENT if m [ 0 ] < np . finfo ( np . float32 ) . eps : NEW_LINE INDENT continue NEW_LINE DEDENT lmd , nn = np . linalg . eigh ( self . _nodes [ i ] [ 2 ] ) NEW_LINE s = m [ 1 ] / m [ 0 ] NEW_LINE nn = np . multiply ( nn , np . sqrt ( m [ 0 ] / lmd ) ) NEW_LINE sl = slice ( 3 * i , 3 * ( i + 1 ) ) NEW_LINE bmat [ sl ] = np . dot ( nn . T , self . _nodes [ i ] [ 1 ] ) - np . dot ( nn . T , s ) NEW_LINE amat [ sl , : 3 ] = np . cross ( s , nn . T ) NEW_LINE amat [ sl , 3 : ] = nn . T NEW_LINE DEDENT x , q , _ , _ = np . linalg . lstsq ( amat , bmat , rcond = - 1 ) NEW_LINE rot , t = so . twist_mul ( x , trans_p . rot , trans_p . t ) NEW_LINE return MstepResult ( tf . RigidTransformation ( rot , t ) , q ) NEW_LINE DEDENT',), ('def registration ( self , target , maxiter = 20 , tol = 1.0e-4 ) : NEW_LINE INDENT q = None NEW_LINE for i in range ( maxiter ) : NEW_LINE INDENT t_target = self . _tf_result . transform ( target ) NEW_LINE estep_res = self . expectation_step ( t_target ) NEW_LINE res = self . maximization_step ( estep_res , self . _tf_result ) NEW_LINE self . _tf_result = res . transformation NEW_LINE for c in self . _callbacks : NEW_LINE INDENT c ( self . _tf_result . inverse ( ) ) NEW_LINE DEDENT log . debug ( \" Iteration : ▁ { } , ▁ Criteria : ▁ { } \" . format ( i , res . q ) ) NEW_LINE if not q is None and abs ( res . q - q ) < tol : NEW_LINE INDENT break NEW_LINE DEDENT q = res . q NEW_LINE DEDENT return MstepResult ( self . _tf_result . inverse ( ) , res . q ) NEW_LINE DEDENT',), ('def squared_kernel_sum ( x , y ) : NEW_LINE INDENT return _math . squared_kernel ( x , y ) . sum ( ) / ( x . shape [ 0 ] * x . shape [ 1 ] * y . shape [ 0 ] ) NEW_LINE DEDENT',), ('def compute_rmse ( source , target_tree ) : NEW_LINE INDENT return sum ( target_tree . query ( source ) [ 0 ] ) / source . shape [ 0 ] NEW_LINE DEDENT',), ('def rbf_kernel ( x , y , beta ) : NEW_LINE INDENT return _math . rbf_kernel ( x , y , beta ) NEW_LINE DEDENT',), ('def tps_kernel ( x , y ) : NEW_LINE INDENT assert x . shape [ 1 ] == y . shape [ 1 ] , \" x ▁ and ▁ y ▁ must ▁ have ▁ same ▁ dimensions . \" NEW_LINE if x . shape [ 1 ] == 2 : NEW_LINE INDENT return _math . tps_kernel_2d ( x , y ) NEW_LINE DEDENT elif x . shape [ 1 ] == 3 : NEW_LINE INDENT return _math . tps_kernel_3d ( x , y ) NEW_LINE DEDENT else : NEW_LINE INDENT raise ValueError ( \" Invalid ▁ dimension ▁ of ▁ x : ▁ % d . \" % x . shape [ 1 ] ) NEW_LINE DEDENT DEDENT',), ('def inverse_multiquadric_kernel ( x , y , c = 1.0 ) : NEW_LINE INDENT return _math . inverse_multiquadric_kernel ( x , y , c ) NEW_LINE DEDENT',), ('def __init__ ( self , scale = 1.0 , centroid = 0.0 ) : NEW_LINE INDENT self . _scale = scale NEW_LINE self . _centroid = centroid NEW_LINE DEDENT',), ('def normalize ( self , x ) : NEW_LINE INDENT return ( x - self . _centroid ) / self . _scale NEW_LINE DEDENT',), ('def denormalize ( self , x ) : NEW_LINE INDENT return x * self . _scale + self . _centroid NEW_LINE DEDENT',), ('def skew ( x ) : NEW_LINE INDENT return np . array ( [ [ 0.0 , - x [ 2 ] , x [ 1 ] ] , [ x [ 2 ] , 0.0 , - x [ 0 ] ] , [ - x [ 1 ] , x [ 0 ] , 0.0 ] ] ) NEW_LINE DEDENT',), ('def twist_trans ( tw , linear = False ) : NEW_LINE INDENT if linear : NEW_LINE INDENT return np . identity ( 3 ) + skew ( tw [ : 3 ] ) , tw [ 3 : ] NEW_LINE DEDENT else : NEW_LINE INDENT twd = np . linalg . norm ( tw [ : 3 ] ) NEW_LINE if twd == 0.0 : NEW_LINE INDENT return np . identity ( 3 ) , tw [ 3 : ] NEW_LINE DEDENT else : NEW_LINE INDENT ntw = tw [ : 3 ] / twd NEW_LINE c = np . cos ( twd ) NEW_LINE s = np . sin ( twd ) NEW_LINE tr = c * np . identity ( 3 ) + ( 1.0 - c ) * np . outer ( ntw , ntw ) + s * skew ( ntw ) NEW_LINE return tr , tw [ 3 : ] NEW_LINE DEDENT DEDENT DEDENT',), ('def twist_mul ( tw , rot , t , linear = False ) : NEW_LINE INDENT tr , tt = twist_trans ( tw , linear = linear ) NEW_LINE return np . dot ( tr , rot ) , np . dot ( t , tr . T ) + tt NEW_LINE DEDENT',), ('def diff_x_from_twist ( x ) : NEW_LINE INDENT return np . array ( [ [ 0.0 , x [ 2 ] , - x [ 1 ] , 1.0 , 0.0 , 0.0 ] , [ - x [ 2 ] , 0.0 , x [ 0 ] , 0.0 , 1.0 , 0.0 ] , [ x [ 1 ] , - x [ 0 ] , 0.0 , 0.0 , 0.0 , 1.0 ] ] ) NEW_LINE DEDENT',), ('def diff_rot_from_quaternion ( q ) : NEW_LINE INDENT rot = t3d . quaternions . quat2mat ( q ) NEW_LINE q2 = np . square ( q ) NEW_LINE z = np . sum ( q2 ) NEW_LINE z2 = z * z NEW_LINE d_rot = np . zeros ( ( 4 , 3 , 3 ) ) NEW_LINE d_rot [ 0 , 0 , 0 ] = 4 * q [ 0 ] * ( q2 [ 2 ] + q2 [ 3 ] ) / z2 NEW_LINE d_rot [ 1 , 0 , 0 ] = 4 * q [ 1 ] * ( q2 [ 2 ] + q2 [ 3 ] ) / z2 NEW_LINE d_rot [ 2 , 0 , 0 ] = - 4 * q [ 2 ] * ( q2 [ 1 ] + q2 [ 0 ] ) / z2 NEW_LINE d_rot [ 3 , 0 , 0 ] = - 4 * q [ 3 ] * ( q2 [ 1 ] + q2 [ 0 ] ) / z2 NEW_LINE d_rot [ 0 , 1 , 1 ] = 4 * q [ 0 ] * ( q2 [ 1 ] + q2 [ 3 ] ) / z2 NEW_LINE d_rot [ 1 , 1 , 1 ] = - 4 * q [ 1 ] * ( q2 [ 2 ] + q2 [ 0 ] ) / z2 NEW_LINE d_rot [ 2 , 1 , 1 ] = 4 * q [ 2 ] * ( q2 [ 1 ] + q2 [ 3 ] ) / z2 NEW_LINE d_rot [ 3 , 1 , 1 ] = - 4 * q [ 3 ] * ( q2 [ 2 ] + q2 [ 0 ] ) / z2 NEW_LINE d_rot [ 0 , 2 , 2 ] = 4 * q [ 0 ] * ( q2 [ 1 ] + q2 [ 2 ] ) / z2 NEW_LINE d_rot [ 1 , 2 , 2 ] = - 4 * q [ 1 ] * ( q2 [ 3 ] + q2 [ 0 ] ) / z2 NEW_LINE d_rot [ 2 , 2 , 2 ] = - 4 * q [ 2 ] * ( q2 [ 1 ] + q2 [ 2 ] ) / z2 NEW_LINE d_rot [ 3 , 2 , 2 ] = 4 * q [ 3 ] * ( q2 [ 3 ] + q2 [ 0 ] ) / z2 NEW_LINE d_rot [ 0 , 0 , 1 ] = - 2 * q [ 3 ] / z - 2 * q [ 0 ] * rot [ 0 , 1 ] / z2 NEW_LINE d_rot [ 1 , 0 , 1 ] = 2 * q [ 2 ] / z - 2 * q [ 1 ] * rot [ 0 , 1 ] / z2 NEW_LINE d_rot [ 2 , 0 , 1 ] = 2 * q [ 1 ] / z - 2 * q [ 2 ] * rot [ 0 , 1 ] / z2 NEW_LINE d_rot [ 3 , 0 , 1 ] = - 2 * q [ 0 ] / z - 2 * q [ 3 ] * rot [ 0 , 1 ] / z2 NEW_LINE d_rot [ 0 , 0 , 2 ] = 2 * q [ 2 ] / z - 2 * q [ 0 ] * rot [ 0 , 2 ] / z2 NEW_LINE d_rot [ 1 , 0 , 2 ] = 2 * q [ 3 ] / z - 2 * q [ 1 ] * rot [ 0 , 2 ] / z2 NEW_LINE d_rot [ 2 , 0 , 2 ] = 2 * q [ 0 ] / z - 2 * q [ 2 ] * rot [ 0 , 2 ] / z2 NEW_LINE d_rot [ 3 , 0 , 2 ] = 2 * q [ 1 ] / z - 2 * q [ 3 ] * rot [ 0 , 2 ] / z2 NEW_LINE d_rot [ 0 , 1 , 0 ] = 2 * q [ 3 ] / z - 2 * q [ 0 ] * rot [ 1 , 0 ] / z2 NEW_LINE d_rot [ 1 , 1 , 0 ] = 2 * q [ 2 ] / z - 2 * q [ 1 ] * rot [ 1 , 0 ] / z2 NEW_LINE d_rot [ 2 , 1 , 0 ] = 2 * q [ 1 ] / z - 2 * q [ 2 ] * rot [ 1 , 0 ] / z2 NEW_LINE d_rot [ 3 , 1 , 0 ] = 2 * q [ 0 ] / z - 2 * q [ 3 ] * rot [ 1 , 0 ] / z2 NEW_LINE d_rot [ 0 , 1 , 2 ] = - 2 * q [ 1 ] / z - 2 * q [ 0 ] * rot [ 1 , 2 ] / z2 NEW_LINE d_rot [ 1 , 1 , 2 ] = - 2 * q [ 0 ] / z - 2 * q [ 1 ] * rot [ 1 , 2 ] / z2 NEW_LINE d_rot [ 2 , 1 , 2 ] = 2 * q [ 3 ] / z - 2 * q [ 2 ] * rot [ 1 , 2 ] / z2 NEW_LINE d_rot [ 3 , 1 , 2 ] = 2 * q [ 2 ] / z - 2 * q [ 3 ] * rot [ 1 , 2 ] / z2 NEW_LINE d_rot [ 0 , 2 , 0 ] = - 2 * q [ 2 ] / z - 2 * q [ 0 ] * rot [ 2 , 0 ] / z2 NEW_LINE d_rot [ 1 , 2 , 0 ] = 2 * q [ 3 ] / z - 2 * q [ 1 ] * rot [ 2 , 0 ] / z2 NEW_LINE d_rot [ 2 , 2 , 0 ] = - 2 * q [ 0 ] / z - 2 * q [ 2 ] * rot [ 2 , 0 ] / z2 NEW_LINE d_rot [ 3 , 2 , 0 ] = 2 * q [ 1 ] / z - 2 * q [ 3 ] * rot [ 2 , 0 ] / z2 NEW_LINE d_rot [ 0 , 2 , 1 ] = 2 * q [ 1 ] / z - 2 * q [ 0 ] * rot [ 2 , 1 ] / z2 NEW_LINE d_rot [ 1 , 2 , 1 ] = 2 * q [ 0 ] / z - 2 * q [ 1 ] * rot [ 2 , 1 ] / z2 NEW_LINE d_rot [ 2 , 2 , 1 ] = 2 * q [ 3 ] / z - 2 * q [ 2 ] * rot [ 2 , 1 ] / z2 NEW_LINE d_rot [ 3 , 2 , 1 ] = 2 * q [ 2 ] / z - 2 * q [ 3 ] * rot [ 2 , 1 ] / z2 NEW_LINE return d_rot NEW_LINE DEDENT',), ('def __init__ ( self , p , with_blur = True ) : NEW_LINE INDENT self . _impl = _permutohedral_lattice . Permutohedral ( ) NEW_LINE self . _impl . init ( p . T , with_blur ) NEW_LINE DEDENT',), ('def get_lattice_size ( self ) : NEW_LINE INDENT return self . _impl . get_lattice_size ( ) NEW_LINE DEDENT',), ('def filter ( self , v , start = 0 ) : NEW_LINE INDENT return self . _impl . filter ( v . T , start ) . T NEW_LINE DEDENT',), ('def asnumpy ( x ) : NEW_LINE INDENT return x NEW_LINE DEDENT',), ('def __init__ ( self , source , target , save = False , keep_window = True ) : NEW_LINE INDENT self . _source = source NEW_LINE self . _target = target NEW_LINE self . _result = copy . deepcopy ( self . _source ) NEW_LINE self . _save = save NEW_LINE self . _cnt = 0 NEW_LINE plt . axis ( \" equal \" ) NEW_LINE source = asnumpy ( self . _source ) NEW_LINE target = asnumpy ( self . _target ) NEW_LINE result = asnumpy ( self . _result ) NEW_LINE plt . plot ( source [ : , 0 ] , source [ : , 1 ] , \" ro \" , label = \" source \" ) NEW_LINE plt . plot ( target [ : , 0 ] , target [ : , 1 ] , \" g ^ \" , label = \" target \" ) NEW_LINE plt . plot ( result [ : , 0 ] , result [ : , 1 ] , \" bo \" , label = \" result \" ) NEW_LINE plt . legend ( ) NEW_LINE plt . draw ( ) NEW_LINE DEDENT',), ('def __call__ ( self , transformation ) : NEW_LINE INDENT self . _result = transformation . transform ( self . _source ) NEW_LINE plt . cla ( ) NEW_LINE plt . axis ( \" equal \" ) NEW_LINE source = asnumpy ( self . _source ) NEW_LINE target = asnumpy ( self . _target ) NEW_LINE result = asnumpy ( self . _result ) NEW_LINE plt . plot ( source [ : , 0 ] , source [ : , 1 ] , \" ro \" , label = \" source \" ) NEW_LINE plt . plot ( target [ : , 0 ] , target [ : , 1 ] , \" g ^ \" , label = \" target \" ) NEW_LINE plt . plot ( result [ : , 0 ] , result [ : , 1 ] , \" bo \" , label = \" result \" ) NEW_LINE plt . legend ( ) NEW_LINE if self . _save : NEW_LINE INDENT plt . savefig ( \" image _ %04d . png \" % self . _cnt ) NEW_LINE DEDENT plt . draw ( ) NEW_LINE plt . pause ( 0.001 ) NEW_LINE self . _cnt += 1 NEW_LINE DEDENT',), ('def __init__ ( self , source , target , save = False , keep_window = True , fov = None ) : NEW_LINE INDENT self . _vis = o3 . visualization . Visualizer ( ) NEW_LINE self . _vis . create_window ( ) NEW_LINE self . _source = source NEW_LINE self . _target = target NEW_LINE self . _result = copy . deepcopy ( self . _source ) NEW_LINE self . _save = save NEW_LINE self . _keep_window = keep_window NEW_LINE self . _source . paint_uniform_color ( [ 1 , 0 , 0 ] ) NEW_LINE self . _target . paint_uniform_color ( [ 0 , 1 , 0 ] ) NEW_LINE self . _result . paint_uniform_color ( [ 0 , 0 , 1 ] ) NEW_LINE self . _vis . add_geometry ( self . _source ) NEW_LINE self . _vis . add_geometry ( self . _target ) NEW_LINE self . _vis . add_geometry ( self . _result ) NEW_LINE if not fov is None : NEW_LINE INDENT ctr = self . _vis . get_view_control ( ) NEW_LINE ctr . change_field_of_view ( step = fov ) NEW_LINE DEDENT self . _cnt = 0 NEW_LINE DEDENT',), ('def __del__ ( self ) : NEW_LINE INDENT if self . _keep_window : NEW_LINE INDENT self . _vis . run ( ) NEW_LINE DEDENT self . _vis . destroy_window ( ) NEW_LINE DEDENT',), ('def __call__ ( self , transformation ) : NEW_LINE INDENT self . _result . points = transformation . transform ( self . _source . points ) NEW_LINE self . _vis . update_geometry ( self . _source ) NEW_LINE self . _vis . update_geometry ( self . _target ) NEW_LINE self . _vis . update_geometry ( self . _result ) NEW_LINE self . _vis . poll_events ( ) NEW_LINE self . _vis . update_renderer ( ) NEW_LINE if self . _save : NEW_LINE INDENT self . _vis . capture_screen_image ( \" image _ %04d . jpg \" % self . _cnt ) NEW_LINE DEDENT self . _cnt += 1 NEW_LINE DEDENT',), ('def estimate_normals ( pcd , params ) : NEW_LINE INDENT pcd . estimate_normals ( search_param = params ) NEW_LINE pcd . orient_normals_to_align_with_direction ( ) NEW_LINE DEDENT',), ('def prepare_source_and_target_rigid_3d ( source_filename , noise_amp = 0.001 , n_random = 500 , orientation = np . deg2rad ( [ 0.0 , 0.0 , 30.0 ] ) , translation = np . zeros ( 3 ) , voxel_size = 0.005 , normals = False ) : NEW_LINE INDENT source = o3 . io . read_point_cloud ( source_filename ) NEW_LINE source = source . voxel_down_sample ( voxel_size = voxel_size ) NEW_LINE print ( source ) NEW_LINE target = copy . deepcopy ( source ) NEW_LINE tp = np . asarray ( target . points ) NEW_LINE np . random . shuffle ( tp ) NEW_LINE rg = 1.5 * ( tp . max ( axis = 0 ) - tp . min ( axis = 0 ) ) NEW_LINE rands = ( np . random . rand ( n_random , 3 ) - 0.5 ) * rg + tp . mean ( axis = 0 ) NEW_LINE target . points = o3 . utility . Vector3dVector ( np . r_ [ tp + noise_amp * np . random . randn ( * tp . shape ) , rands ] ) NEW_LINE ans = np . identity ( 4 ) NEW_LINE ans [ : 3 , : 3 ] = t3d . euler . euler2mat ( * orientation ) NEW_LINE ans [ : 3 , 3 ] = translation NEW_LINE target . transform ( ans ) NEW_LINE if normals : NEW_LINE INDENT estimate_normals ( source , o3 . geometry . KDTreeSearchParamHybrid ( radius = 0.3 , max_nn = 50 ) ) NEW_LINE estimate_normals ( target , o3 . geometry . KDTreeSearchParamHybrid ( radius = 0.3 , max_nn = 50 ) ) NEW_LINE DEDENT return source , target NEW_LINE DEDENT',), ('def prepare_source_and_target_nonrigid_2d ( source_filename , target_filename ) : NEW_LINE INDENT source = np . loadtxt ( source_filename ) NEW_LINE target = np . loadtxt ( target_filename ) NEW_LINE return source , target NEW_LINE DEDENT',), ('def prepare_source_and_target_nonrigid_3d ( source_filename , target_filename , voxel_size = 5.0 ) : NEW_LINE INDENT source = o3 . geometry . PointCloud ( ) NEW_LINE target = o3 . geometry . PointCloud ( ) NEW_LINE source . points = o3 . utility . Vector3dVector ( np . loadtxt ( source_filename ) ) NEW_LINE target . points = o3 . utility . Vector3dVector ( np . loadtxt ( target_filename ) ) NEW_LINE source = source . voxel_down_sample ( voxel_size = voxel_size ) NEW_LINE target = target . voxel_down_sample ( voxel_size = voxel_size ) NEW_LINE print ( source ) NEW_LINE print ( target ) NEW_LINE return source , target NEW_LINE DEDENT',)]\n",
            "1.195784144103527\n",
            "On batch 1279\n",
            "tensor([0.1259, 0.1261, 0.1220, 0.1242, 0.1256, 0.1272, 0.1226, 0.1263],\n",
            "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "(\"\\n\\\\hat{\\\\Lambda}_j=\\\\sum_{i=1}^{2m}\\\\frac{2h_{i,j}\\\\{y_i-(\\\\hat{\\\\mu}_i-h_{i,j}\\\\hat{s}'_{j})\\\\}}{\\\\hat{\\\\sigma}_i^2-h_{i,j}^2(1-\\\\hat{s}_j^{\\\\prime 2}) },\\n\",)\n",
            "[('def H_change ( ) : NEW_LINE INDENT global H_re , H_im , H , Ht NEW_LINE H_re = torch . normal ( 0.0 , std = math . sqrt ( 0.5 ) * torch . ones ( ( int ) ( M / 2 ) , ( int ) ( N / 2 ) ) ) NEW_LINE H_im = torch . normal ( 0.0 , std = math . sqrt ( 0.5 ) * torch . ones ( ( int ) ( M / 2 ) , ( int ) ( N / 2 ) ) ) NEW_LINE H = torch . cat ( ( torch . cat ( ( H_re , H_im ) , 0 ) , torch . cat ( ( - 1 * H_im , H_re ) , 0 ) ) , 1 ) NEW_LINE H = H . cuda ( ) NEW_LINE Ht = H . t ( ) NEW_LINE Ht = Ht . cuda ( ) NEW_LINE DEDENT',), ('def write_param ( ) : NEW_LINE INDENT f = open ( file_name , \" a \" ) NEW_LINE f . write ( \\' \\\\n Parameter : \\\\n \\' ) NEW_LINE f . write ( \\' - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \\\\n \\' ) NEW_LINE f . write ( \\' ( N , M ) = : ( { 0 } , {1 } ) \\\\n \\' . format ( N , M ) ) NEW_LINE f . write ( \\' adam _ lr : {0 } \\\\n \\' . format ( adam_lr ) ) NEW_LINE f . write ( \\' num _ layers : {0 } \\\\n \\' . format ( num_layers ) ) NEW_LINE f . write ( \\' batch _ size : {0 } \\\\n \\' . format ( batch_size ) ) NEW_LINE f . write ( \\' num _ batch : {0 } \\\\n \\' . format ( num_batch ) ) NEW_LINE f . write ( \\' - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \\\\n \\' ) NEW_LINE f . close ( ) NEW_LINE DEDENT',), ('def isnan ( x ) : NEW_LINE INDENT return x != x NEW_LINE DEDENT',), ('def generate_batch ( ) : NEW_LINE INDENT return 1.0 - 2.0 * torch . bernoulli ( 0.5 * torch . ones ( batch_size , N ) ) NEW_LINE DEDENT',), ('def eval ( network , t ) : NEW_LINE INDENT s_zero = torch . zeros ( batch_size , N ) . cuda ( ) NEW_LINE accuracy , num_err = 0.0 , 0.0 NEW_LINE H_change ( ) NEW_LINE for i in range ( test_itr ) : NEW_LINE INDENT x = generate_batch ( ) . cuda ( ) NEW_LINE x_hat = network ( x , s_zero , t + 1 ) . cuda ( ) NEW_LINE if isnan ( x_hat ) . any ( ) : NEW_LINE INDENT print ( \" Nan \" ) NEW_LINE continue NEW_LINE DEDENT err = x * torch . sign ( x_hat ) NEW_LINE num_err += torch . nonzero ( F . relu ( err ) ) . size ( 0 ) NEW_LINE DEDENT accuracy = num_err / ( test_itr * batch_size * N ) NEW_LINE BER = 1 - accuracy NEW_LINE print ( \\' ( {0 } ) ▁ BER : {1:6.6f } \\' . format ( t + 1 , BER ) ) NEW_LINE return BER NEW_LINE DEDENT',), ('def __init__ ( self ) : NEW_LINE INDENT super ( TPG_NET , self ) . __init__ ( ) NEW_LINE self . gamma = nn . Parameter ( torch . normal ( 1.0 , 0.1 * torch . ones ( num_layers ) ) ) NEW_LINE self . theta = nn . Parameter ( torch . normal ( 1.0 , 0.1 * torch . ones ( num_layers ) ) ) NEW_LINE self . alpha = nn . Parameter ( torch . abs ( torch . normal ( 0.0 , 0.01 * torch . ones ( 1 ) ) ) ) NEW_LINE DEDENT',), ('def shrinkage_function ( self , y , tau2 ) : NEW_LINE INDENT return torch . tanh ( y / tau2 ) NEW_LINE DEDENT',), ('def forward ( self , x , s , max_itr ) : NEW_LINE INDENT alpha_I = self . alpha [ 0 ] * torch . eye ( M ) . cuda ( ) NEW_LINE W = Ht . mm ( ( H . mm ( Ht ) + alpha_I ) . inverse ( ) ) NEW_LINE Wt = W . t ( ) NEW_LINE y = x . mm ( Ht ) + torch . normal ( 0.0 , sigma_std * torch . ones ( batch_size , M ) ) . cuda ( ) NEW_LINE for i in range ( max_itr ) : NEW_LINE INDENT t = y - s . mm ( Ht ) NEW_LINE tau2 = torch . abs ( self . theta [ i ] ) NEW_LINE r = s + t . mm ( Wt ) * self . gamma [ i ] NEW_LINE s = self . shrinkage_function ( r , tau2 ) NEW_LINE DEDENT return s NEW_LINE DEDENT',)]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-2eaac9f5331e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m       \u001b[0mloss_avg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code_rep"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzfkAfweiFKG",
        "outputId": "817c27c1-8480-4e93-bf3c-c2bbd8c3a0c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[[ 0.7814, -0.1531,  0.2438,  ...,  0.5276,  0.1782,  0.2289]]]),\n",
              " tensor([[[ 0.4640, -0.0946,  0.2987,  ...,  0.4522,  0.2744,  0.2990]]]),\n",
              " tensor([[[ 0.9164, -0.3907,  0.0960,  ...,  0.5478,  0.3017, -0.0221]]]),\n",
              " tensor([[[ 0.9199, -0.3740,  0.1033,  ...,  0.5090,  0.2973, -0.0067]]]),\n",
              " tensor([[[ 0.9440, -0.3906,  0.1073,  ...,  0.5119,  0.3007, -0.0176]]]),\n",
              " tensor([[[ 0.8080, -0.2522,  0.1362,  ...,  0.4910,  0.2463,  0.0997]]]),\n",
              " tensor([[[ 0.7899, -0.2610,  0.1008,  ...,  0.4811,  0.2407,  0.0743]]]),\n",
              " tensor([[[ 0.8414, -0.2704,  0.1358,  ...,  0.4767,  0.2585,  0.0918]]]),\n",
              " tensor([[[ 0.7523, -0.2260,  0.0746,  ...,  0.4840,  0.2679,  0.1212]]]),\n",
              " tensor([[[ 0.8664, -0.1233,  0.0296,  ...,  0.3527,  0.2741,  0.1871]]]),\n",
              " tensor([[[ 0.7946, -0.1043,  0.0557,  ...,  0.3444,  0.2854,  0.1643]]]),\n",
              " tensor([[[ 0.8321, -0.1260,  0.0382,  ...,  0.3618,  0.2802,  0.1615]]]),\n",
              " tensor([[[ 0.8621, -0.1249,  0.0124,  ...,  0.3173,  0.2748,  0.2579]]]),\n",
              " tensor([[[ 0.7980, -0.0452,  0.0809,  ...,  0.3859,  0.2468,  0.2645]]]),\n",
              " tensor([[[ 0.8297, -0.1134,  0.1162,  ...,  0.2809,  0.2304,  0.2261]]]),\n",
              " tensor([[[ 0.8701, -0.2255,  0.1205,  ...,  0.5024,  0.1990,  0.2280]]]),\n",
              " tensor([[[ 0.4837, -0.0859,  0.1674,  ...,  0.4295,  0.1844,  0.2649]]]),\n",
              " tensor([[[0.5469, 0.0109, 0.1969,  ..., 0.4752, 0.0706, 0.2228]]]),\n",
              " tensor([[[ 0.5228, -0.0429,  0.0735,  ...,  0.3193,  0.2687,  0.2165]]]),\n",
              " tensor([[[ 0.6423, -0.0784, -0.0033,  ...,  0.4051,  0.2856,  0.2489]]]),\n",
              " tensor([[[ 0.5408, -0.2126,  0.3348,  ...,  0.5247,  0.0839,  0.3751]]]),\n",
              " tensor([[[ 0.7719, -0.1331,  0.1098,  ...,  0.4079,  0.3715,  0.0222]]]),\n",
              " tensor([[[ 0.7842, -0.1669,  0.0721,  ...,  0.2581,  0.2087,  0.1804]]]),\n",
              " tensor([[[ 0.6367, -0.1957,  0.0849,  ...,  0.2954,  0.3996,  0.0179]]]),\n",
              " tensor([[[ 0.6221,  0.0567,  0.0631,  ...,  0.4684,  0.2737, -0.0228]]]),\n",
              " tensor([[[ 0.5619, -0.1331,  0.1161,  ...,  0.4885,  0.3910,  0.0136]]]),\n",
              " tensor([[[ 8.4810e-01, -1.4870e-01,  1.3544e-01,  ...,  3.6342e-01,\n",
              "            4.3833e-01,  1.3433e-04]]]),\n",
              " tensor([[[0.7238, 0.0393, 0.1793,  ..., 0.4955, 0.2182, 0.3443]]]),\n",
              " tensor([[[ 0.8718, -0.0829,  0.2484,  ...,  0.4650,  0.4510,  0.1206]]]),\n",
              " tensor([[[0.4398, 0.0435, 0.1635,  ..., 0.5088, 0.2372, 0.0057]]]),\n",
              " tensor([[[ 0.6769, -0.1125, -0.1427,  ...,  0.6662, -0.0316,  0.2369]]]),\n",
              " tensor([[[0.7048, 0.0783, 0.3283,  ..., 0.5428, 0.3210, 0.3558]]]),\n",
              " tensor([[[ 0.6962, -0.1966,  0.0768,  ...,  0.5144,  0.2925,  0.1592]]]),\n",
              " tensor([[[ 0.6897, -0.0279,  0.0689,  ...,  0.5242,  0.3445,  0.1388]]]),\n",
              " tensor([[[ 0.6654, -0.1141,  0.0896,  ...,  0.7175,  0.1809,  0.2496]]]),\n",
              " tensor([[[ 0.7731, -0.2269,  0.2070,  ...,  0.7341,  0.1498,  0.3872]]]),\n",
              " tensor([[[ 0.8124, -0.0954,  0.0887,  ...,  0.6957,  0.2510,  0.1577]]]),\n",
              " tensor([[[ 0.6260, -0.1319,  0.2911,  ...,  0.5407,  0.3226,  0.4711]]]),\n",
              " tensor([[[ 0.8046, -0.2094,  0.1390,  ...,  0.6063,  0.1524,  0.2869]]]),\n",
              " tensor([[[ 0.6660, -0.3841,  0.2874,  ...,  0.7687,  0.2183,  0.0481]]]),\n",
              " tensor([[[ 0.6721, -0.2915,  0.0911,  ...,  0.3297,  0.5388,  0.0362]]]),\n",
              " tensor([[[ 0.7788, -0.2594,  0.2674,  ...,  0.6853,  0.2718,  0.3051]]]),\n",
              " tensor([[[ 0.4777, -0.1662,  0.2018,  ...,  0.6173,  0.1505,  0.3699]]]),\n",
              " tensor([[[ 0.8801, -0.1332,  0.2174,  ...,  0.5846,  0.1887,  0.3818]]]),\n",
              " tensor([[[ 0.5933, -0.2126,  0.2190,  ...,  0.5322,  0.1537,  0.2579]]]),\n",
              " tensor([[[0.8365, 0.0037, 0.2409,  ..., 0.5340, 0.3309, 0.3144]]]),\n",
              " tensor([[[ 0.5012, -0.2055,  0.2122,  ...,  0.5687,  0.1708,  0.3792]]]),\n",
              " tensor([[[ 0.8205, -0.0490,  0.2660,  ...,  0.5630,  0.2370,  0.3910]]]),\n",
              " tensor([[[ 0.4344, -0.1044,  0.2297,  ...,  0.4990,  0.2038,  0.3400]]]),\n",
              " tensor([[[ 0.8556, -0.0595,  0.2309,  ...,  0.5491,  0.2939,  0.2895]]]),\n",
              " tensor([[[ 0.5000, -0.0957,  0.2709,  ...,  0.4685,  0.2379,  0.3407]]])]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "torch.save(combined_model.state_dict(),\"gdrive/MyDrive/RSS/Models/combined_model\"+str(time.strftime('%Y-%m-%d_%H:%M:%S.pt', time.localtime())) )"
      ],
      "metadata": {
        "id": "OUjo25d_TSxV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}