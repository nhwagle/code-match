{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TransCoder Based Code Functions to Embeddings .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhwagle/code-match/blob/main/TransCoder_Based_Code_Functions_to_Embeddings_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GSKxsHXzWKw"
      },
      "source": [
        "This notebook is a bit messier, but it also contains content we utilized to process functions into embedding representations utilizing Facebook AI Research's TransCoder models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82i_Cc08zWK3"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing codegen. Their install_env.sh won't work for colab so modifying such that all conda imports are done with pip"
      ],
      "metadata": {
        "id": "Lq8FKDVXwgxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/CodeGen.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ags1bdA5vRPF",
        "outputId": "cfb9272a-46ba-47b8-bbed-8e647c55a41e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CodeGen'...\n",
            "remote: Enumerating objects: 2770, done.\u001b[K\n",
            "remote: Total 2770 (delta 0), reused 0 (delta 0), pack-reused 2770\u001b[K\n",
            "Receiving objects: 100% (2770/2770), 12.43 MiB | 29.06 MiB/s, done.\n",
            "Resolving deltas: 100% (1371/1371), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv CodeGen/* ./"
      ],
      "metadata": {
        "id": "GEj6N2EV3TOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchaudio"
      ],
      "metadata": {
        "id": "ZXwX4tnk4xlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install stringcase transformers ply slimit astunparse submitit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzjVFdEo5rwE",
        "outputId": "76779afa-0a39-4d40-e7be-af9f6f6ed695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stringcase\n",
            "  Downloading stringcase-1.2.0.tar.gz (3.0 kB)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 5.2 MB/s \n",
            "\u001b[?25hCollecting ply\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting slimit\n",
            "  Downloading slimit-0.8.1.zip (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse in /usr/local/lib/python3.7/dist-packages (1.6.3)\n",
            "Collecting submitit\n",
            "  Downloading submitit-1.4.2-py3-none-any.whl (71 kB)\n",
            "\u001b[K     |████████████████████████████████| 71 kB 168 kB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 50.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 34.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 40.5 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from astunparse) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse) (0.37.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from submitit) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Building wheels for collected packages: stringcase, slimit\n",
            "  Building wheel for stringcase (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stringcase: filename=stringcase-1.2.0-py3-none-any.whl size=3587 sha256=eda9832bd43267abe82db3cae2e1705d13094b3cf61c3eaf0eb0fb979ad0c17a\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/ab/a3/a8fa7e0a07e80f547e03468c03827f8257f7339327986faed1\n",
            "  Building wheel for slimit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for slimit: filename=slimit-0.8.1-py3-none-any.whl size=79458 sha256=4d72470edd572dd02a2d8e46ec90120f55800605e0035020ea05cf219cc19ecc\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/0b/89/cee8d5525ed7fa925e6d6ab76a19176c499fd1992c2f822644\n",
            "Successfully built stringcase slimit\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, ply, huggingface-hub, transformers, submitit, stringcase, slimit\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 ply-3.11 pyyaml-6.0 sacremoses-0.0.49 slimit-0.8.1 stringcase-1.2.0 submitit-1.4.2 tokenizers-0.12.1 transformers-4.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import stringcase\n",
        "import six\n",
        "import sklearn\n",
        "import transformers\n",
        "import ply\n",
        "import slimit \n",
        "import astunparse \n",
        "import submitit"
      ],
      "metadata": {
        "id": "0sTzNevt5pYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA/apex\n",
        "%cd apex\n",
        "%pip install -v --no-cache-dir ./"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxBzSWWr_oKW",
        "outputId": "8ff9565a-2e18-4f47-9d11-87ce89d2313a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 9614, done.\u001b[K\n",
            "remote: Counting objects: 100% (685/685), done.\u001b[K\n",
            "remote: Compressing objects: 100% (349/349), done.\u001b[K\n",
            "remote: Total 9614 (delta 412), reused 512 (delta 317), pack-reused 8929\u001b[K\n",
            "Receiving objects: 100% (9614/9614), 14.82 MiB | 26.57 MiB/s, done.\n",
            "Resolving deltas: 100% (6525/6525), done.\n",
            "/content/apex\n",
            "Using pip 21.1.3 from /usr/local/lib/python3.7/dist-packages/pip (python 3.7)\n",
            "Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\n",
            "Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\n",
            "Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/include/python3.7/UNKNOWN\n",
            "sysconfig: /usr/include/python3.7m/UNKNOWN\n",
            "Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/bin\n",
            "sysconfig: /usr/bin\n",
            "Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local\n",
            "sysconfig: /usr\n",
            "Additional context:\n",
            "user = False\n",
            "home = None\n",
            "root = None\n",
            "prefix = None\n",
            "Non-user install because site-packages writeable\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-gn0ombr3\n",
            "Created temporary directory: /tmp/pip-req-tracker-j55a0_c6\n",
            "Initialized build tracking at /tmp/pip-req-tracker-j55a0_c6\n",
            "Created build tracker: /tmp/pip-req-tracker-j55a0_c6\n",
            "Entered build tracker: /tmp/pip-req-tracker-j55a0_c6\n",
            "Created temporary directory: /tmp/pip-install-nyvm0noa\n",
            "Processing /content/apex\n",
            "  Created temporary directory: /tmp/pip-req-build-_9zg87m1\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-j55a0_c6'\n",
            "    Running setup.py (path:/tmp/pip-req-build-_9zg87m1/setup.py) egg_info for package from file:///content/apex\n",
            "    Created temporary directory: /tmp/pip-pip-egg-info-dd22raag\n",
            "    Running command python setup.py egg_info\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.11.0+cu113\n",
            "\n",
            "\n",
            "    running egg_info\n",
            "    creating /tmp/pip-pip-egg-info-dd22raag/apex.egg-info\n",
            "    writing /tmp/pip-pip-egg-info-dd22raag/apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-pip-egg-info-dd22raag/apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-pip-egg-info-dd22raag/apex.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-pip-egg-info-dd22raag/apex.egg-info/SOURCES.txt'\n",
            "    adding license file 'LICENSE'\n",
            "    writing manifest file '/tmp/pip-pip-egg-info-dd22raag/apex.egg-info/SOURCES.txt'\n",
            "    /tmp/pip-req-build-_9zg87m1/setup.py:121: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  Source in /tmp/pip-req-build-_9zg87m1 has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n",
            "  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-j55a0_c6'\n",
            "Created temporary directory: /tmp/pip-unpack-xlrtun_7\n",
            "Building wheels for collected packages: apex\n",
            "  Created temporary directory: /tmp/pip-wheel-951y9t0d\n",
            "  Building wheel for apex (setup.py) ... \u001b[?25l  Destination directory: /tmp/pip-wheel-951y9t0d\n",
            "  Running command /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-_9zg87m1/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-_9zg87m1/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-951y9t0d\n",
            "\n",
            "\n",
            "  torch.__version__  = 1.11.0+cu113\n",
            "\n",
            "\n",
            "  /tmp/pip-req-build-_9zg87m1/setup.py:121: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "    warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib\n",
            "  creating build/lib/apex\n",
            "  copying apex/_autocast_utils.py -> build/lib/apex\n",
            "  copying apex/__init__.py -> build/lib/apex\n",
            "  creating build/lib/apex/pyprof\n",
            "  copying apex/pyprof/__init__.py -> build/lib/apex/pyprof\n",
            "  creating build/lib/apex/RNN\n",
            "  copying apex/RNN/models.py -> build/lib/apex/RNN\n",
            "  copying apex/RNN/cells.py -> build/lib/apex/RNN\n",
            "  copying apex/RNN/__init__.py -> build/lib/apex/RNN\n",
            "  copying apex/RNN/RNNBackend.py -> build/lib/apex/RNN\n",
            "  creating build/lib/apex/parallel\n",
            "  copying apex/parallel/LARC.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/sync_batchnorm.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/distributed.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/multiproc.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/__init__.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/optimized_sync_batchnorm.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
            "  creating build/lib/apex/reparameterization\n",
            "  copying apex/reparameterization/weight_norm.py -> build/lib/apex/reparameterization\n",
            "  copying apex/reparameterization/__init__.py -> build/lib/apex/reparameterization\n",
            "  copying apex/reparameterization/reparameterization.py -> build/lib/apex/reparameterization\n",
            "  creating build/lib/apex/contrib\n",
            "  copying apex/contrib/__init__.py -> build/lib/apex/contrib\n",
            "  creating build/lib/apex/transformer\n",
            "  copying apex/transformer/utils.py -> build/lib/apex/transformer\n",
            "  copying apex/transformer/microbatches.py -> build/lib/apex/transformer\n",
            "  copying apex/transformer/enums.py -> build/lib/apex/transformer\n",
            "  copying apex/transformer/__init__.py -> build/lib/apex/transformer\n",
            "  copying apex/transformer/log_util.py -> build/lib/apex/transformer\n",
            "  copying apex/transformer/parallel_state.py -> build/lib/apex/transformer\n",
            "  creating build/lib/apex/mlp\n",
            "  copying apex/mlp/mlp.py -> build/lib/apex/mlp\n",
            "  copying apex/mlp/__init__.py -> build/lib/apex/mlp\n",
            "  creating build/lib/apex/amp\n",
            "  copying apex/amp/utils.py -> build/lib/apex/amp\n",
            "  copying apex/amp/_amp_state.py -> build/lib/apex/amp\n",
            "  copying apex/amp/amp.py -> build/lib/apex/amp\n",
            "  copying apex/amp/_process_optimizer.py -> build/lib/apex/amp\n",
            "  copying apex/amp/frontend.py -> build/lib/apex/amp\n",
            "  copying apex/amp/rnn_compat.py -> build/lib/apex/amp\n",
            "  copying apex/amp/__version__.py -> build/lib/apex/amp\n",
            "  copying apex/amp/scaler.py -> build/lib/apex/amp\n",
            "  copying apex/amp/wrap.py -> build/lib/apex/amp\n",
            "  copying apex/amp/compat.py -> build/lib/apex/amp\n",
            "  copying apex/amp/__init__.py -> build/lib/apex/amp\n",
            "  copying apex/amp/_initialize.py -> build/lib/apex/amp\n",
            "  copying apex/amp/opt.py -> build/lib/apex/amp\n",
            "  copying apex/amp/handle.py -> build/lib/apex/amp\n",
            "  creating build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/fp16_optimizer.py -> build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/fp16util.py -> build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/loss_scaler.py -> build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/__init__.py -> build/lib/apex/fp16_utils\n",
            "  creating build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_novograd.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_sgd.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_adam.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/__init__.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_lamb.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_mixed_precision_lamb.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_adagrad.py -> build/lib/apex/optimizers\n",
            "  creating build/lib/apex/fused_dense\n",
            "  copying apex/fused_dense/__init__.py -> build/lib/apex/fused_dense\n",
            "  copying apex/fused_dense/fused_dense.py -> build/lib/apex/fused_dense\n",
            "  creating build/lib/apex/multi_tensor_apply\n",
            "  copying apex/multi_tensor_apply/__init__.py -> build/lib/apex/multi_tensor_apply\n",
            "  copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib/apex/multi_tensor_apply\n",
            "  creating build/lib/apex/normalization\n",
            "  copying apex/normalization/__init__.py -> build/lib/apex/normalization\n",
            "  copying apex/normalization/fused_layer_norm.py -> build/lib/apex/normalization\n",
            "  creating build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/embedding.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/loss.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/pointwise.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/activation.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/misc.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/pooling.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/conv.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/data.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/softmax.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/utility.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/usage.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/__main__.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/convert.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/optim.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/linear.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/reduction.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/__init__.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/normalization.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/dropout.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/blas.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/recurrentCell.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/randomSample.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/base.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/prof.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/output.py -> build/lib/apex/pyprof/prof\n",
            "  creating build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/db.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/parse.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/__main__.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/nvvp.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/__init__.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/kernel.py -> build/lib/apex/pyprof/parse\n",
            "  creating build/lib/apex/pyprof/nvtx\n",
            "  copying apex/pyprof/nvtx/__init__.py -> build/lib/apex/pyprof/nvtx\n",
            "  copying apex/pyprof/nvtx/nvmarker.py -> build/lib/apex/pyprof/nvtx\n",
            "  creating build/lib/apex/contrib/focal_loss\n",
            "  copying apex/contrib/focal_loss/focal_loss.py -> build/lib/apex/contrib/focal_loss\n",
            "  copying apex/contrib/focal_loss/__init__.py -> build/lib/apex/contrib/focal_loss\n",
            "  creating build/lib/apex/contrib/groupbn\n",
            "  copying apex/contrib/groupbn/batch_norm.py -> build/lib/apex/contrib/groupbn\n",
            "  copying apex/contrib/groupbn/__init__.py -> build/lib/apex/contrib/groupbn\n",
            "  creating build/lib/apex/contrib/layer_norm\n",
            "  copying apex/contrib/layer_norm/__init__.py -> build/lib/apex/contrib/layer_norm\n",
            "  copying apex/contrib/layer_norm/layer_norm.py -> build/lib/apex/contrib/layer_norm\n",
            "  creating build/lib/apex/contrib/conv_bias_relu\n",
            "  copying apex/contrib/conv_bias_relu/conv_bias_relu.py -> build/lib/apex/contrib/conv_bias_relu\n",
            "  copying apex/contrib/conv_bias_relu/__init__.py -> build/lib/apex/contrib/conv_bias_relu\n",
            "  creating build/lib/apex/contrib/fmha\n",
            "  copying apex/contrib/fmha/__init__.py -> build/lib/apex/contrib/fmha\n",
            "  copying apex/contrib/fmha/fmha.py -> build/lib/apex/contrib/fmha\n",
            "  creating build/lib/apex/contrib/xentropy\n",
            "  copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib/apex/contrib/xentropy\n",
            "  copying apex/contrib/xentropy/__init__.py -> build/lib/apex/contrib/xentropy\n",
            "  creating build/lib/apex/contrib/transducer\n",
            "  copying apex/contrib/transducer/__init__.py -> build/lib/apex/contrib/transducer\n",
            "  copying apex/contrib/transducer/transducer.py -> build/lib/apex/contrib/transducer\n",
            "  creating build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/__init__.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  creating build/lib/apex/contrib/peer_memory\n",
            "  copying apex/contrib/peer_memory/peer_halo_exchange_module_tests.py -> build/lib/apex/contrib/peer_memory\n",
            "  copying apex/contrib/peer_memory/__init__.py -> build/lib/apex/contrib/peer_memory\n",
            "  copying apex/contrib/peer_memory/peer_memory.py -> build/lib/apex/contrib/peer_memory\n",
            "  copying apex/contrib/peer_memory/peer_halo_exchanger_1d.py -> build/lib/apex/contrib/peer_memory\n",
            "  creating build/lib/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/permutation_lib.py -> build/lib/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/__init__.py -> build/lib/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/sparse_masklib.py -> build/lib/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/asp.py -> build/lib/apex/contrib/sparsity\n",
            "  creating build/lib/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/halo_exchangers.py -> build/lib/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/bottleneck.py -> build/lib/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/bottleneck_module_test.py -> build/lib/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/__init__.py -> build/lib/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/test.py -> build/lib/apex/contrib/bottleneck\n",
            "  creating build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_sgd.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_adam.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/__init__.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
            "  creating build/lib/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> build/lib/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> build/lib/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying apex/contrib/sparsity/permutation_search_kernels/__init__.py -> build/lib/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> build/lib/apex/contrib/sparsity/permutation_search_kernels\n",
            "  creating build/lib/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/utils.py -> build/lib/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/mappings.py -> build/lib/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/random.py -> build/lib/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/data.py -> build/lib/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/layers.py -> build/lib/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/memory.py -> build/lib/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/cross_entropy.py -> build/lib/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/__init__.py -> build/lib/apex/transformer/tensor_parallel\n",
            "  creating build/lib/apex/transformer/testing\n",
            "  copying apex/transformer/testing/arguments.py -> build/lib/apex/transformer/testing\n",
            "  copying apex/transformer/testing/distributed_test_base.py -> build/lib/apex/transformer/testing\n",
            "  copying apex/transformer/testing/global_vars.py -> build/lib/apex/transformer/testing\n",
            "  copying apex/transformer/testing/__init__.py -> build/lib/apex/transformer/testing\n",
            "  copying apex/transformer/testing/commons.py -> build/lib/apex/transformer/testing\n",
            "  copying apex/transformer/testing/standalone_gpt.py -> build/lib/apex/transformer/testing\n",
            "  copying apex/transformer/testing/standalone_bert.py -> build/lib/apex/transformer/testing\n",
            "  creating build/lib/apex/transformer/functional\n",
            "  copying apex/transformer/functional/fused_softmax.py -> build/lib/apex/transformer/functional\n",
            "  copying apex/transformer/functional/__init__.py -> build/lib/apex/transformer/functional\n",
            "  creating build/lib/apex/transformer/_data\n",
            "  copying apex/transformer/_data/_batchsampler.py -> build/lib/apex/transformer/_data\n",
            "  copying apex/transformer/_data/__init__.py -> build/lib/apex/transformer/_data\n",
            "  creating build/lib/apex/transformer/pipeline_parallel\n",
            "  copying apex/transformer/pipeline_parallel/utils.py -> build/lib/apex/transformer/pipeline_parallel\n",
            "  copying apex/transformer/pipeline_parallel/p2p_communication.py -> build/lib/apex/transformer/pipeline_parallel\n",
            "  copying apex/transformer/pipeline_parallel/_timers.py -> build/lib/apex/transformer/pipeline_parallel\n",
            "  copying apex/transformer/pipeline_parallel/__init__.py -> build/lib/apex/transformer/pipeline_parallel\n",
            "  creating build/lib/apex/transformer/amp\n",
            "  copying apex/transformer/amp/grad_scaler.py -> build/lib/apex/transformer/amp\n",
            "  copying apex/transformer/amp/__init__.py -> build/lib/apex/transformer/amp\n",
            "  creating build/lib/apex/transformer/pipeline_parallel/schedules\n",
            "  copying apex/transformer/pipeline_parallel/schedules/common.py -> build/lib/apex/transformer/pipeline_parallel/schedules\n",
            "  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> build/lib/apex/transformer/pipeline_parallel/schedules\n",
            "  copying apex/transformer/pipeline_parallel/schedules/__init__.py -> build/lib/apex/transformer/pipeline_parallel/schedules\n",
            "  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> build/lib/apex/transformer/pipeline_parallel/schedules\n",
            "  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> build/lib/apex/transformer/pipeline_parallel/schedules\n",
            "  creating build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/torch_overrides.py -> build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/functional_overrides.py -> build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/tensor_overrides.py -> build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/__init__.py -> build/lib/apex/amp/lists\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/apex\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/embedding.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/loss.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/pointwise.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/activation.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/misc.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/pooling.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/conv.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/data.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/softmax.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/utility.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/usage.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/convert.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/index_slice_join_mutate.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/optim.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/linear.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/reduction.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/normalization.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/dropout.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/blas.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/recurrentCell.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/randomSample.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/base.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/prof.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/output.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/db.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/parse.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/nvvp.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/kernel.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
            "  copying build/lib/apex/pyprof/nvtx/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
            "  copying build/lib/apex/pyprof/nvtx/nvmarker.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
            "  copying build/lib/apex/_autocast_utils.py -> build/bdist.linux-x86_64/wheel/apex\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/models.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/cells.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/__init__.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/LARC.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/distributed.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  copying build/lib/apex/reparameterization/weight_norm.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  copying build/lib/apex/reparameterization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  copying build/lib/apex/reparameterization/reparameterization.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/focal_loss\n",
            "  copying build/lib/apex/contrib/focal_loss/focal_loss.py -> build/bdist.linux-x86_64/wheel/apex/contrib/focal_loss\n",
            "  copying build/lib/apex/contrib/focal_loss/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/focal_loss\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  copying build/lib/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  copying build/lib/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
            "  copying build/lib/apex/contrib/layer_norm/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
            "  copying build/lib/apex/contrib/layer_norm/layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/conv_bias_relu\n",
            "  copying build/lib/apex/contrib/conv_bias_relu/conv_bias_relu.py -> build/bdist.linux-x86_64/wheel/apex/contrib/conv_bias_relu\n",
            "  copying build/lib/apex/contrib/conv_bias_relu/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/conv_bias_relu\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
            "  copying build/lib/apex/contrib/fmha/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
            "  copying build/lib/apex/contrib/fmha/fmha.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  copying build/lib/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  copying build/lib/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
            "  copying build/lib/apex/contrib/transducer/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
            "  copying build/lib/apex/contrib/transducer/transducer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
            "  copying build/lib/apex/contrib/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory\n",
            "  copying build/lib/apex/contrib/peer_memory/peer_halo_exchange_module_tests.py -> build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory\n",
            "  copying build/lib/apex/contrib/peer_memory/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory\n",
            "  copying build/lib/apex/contrib/peer_memory/peer_memory.py -> build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory\n",
            "  copying build/lib/apex/contrib/peer_memory/peer_halo_exchanger_1d.py -> build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  copying build/lib/apex/contrib/sparsity/permutation_lib.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  copying build/lib/apex/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  copying build/lib/apex/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying build/lib/apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying build/lib/apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying build/lib/apex/contrib/sparsity/permutation_search_kernels/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying build/lib/apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying build/lib/apex/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  copying build/lib/apex/contrib/bottleneck/halo_exchangers.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  copying build/lib/apex/contrib/bottleneck/bottleneck.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  copying build/lib/apex/contrib/bottleneck/bottleneck_module_test.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  copying build/lib/apex/contrib/bottleneck/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  copying build/lib/apex/contrib/bottleneck/test.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/transformer\n",
            "  copying build/lib/apex/transformer/utils.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  copying build/lib/apex/transformer/tensor_parallel/utils.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  copying build/lib/apex/transformer/tensor_parallel/mappings.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  copying build/lib/apex/transformer/tensor_parallel/random.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  copying build/lib/apex/transformer/tensor_parallel/data.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  copying build/lib/apex/transformer/tensor_parallel/layers.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  copying build/lib/apex/transformer/tensor_parallel/memory.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  copying build/lib/apex/transformer/tensor_parallel/cross_entropy.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  copying build/lib/apex/transformer/tensor_parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  copying build/lib/apex/transformer/microbatches.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
            "  copying build/lib/apex/transformer/testing/arguments.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
            "  copying build/lib/apex/transformer/testing/distributed_test_base.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
            "  copying build/lib/apex/transformer/testing/global_vars.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
            "  copying build/lib/apex/transformer/testing/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
            "  copying build/lib/apex/transformer/testing/commons.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
            "  copying build/lib/apex/transformer/testing/standalone_gpt.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
            "  copying build/lib/apex/transformer/testing/standalone_bert.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/transformer/functional\n",
            "  copying build/lib/apex/transformer/functional/fused_softmax.py -> build/bdist.linux-x86_64/wheel/apex/transformer/functional\n",
            "  copying build/lib/apex/transformer/functional/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/functional\n",
            "  copying build/lib/apex/transformer/enums.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n",
            "  copying build/lib/apex/transformer/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/transformer/_data\n",
            "  copying build/lib/apex/transformer/_data/_batchsampler.py -> build/bdist.linux-x86_64/wheel/apex/transformer/_data\n",
            "  copying build/lib/apex/transformer/_data/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/_data\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n",
            "  copying build/lib/apex/transformer/pipeline_parallel/utils.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n",
            "  copying build/lib/apex/transformer/pipeline_parallel/p2p_communication.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n",
            "  copying build/lib/apex/transformer/pipeline_parallel/_timers.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n",
            "  copying build/lib/apex/transformer/pipeline_parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib/apex/transformer/pipeline_parallel/schedules/common.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib/apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib/apex/transformer/pipeline_parallel/schedules/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/transformer/amp\n",
            "  copying build/lib/apex/transformer/amp/grad_scaler.py -> build/bdist.linux-x86_64/wheel/apex/transformer/amp\n",
            "  copying build/lib/apex/transformer/amp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/amp\n",
            "  copying build/lib/apex/transformer/log_util.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n",
            "  copying build/lib/apex/transformer/parallel_state.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n",
            "  copying build/lib/apex/__init__.py -> build/bdist.linux-x86_64/wheel/apex\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/mlp\n",
            "  copying build/lib/apex/mlp/mlp.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n",
            "  copying build/lib/apex/mlp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/utils.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/amp.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/frontend.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/__version__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/scaler.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/wrap.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/_initialize.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/opt.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/handle.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_mixed_precision_lamb.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/fused_dense\n",
            "  copying build/lib/apex/fused_dense/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fused_dense\n",
            "  copying build/lib/apex/fused_dense/fused_dense.py -> build/bdist.linux-x86_64/wheel/apex/fused_dense\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  copying build/lib/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  copying build/lib/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  copying build/lib/apex/normalization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  copying build/lib/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  creating apex.egg-info\n",
            "  writing apex.egg-info/PKG-INFO\n",
            "  writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "  writing top-level names to apex.egg-info/top_level.txt\n",
            "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "  Copying apex.egg-info to build/bdist.linux-x86_64/wheel/apex-0.1-py3.7.egg-info\n",
            "  running install_scripts\n",
            "  adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n",
            "  creating build/bdist.linux-x86_64/wheel/apex-0.1.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-951y9t0d/apex-0.1-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'apex/__init__.py'\n",
            "  adding 'apex/_autocast_utils.py'\n",
            "  adding 'apex/RNN/RNNBackend.py'\n",
            "  adding 'apex/RNN/__init__.py'\n",
            "  adding 'apex/RNN/cells.py'\n",
            "  adding 'apex/RNN/models.py'\n",
            "  adding 'apex/amp/__init__.py'\n",
            "  adding 'apex/amp/__version__.py'\n",
            "  adding 'apex/amp/_amp_state.py'\n",
            "  adding 'apex/amp/_initialize.py'\n",
            "  adding 'apex/amp/_process_optimizer.py'\n",
            "  adding 'apex/amp/amp.py'\n",
            "  adding 'apex/amp/compat.py'\n",
            "  adding 'apex/amp/frontend.py'\n",
            "  adding 'apex/amp/handle.py'\n",
            "  adding 'apex/amp/opt.py'\n",
            "  adding 'apex/amp/rnn_compat.py'\n",
            "  adding 'apex/amp/scaler.py'\n",
            "  adding 'apex/amp/utils.py'\n",
            "  adding 'apex/amp/wrap.py'\n",
            "  adding 'apex/amp/lists/__init__.py'\n",
            "  adding 'apex/amp/lists/functional_overrides.py'\n",
            "  adding 'apex/amp/lists/tensor_overrides.py'\n",
            "  adding 'apex/amp/lists/torch_overrides.py'\n",
            "  adding 'apex/contrib/__init__.py'\n",
            "  adding 'apex/contrib/bottleneck/__init__.py'\n",
            "  adding 'apex/contrib/bottleneck/bottleneck.py'\n",
            "  adding 'apex/contrib/bottleneck/bottleneck_module_test.py'\n",
            "  adding 'apex/contrib/bottleneck/halo_exchangers.py'\n",
            "  adding 'apex/contrib/bottleneck/test.py'\n",
            "  adding 'apex/contrib/conv_bias_relu/__init__.py'\n",
            "  adding 'apex/contrib/conv_bias_relu/conv_bias_relu.py'\n",
            "  adding 'apex/contrib/fmha/__init__.py'\n",
            "  adding 'apex/contrib/fmha/fmha.py'\n",
            "  adding 'apex/contrib/focal_loss/__init__.py'\n",
            "  adding 'apex/contrib/focal_loss/focal_loss.py'\n",
            "  adding 'apex/contrib/groupbn/__init__.py'\n",
            "  adding 'apex/contrib/groupbn/batch_norm.py'\n",
            "  adding 'apex/contrib/layer_norm/__init__.py'\n",
            "  adding 'apex/contrib/layer_norm/layer_norm.py'\n",
            "  adding 'apex/contrib/multihead_attn/__init__.py'\n",
            "  adding 'apex/contrib/multihead_attn/encdec_multihead_attn.py'\n",
            "  adding 'apex/contrib/multihead_attn/encdec_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/mask_softmax_dropout_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/self_multihead_attn.py'\n",
            "  adding 'apex/contrib/multihead_attn/self_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/optimizers/__init__.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_adam.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_adam_v2.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_adam_v3.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_lamb.py'\n",
            "  adding 'apex/contrib/optimizers/fp16_optimizer.py'\n",
            "  adding 'apex/contrib/optimizers/fused_adam.py'\n",
            "  adding 'apex/contrib/optimizers/fused_lamb.py'\n",
            "  adding 'apex/contrib/optimizers/fused_sgd.py'\n",
            "  adding 'apex/contrib/peer_memory/__init__.py'\n",
            "  adding 'apex/contrib/peer_memory/peer_halo_exchange_module_tests.py'\n",
            "  adding 'apex/contrib/peer_memory/peer_halo_exchanger_1d.py'\n",
            "  adding 'apex/contrib/peer_memory/peer_memory.py'\n",
            "  adding 'apex/contrib/sparsity/__init__.py'\n",
            "  adding 'apex/contrib/sparsity/asp.py'\n",
            "  adding 'apex/contrib/sparsity/permutation_lib.py'\n",
            "  adding 'apex/contrib/sparsity/sparse_masklib.py'\n",
            "  adding 'apex/contrib/sparsity/permutation_search_kernels/__init__.py'\n",
            "  adding 'apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py'\n",
            "  adding 'apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py'\n",
            "  adding 'apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py'\n",
            "  adding 'apex/contrib/transducer/__init__.py'\n",
            "  adding 'apex/contrib/transducer/transducer.py'\n",
            "  adding 'apex/contrib/xentropy/__init__.py'\n",
            "  adding 'apex/contrib/xentropy/softmax_xentropy.py'\n",
            "  adding 'apex/fp16_utils/__init__.py'\n",
            "  adding 'apex/fp16_utils/fp16_optimizer.py'\n",
            "  adding 'apex/fp16_utils/fp16util.py'\n",
            "  adding 'apex/fp16_utils/loss_scaler.py'\n",
            "  adding 'apex/fused_dense/__init__.py'\n",
            "  adding 'apex/fused_dense/fused_dense.py'\n",
            "  adding 'apex/mlp/__init__.py'\n",
            "  adding 'apex/mlp/mlp.py'\n",
            "  adding 'apex/multi_tensor_apply/__init__.py'\n",
            "  adding 'apex/multi_tensor_apply/multi_tensor_apply.py'\n",
            "  adding 'apex/normalization/__init__.py'\n",
            "  adding 'apex/normalization/fused_layer_norm.py'\n",
            "  adding 'apex/optimizers/__init__.py'\n",
            "  adding 'apex/optimizers/fused_adagrad.py'\n",
            "  adding 'apex/optimizers/fused_adam.py'\n",
            "  adding 'apex/optimizers/fused_lamb.py'\n",
            "  adding 'apex/optimizers/fused_mixed_precision_lamb.py'\n",
            "  adding 'apex/optimizers/fused_novograd.py'\n",
            "  adding 'apex/optimizers/fused_sgd.py'\n",
            "  adding 'apex/parallel/LARC.py'\n",
            "  adding 'apex/parallel/__init__.py'\n",
            "  adding 'apex/parallel/distributed.py'\n",
            "  adding 'apex/parallel/multiproc.py'\n",
            "  adding 'apex/parallel/optimized_sync_batchnorm.py'\n",
            "  adding 'apex/parallel/optimized_sync_batchnorm_kernel.py'\n",
            "  adding 'apex/parallel/sync_batchnorm.py'\n",
            "  adding 'apex/parallel/sync_batchnorm_kernel.py'\n",
            "  adding 'apex/pyprof/__init__.py'\n",
            "  adding 'apex/pyprof/nvtx/__init__.py'\n",
            "  adding 'apex/pyprof/nvtx/nvmarker.py'\n",
            "  adding 'apex/pyprof/parse/__init__.py'\n",
            "  adding 'apex/pyprof/parse/__main__.py'\n",
            "  adding 'apex/pyprof/parse/db.py'\n",
            "  adding 'apex/pyprof/parse/kernel.py'\n",
            "  adding 'apex/pyprof/parse/nvvp.py'\n",
            "  adding 'apex/pyprof/parse/parse.py'\n",
            "  adding 'apex/pyprof/prof/__init__.py'\n",
            "  adding 'apex/pyprof/prof/__main__.py'\n",
            "  adding 'apex/pyprof/prof/activation.py'\n",
            "  adding 'apex/pyprof/prof/base.py'\n",
            "  adding 'apex/pyprof/prof/blas.py'\n",
            "  adding 'apex/pyprof/prof/conv.py'\n",
            "  adding 'apex/pyprof/prof/convert.py'\n",
            "  adding 'apex/pyprof/prof/data.py'\n",
            "  adding 'apex/pyprof/prof/dropout.py'\n",
            "  adding 'apex/pyprof/prof/embedding.py'\n",
            "  adding 'apex/pyprof/prof/index_slice_join_mutate.py'\n",
            "  adding 'apex/pyprof/prof/linear.py'\n",
            "  adding 'apex/pyprof/prof/loss.py'\n",
            "  adding 'apex/pyprof/prof/misc.py'\n",
            "  adding 'apex/pyprof/prof/normalization.py'\n",
            "  adding 'apex/pyprof/prof/optim.py'\n",
            "  adding 'apex/pyprof/prof/output.py'\n",
            "  adding 'apex/pyprof/prof/pointwise.py'\n",
            "  adding 'apex/pyprof/prof/pooling.py'\n",
            "  adding 'apex/pyprof/prof/prof.py'\n",
            "  adding 'apex/pyprof/prof/randomSample.py'\n",
            "  adding 'apex/pyprof/prof/recurrentCell.py'\n",
            "  adding 'apex/pyprof/prof/reduction.py'\n",
            "  adding 'apex/pyprof/prof/softmax.py'\n",
            "  adding 'apex/pyprof/prof/usage.py'\n",
            "  adding 'apex/pyprof/prof/utility.py'\n",
            "  adding 'apex/reparameterization/__init__.py'\n",
            "  adding 'apex/reparameterization/reparameterization.py'\n",
            "  adding 'apex/reparameterization/weight_norm.py'\n",
            "  adding 'apex/transformer/__init__.py'\n",
            "  adding 'apex/transformer/enums.py'\n",
            "  adding 'apex/transformer/log_util.py'\n",
            "  adding 'apex/transformer/microbatches.py'\n",
            "  adding 'apex/transformer/parallel_state.py'\n",
            "  adding 'apex/transformer/utils.py'\n",
            "  adding 'apex/transformer/_data/__init__.py'\n",
            "  adding 'apex/transformer/_data/_batchsampler.py'\n",
            "  adding 'apex/transformer/amp/__init__.py'\n",
            "  adding 'apex/transformer/amp/grad_scaler.py'\n",
            "  adding 'apex/transformer/functional/__init__.py'\n",
            "  adding 'apex/transformer/functional/fused_softmax.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/__init__.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/_timers.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/p2p_communication.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/utils.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/schedules/__init__.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/schedules/common.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py'\n",
            "  adding 'apex/transformer/tensor_parallel/__init__.py'\n",
            "  adding 'apex/transformer/tensor_parallel/cross_entropy.py'\n",
            "  adding 'apex/transformer/tensor_parallel/data.py'\n",
            "  adding 'apex/transformer/tensor_parallel/layers.py'\n",
            "  adding 'apex/transformer/tensor_parallel/mappings.py'\n",
            "  adding 'apex/transformer/tensor_parallel/memory.py'\n",
            "  adding 'apex/transformer/tensor_parallel/random.py'\n",
            "  adding 'apex/transformer/tensor_parallel/utils.py'\n",
            "  adding 'apex/transformer/testing/__init__.py'\n",
            "  adding 'apex/transformer/testing/arguments.py'\n",
            "  adding 'apex/transformer/testing/commons.py'\n",
            "  adding 'apex/transformer/testing/distributed_test_base.py'\n",
            "  adding 'apex/transformer/testing/global_vars.py'\n",
            "  adding 'apex/transformer/testing/standalone_bert.py'\n",
            "  adding 'apex/transformer/testing/standalone_gpt.py'\n",
            "  adding 'apex-0.1.dist-info/LICENSE'\n",
            "  adding 'apex-0.1.dist-info/METADATA'\n",
            "  adding 'apex-0.1.dist-info/WHEEL'\n",
            "  adding 'apex-0.1.dist-info/top_level.txt'\n",
            "  adding 'apex-0.1.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "\u001b[?25hdone\n",
            "  Created wheel for apex: filename=apex-0.1-py3-none-any.whl size=332820 sha256=56192224f8295dca78be0a399a79caeecd92388805019f914bc30d3462fb66f7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gn0ombr3/wheels/02/1d/54/16beaa489b73437cc70f3f4ef0bbaa36f0ac443dd94834df91\n",
            "Successfully built apex\n",
            "Installing collected packages: apex\n",
            "  Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\n",
            "  Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\n",
            "  Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/include/python3.7/apex\n",
            "  sysconfig: /usr/include/python3.7m/apex\n",
            "  Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/bin\n",
            "  sysconfig: /usr/bin\n",
            "  Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local\n",
            "  sysconfig: /usr\n",
            "  Additional context:\n",
            "  user = False\n",
            "  home = None\n",
            "  root = None\n",
            "  prefix = None\n",
            "\n",
            "Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\n",
            "Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\n",
            "Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/include/python3.7/UNKNOWN\n",
            "sysconfig: /usr/include/python3.7m/UNKNOWN\n",
            "Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/bin\n",
            "sysconfig: /usr/bin\n",
            "Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local\n",
            "sysconfig: /usr\n",
            "Additional context:\n",
            "user = False\n",
            "home = None\n",
            "root = None\n",
            "prefix = None\n",
            "Successfully installed apex-0.1\n",
            "Removed build tracker: '/tmp/pip-req-tracker-j55a0_c6'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "id": "PIiHJTLssA2q",
        "outputId": "c5745a5d-6c88-4181-8919-6c3abf08390a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "# pip install cython\n",
        "# cd codegen_sources/model/tools\n",
        "# git clone https://github.com/glample/fastBPE.git\n",
        "\n",
        "# cd fastBPE\n",
        "# g++ -std=c++11 -pthread -O3 fastBPE/main.cc -IfastBPE -o fast\n",
        "# python setup.py install\n",
        "# cd ../../../../\n",
        "\n",
        "mkdir tree-sitter\n",
        "cd tree-sitter\n",
        "git clone https://github.com/tree-sitter/tree-sitter-cpp.git\n",
        "git clone https://github.com/tree-sitter/tree-sitter-java.git\n",
        "git clone https://github.com/tree-sitter/tree-sitter-python.git\n",
        "cd ..\n",
        "\n",
        "cd codegen_sources/test_generation/\n",
        "wget https://github.com/EvoSuite/evosuite/releases/download/v1.1.0/evosuite-1.1.0.jar\n",
        "cd ../..\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAp8GRDp2WJr",
        "outputId": "2ad8292d-3bc3-4413-b688-45ce33144e91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tree-sitter-cpp'...\n",
            "remote: Enumerating objects: 1736, done.\u001b[K\n",
            "remote: Counting objects: 100% (647/647), done.\u001b[K\n",
            "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "remote: Total 1736 (delta 620), reused 586 (delta 586), pack-reused 1089\u001b[K\n",
            "Receiving objects: 100% (1736/1736), 51.47 MiB | 31.02 MiB/s, done.\n",
            "Resolving deltas: 100% (1145/1145), done.\n",
            "Cloning into 'tree-sitter-java'...\n",
            "remote: Enumerating objects: 1798, done.\u001b[K\n",
            "remote: Counting objects: 100% (407/407), done.\u001b[K\n",
            "remote: Compressing objects: 100% (116/116), done.\u001b[K\n",
            "remote: Total 1798 (delta 314), reused 365 (delta 284), pack-reused 1391\u001b[K\n",
            "Receiving objects: 100% (1798/1798), 14.03 MiB | 14.80 MiB/s, done.\n",
            "Resolving deltas: 100% (1103/1103), done.\n",
            "Cloning into 'tree-sitter-python'...\n",
            "remote: Enumerating objects: 2502, done.\u001b[K\n",
            "remote: Counting objects: 100% (246/246), done.\u001b[K\n",
            "remote: Compressing objects: 100% (105/105), done.\u001b[K\n",
            "remote: Total 2502 (delta 139), reused 234 (delta 132), pack-reused 2256\u001b[K\n",
            "Receiving objects: 100% (2502/2502), 18.95 MiB | 22.59 MiB/s, done.\n",
            "Resolving deltas: 100% (1568/1568), done.\n",
            "--2022-04-26 15:00:01--  https://github.com/EvoSuite/evosuite/releases/download/v1.1.0/evosuite-1.1.0.jar\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/42201162/0830de00-0a6f-11eb-84a5-e00e5712c755?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220426%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220426T150001Z&X-Amz-Expires=300&X-Amz-Signature=265e579cc76763bf5e7cc80b866c19e267ad6a945e42adec2d590c6ac66c60f6&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=42201162&response-content-disposition=attachment%3B%20filename%3Devosuite-1.1.0.jar&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-04-26 15:00:01--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/42201162/0830de00-0a6f-11eb-84a5-e00e5712c755?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220426%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220426T150001Z&X-Amz-Expires=300&X-Amz-Signature=265e579cc76763bf5e7cc80b866c19e267ad6a945e42adec2d590c6ac66c60f6&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=42201162&response-content-disposition=attachment%3B%20filename%3Devosuite-1.1.0.jar&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17832709 (17M) [application/octet-stream]\n",
            "Saving to: ‘evosuite-1.1.0.jar’\n",
            "\n",
            "evosuite-1.1.0.jar  100%[===================>]  17.01M   112MB/s    in 0.2s    \n",
            "\n",
            "2022-04-26 15:00:01 (112 MB/s) - ‘evosuite-1.1.0.jar’ saved [17832709/17832709]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install sacrebleu==\"1.2.11\" javalang tree_sitter psutil fastBPE\n",
        "%pip install hydra-core --upgrade --pre\n",
        "%pip install black==19.10b0"
      ],
      "metadata": {
        "id": "sU4xNT6D1U45",
        "outputId": "7df9b5d2-c8fb-474b-a58b-af5b06426f04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacrebleu==1.2.11\n",
            "  Downloading sacrebleu-1.2.11.tar.gz (22 kB)\n",
            "Collecting javalang\n",
            "  Downloading javalang-0.13.0-py3-none-any.whl (22 kB)\n",
            "Collecting tree_sitter\n",
            "  Downloading tree_sitter-0.20.0.tar.gz (116 kB)\n",
            "\u001b[K     |████████████████████████████████| 116 kB 7.5 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Collecting fastBPE\n",
            "  Downloading fastBPE-0.1.0.tar.gz (35 kB)\n",
            "Collecting typing\n",
            "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from javalang) (1.15.0)\n",
            "Building wheels for collected packages: sacrebleu, tree-sitter, fastBPE, typing\n",
            "  Building wheel for sacrebleu (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacrebleu: filename=sacrebleu-1.2.11-py3-none-any.whl size=18639 sha256=78820eb55094691913df842aab7b2bd3ac2d367cec8467c02a4e464edcd3286d\n",
            "  Stored in directory: /root/.cache/pip/wheels/e2/67/3e/e5459f232d19e16b12df98130d7799af72253945c114da1487\n",
            "  Building wheel for tree-sitter (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tree-sitter: filename=tree_sitter-0.20.0-cp37-cp37m-linux_x86_64.whl size=304848 sha256=38210f50fe9caefd80f5b40e3cd0b0f7097fb60e3eb35aae0a547db3ea0a6f5a\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/70/97/43e08c95ce68348303fd3f71adfa96193db8d9cf60a14163e0\n",
            "  Building wheel for fastBPE (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastBPE: filename=fastBPE-0.1.0-cp37-cp37m-linux_x86_64.whl size=483176 sha256=4422e62a8e90865521373a2062d4b72f38691c96e3256cb3b393a6353cf9358e\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/d4/0e/0d317a65f77d3f8049fedd8a2ee0519164cf3e6bd77ef886f1\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26325 sha256=a4420c841932daf45f824fa0a730dfe6b52a47ab6f05a7dbf2362a9d2f751464\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/f3/15/01aa6571f0a72ee6ae7b827c1491c37a1f72d686fd22b43b0e\n",
            "Successfully built sacrebleu tree-sitter fastBPE typing\n",
            "Installing collected packages: typing, tree-sitter, sacrebleu, javalang, fastBPE\n",
            "Successfully installed fastBPE-0.1.0 javalang-0.13.0 sacrebleu-1.2.11 tree-sitter-0.20.0 typing-3.7.4.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hydra-core\n",
            "  Downloading hydra_core-1.2.0.dev5-py3-none-any.whl (150 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▏                             | 10 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 20 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 30 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 40 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 61 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 81 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 92 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 150 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 64.2 MB/s \n",
            "\u001b[?25hCollecting omegaconf~=2.1\n",
            "  Downloading omegaconf-2.2.0.dev2-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from hydra-core) (21.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core) (5.7.1)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf~=2.1->hydra-core) (6.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->hydra-core) (3.0.8)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=ec54f1786e8c68f944e7786f02630952ecb258000eafbd57e76e5fbeaef45699\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, omegaconf, hydra-core\n",
            "Successfully installed antlr4-python3-runtime-4.8 hydra-core-1.2.0.dev5 omegaconf-2.2.0.dev2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting black==19.10b0\n",
            "  Downloading black-19.10b0-py36-none-any.whl (97 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 19.9 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 20 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 30 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 40 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 51 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 81 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 92 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 97 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting toml>=0.9.4\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting pathspec<1,>=0.6\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting typed-ast>=1.4.0\n",
            "  Downloading typed_ast-1.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "\u001b[K     |████████████████████████████████| 843 kB 35.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=6.5 in /usr/local/lib/python3.7/dist-packages (from black==19.10b0) (7.1.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from black==19.10b0) (2019.12.20)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from black==19.10b0) (21.4.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==19.10b0) (1.4.4)\n",
            "Installing collected packages: typed-ast, toml, pathspec, black\n",
            "Successfully installed black-19.10b0 pathspec-0.9.0 toml-0.10.2 typed-ast-1.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUL_IFxeA3L7",
        "outputId": "3cd2d3c9-5b66-4eb6-ba5a-1b06454da750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/gdrive/MyDrive/RSS/Data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-dGMK1NA3R8",
        "outputId": "e6038852-99fe-4f5f-cdbd-d253fe2c993c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "algorithms.csv\tcode.csv\t  code-small.csv  func-rep-small.csv\n",
            "code-all.csv\tcode-func-rep.pt  equations.csv   func-rep-small.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Data Handling and Plotting\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Fp5ZVxhXAe_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eqns = pd.read_csv(\"/content/gdrive/MyDrive/RSS/Data/equations.csv\")\n",
        "algs = pd.read_csv(\"/content/gdrive/MyDrive/RSS/Data/algorithms.csv\")\n",
        "code = pd.read_csv(\"/content/gdrive/MyDrive/RSS/Data/code.csv\")"
      ],
      "metadata": {
        "id": "UQe_7U9zmPKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo_c = code.iloc[1]['code']"
      ],
      "metadata": {
        "id": "vGiDynIxAh9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo_c"
      ],
      "metadata": {
        "id": "ZKmVRckn5S9K",
        "outputId": "5c9e6b7d-9631-4983-da06-bf44a51cf336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import pdb\\nimport decimal\\nfrom torch.autograd import Variable\\n\\ndef check_config_used(config, target_source):\\n    config_count = dict(vars(config))\\n    #Initialize each key have zero value\\n    for k in config_count.keys():\\n        config_count[k] = 0\\n\\n    for source in target_source:\\n        fp = open(source, \\'r\\')\\n        text = fp.read()\\n        for k in config_count.keys():\\n            if(text.find(k) >= 0):\\n                config_count[k] = 1\\n        fp.close()\\n\\n    config_unused = []\\n\\n    #Check whether unused config exists\\n    for k in config_count.keys():\\n        if(config_count[k] == 0):\\n            config_unused.append(k)\\n\\n    print(\\'unused config = \\')\\n    print(config_unused)\\n    assert(len(config_unused) == 0), \\'unused config exists, please properly use it or comment it\\'\\n\\n\\ndef to_np(x):\\n    return x.data.cpu().numpy()\\n\\n\\nclass AverageMeter(object):\\n    \"\"\"Computes and stores the average and current value\"\"\"\\n\\n    def __init__(self):\\n        self.reset()\\n\\n    def reset(self):\\n        self.val = 0\\n        self.avg = 0\\n        self.sum = 0\\n        self.count = 0\\n\\n    def update(self, val, n=1):\\n        self.val = val\\n        self.sum += val * n\\n        self.count += n\\n        self.avg = self.sum / self.count\\n\\n\\ndef get_weight_statistic(M):\\n    print(\\'Model parameter statistic\\')\\n    #pdb.set_trace()\\n    modules = list(M.modules())[0]._modules\\n    for k,v in modules.items():\\n        #print(k)\\n        #print(type(v))\\n        #pdb.set_trace()\\n        if(len(v.state_dict())>2):\\n            for l in range(len(v)):\\n                layer = v[l]\\n                #print(\\'layer = \\'); print(layer); print(\\' \\')\\n                if(hasattr(layer, \\'module\\')):\\n                    layer_m = layer.module\\n                    for j in range(len(layer_m)):\\n                        sublayer = layer_m[j]\\n                        if(hasattr(sublayer, \\'bias\\')):\\n                            #pdb.set_trace()\\n                            if(sublayer.bias is not None):\\n                                print(str(sublayer) + \\' : weight = \\' + str(sublayer.weight.data.min())[:5] + \\' ~ \\' + str(sublayer.weight.data.max())[:5] + \\' (\\' + str(decimal.Decimal(sublayer.weight.data.mean()))[:7] + \\')\\'\\n                                \\', bias = \\' + str(sublayer.bias.data.min())[:5] + \\' ~ \\' + str(sublayer.bias.data.max())[:5] + \\' (\\' + str(decimal.Decimal(sublayer.bias.data.mean()))[:7] + \\')\\' )\\n                            else:\\n                                print(str(sublayer) + \\' : weight = \\' + str(sublayer.weight.data.min())[:5] + \\' ~ \\' + str(sublayer.weight.data.max())[:5] + \\' (\\' + str(\\n                                    decimal.Decimal(sublayer.weight.data.mean()))[:7] + \\')\\')\\n                        else:\\n                            print(str(sublayer) + \\' : weight = \\' + str(sublayer.weight.data.min())[:5] + \\' ~ \\' + str(sublayer.weight.data.max())[:5] + \\' (\\' + str(decimal.Decimal(sublayer.weight.data.mean()))[:7] + \\')\\' )\\n                else:\\n                    if(hasattr(layer, \\'weight\\')):\\n                        if(hasattr(layer, \\'bias\\')):\\n                            if(hasattr(layer.bias, \\'data\\')):\\n                                #pdb.set_trace()\\n                                print(str(layer) + \\' : weight = \\' + str(layer.weight.data.min())[:5] + \\' ~ \\' + str(layer.weight.data.max())[:5] + \\' (\\' + str(decimal.Decimal(layer.weight.data.mean()))[:7] + \\')\\'\\n                                \\', bias = \\' + str(layer.bias.data.min())[:5] + \\' ~ \\' + str(layer.bias.data.max())[:5] + \\' (\\' + str(decimal.Decimal(layer.bias.data.mean()))[:7] + \\')\\' )\\n                        else:\\n                            print(str(layer) + \\' : weight = \\' + str(layer.weight.data.min())[:5] + \\' ~ \\' + str(layer.weight.data.max())[:5] + \\' (\\' + str(decimal.Decimal(layer.weight.data.mean()))[:7] + \\')\\' )\\n                    if(hasattr(layer, \\'rnn\\')):\\n                        #pdb.set_trace()\\n                        rnn_layer = layer.rnn\\n                        print(str(rnn_layer))\\n                        print(\\'\\\\tweight_hh_l0 = \\' + str(rnn_layer.weight_hh_l0.data.min())[:5] + \\' ~ \\' + str(\\n                            rnn_layer.weight_hh_l0.data.max())[:5] + \\' (\\' + str(decimal.Decimal(rnn_layer.weight_hh_l0.data.mean()))[:7] + \\')\\')\\n                        print(\\'\\\\tweight_hh_l0_reverse = \\' + str(rnn_layer.weight_hh_l0_reverse.data.min())[:5] + \\' ~ \\' + str(\\n                            rnn_layer.weight_hh_l0_reverse.data.max())[:5] + \\' (\\' + str(decimal.Decimal(rnn_layer.weight_hh_l0_reverse.data.mean()))[:7] + \\')\\')\\n                        print(\\'\\\\tweight_ih_l0 = \\' + str(rnn_layer.weight_ih_l0.data.min())[:5] + \\' ~ \\' + str(\\n                            rnn_layer.weight_ih_l0.data.max())[:5] + \\' (\\' + str(decimal.Decimal(rnn_layer.weight_ih_l0.data.mean()))[:7] + \\')\\')\\n                        print(\\'\\\\tweight_hh_l0_reverse = \\' + str(rnn_layer.weight_hh_l0_reverse.data.min())[:5] + \\' ~ \\' + str(\\n                            rnn_layer.weight_hh_l0_reverse.data.max())[:5] + \\' (\\' + str(decimal.Decimal(rnn_layer.weight_hh_l0_reverse.data.mean()))[:7] + \\')\\')\\n\\n                    if(hasattr(layer, \\'batch_norm\\')):\\n                        if(layer.batch_norm):\\n                            bn_layer = layer.batch_norm.module\\n                            print(str(bn_layer) + \\' : weight = \\' + str(bn_layer.weight.data.min())[:5] + \\' ~ \\' + str(bn_layer.weight.data.max())[:5] + \\' (\\' + str(decimal.Decimal(bn_layer.weight.data.mean()))[:7] +\\n                                  \\'), bias = \\' + str(bn_layer.bias.data.min())[:5] + \\' ~ \\' + str(bn_layer.bias.data.max())[:5] + \\' (\\' + str(decimal.Decimal(bn_layer.bias.data.mean()))[:7] + \\')\\')\\n\\n\\n\\n        else:\\n            if(hasattr(v, \\'weight\\')):\\n                if(hasattr(v, \\'bias\\')):\\n                    print(k + \\' : weight = \\' + str(v.weight.data.min())[:5] + \\' ~ \\' + str(v.weight.data.max())[:5] + \\' (\\' + str(decimal.Decimal(v.weight.data.mean()))[:7] + \\')\\'\\n                  \\', bias = \\' + str(v.bias.data.min())[:5] + \\' ~ \\' + str(v.bias.data.max())[:5] + \\' (\\' + str(decimal.Decimal(v.bias.data.mean()))[:7] + \\')\\' )\\n                else:\\n                    print(k + \\' : weight = \\' + str(v.weight.data.min())[:5] + \\' ~ \\' + str(v.weight.data.max())[:5] + \\' (\\' + str(decimal.Decimal(v.weight.data.mean()))[:7] + \\')\\' )\\n        print(\\' \\')\\n        print(\\' \\')\\n\\n\\ndef weights_init(m):\\n    classname = m.__class__.__name__\\n    if classname.find(\\'Conv\\') != -1 and classname.find(\\'ConvResidualBlock\\') == -1:\\n        #m.weight.data.normal_(0.0, 0.01)\\n        #m.weight.data.normal_(0.0, 0.0001)\\n        m.weight.data.normal_(0.0, 0.1)\\n        if hasattr(m, \\'bias\\'):\\n            if(hasattr(m.bias, \\'data\\')):\\n                m.bias.data.fill_(0)\\n    elif classname.find(\\'BatchNorm\\') != -1:\\n        m.weight.data.normal_(1.0, 0.01)\\n        m.bias.data.fill_(0)\\n    elif classname.find(\\'Embedding\\') != -1: # added by ken\\n        m.weight.data.normal_(0.0, 0.01)\\n    #elif classname.find(\\'rnn\\')  # no RNN for now\\n\\n\\n\\ndef _get_variable(inputs, cuda=True):\\n    if(cuda):\\n        out = Variable(inputs.cuda())\\n    else:\\n        out = Variable(inputs)\\n    return out\\n\\n\\ndef _get_variable_volatile(inputs, cuda=True):\\n    if(cuda):\\n        out = Variable(inputs.cuda(), volatile=True)\\n    else:\\n        out = Variable(inputs, volatile=True)\\n    return out\\n\\n\\ndef _get_variable_nograd(inputs, cuda=True):\\n    if(cuda):\\n        out = Variable(inputs.cuda(), requires_grad=False)\\n    else:\\n        out = Variable(inputs, requires_grad=False)\\n    return out'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modified translate function to only yield embedding"
      ],
      "metadata": {
        "id": "uScFxLq1j0cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Copyright (c) 2019-present, Facebook, Inc.\n",
        "# All rights reserved.\n",
        "#\n",
        "# This source code is licensed under the license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "#\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import torch\n",
        "from codegen_sources.model.src.logger import create_logger\n",
        "from codegen_sources.preprocessing.lang_processors.cpp_processor import CppProcessor\n",
        "from codegen_sources.preprocessing.lang_processors.java_processor import JavaProcessor\n",
        "from codegen_sources.preprocessing.lang_processors.python_processor import (\n",
        "    PythonProcessor,\n",
        ")\n",
        "from codegen_sources.preprocessing.lang_processors.lang_processor import LangProcessor\n",
        "from codegen_sources.preprocessing.bpe_modes.fast_bpe_mode import FastBPEMode\n",
        "from codegen_sources.preprocessing.bpe_modes.roberta_bpe_mode import RobertaBPEMode\n",
        "from codegen_sources.model.src.data.dictionary import (\n",
        "    Dictionary,\n",
        "    BOS_WORD,\n",
        "    EOS_WORD,\n",
        "    PAD_WORD,\n",
        "    UNK_WORD,\n",
        "    MASK_WORD,\n",
        ")\n",
        "from codegen_sources.model.src.utils import restore_roberta_segmentation_sentence\n",
        "from codegen_sources.model.src.model import build_model\n",
        "from codegen_sources.model.src.utils import AttrDict, TREE_SITTER_ROOT\n",
        "\n",
        "SUPPORTED_LANGUAGES = [\"cpp\", \"java\", \"python\"]\n",
        "\n",
        "logger = create_logger(None, 0)\n",
        "\n",
        "\n",
        "\n",
        "class Translator:\n",
        "    def __init__(self, model_path, BPE_path):\n",
        "        # reload model\n",
        "        reloaded = torch.load(model_path, map_location=\"cpu\")\n",
        "        # change params of the reloaded model so that it will\n",
        "        # relaod its own weights and not the MLM or DOBF pretrained model\n",
        "        reloaded[\"params\"][\"reload_model\"] = \",\".join([model_path] * 2)\n",
        "        reloaded[\"params\"][\"lgs_mapping\"] = \"\"\n",
        "        reloaded[\"params\"][\"reload_encoder_for_decoder\"] = False\n",
        "        self.reloaded_params = AttrDict(reloaded[\"params\"])\n",
        "\n",
        "        # build dictionary / update parameters\n",
        "        self.dico = Dictionary(\n",
        "            reloaded[\"dico_id2word\"], reloaded[\"dico_word2id\"], reloaded[\"dico_counts\"]\n",
        "        )\n",
        "        assert self.reloaded_params.n_words == len(self.dico)\n",
        "        assert self.reloaded_params.bos_index == self.dico.index(BOS_WORD)\n",
        "        assert self.reloaded_params.eos_index == self.dico.index(EOS_WORD)\n",
        "        assert self.reloaded_params.pad_index == self.dico.index(PAD_WORD)\n",
        "        assert self.reloaded_params.unk_index == self.dico.index(UNK_WORD)\n",
        "        assert self.reloaded_params.mask_index == self.dico.index(MASK_WORD)\n",
        "\n",
        "        # build model / reload weights (in the build_model method)\n",
        "        encoder, decoder = build_model(self.reloaded_params, self.dico)\n",
        "        self.encoder = encoder[0]\n",
        "        # self.decoder = decoder[0]\n",
        "        self.encoder.cuda()\n",
        "        # self.decoder.cuda()\n",
        "        self.encoder.eval()\n",
        "        # self.decoder.eval()\n",
        "\n",
        "        # reload bpe\n",
        "        if getattr(self.reloaded_params, \"roberta_mode\", False):\n",
        "            self.bpe_model = RobertaBPEMode()\n",
        "        else:\n",
        "            self.bpe_model = FastBPEMode(\n",
        "                codes=os.path.abspath(BPE_path), vocab_path=None\n",
        "            )\n",
        "\n",
        "    def translate(\n",
        "        self,\n",
        "        input_code,\n",
        "        lang1,\n",
        "        suffix1=\"_sa\",\n",
        "        suffix2=\"_sa\",\n",
        "        n=1,\n",
        "        sample_temperature=None,\n",
        "        device=\"cuda:0\",\n",
        "        tokenized=False,\n",
        "        detokenize=True,\n",
        "        max_tokens=1024,\n",
        "        length_penalty=0.5,\n",
        "        max_len=None,\n",
        "    ):\n",
        "\n",
        "        # Build language processors\n",
        "        assert lang1 in SUPPORTED_LANGUAGES, lang1\n",
        "        src_lang_processor = LangProcessor.processors[lang1](\n",
        "            root_folder=TREE_SITTER_ROOT\n",
        "        )\n",
        "        tokenizer = src_lang_processor.tokenize_code\n",
        "\n",
        "\n",
        "        lang1 += suffix1\n",
        "\n",
        "        assert (\n",
        "            lang1 in self.reloaded_params.lang2id.keys()\n",
        "        ), f\"{lang1} should be in {self.reloaded_params.lang2id.keys()}\"\n",
        "\n",
        "        with torch.no_grad():\n",
        "            lang1_id = self.reloaded_params.lang2id[lang1]\n",
        "            # lang2_id = self.reloaded_params.lang2id[lang2]\n",
        "\n",
        "            # Convert source code to ids\n",
        "            if tokenized:\n",
        "                tokens = input_code.strip().split()\n",
        "            else:\n",
        "                tokens = [t for t in tokenizer(input_code)]\n",
        "            \n",
        "            \n",
        "            \n",
        "\n",
        "            #print(f\"Tokenized {lang1} function:\")\n",
        "            #print(tokens)\n",
        "            tokens = self.bpe_model.apply_bpe(\" \".join(tokens)).split()\n",
        "            tokens = [\"</s>\"] + tokens + [\"</s>\"]\n",
        "            \n",
        "            #### MODIFIED HERE --> Use the first part of functions that are too long\n",
        "            ##\n",
        "            if len(tokens) > 1024:\n",
        "                tokens = tokens[:1024]\n",
        "            input_code = \" \".join(tokens)\n",
        "            if max_tokens is not None and len(input_code.split()) > max_tokens:\n",
        "                logger.info(\n",
        "                    f\"Ignoring long input sentence of size {len(input_code.split())}\"\n",
        "                )\n",
        "                print(\"Input is too long...\")\n",
        "                return None\n",
        "\n",
        "            # Create torch batch\n",
        "            len1 = len(input_code.split())\n",
        "            len1 = torch.LongTensor(1).fill_(len1).to(device)\n",
        "            x1 = torch.LongTensor([self.dico.index(w) for w in input_code.split()]).to(\n",
        "                device\n",
        "            )[:, None]\n",
        "            langs1 = x1.clone().fill_(lang1_id)\n",
        "\n",
        "            # Encode\n",
        "            enc1 = self.encoder(\"fwd\", x=x1, lengths=len1, langs=langs1, causal=False)\n",
        "            enc1 = enc1.transpose(0, 1)\n",
        "            if n > 1:\n",
        "                enc1 = enc1.repeat(n, 1, 1)\n",
        "                len1 = len1.expand(n)\n",
        "\n",
        "\n",
        "            return enc1, len1.item()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YxKr48w07b_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9acad12-16a9-4775-d2f5-569c83cc535f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adding to path /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "1Qe5gSbsL4hG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our class for splitting code and embedding it using the encoder as a pretrained model from transCoder."
      ],
      "metadata": {
        "id": "A5dt0T-jkCDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from logging import root\n",
        "from codegen_sources.preprocessing.lang_processors.python_processor import PythonProcessor\n",
        "\n",
        "class TextEncoder:\n",
        "\n",
        "  def __init__(self,\n",
        "               model_path = '/content/gdrive/MyDrive/RSS/Models/translator_transcoder_size_from_DOBF.pth', \n",
        "               BPE_path = '/content/gdrive/MyDrive/RSS/Models/', \n",
        "               parse_tree_root = \"./tree-sitter-python\"):\n",
        "\n",
        "      self.p_processor = PythonProcessor(root_folder=parse_tree_root)\n",
        "      self.translator = Translator(model_path, BPE_path)\n",
        "  \n",
        "  def get_functions(self, code):\n",
        "      tokenized_code = self.p_processor.tokenize_code(code)\n",
        "      functions = self.p_processor.extract_functions(tokenized_code)\n",
        "      return functions[0] + functions[1]\n",
        "\n",
        "  def process_text(self, base_code):\n",
        "      # start = time.time()\n",
        "      functions = self.get_functions(base_code)\n",
        "      second = time.time()\n",
        "      # print(second-start)\n",
        "      results = []\n",
        "      for index,func in enumerate(functions):\n",
        "          with torch.no_grad():            \n",
        "              output = self.translator.translate(func,lang1='python')\n",
        "          if output is None:\n",
        "              print(f\"Encoding at function index {index} failed.\")\n",
        "          else:\n",
        "              results.append(output[0].mean(dim=1).detach().cpu())\n",
        "      # print(time.time()-second)\n",
        "      return functions, results\n"
      ],
      "metadata": {
        "id": "X8EErEK73nUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "encoder = TextEncoder()\n",
        "i = 1\n",
        "times = []\n",
        "for row in code.iterrows():\n",
        "    start = time.time()\n",
        "    id = row[1]['id']\n",
        "    try:\n",
        "        print('Processing code', i)\n",
        "        c = row[1]['code']\n",
        "        res = encoder.process_text(c)\n",
        "        datapt = [id, res[0], res[1]]\n",
        "        data.append(datapt)\n",
        "    except:\n",
        "        print('Failed on', id)\n",
        "    i += 1\n",
        "    times.append(time.time()-start)\n",
        "    if i == 200:\n",
        "      break"
      ],
      "metadata": {
        "id": "m49zKreDNVpB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92ffe398-29f0-4a6b-c731-60645202fe7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - 04/26/22 15:11:20 - 0:09:41 - ============ Model Reloading\n",
            "INFO - 04/26/22 15:11:20 - 0:09:41 - Reloading encoder from /content/gdrive/MyDrive/RSS/Models/translator_transcoder_size_from_DOBF.pth ...\n",
            "WARNING - 04/26/22 15:11:22 - 0:09:43 - Lang cpp_sa matched to pretrained cpp_sa lang embedding.\n",
            "WARNING - 04/26/22 15:11:22 - 0:09:43 - Lang java_sa matched to pretrained java_sa lang embedding.\n",
            "WARNING - 04/26/22 15:11:22 - 0:09:43 - Lang python_sa matched to pretrained python_sa lang embedding.\n",
            "INFO - 04/26/22 15:11:22 - 0:09:43 - Reloading decoders from /content/gdrive/MyDrive/RSS/Models/translator_transcoder_size_from_DOBF.pth ...\n",
            "WARNING - 04/26/22 15:11:24 - 0:09:46 - Lang cpp_sa matched to pretrained cpp_sa lang embedding.\n",
            "WARNING - 04/26/22 15:11:24 - 0:09:46 - Lang java_sa matched to pretrained java_sa lang embedding.\n",
            "WARNING - 04/26/22 15:11:24 - 0:09:46 - Lang python_sa matched to pretrained python_sa lang embedding.\n",
            "INFO - 04/26/22 15:11:24 - 0:09:46 - Number of parameters (encoder): 143279616\n",
            "INFO - 04/26/22 15:11:24 - 0:09:46 - Number of parameters (decoders): 168482304\n",
            "INFO - 04/26/22 15:11:24 - 0:09:46 - Number of decoders: 1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing code 1\n",
            "0.010053634643554688\n",
            "0.05098843574523926\n",
            "Processing code 2\n",
            "0.024817466735839844\n",
            "0.17630362510681152\n",
            "Processing code 3\n",
            "0.012145757675170898\n",
            "0.07665824890136719\n",
            "Processing code 4\n",
            "0.025154590606689453\n",
            "0.20233750343322754\n",
            "Processing code 5\n",
            "0.03563523292541504\n",
            "0.2286548614501953\n",
            "Processing code 6\n",
            "0.027796030044555664\n",
            "0.2080059051513672\n",
            "Processing code 7\n",
            "0.009528875350952148\n",
            "0.18248486518859863\n",
            "Processing code 8\n",
            "0.04576683044433594\n",
            "0.56313157081604\n",
            "Processing code 9\n",
            "0.043760061264038086\n",
            "0.24843382835388184\n",
            "Processing code 10\n",
            "0.030311107635498047\n",
            "0.03512167930603027\n",
            "Processing code 11\n",
            "0.002378702163696289\n",
            "5.245208740234375e-05\n",
            "Processing code 12\n",
            "0.013867616653442383\n",
            "0.015070438385009766\n",
            "Processing code 13\n",
            "0.034552574157714844\n",
            "0.20344161987304688\n",
            "Processing code 14\n",
            "0.049897193908691406\n",
            "0.05775332450866699\n",
            "Processing code 15\n",
            "0.014428853988647461\n",
            "0.16242361068725586\n",
            "Processing code 16\n",
            "0.04957008361816406\n",
            "0.010039567947387695\n",
            "Processing code 17\n",
            "0.052684783935546875\n",
            "0.014431953430175781\n",
            "Processing code 18\n",
            "0.13896965980529785\n",
            "0.9438326358795166\n",
            "Processing code 19\n",
            "0.004201412200927734\n",
            "9.703636169433594e-05\n",
            "Processing code 20\n",
            "0.0026586055755615234\n",
            "0.00010275840759277344\n",
            "Processing code 21\n",
            "0.0065844058990478516\n",
            "0.00010180473327636719\n",
            "Processing code 22\n",
            "0.004882097244262695\n",
            "9.107589721679688e-05\n",
            "Processing code 23\n",
            "0.03059220314025879\n",
            "0.14820122718811035\n",
            "Processing code 24\n",
            "0.003499746322631836\n",
            "8.797645568847656e-05\n",
            "Processing code 25\n",
            "0.029916048049926758\n",
            "0.24975156784057617\n",
            "Processing code 26\n",
            "0.04028034210205078\n",
            "0.0009772777557373047\n",
            "Processing code 27\n",
            "0.0007779598236083984\n",
            "7.128715515136719e-05\n",
            "Processing code 28\n",
            "0.013434886932373047\n",
            "0.08730196952819824\n",
            "Processing code 29\n",
            "0.12361025810241699\n",
            "0.8388872146606445\n",
            "Processing code 30\n",
            "0.04563546180725098\n",
            "0.5462555885314941\n",
            "Processing code 31\n",
            "0.00115203857421875\n",
            "0.0004444122314453125\n",
            "Processing code 32\n",
            "0.00813436508178711\n",
            "0.09969782829284668\n",
            "Processing code 33\n",
            "0.03816699981689453\n",
            "0.27773284912109375\n",
            "Processing code 34\n",
            "0.0648508071899414\n",
            "0.766923189163208\n",
            "Processing code 35\n",
            "0.0806879997253418\n",
            "0.6793584823608398\n",
            "Processing code 36\n",
            "0.03325176239013672\n",
            "0.76165771484375\n",
            "Processing code 37\n",
            "0.011087894439697266\n",
            "0.04375338554382324\n",
            "Processing code 38\n",
            "0.004941701889038086\n",
            "0.05952191352844238\n",
            "Processing code 39\n",
            "0.006958484649658203\n",
            "0.1340193748474121\n",
            "Processing code 40\n",
            "0.012220621109008789\n",
            "0.12781167030334473\n",
            "Processing code 41\n",
            "0.0025186538696289062\n",
            "0.0007073879241943359\n",
            "Processing code 42\n",
            "0.007706642150878906\n",
            "0.12863659858703613\n",
            "Processing code 43\n",
            "0.0018165111541748047\n",
            "0.04241633415222168\n",
            "Processing code 44\n",
            "0.006175041198730469\n",
            "0.059561729431152344\n",
            "Processing code 45\n",
            "0.005978107452392578\n",
            "0.04159975051879883\n",
            "Processing code 46\n",
            "0.004101276397705078\n",
            "0.09877824783325195\n",
            "Processing code 47\n",
            "0.023533105850219727\n",
            "0.16322875022888184\n",
            "Processing code 48\n",
            "0.00725555419921875\n",
            "0.11316061019897461\n",
            "Processing code 49\n",
            "0.0010840892791748047\n",
            "0.028998136520385742\n",
            "Processing code 50\n",
            "0.025935888290405273\n",
            "0.2199704647064209\n",
            "Processing code 51\n",
            "0.027619361877441406\n",
            "0.5499284267425537\n",
            "Processing code 52\n",
            "0.007308006286621094\n",
            "0.07013201713562012\n",
            "Processing code 53\n",
            "0.009935140609741211\n",
            "6.985664367675781e-05\n",
            "Processing code 54\n",
            "0.007493257522583008\n",
            "0.15837883949279785\n",
            "Processing code 55\n",
            "0.010753870010375977\n",
            "0.10809826850891113\n",
            "Processing code 56\n",
            "0.007708311080932617\n",
            "0.07235455513000488\n",
            "Processing code 57\n",
            "0.011387348175048828\n",
            "0.09137749671936035\n",
            "Processing code 58\n",
            "0.002046823501586914\n",
            "6.151199340820312e-05\n",
            "Processing code 59\n",
            "0.01178598403930664\n",
            "0.06415319442749023\n",
            "Processing code 60\n",
            "0.004086732864379883\n",
            "0.07129240036010742\n",
            "Processing code 61\n",
            "0.007609367370605469\n",
            "5.4836273193359375e-05\n",
            "Processing code 62\n",
            "0.08803319931030273\n",
            "0.11029052734375\n",
            "Processing code 63\n",
            "0.00119781494140625\n",
            "0.014491081237792969\n",
            "Processing code 64\n",
            "0.07233834266662598\n",
            "0.09414911270141602\n",
            "Processing code 65\n",
            "0.007779836654663086\n",
            "0.09996438026428223\n",
            "Processing code 66\n",
            "0.0006792545318603516\n",
            "0.011936187744140625\n",
            "Processing code 67\n",
            "0.05483746528625488\n",
            "0.20284175872802734\n",
            "Processing code 68\n",
            "0.07226848602294922\n",
            "0.2604517936706543\n",
            "Processing code 69\n",
            "0.03013157844543457\n",
            "0.4585690498352051\n",
            "Processing code 70\n",
            "0.031400203704833984\n",
            "0.06451249122619629\n",
            "Processing code 71\n",
            "0.02525949478149414\n",
            "0.22972726821899414\n",
            "Processing code 72\n",
            "0.008170366287231445\n",
            "0.10148000717163086\n",
            "Processing code 73\n",
            "0.06417417526245117\n",
            "0.09042692184448242\n",
            "Processing code 74\n",
            "0.023632287979125977\n",
            "0.08305168151855469\n",
            "Processing code 75\n",
            "0.00402069091796875\n",
            "0.038611412048339844\n",
            "Processing code 76\n",
            "0.008624792098999023\n",
            "0.1032414436340332\n",
            "Processing code 77\n",
            "0.007845878601074219\n",
            "0.08652901649475098\n",
            "Processing code 78\n",
            "0.0015342235565185547\n",
            "0.020613670349121094\n",
            "Processing code 79\n",
            "0.006783485412597656\n",
            "0.06948113441467285\n",
            "Processing code 80\n",
            "0.008051395416259766\n",
            "0.07566380500793457\n",
            "Processing code 81\n",
            "0.00284576416015625\n",
            "0.0358426570892334\n",
            "Processing code 82\n",
            "0.019144058227539062\n",
            "0.042899370193481445\n",
            "Processing code 83\n",
            "0.0011096000671386719\n",
            "0.014950275421142578\n",
            "Processing code 84\n",
            "0.0036084651947021484\n",
            "0.053671836853027344\n",
            "Processing code 85\n",
            "0.0003981590270996094\n",
            "5.2928924560546875e-05\n",
            "Processing code 86\n",
            "0.0017123222351074219\n",
            "0.03195595741271973\n",
            "Processing code 87\n",
            "0.001672506332397461\n",
            "0.02688765525817871\n",
            "Processing code 88\n",
            "0.009101390838623047\n",
            "0.1812293529510498\n",
            "Processing code 89\n",
            "0.0023186206817626953\n",
            "0.03812146186828613\n",
            "Processing code 90\n",
            "0.04897761344909668\n",
            "0.07944893836975098\n",
            "Processing code 91\n",
            "0.010718822479248047\n",
            "0.09228634834289551\n",
            "Processing code 92\n",
            "0.010084867477416992\n",
            "0.07042932510375977\n",
            "Processing code 93\n",
            "0.00244903564453125\n",
            "0.03628659248352051\n",
            "Processing code 94\n",
            "0.03905153274536133\n",
            "0.06850028038024902\n",
            "Processing code 95\n",
            "0.007306337356567383\n",
            "0.07454824447631836\n",
            "Processing code 96\n",
            "0.04772353172302246\n",
            "0.08859968185424805\n",
            "Processing code 97\n",
            "0.0016257762908935547\n",
            "0.0263669490814209\n",
            "Processing code 98\n",
            "0.003114461898803711\n",
            "0.038320064544677734\n",
            "Processing code 99\n",
            "0.0022153854370117188\n",
            "0.027835369110107422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(times).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c75-jZdabGBO",
        "outputId": "1d58f4b1-e046-4c7c-b1de-ffa9a2141142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15854143855547664"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(785*38*.1534)/60"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-F0nXk_y5ZIs",
        "outputId": "bbcc684c-3748-45a0-d39c-d4ea09b768a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76.26536666666668"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "codedf = pd.DataFrame(data, columns=['id', 'functions', 'representations'])\n",
        "codedf.to_pickle('/content/gdrive/MyDrive/RSS/Data/func-rep-small.pt')\n",
        "codedf.head()"
      ],
      "metadata": {
        "id": "a4Zx4ylRRESi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "fb38650c-c92d-47a4-b5a8-a2e6f908aefa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id                                          functions  \\\n",
              "0  1811.02182  [def main ( config ) : NEW_LINE INDENT from da...   \n",
              "1  1811.02182  [def check_config_used ( config , target_sourc...   \n",
              "2  1811.02182  [def __init__ ( self , batch_size , paired = F...   \n",
              "3  1811.02182  [def weights_init ( m ) : NEW_LINE INDENT clas...   \n",
              "4  1811.02182  [def weights_init ( m ) : NEW_LINE INDENT clas...   \n",
              "\n",
              "                                     representations  \n",
              "0  [[[tensor(0.6232), tensor(-0.2805), tensor(0.3...  \n",
              "1  [[[tensor(0.6108), tensor(-0.2560), tensor(0.1...  \n",
              "2  [[[tensor(0.8430), tensor(0.1034), tensor(0.30...  \n",
              "3  [[[tensor(0.6790), tensor(-0.0221), tensor(0.1...  \n",
              "4  [[[tensor(0.6790), tensor(-0.0221), tensor(0.1...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac4074c9-e6fd-41dc-8cc3-2afedc96ad4e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>functions</th>\n",
              "      <th>representations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1811.02182</td>\n",
              "      <td>[def main ( config ) : NEW_LINE INDENT from da...</td>\n",
              "      <td>[[[tensor(0.6232), tensor(-0.2805), tensor(0.3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1811.02182</td>\n",
              "      <td>[def check_config_used ( config , target_sourc...</td>\n",
              "      <td>[[[tensor(0.6108), tensor(-0.2560), tensor(0.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1811.02182</td>\n",
              "      <td>[def __init__ ( self , batch_size , paired = F...</td>\n",
              "      <td>[[[tensor(0.8430), tensor(0.1034), tensor(0.30...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1811.02182</td>\n",
              "      <td>[def weights_init ( m ) : NEW_LINE INDENT clas...</td>\n",
              "      <td>[[[tensor(0.6790), tensor(-0.0221), tensor(0.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1811.02182</td>\n",
              "      <td>[def weights_init ( m ) : NEW_LINE INDENT clas...</td>\n",
              "      <td>[[[tensor(0.6790), tensor(-0.0221), tensor(0.1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac4074c9-e6fd-41dc-8cc3-2afedc96ad4e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ac4074c9-e6fd-41dc-8cc3-2afedc96ad4e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ac4074c9-e6fd-41dc-8cc3-2afedc96ad4e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "codedf.iloc[0].representations[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhHXBhyr5bWu",
        "outputId": "5bff249e-d38f-48b7-e799-0537214f11d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "codedf.to_csv('code-func-rep.csv')\n",
        "files.download('code-func-rep.csv') "
      ],
      "metadata": {
        "id": "aKmr_V8Zp0b-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "fc38857a-aff6-4ad3-fb2a-bc5120fee03a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4bb9efb3-494e-4e77-836b-62272ed215e1\", \"code-func-rep.csv\", 96939)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = TextEncoder()\n",
        "res = encoder.process_text(code.iloc[0]['code'])\n",
        "res[0], res[1]"
      ],
      "metadata": {
        "id": "C3Kp0RUhj6Jb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzYG6YIUN0wY",
        "outputId": "33438cd2-dc3c-4590-89da-907836097079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YSELH3EKiEb",
        "outputId": "d00491df-597e-4528-8726-3ffa899c26fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demo_alg = algs.iloc[10]['alg']"
      ],
      "metadata": {
        "id": "rybkNzDJ6mmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pylatexenc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkX8U_MvOtX4",
        "outputId": "21a4fcf2-f040-4e13-c2a6-48ff857df620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pylatexenc\n",
            "  Downloading pylatexenc-2.10.tar.gz (162 kB)\n",
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 36.7 MB/s eta 0:00:01\r\u001b[K     |████                            | 20 kB 42.8 MB/s eta 0:00:01\r\u001b[K     |██████                          | 30 kB 45.6 MB/s eta 0:00:01\r\u001b[K     |████████                        | 40 kB 34.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 51 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 61 kB 39.8 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 71 kB 30.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 81 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 92 kB 32.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 102 kB 33.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 112 kB 33.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 122 kB 33.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 133 kB 33.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 143 kB 33.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 153 kB 33.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 162 kB 33.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pylatexenc\n",
            "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136835 sha256=bdc314832bc7b072c872a8a8cec310738991c4eee20ee913c04a6f9d5492ea15\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/8a/f5/33ee79d4473eb201b519fa40f989b842e373237395a3421f52\n",
            "Successfully built pylatexenc\n",
            "Installing collected packages: pylatexenc\n",
            "Successfully installed pylatexenc-2.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pylatexenc.latex2text import LatexNodes2Text\n",
        "\n",
        "latex = demo_alg\n",
        "text = LatexNodes2Text().latex_to_text(latex)\n",
        "# import re\n",
        "print(demo_alg)\n",
        "# re.split('[\\s{}]',demo_alg)\n",
        "print(word_tokenize(text))\n",
        "# word_tokenize(demo_alg)\n",
        "\n",
        "# sentences = sent_tokenize(text)\n",
        "# examples = []\n",
        "# for sentence in sentences:\n",
        "#     sentence = \"\".join(char for char in sentence if char not in punctuation)\n",
        "#     sentence = \"\".join(char for char in sentence if not char.isdigit())\n",
        "#     sentence = sentence.lower()\n",
        "#     tokens = word_tokenize(sentence)\n",
        "#     examples.append(tokens)\n",
        "# return examples\n",
        "\n",
        "# tokenize(\"Why, hello there! What's your name?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0HxoIK3MOC6",
        "outputId": "3989acd6-8050-4830-ca31-5d5da59c3b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[t]\n",
            "\\caption{Hypergraph marginalization for HMMs and PCFGs}\n",
            "\\label{fig:marg-hmm-pcfg}\n",
            "\\begin{minipage}[t]{0.45\\textwidth}\n",
            "%\\small\n",
            "\\begin{algorithmic}\n",
            "\\STATE {[\\textit{HMM - Backward}]}\n",
            "\\FOR {$t \\leftarrow (t+1)$ in right-to-left order}\n",
            "\\FOR {$z_{t+1} \\in \\mcL$}\n",
            "\\STATE $[\\beta_{t+1}]_{z_{t+1}} = [\\alpha_{t+1}]_{z_{t+1}}$\n",
            "\\ENDFOR\n",
            "\\STATE $\\alpha_t \\stackrel{+}{\\gets} \\Psi_t \\beta_{t+1}$\n",
            "\\ENDFOR\n",
            "\\STATE \\textbf{return} $\\alpha_0^\\top \\mathbf{1}$\n",
            "\\end{algorithmic}\n",
            "\\end{minipage}\n",
            "\\vspace{0pt}\n",
            "\\begin{minipage}[t]{0.50\\textwidth}\n",
            "%\\small\n",
            "\\begin{algorithmic} \n",
            "\\STATE {[\\textit{PCFG - CKY}]}\n",
            "\\FOR {$(i,k) \\leftarrow (i,j), (j,k)$ in span-size order}\n",
            "\\FOR {$z_1,z_2 \\in \\mcL_{i,j}\\times\\mcL_{j,k}$}\n",
            "\\STATE $[\\beta_{i,j,k}]_{(z_1,z_2)} = [\\alpha_{i,j}]_{z_1}[\\alpha_{j,k}]_{z_2}$\n",
            "\\ENDFOR\n",
            "\\STATE $\\alpha_{i,k} \\stackrel{+}{\\gets} \\Psi\\beta_{i,j,k}$\n",
            "\\ENDFOR\n",
            "\\STATE \\textbf{return} $\\alpha_{1,T}^\\top \\mathbf{1}$\n",
            "\\end{algorithmic}\n",
            "\\end{minipage}\n",
            "\n",
            "['[', 't', ']', 'Hypergraph', 'marginalization', 'for', 'HMMs', 'and', 'PCFGs', '[', 't', ']', '0.45', '[', 'HMM', '-', 'Backward', ']', 't', '←', '(', 't+1', ')', 'in', 'right-to-left', 'order', 'z_t+1∈', '[', 'β_t+1', ']', '_z_t+1', '=', '[', 'α_t+1', ']', '_z_t+1', 'α_t', '+Ψ_t', 'β_t+1', 'return', 'α_0^⊤1', '[', 't', ']', '0.50', '[', 'PCFG', '-', 'CKY', ']', '(', 'i', ',', 'k', ')', '←', '(', 'i', ',', 'j', ')', ',', '(', 'j', ',', 'k', ')', 'in', 'span-size', 'order', 'z_1', ',', 'z_2', '∈_i', ',', 'j×_j', ',', 'k', '[', 'β_i', ',', 'j', ',', 'k', ']', '_', '(', 'z_1', ',', 'z_2', ')', '=', '[', 'α_i', ',', 'j', ']', '_z_1', '[', 'α_j', ',', 'k', ']', '_z_2', 'α_i', ',', 'k+Ψβ_i', ',', 'j', ',', 'k', 'return', 'α_1', ',', 'T^⊤1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uni_toks = {i for i in word_tokenize(text)}"
      ],
      "metadata": {
        "id": "BicmxCyyP2e1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uni_toks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbmF97WkP_Py",
        "outputId": "d80be10c-34ae-418c-fe23-c47e1e175bce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'(',\n",
              " ')',\n",
              " '+Ψ_t',\n",
              " ',',\n",
              " '-',\n",
              " '0.45',\n",
              " '0.50',\n",
              " '=',\n",
              " 'Backward',\n",
              " 'CKY',\n",
              " 'HMM',\n",
              " 'HMMs',\n",
              " 'Hypergraph',\n",
              " 'PCFG',\n",
              " 'PCFGs',\n",
              " 'T^⊤1',\n",
              " '[',\n",
              " ']',\n",
              " '_',\n",
              " '_z_1',\n",
              " '_z_2',\n",
              " '_z_t+1',\n",
              " 'and',\n",
              " 'for',\n",
              " 'i',\n",
              " 'in',\n",
              " 'j',\n",
              " 'j×_j',\n",
              " 'k',\n",
              " 'k+Ψβ_i',\n",
              " 'marginalization',\n",
              " 'order',\n",
              " 'return',\n",
              " 'right-to-left',\n",
              " 'span-size',\n",
              " 't',\n",
              " 't+1',\n",
              " 'z_1',\n",
              " 'z_2',\n",
              " 'z_t+1∈',\n",
              " 'α_0^⊤1',\n",
              " 'α_1',\n",
              " 'α_i',\n",
              " 'α_j',\n",
              " 'α_t',\n",
              " 'α_t+1',\n",
              " 'β_i',\n",
              " 'β_t+1',\n",
              " '←',\n",
              " '∈_i'}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch\n",
        "from transformers import BertTokenizer\n",
        "from transformers import DistilBertTokenizer\n",
        "\n",
        "print(torch.__version__)\n",
        "print(transformers.__version__)\n",
        "\n",
        "# THERE IS A UNICODE character between the , and '' (specifically \\U+200D\\U+200D\\U+200D\\U+200D)\n",
        "sentence = ' '.join(uni_toks)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "# tokenizer = BertTokenizer.from_pretrained(\n",
        "#             \"bert-base-cased\",\n",
        "#             do_lower_case=False,\n",
        "#             use_fast=False\n",
        "#         )\n",
        "\n",
        "print(uni_toks)\n",
        "print(tokenizer.tokenize(sentence))\n",
        "\n",
        "# special_tokens_dict = {'additional_special_tokens': ['\\uf0b7']}\n",
        "# num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "# test_words = ['crazy', 'character', '\\uf0b7']\n",
        "# tokenizer(test_words, is_split_into_words=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyTrapL8Pp2s",
        "outputId": "a914fdbf-1391-4cb6-8a79-c52785e5c949"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n",
            "4.18.0\n",
            "{'-', 'order', 'for', 'α_0^⊤1', 'PCFGs', ',', 'span-size', 'k', '_z_2', 'z_t+1∈', 't', '=', 'j×_j', 'j', 't+1', 'Hypergraph', '∈_i', 'α_i', 'and', 'CKY', ']', 'α_1', 'k+Ψβ_i', '0.50', 'marginalization', 'z_1', 'β_i', '[', 'T^⊤1', 'α_j', ')', 'in', 'HMMs', 'Backward', 'right-to-left', '←', '+Ψ_t', '_z_t+1', 'HMM', 'α_t', 'β_t+1', 'PCFG', '_z_1', 'z_2', 'α_t+1', 'return', 'i', '_', '(', '0.45'}\n",
            "['-', 'order', 'for', 'α', '_', '0', '^', '[UNK]', 'pc', '##f', '##gs', ',', 'span', '-', 'size', 'k', '_', 'z', '_', '2', 'z', '_', 't', '+', '1', '##∈', 't', '=', 'j', '##×', '_', 'j', 'j', 't', '+', '1', 'hyper', '##graph', '∈', '_', 'i', 'α', '_', 'i', 'and', 'ck', '##y', ']', 'α', '_', '1', 'k', '+', 'ψ', '##β', '_', 'i', '0', '.', '50', 'marginal', '##ization', 'z', '_', '1', 'β', '_', 'i', '[', 't', '^', '[UNK]', 'α', '_', 'j', ')', 'in', 'hmm', '##s', 'backward', 'right', '-', 'to', '-', 'left', '←', '+', 'ψ', '_', 't', '_', 'z', '_', 't', '+', '1', 'hmm', 'α', '_', 't', 'β', '_', 't', '+', '1', 'pc', '##f', '##g', '_', 'z', '_', '1', 'z', '_', '2', 'α', '_', 't', '+', '1', 'return', 'i', '_', '(', '0', '.', '45']\n"
          ]
        }
      ]
    }
  ]
}